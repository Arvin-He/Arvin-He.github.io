{"meta":{"title":"Simple & Freedom","subtitle":"Learn and live.","description":"Learn and live.","author":"Arvin","url":"http://arvin-he.github.io"},"pages":[{"title":"","date":"2017-09-08T03:51:39.091Z","updated":"2017-09-08T03:51:39.091Z","comments":true,"path":"404.html","permalink":"http://arvin-he.github.io/404.html","excerpt":"","text":"var QZONE = window.QZONE || {}; function imagezoom(imgobj, box_w, box_h) { var src_w = imgobj.width; var src_h = imgobj.height; var r1 = src_w / src_h, r2 = box_w / box_h; var dst_w, dst_h; if (r1 > r2) { dst_w = box_w; dst_h = Math.round(dst_w / src_w * src_h); } else { if (r1 < r2) { dst_h = box_h; dst_w = Math.round(dst_h / src_h * src_w); } else { dst_w = box_w; dst_h = box_h; } } imgobj.style.marginLeft = (box_w - dst_w) / 2 + \"px\"; imgobj.style.marginTop = (box_h - dst_h) / 2 + \"px\"; imgobj.style.width = dst_w + \"px\"; imgobj.style.height = dst_h + \"px\"; imgobj.style.opacity = 1; } (function(_w, _d) { var ha = _d.head || _d.getElementsByTagName(\"head\")[0]; var $scope = {}; var current; var tmnow; var chId; var homePageUrl, homePageName; var scs = document.getElementsByTagName(\"script\"); if (location.href.indexOf(\"fm.qq.com\") > -1 || location.href.indexOf(\"fm.qzone.qq.com\") > -1) { homePageName = \"\\u8fd4\\u56de\\u4f01\\u9e45FM\"; homePageUrl = \"http://fm.qq.com\"; } else { if (location.href.indexOf(\"qzone.qq.com\") > -1) { homePageName = \"\\u8fd4\\u56de\\u6211\\u7684\\u7a7a\\u95f4\"; homePageUrl = \"http://qzone.qq.com\"; } else { homePageName = \"\\u8fd4\\u56de\\u817e\\u8baf\\u7f51\"; homePageUrl = \"http://www.qq.com\"; } } for (var i = 0;i < scs.length;i++) { if (scs[i].src.indexOf(\"404/search_children.js\") > -1) { if (scs[i].getAttribute(\"homePageUrl\")) { homePageUrl = scs[i].getAttribute(\"homePageUrl\"); } if (scs[i].getAttribute(\"homePageName\")) { homePageName = scs[i].getAttribute(\"homePageName\"); } break; } } $scope.rettext = homePageName; $scope.retlink = homePageUrl; function getData(srcUrl, callback) { var sc = _d.createElement(\"script\"); function orc() { if (sc.readyState === \"loaded\") { setTimeout(function() { callback && callback(); }, 0); } } if (sc.addEventListener) { if (callback) { sc.addEventListener(\"load\", callback, false); } } else { sc.attachEvent(\"onreadystatechange\", orc); } ha && ha.appendChild(sc); sc.src = srcUrl; } function resolveData(d) { var tid, len, ddata = [], tdata; if (\"object\" == typeof d && (d.data && (len = d.data.length))) { for (var i = 0;i < len;i++) { var expire = d.data[i].expire; d.data[i]._id = new Date * Math.random() * Math.random() * 1E7; if (expire && tmnow * 1E3 < Date.parse(expire.replace(/\\s[\\s\\S]*$/, \"\").replace(/\\-/g, \"/\"))) { var _c = d.data[i].city, _p = d.data[i].province; if (_c && city) { if ((\"_\" + _c + \"_\").indexOf(\"_\" + city + \"_\") > -1) { ddata.push(d.data[i]); continue; } } if (_p && province) { if ((\"_\" + _p + \"_\").indexOf(\"_\" + province + \"_\") > -1) { ddata.push(d.data[i]); } } } } tid = Math.floor(Math.random() * (ddata.length || len)); tdata = (ddata.length ? ddata : d.data)[chId = tid]; if (_w.foundjsondata) { tdata.ta = tdata.sex.indexOf(\"\\u5973\") > -1 ? \"\\u5979\" : \"\\u4ed6\"; tdata.name = \"\\u201c7\\u00b718\\u7279\\u5927\\u62d0\\u5356\\u5a74\\u513f\\u6848\\u201d\\u544a\\u7834\\uff0c\\u88ab\\u89e3\\u6551\\u768415\\u540d\\u5b69\\u5b50\\u4e2d\\uff0c2\\u4eba\\u7531\\u4eb2\\u751f\\u7236\\u6bcd\\u9886\\u56de\\uff0c\\u4ecd\\u670913\\u540d\\u5b69\\u5b50\\u672a\\u627e\\u5230\\u4eb2\\u751f\\u7236\\u6bcd\\uff0c\\u88ab\\u5b89\\u7f6e\\u5728\\u60e0\\u5dde\\u5e02\\u793e\\u4f1a\\u798f\\u5229\\u9662\\uff0c\" + tdata.ta + \"\\u662f\\u5176\\u4e2d\\u4e4b\\u4e00\\u3002\"; tdata.url = tdata.url.replace(/#p=(\\d{1,2})/, function(a, n) { return \"#p=\" + (+n + 1); }); return format(tmpl2, tdata); } if (!tdata.ext1) { tdata.ext1 = \"\\u4f46\\u6211\\u4eec\\u53ef\\u4ee5\\u4e00\\u8d77\\u5bfb\\u627e\\u5931\\u8e2a\\u5b9d\\u8d1d\"; } return tdata; } } function setTopData(tdata) { current = tdata; $scope.topname = tdata.name; $scope.topgender = tdata.sex; $scope.topbirth = tdata.birth_time; $scope.toplostdate = tdata.lost_time; $scope.toplostplace = tdata.lost_place; $scope.toplostdesc = tdata.child_feature; $scope.toplink = tdata.url; $scope.topimg = tdata.child_pic; $scope.topid = tdata._id; document.body.innerHTML = template(\"body\", $scope); } function init(data) { tmnow = data.tm_now * 1E3; var tdata = resolveData(jsondata); $scope.whichin = 0; jsondata.data.splice(chId, 1); $scope.otherdata = [tdata].concat(jsondata.data.slice(0, 5)); setTopData(tdata); } var timeout; window._Callback = function(d) { clearTimeout(timeout); init(d); }; timeout = setTimeout(function() { _Callback({tm_now:(new Date).getTime() / 1E3}); }, 2E3); _w.share = function(target) { var summary = [\"\\u80cc\\u666f\\uff1a\", current.name, \"\\uff0c\\u6027\\u522b\\uff1a\", current.sex, \"\\uff0c\\u51fa\\u751f\\u65f6\\u95f4\\uff1a\", current.birth_time, \"\\uff0c\\u5931\\u8e2a\\u65f6\\u95f4\\uff1a\", current.lost_time, \"\\uff0c\\u7279\\u5f81\\u63cf\\u8ff0\\uff1a\", current.child_feature].join(\"\"); if (summary) { summary = \"#\\u5bfb\\u627e\\u5931\\u8e2a\\u7684\\u5b9d\\u8d1d#\" + summary; } var stitle = \"\\u5931\\u8e2a\\u7684\\u5b9d\\u8d1d\\u8be6\\u60c5\"; var desc = \"\\u5931\\u8e2a\\u7684\\u5b9d\\u8d1d\\u8981\\u56de\\u5bb6\\uff0c\\u5feb\\u6765\\u53c2\\u4e0e\\u7231\\u5fc3\\u7684\\u4f20\\u9012\\u5427\\uff01\"; var encode = encodeURIComponent; var opts = {\"surl\":\"http://qzone.qq.com/gy/404/\" + current.id + \"/lostchild.html\", \"site\":\"QQ\\u7a7a\\u95f4\", \"summary\":summary || \"#\\u5b9d\\u8d1d\\u56de\\u5bb6#\\u817e\\u8baf\\u5fd7\\u613f\\u8005\\u7528\\u6280\\u672f\\u70b9\\u4eae\\u516c\\u76ca\\uff0c\\u8ba9\\u6211\\u4eec\\u4e00\\u8d77\\u5bfb\\u627e\\u8d70\\u5931\\u7684\\u513f\\u7ae5\\u5427\\uff01\", \"stitle\":stitle, \"pics\":current.child_pic, \"desc\":desc, \"origin_url\":current.url}; var surl = opts.surl || \"http://www.qq.com/404/\", summary = opts.summary || \"\\u8fd9\\u4e2a\\u662f\\u5206\\u4eab\\u7684\\u5185\\u5bb9\", stitle = opts.stitle || \"\\u8fd9\\u4e2a\\u662f\\u5206\\u4eab\\u7684\\u6807\\u9898\", pics = opts.pics || \"http://qzonestyle.gtimg.cn/qzone_v6/act/img/20120422_qzone_7_years/pop_up/icon-pop-seven-years.png\", site = opts.site || \"\\u8fd9\\u4e2a\\u662f\\u5206\\u4eab\\u94fe\\u63a5\\u7684\\u6587\\u5b57\", desc = opts.desc || \"\\u5931\\u8e2a\\u7684\\u5b9d\\u8d1d\\u8981\\u56de\\u5bb6\\uff0c\\u5feb\\u6765\\u53c2\\u4e0e\\u7231\\u5fc3\\u7684\\u4f20\\u9012\\u5427\\uff01\", origin_url = opts.origin_url || \"http://www.qq.com/404/\"; var shareList = {weibo:{method:function(evt) { var w = \"http://v.t.qq.com/share/share.php\", q = [\"?site=\", encode(surl + \"#via=share_t_weib\"), \"&title=\", encode(summary), \"&pic=\", encode(pics), \"&url=\", encode(surl)].join(\"\"), p = [w, q].join(\"\"); openit(p, \"weibo\", \"width=700, height=680, top=0, left=0, toolbar=no, menubar=no, scrollbars=no, location=yes, resizable=no, status=no\"); }}, qzone:{method:function(evt) { var buff = [], ps = {url:surl + \"#via=404-qzoneshare\", desc:desc || \"\\u5931\\u8e2a\\u7684\\u5b9d\\u8d1d\\u8981\\u56de\\u5bb6\\uff0c\\u5feb\\u6765\\u53c2\\u4e0e\\u7231\\u5fc3\\u7684\\u4f20\\u9012\\u5427\\uff01\", summary:summary, title:stitle, pics:pics, site:site}; for (var k in ps) { buff.push(k + \"=\" + encode(ps[k] || \"\")); } var w = \"http://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?\" + buff.join(\"&\"), q = [\"#via=share_t_qzone\", \"&title=\", encode(summary), \"&pic=\", encode(pics), \"&url=\", encode(surl)].join(\"\"), p = [w, q].join(\"\"); openit(p, \"qzone\", \"width=700, height=680, top=0, left=0, toolbar=no, menubar=no, scrollbars=no, location=yes, resizable=no, status=no\"); }}, sina:{method:function() { var w = \"http://v.t.sina.com.cn/share/share.php\", q = [\"?url=\", encode(surl + \"#via=share_x_weib\"), \"&title=\", encode(summary), \"&source=\", \"&sourceUrl=\", surl, \"&content=utf-8\", \"&pic=\", encode(pics)].join(\"\"), p = [w, q].join(\"\"); openit(p, \"sina\", \"toolbar=0,status=0,resizable=1,width=440,height=430\"); }}, kaixin:{method:function() { var n = \"http://www.kaixin001.com/repaste/bshare.php?rurl=\" + encode(surl + \"#via=share_kaixin\") + \"&rcontent=&rtitle=\" + encode(summary); openit(n, \"kaixin\", \"toolbar=0,status=0,resizable=1,width=600,height=360\"); }}, renren:{method:function() { var n = \"http://www.connect.renren.com/share/sharer?title=\" + encode(summary) + \"&url=\" + encode(surl + \"#via=share_renren\"), p = window.open(n, \"rr\", \"toolbar=0,status=0,resizable=1,width=510,height=300\"); if (p) { p.focus(); } }}, weixin:{method:function() { var n = \"http://qzone.qq.com/gy/404/page/qrcode.html?url=\" + encode(origin_url + \"#via=share_weixin\"), p = window.open(n, \"rr\", \"toolbar=0,status=0,resizable=1,width=620,height=430\"); if (p) { p.focus(); } }}}; var openit = function(u, n, p) { function o() { var z; if (!(z = window.open(u, n, p))) { location.href = u; } else { z.focus(); } } o(); }; shareList[target] && shareList[target].method(); }; _w.toThis = function(id) { for (var i = 0;i < $scope.otherdata.length;i++) { if ($scope.otherdata[i]._id == id) { setTopData($scope.otherdata[i]); break; } } return false; }; var meta = document.createElement(\"meta\"); meta.name = \"viewport\"; meta.content = \"width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no\"; ha.appendChild(meta); (function registerStyle() { var link = document.createElement(\"link\"); link.rel = \"stylesheet\"; link.type = \"text/css\"; link.href = \"https://qzone.qq.com/gy/404/style/404style.css\"; ha.appendChild(link); })(); (function initStat() { var qqDomainNameRE = /\\.qq\\.com$/i, qzoneDomainNameRE = /\\bqzone\\.qq\\.com$/i, qzsDomainNameRE = /\\bqzonestyle\\.gtimg\\.cn$/i; function cb() { var url = location.host; var src = \"\"; if (qzoneDomainNameRE.test(url)) { src = \"new404.qzone\"; } else { if (qqDomainNameRE.test(url)) { src = \"new404.qq\"; } else { if (qzsDomainNameRE.test(url)) { src = \"new404.qzonestyle\"; } else { src = url.replace(\".\", \"_\"); } } } _w.TCISD && (_w.TCISD.pv && _w.TCISD.pv(\"hat.qzone.qq.com\", \"/gy/lostchild/\" + src)); } getData(\"https://qzonestyle.gtimg.cn/ac/qzfl/stat.js\", cb); })(); })(window, document); !function() { function a(a, b) { return(/string|function/.test(typeof b) ? h : g)(a, b); } function b(a, c) { return \"string\" != typeof a && (c = typeof a, \"number\" === c ? a += \"\" : a = \"function\" === c ? b(a.call(a)) : \"\"), a; } function c(a) { return l[a]; } function d(a) { return b(a).replace(/&(?![\\w#]+;)|[\"']/g, c); } function e(a, b) { if (m(a)) { for (var c = 0, d = a.length;d > c;c++) { b.call(a, a[c], c, a); } } else { for (c in a) { b.call(a, a[c], c); } } } function f(a, b) { var c = /(\\/)[^/]+\\1\\.\\.\\1/, d = (\"./\" + a).replace(/[^/]+$/, \"\"), e = d + b; for (e = e.replace(/\\/\\.\\//g, \"/\");e.match(c);) { e = e.replace(c, \"/\"); } return e; } function g(b, c) { var d = a.get(b) || i({filename:b, name:\"Render Error\", message:\"Template not found\"}); return c ? d(c) : d; } function h(a, b) { if (\"string\" == typeof b) { var c = b; b = function() { return new k(c); }; } var d = j[a] = function(c) { try { return new b(c, a) + \"\"; } catch (d) { return i(d)(); } }; return d.prototype = b.prototype = n, d.toString = function() { return b + \"\"; }, d; } function i(a) { var b = \"{Template Error}\", c = a.stack || \"\"; if (c) { c = c.split(\"\\n\").slice(0, 2).join(\"\\n\"); } else { for (var d in a) { c += \"\\n\" + a[d] + \"\\n\\n\"; } } return function() { return \"object\" == typeof console && console.error(b + \"\\n\\n\" + c), b; }; } var j = a.cache = {}, k = this.String, l = {\"\":\"&#62;\", '\"':\"&#34;\", \"'\":\"&#39;\", \"&\":\"&#38;\"}, m = Array.isArray || function(a) { return \"[object Array]\" === {}.toString.call(a); }, n = a.utils = {$helpers:{}, $include:function(a, b, c) { return a = f(c, a), g(a, b); }, $string:b, $escape:d, $each:e}, o = a.helpers = n.$helpers; a.get = function(a) { return j[a.replace(/^\\.\\//, \"\")]; }, a.helper = function(a, b) { o[a] = b; }, \"function\" == typeof define ? define(function() { return a; }) : \"undefined\" != typeof exports ? module.exports = a : this.template = a, a(\"body\", function(a) { var b = this, c = (b.$helpers, b.$escape), d = a.retlink, e = a.rettext, f = a.topid, g = a.topimg, h = a.topname, i = a.topgender, j = a.topbirth, l = a.toplostdate, m = a.toplostplace, n = a.toplostdesc, o = a.toplink, p = b.$each, q = a.otherdata, r = (a.otheritem, a.index, \"\"); return r += ' 404\\uff0c\\u60a8\\u8bbf\\u95ee\\u7684\\u9875\\u9762\\u627e\\u4e0d\\u56de\\u6765\\u4e86\\uff0c\\u4f46\\u6211\\u4eec\\u53ef\\u4ee5\\u4e00\\u8d77\\u5e2e\\u4ed6\\u4eec\\u56de\\u5bb6\\uff01 ', r += c(e), r += ' ', r += c(h), r += '(', r += c(i), r += ') \\u51fa\\u751f\\u65e5\\u671f\\uff1a', r += c(j), r += ' \\u5931\\u8e2a\\u65f6\\u95f4\\uff1a', r += c(l), r += ' \\u5931\\u8e2a\\u5730\\u70b9\\uff1a', r += c(m), r += ' \\u5931\\u8e2a\\u4eba\\u7279\\u5f81\\u63cf\\u8ff0\\uff1a', r += c(n), r += ' \\u67e5\\u770b\\u8be6\\u60c5 \\u5206\\u4eab \\u817e\\u8baf\\u5fae\\u535a QQ\\u7a7a\\u95f4 \\u65b0\\u6d6a\\u5fae\\u535a \\u5fae\\u4fe1 ', p(q, function(a) { r += ' '; }), r += \" \", new k(r); }); }();"},{"title":"404 Not Found：该页无法显示","date":"2017-04-02T02:48:36.000Z","updated":"2017-09-08T03:51:39.094Z","comments":true,"path":"404/index.html","permalink":"http://arvin-he.github.io/404/index.html","excerpt":"","text":".article-header { padding: 0; padding-top: 26px; border-left: none; text-align: center; } .article-header:hover { border-left: none; } .article-title { font-size: 2.1em; } strong a { color: #747474; } .article-meta { display: none; } .share { display: none; } .ds-meta { display: none; } .player { margin-left: -10px; } .sign { text-align: right; font-style: italic; } #page-visit { display: none; } .center { text-align: center; height: 2.5em; font-weight: bold; } .article-entry hr { margin: 0; } .pic { text-align: center; margin: 0; } .pic br { display: none; } #container .article-info-post.article-info { display: none; } #container .article .article-title { padding: 0; }"},{"title":"关于Arvin","date":"2017-04-02T02:05:08.000Z","updated":"2017-09-08T03:51:40.207Z","comments":true,"path":"about/index.html","permalink":"http://arvin-he.github.io/about/index.html","excerpt":"","text":"其实关于我没有什么想说的,只是想好好生活,做好自己喜欢的事.喜欢简单舒适的格调.Motto: To be a better man. 喜欢做的事 喜欢读书喜欢健身喜欢写写文章… 博客内容以技术学习与分享为主，主要关注： Python3 Web全栈 Node.js JavaScript Linux BigData AI 联系Arvin 微信: JUNHE_1218E-mail: junhe3209@gmail.comGitHub: https://github.com/Arvin-He"},{"title":"categories","date":"2017-03-31T10:06:44.000Z","updated":"2017-09-08T03:51:40.210Z","comments":true,"path":"categories/index.html","permalink":"http://arvin-he.github.io/categories/index.html","excerpt":"","text":""},{"title":"readnotes","date":"2017-07-10T01:32:12.000Z","updated":"2017-09-08T03:51:40.286Z","comments":true,"path":"readnotes/index.html","permalink":"http://arvin-he.github.io/readnotes/index.html","excerpt":"","text":""},{"title":"essay","date":"2017-07-10T01:32:03.000Z","updated":"2017-09-08T03:51:40.212Z","comments":true,"path":"essay/index.html","permalink":"http://arvin-he.github.io/essay/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-03-31T09:15:53.000Z","updated":"2017-09-08T03:51:40.288Z","comments":true,"path":"tags/index.html","permalink":"http://arvin-he.github.io/tags/index.html","excerpt":"","text":""},{"title":"life","date":"2017-04-17T11:40:34.000Z","updated":"2017-09-08T03:51:40.217Z","comments":true,"path":"life/index.html","permalink":"http://arvin-he.github.io/life/index.html","excerpt":"","text":""}],"posts":[{"title":"scrapy笔记","slug":"py-scrapy2-2018-01-16","date":"2018-01-16T08:01:23.000Z","updated":"2018-01-16T09:51:54.739Z","comments":true,"path":"2018/01/16/py-scrapy2-2018-01-16/","link":"","permalink":"http://arvin-he.github.io/2018/01/16/py-scrapy2-2018-01-16/","excerpt":"","text":"scrapy命令行工具(command line tools)查看scrapy所有可用的命令1scrapy -h 查看某个命令具体用法,以startproject为例子1scrapy startproject -h 创建爬虫项目1scrapy startproject myproject 创建一个新的spider1scrapy genspider mydomain mydomain.com 启动终端12scrapy shell &lt;url&gt;如: scrapy shell https://www.baidu.com 针对通用爬虫设定的一些建议增加并发并发是指同时处理的 request 的数量。其有全局限制和局部(每个网站)的限制。Scrapy 默认的全局并发限制对同时爬取大量网站的情况并不适用，因此需要增加这个值。增加全局并发数CONCURRENT_REQUESTS = 100设置 Log 级别：LOG_LEVEL = ‘INFO’禁止 cookies,禁止 cookies 能减少 CPU 使用率及 Scrapy 爬虫在内存中记录的踪迹，提高性能。COOKIES_ENABLED = False禁止重试,当站点响应很慢(甚至失败)时， 访问这样的站点会造成超时并重试多次。这是不必要的，同时也占用了爬虫爬取其他站点的能力。RETRY_ENABLED = False减小下载超时,减小下载超时能让卡住的连接能被快速的放弃并解放处理其他站点的能力。DOWNLOAD_TIMEOUT = 15禁止重定向,当进行通用爬取时，一般的做法是保存重定向的地址，并在之后的爬取进行解析。否则重定向循环可能会导致爬虫在某个站点耗费过多资源。REDIRECT_ENABLED = False启用 “Ajax Crawlable Pages” 爬取,有些站点声明其为 ajax crawlabl。这意味着该网站提供了原本只有 ajax 获取到的数据的纯 HTML 版本。网站通过两种方法声明：(1)在 url 中使用#! - 这是默认的方式;(2)使用特殊的 meta 标签 - 这在”main”, “index” 页面中使用。Scrapy 自动解决(1)；解决(2)您需要启用 AjaxCrawlMiddleware：AJAXCRAWL_ENABLED = True","categories":[{"name":"python","slug":"python","permalink":"http://arvin-he.github.io/categories/python/"}],"tags":[{"name":"scrapy","slug":"scrapy","permalink":"http://arvin-he.github.io/tags/scrapy/"}]},{"title":"scrapy笔记-安装","slug":"py-scrapy1-2018-01-15","date":"2018-01-15T09:32:19.000Z","updated":"2018-01-16T08:01:57.757Z","comments":true,"path":"2018/01/15/py-scrapy1-2018-01-15/","link":"","permalink":"http://arvin-he.github.io/2018/01/15/py-scrapy1-2018-01-15/","excerpt":"","text":"windows下scrapy安装下载依赖的第三方离线包到 这个地址下载一些在windows平台编译的第三方库. pywin32 twisted注意: 根据python的版本下载对应的离线包. 安装或更新依赖的第三方离线包下载好后就安装 在控制台切换目录到离线包所在的目录 安装离线包12pip install pywin32pip install twisted 如果是更新包则:12pip install pywin32 -Upip install twisted -U 安装或更新scrapy下载安装1pip install scrapy 下载更新1pip install scrapy -U import win32api 出现ImportError: DLL load failed 错误的解决方法windows下使用scrapy,出现出现ImportError: DLL load failed 错误,网上解决方法大多是安装pywin32,可是安装后还是会出错.之后又试了一下网上的方法:将\\Lib\\site-packages\\pywin32_system32*拷贝至C:\\Windows\\System32目录下,仍然出错.最后,找到一个好方法:安装pypiwin321pip install pypiwin32 然后再开始执行scrapy就顺利运行了.","categories":[{"name":"python","slug":"python","permalink":"http://arvin-he.github.io/categories/python/"}],"tags":[{"name":"scrapy","slug":"scrapy","permalink":"http://arvin-he.github.io/tags/scrapy/"}]},{"title":"python之pip常用命令","slug":"py-pipcmds-2018-01-15","date":"2018-01-15T09:08:06.000Z","updated":"2018-01-15T09:15:40.156Z","comments":true,"path":"2018/01/15/py-pipcmds-2018-01-15/","link":"","permalink":"http://arvin-he.github.io/2018/01/15/py-pipcmds-2018-01-15/","excerpt":"","text":"pip常用命令1. 安装第三方库12pip install scrapypython -m pip install scrapy 2. 更新第三方库1pip install scrapy -U 3. 制作本地*.whl安装离线包1pip wheel pycrpyo 4. 导出pip list列表到requirements.txt1pip freeze &gt; requirements.txt","categories":[{"name":"python","slug":"python","permalink":"http://arvin-he.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://arvin-he.github.io/tags/python/"}]},{"title":"css笔记1","slug":"css-note1-2018-01-11","date":"2018-01-11T13:19:50.000Z","updated":"2018-01-15T09:47:58.272Z","comments":true,"path":"2018/01/11/css-note1-2018-01-11/","link":"","permalink":"http://arvin-he.github.io/2018/01/11/css-note1-2018-01-11/","excerpt":"","text":"CSS样式优先级*(通配符) &lt; tag(标签) &lt; class &lt; 行间style与class元素.style.属性 = xxx 是修改行间样式之后再修改className不会有效果 建议:要么统一用style,要么统一用className,混用则容易产生错乱,也很难排查问题. 行为,样式,结构三者分离","categories":[{"name":"web","slug":"web","permalink":"http://arvin-he.github.io/categories/web/"}],"tags":[{"name":"css","slug":"css","permalink":"http://arvin-he.github.io/tags/css/"}]},{"title":"selenium-phatomjs使用","slug":"selenium-phatomjs-2017-12-11","date":"2017-12-11T12:42:16.000Z","updated":"2018-01-15T09:47:58.285Z","comments":true,"path":"2017/12/11/selenium-phatomjs-2017-12-11/","link":"","permalink":"http://arvin-he.github.io/2017/12/11/selenium-phatomjs-2017-12-11/","excerpt":"","text":"使用selenium和phantomjs爬取动态网页1234567from selenium import webdriverurl = \"http://www.dangniao.com/mh/22996/392953.html\"browser = webdriver.PhantomJS(\"/usr/local/mysoft/phantomjs-2.1.1/bin/phantomjs\")browser.get(url)# 模拟用户点击browser.find_element_by_class_name(\"zsxiaye\").click()src = browser.find_element_by_css_selector(\"#wdwailian img\").get_attribute(\"src\") 常用的phantomJS配置选项12345678910111213141516171819from selenium import webdriver# 引入配置对象DesiredCapabilitiesfrom selenium.webdriver.common.desired_capabilities import DesiredCapabilitiesdcap = dict(DesiredCapabilities.PHANTOMJS)#从USER_AGENTS列表中随机选一个浏览器头，伪装浏览器dcap[\"phantomjs.page.settings.userAgent\"] = (random.choice(USER_AGENTS))# 不载入图片，爬页面速度会快很多dcap[\"phantomjs.page.settings.loadImages\"] = False# 设置代理service_args = ['--proxy=127.0.0.1:9999','--proxy-type=socks5']#打开带配置信息的phantomJS浏览器driver = webdriver.PhantomJS(phantomjs_driver_path, desired_capabilities=dcap,service_args=service_args) # 隐式等待5秒，可以自己调节driver.implicitly_wait(5)# 设置10秒页面超时返回，类似于requests.get()的timeout选项，driver.get()没有timeout选项# 以前遇到过driver.get(url)一直不返回，但也不报错的问题，这时程序会卡住，设置超时选项能解决这个问题。driver.set_page_load_timeout(10)# 设置10秒脚本超时时间driver.set_script_timeout(10) phantomJS的并发问题phantomJS本身在多线程方面还有很多bug，建议使用多进程,关于多进程，推荐使用multiprocessing库，简洁、高效.12345from multiprocessing import Poolpool = Pool(8)data_list = pool.map(get, url_list)pool.close()pool.join() phantomJS进程不自动退出问题主程序退出后，selenium不保证phantomJS也成功退出，最好手动关闭phantomJS进程。12345678try: self.driver.get(url) self.wait_() return Trueexcept Exception as e: # 手动关闭phantomjs进程 self.driver.quit() return False","categories":[{"name":"python","slug":"python","permalink":"http://arvin-he.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://arvin-he.github.io/tags/python/"}]},{"title":"jQuery笔记","slug":"jQuery-notes1-2017-12-08","date":"2017-12-08T09:31:58.000Z","updated":"2017-12-08T09:59:27.496Z","comments":true,"path":"2017/12/08/jQuery-notes1-2017-12-08/","link":"","permalink":"http://arvin-he.github.io/2017/12/08/jQuery-notes1-2017-12-08/","excerpt":"","text":"jQuery介绍jQuery是JavaScript世界中使用最广泛的一个库。jQuery能帮我们干这些事情： 消除浏览器差异：你不需要自己写冗长的代码来针对不同的浏览器来绑定事件，编写AJAX等代码； 简洁的操作DOM的方法：写$(‘#test’)肯定比document.getElementById(‘test’)来得简洁； 轻松实现动画、修改CSS等各种操作。jQuery的理念“Write Less, Do More“，让你写更少的代码，完成更多的工作！ 目前jQuery有1.x和2.x两个主要版本，区别在于2.x移除了对古老的IE 6、7、8的支持，因此2.x的代码更精简。选择哪个版本主要取决于你是否想支持IE 6~8。jQuery只是一个jquery-xxx.js文件，但你会看到有compressed（已压缩）和uncompressed（未压缩）两种版本，使用时完全一样，但如果你想深入研究jQuery源码，那就用uncompressed版本。 jQuery使用$是著名的jQuery符号。jQuery把所有功能全部封装在一个全局变量jQuery中，而$也是一个合法的变量名，它是变量jQuery的别名：1234window.jQuery; // jQuery(selector, context)window.$; // jQuery(selector, context)$ === jQuery; // truetypeof($); // 'function' $本质上就是一个函数，但是函数也是对象，于是$除了可以直接调用外，也可以有很多其他属性。 注意: 你看到的$函数名可能不是jQuery(selector, context)，因为很多JavaScript压缩工具可以对函数名和参数改名，压缩过的jQuery源码$函数可能变成a(b, c)。这也被叫做代码混淆,也起到一定的安全作用. 绝大多数时候，直接用$,但是，如果$这个变量被占用了，而且还不能改，那我们就只能让jQuery把$变量交出来，然后就只能使用jQuery这个变量. 选择器选择器是jQuery的核心。一个选择器写出来类似$(‘#dom-id’)。Query的选择器就是帮助我们快速定位到一个或多个DOM节点。123456789101112131415161718192021222324// 按ID查找,注意: #abc以#开头。返回的对象是jQuery对象。// 查找&lt;div id=\"abc\"&gt;:var div = $('#abc');// 按tag查找var ps = $('p'); // 返回所有&lt;p&gt;节点ps.length; // 数一数页面有多少个&lt;p&gt;节点// 按class查找, 按class查找注意在class名称前加一个.var a = $('.red'); // 所有节点包含`class=\"red\"`都将返回// 例如:// &lt;div class=\"red\"&gt;...&lt;/div&gt;// &lt;p class=\"green red\"&gt;...&lt;/p&gt;// 节点有多个class，我们可以查找同时包含red和green的节点：var a = $('.red.green'); // 注意没有空格！// 符合条件的节点：// &lt;div class=\"red green\"&gt;...&lt;/div&gt;// &lt;div class=\"blue green red\"&gt;...&lt;/div&gt;// 按属性查找var email = $('[name=email]'); // 找出&lt;??? name=\"email\"&gt;var icons = $('[name^=icon]'); // 找出所有name属性值以icon开头的DOMvar names = $('[name$=with]'); // 找出所有name属性值以with结尾的DOMvar icons = $('[class^=\"icon-\"]'); // 找出所有class包含至少一个以`icon-`开头的DOM 组合查找var emailInput = $(&#39;input[name=email]&#39;); // 不会找出&lt;div name=&quot;email&quot;&gt;var tr = $(&#39;tr.red&#39;); // 找出&lt;tr class=&quot;red ...&quot;&gt;...&lt;/tr&gt; 多项选择器多项选择器就是把多个选择器用,组合起来一块选：12$('p,div'); // 把&lt;p&gt;和&lt;div&gt;都选出来$('p.red,p.green'); // 把&lt;p class=\"red\"&gt;和&lt;p class=\"green\"&gt;都选出来 总之jQuery的选择器不会返回undefined或者null，这样的好处是你不必在下一行判断if (div === undefined)。jQuery对象和DOM对象之间可以互相转化：123var div = $('#abc'); // jQuery对象var divDom = div.get(0); // 假设存在div，获取第1个DOM元素var another = $(divDom); // 重新把DOM包装为jQuery对象 通常情况下你不需要获取DOM对象，直接使用jQuery对象更加方便。如果你拿到了一个DOM对象，那可以简单地调用$(aDomObject)把它变成jQuery对象，这样就可以方便地使用jQuery的API了。","categories":[{"name":"js","slug":"js","permalink":"http://arvin-he.github.io/categories/js/"}],"tags":[{"name":"js","slug":"js","permalink":"http://arvin-he.github.io/tags/js/"}]},{"title":"javascript之DOM操作","slug":"js-dom-2017-12-08","date":"2017-12-08T08:00:15.000Z","updated":"2017-12-08T09:30:35.699Z","comments":true,"path":"2017/12/08/js-dom-2017-12-08/","link":"","permalink":"http://arvin-he.github.io/2017/12/08/js-dom-2017-12-08/","excerpt":"","text":"DOM操作DOM是一个树形结构, 常用操作有:更新, 遍历, 添加, 删除 获取dom节点的方法:document.getElementById()document.getElementsByTagName()document.getElementsByClassName() //CSS选择器可以连续调用: var trs = document.getElementById(&#39;test-table&#39;).getElementsByTagName(&#39;tr&#39;); 使用selector语法:querySelector()querySelectorAll()注意: 低版本的IE&lt;8不支持querySelector和querySelectorAll。IE8仅有限支持。 根节点Document已经自动绑定为全局变量document。严格地讲，我们这里的DOM节点是指Element，但是DOM节点实际上是Node，在HTML中，Node包括Element、Comment、CDATA_SECTION等很多种，以及根节点Document类型，但是，绝大多数时候我们只关心Element. 更新DOM直接修改节点的文本，方法有两种: 修改innerHTML属性，这个方式非常强大，不但可以修改一个DOM节点的文本内容，还可以直接通过HTML片段修改DOM节点内部的子树.注意: 在写入HTML。如果写入的字符串是通过网络拿到了，要注意对字符编码来避免XSS攻击。 修改innerText或textContent属性，这样可以自动对字符串进行HTML编码，保证无法设置任何HTML标签.innerText不返回隐藏元素的文本，而textContent返回所有文本。另外注意IE&lt;9不支持textContent。 DOM节点的style属性对应所有的CSS，可以直接获取或设置。注意:CSS允许font-size这样的名称，但它并非JavaScript有效的属性名，需要在JavaScript中改写为驼峰式命名fontSize. 插入DOM两个办法可以插入新的节点 使用appendChild，把一个子节点添加到父节点的最后一个子节点 使用insertBefore, 使用parentElement.insertBefore(newElement, referenceElement);，子节点会插入到referenceElement之前。 删除DOM 调用父节点的removeChild把当前节点删掉注意:删除后的节点虽然不在文档树中了，但其实它还在内存中，可以随时再次被添加到别的位置 当遍历一个父节点的子节点并进行删除操作时，要注意，children属性是一个只读属性，并且它在子节点变化时会实时更新删除多个节点时，要注意children属性时刻都在变化, 容易造成index溢出. 表单操作HTML表单的输入控件主要有以下几种： 文本框，对应的，用于输入文本； 口令框，对应的，用于输入口令； 单选框，对应的，用于选择一项； 复选框，对应的，用于选择多项； 下拉框，对应的，用于选择一项； 隐藏文本，对应的，用户不可见，但表单提交时会把隐藏文本发送到服务器。 直接调用value获得对应的用户输入值, input.value; // &#39;用户输入的值&#39;对于单选框和复选框，value属性返回的永远是HTML预设的值，要获得的实际是用户是否“勾上了”选项，应该用checked判断. HTML5控件HTML5新增了大量标准控件，常用的包括date、datetime、datetime-local、color等，它们都使用&lt;input&gt;标签.不支持HTML5的浏览器无法识别新的控件，会把它们当做type=”text”来显示。支持HTML5的浏览器将获得格式化的字符串 提交表单第一种方式:通过&lt;form&gt;元素的submit()方法提交一个表单, 这种方式的缺点是扰乱了浏览器对form的正常提交。浏览器默认点击&lt;button type=&quot;submit&quot;&gt;或用户在最后一个输入框按回车键时提交表单。 第二种方式:响应&lt;form&gt;本身的onsubmit事件，在提交form时作修改.出于安全考虑，提交表单时不传输明文口令，而是口令的MD5, 口令框的显示会突然从几个*变成32个*,(MD5有32个字符)要想不改变用户的输入，可以利用&lt;input type=&quot;hidden&quot;&gt;实现. 注意到id为md5-password的&lt;input&gt;标记了name=”password”，而用户输入的id为input-password的&lt;input&gt;没有name属性。没有name属性的&lt;input&gt;的数据不会被提交。 文件操作在HTML表单中，可以上传文件的唯一控件就是&lt;input type=&quot;file&quot;&gt;注意： 当一个表单包含&lt;input type=&quot;file&quot;&gt;时，表单的enctype必须指定为multipart/form-data，method必须指定为post，这样浏览器才能正确编码并以multipart/form-data格式发送表单的数据。出于安全考虑，浏览器只允许用户点击&lt;input type=&quot;file&quot;&gt;来选择本地文件，用JavaScript对&lt;input type=&quot;file&quot;&gt;的value赋值是没有任何效果的。当用户选择了上传某个文件后，JavaScript也无法获得该文件的真实路径 File API随着HTML5的普及，新增的File API允许JavaScript读取文件内容，获得更多的文件信息。HTML5的File API提供了File和FileReader两个主要对象，可以获得文件信息并读取文件。 回调浏览器的JavaScript执行引擎在执行JavaScript代码时，总是以单线程模式执行，也就是说，任何时候，JavaScript代码都不可能同时有多于1个线程在执行.在JavaScript中，执行多任务实际上都是异步调用. AJAXAsynchronous JavaScript and XML，意思就是用JavaScript执行异步网络请求。通过检测window对象是否有XMLHttpRequest属性来确定浏览器是否支持标准的XMLHttpRequest,不要根据浏览器的navigator.userAgent来检测浏览器是否支持某个JavaScript特性. 安全限制由于浏览器的同源策略,默认情况下，JavaScript在发送AJAX请求时，URL的域名必须和当前页面完全一致,即域名,协议和端口号要一致.有的浏览器可能允许端口不同.那是不是用JavaScript无法请求外域（就是其他网站）的URL了呢？方法还是有的，大概有这么几种：一是: 通过Flash插件发送HTTP请求，这种方式可以绕过浏览器的安全限制，但必须安装Flash，并且跟Flash交互。不过Flash用起来麻烦，而且现在用得也越来越少了。二是:通过在同源域名下架设一个代理服务器来转发，JavaScript负责把请求发送到代理服务器,代理服务器再把结果返回，这样就遵守了浏览器的同源策略。这种方式麻烦之处在于需要服务器端额外做开发。第三种方式称为JSONP，它有个限制，只能用GET请求，并且要求返回JavaScript。这种方式跨域实际上是利用了浏览器允许跨域引用JavaScript资源.JSONP通常以函数调用的形式返回 CORS(Cross-Origin Resource Sharing): 是HTML5规范定义的如何跨域访问资源Origin表示本域，也就是浏览器当前页面的域。当JavaScript向外域（如sina.com）发起请求后，浏览器收到响应后，首先检查Access-Control-Allow-Origin是否包含本域，如果是，则此次跨域请求成功，如果不是，则请求失败，JavaScript将无法获取到响应的任何数据。假设本域是my.com，外域是sina.com，只要响应头Access-Control-Allow-Origin为http://my.com，或者是*，本次请求就可以成功。可见，跨域能否成功，取决于对方服务器是否愿意给你设置一个正确的Access-Control-Allow-Origin，决定权始终在对方手中。 promisePromise最大的好处是在异步执行的流程中，把执行代码和处理结果的代码清晰地分离了.Promise还可以做更多的事情，比如，有若干个异步任务，需要先做任务1，如果成功后再做任务2，任何任务失败则不再继续并执行错误处理函数。job1.then(job2).then(job3).catch(handleError); ,其中，job1、job2和job3都是Promise对象。 canvasCanvas是HTML5新增的组件，它就像一块幕布，可以用JavaScript在上面绘制各种图表、动画等。没有Canvas的年代，绘图只能借助Flash插件实现，页面不得不用JavaScript和Flash进行交互。有了Canvas，我们就再也不需要Flash了，直接使用JavaScript完成绘制。","categories":[{"name":"js","slug":"js","permalink":"http://arvin-he.github.io/categories/js/"}],"tags":[{"name":"js","slug":"js","permalink":"http://arvin-he.github.io/tags/js/"}]},{"title":"Appium笔记","slug":"appium-notes1-2017-12-08","date":"2017-12-08T06:22:04.000Z","updated":"2017-12-08T06:33:48.014Z","comments":true,"path":"2017/12/08/appium-notes1-2017-12-08/","link":"","permalink":"http://arvin-he.github.io/2017/12/08/appium-notes1-2017-12-08/","excerpt":"","text":"关于appium手机app自动化测试，现有支持的app的手机平台（Andriod和IOS）, 选择Appium工具。因为Andriod和IOS，Appium都支持。 web自动化测试的路线是这样的：编程语言基础—&gt;测试框架—&gt;webdriver API（selenium2）—&gt;开发自动化测试项目。 移动自动化的测试的路线则是这样的：编程语言基础—&gt;测试框架—&gt;android/IOS开发测试基础—&gt;appium API —&gt;开发移动自动化项目。 appium就是node的其中一个开源项目，appiun server端是用node实现，遵循了REST架构，所以appium可以用node的包管理工具npm来进行安装。 安装appium 使用淘宝镜像安装, 输入”cnpm install -g appium” 即可在线安装. 安装appium的客户端，基于python的开发环境，可以用pip安装appium客户端, 输入”pip install Appium-Python-Client”，","categories":[{"name":"node.js","slug":"node-js","permalink":"http://arvin-he.github.io/categories/node-js/"}],"tags":[{"name":"node.js","slug":"node-js","permalink":"http://arvin-he.github.io/tags/node-js/"}]},{"title":"javascript 标准对象","slug":"js-object-2017-12-08","date":"2017-12-08T01:04:29.000Z","updated":"2017-12-08T01:08:46.319Z","comments":true,"path":"2017/12/08/js-object-2017-12-08/","link":"","permalink":"http://arvin-he.github.io/2017/12/08/js-object-2017-12-08/","excerpt":"","text":"javascript标准对象 不要使用new Number()、new Boolean()、new String()创建包装对象； 用parseInt()或parseFloat()来转换任意类型到number； 用String()来转换任意类型到string，或者直接调用某个对象的toString()方法； 通常不必把任意类型转换为boolean再判断，因为可以直接写if (myVar) {…}； typeof操作符可以判断出number、boolean、string、function和undefined； 判断Array要使用Array.isArray(arr)； 判断null请使用myVar === null； 判断某个全局变量是否存在用typeof window.myVar === ‘undefined’； 函数内部判断某个变量是否存在用typeof myVar === ‘undefined’。 不是任何对象都有toString()方法, null和undefined就没有！这两个特殊值要除外，虽然null还伪装成了object类型。 number对象调用toString()需要特殊处理,123..toString(); // &#39;123&#39;, 注意是两个点！ 或 (123).toString(); // &#39;123&#39;","categories":[{"name":"js","slug":"js","permalink":"http://arvin-he.github.io/categories/js/"}],"tags":[{"name":"js","slug":"js","permalink":"http://arvin-he.github.io/tags/js/"}]},{"title":"selenium笔记","slug":"selenium-notes1-2017-12-07","date":"2017-12-07T13:39:06.000Z","updated":"2017-12-08T06:01:11.247Z","comments":true,"path":"2017/12/07/selenium-notes1-2017-12-07/","link":"","permalink":"http://arvin-he.github.io/2017/12/07/selenium-notes1-2017-12-07/","excerpt":"","text":"selenium使用123456789from selenium import webdriverdriver = webdriver.Firefox()driver.get(\"http://www.python.org\")assert \"Python\" in driver.titleelem = driver.find_element_by_name(\"q\")elem.send_keys(\"pycon\")elem.send_keys(Keys.RETURN)assert \"No results found.\" not in driver.page_sourcedriver.close() 使用selenium登陆淘宝1234567891011121314151617181920212223242526# -*- coding:utf-8 -*-from selenium import webdriverfrom pprint import pprintdriver = webdriver.Firefox()driver.get('https://www.taobao.com/')assert \"淘宝\" in driver.titleelem = driver.find_element_by_class_name('member-ft')tags = elem.find_elements_by_tag_name('a')login_url = ''for tag in tags: if 'login' in tag.get_attribute('href'): login_url = tag.get_attribute('href')if login_url: driver.get(login_url) driver.find_element_by_id('J_Quick2Static').click() elem = driver.find_element_by_id('TPL_username_1') elem.send_keys('淘宝账号') elem2 = driver.find_element_by_id('TPL_password_1') elem2.send_keys('淘宝账号密码') driver.find_element_by_id('J_SubmitStatic').click() assert \"No results found.\" not in driver.page_source cookies = driver.get_cookies() pprint(cookies)# driver.close()","categories":[{"name":"python","slug":"python","permalink":"http://arvin-he.github.io/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://arvin-he.github.io/tags/python/"}]},{"title":"javascript笔记(二)","slug":"js-notes2-2017-12-04","date":"2017-12-04T01:34:52.000Z","updated":"2017-12-08T07:56:05.733Z","comments":true,"path":"2017/12/04/js-notes2-2017-12-04/","link":"","permalink":"http://arvin-he.github.io/2017/12/04/js-notes2-2017-12-04/","excerpt":"","text":"变量作用域 局部作用域var 声明局部变量,生命周期在函数内部. 而JavaScript的变量作用域实际上是函数内部，以及变量提升的作用,我们在for循环等语句块中是无法定义具有局部作用域的变量的：为了解决块级作用域，(如for循环), ES6引入了新的关键字let，用let替代var可以申明一个块级作用域的变量： 全局作用域不在任何函数内定义的变量就具有全局作用域。JavaScript默认有一个全局对象window，全局作用域的变量实际上被绑定到window的course属性.以变量方式var foo = function () {}定义的函数实际上也是一个全局变量，因此，顶层函数的定义也被视为一个全局变量，并绑定到window对象.JavaScript实际上只有一个全局作用域。任何变量（函数也视为变量），如果没有在当前函数作用域中找到，就会继续往上查找，最后如果在全局作用域中也没有找到，则报ReferenceError错误。 命名空间局变量会绑定到window上，不同的JavaScript文件如果使用了相同的全局变量，或者定义了相同名字的顶层函数，都会造成命名冲突，并且很难被发现。减少冲突的一个方法是把自己的所有变量和函数全部绑定到一个自定义的全局变量中.123456789// 唯一的全局变量MYAPP:var MYAPP = &#123;&#125;;// 其他变量:MYAPP.name = 'myapp';MYAPP.version = 1.0;// 其他函数:MYAPP.foo = function () &#123; return 'foo';&#125;; 把自己的代码全部放入唯一的名字空间MYAPP中，会大大减少全局变量冲突的可能。许多著名的JavaScript库都是这么干的：jQuery，YUI，underscore等等。 常量要申明一个常量，在ES6之前是不行的，我们通常用全部大写的变量来表示这是一个常量，不要修改它的值：ES6标准引入了新的关键字const来定义常量，const与let都具有块级作用域 解构赋值ES6开始，JavaScript引入了解构赋值，可以同时对一组变量进行赋值。解构赋值在很多时候可以大大简化代码. 但是，需要在支持ES6解构赋值特性的现代浏览器中才能正常运行注意: 对数组元素进行解构赋值时，多个变量要用[]括起来。 如果数组本身还有嵌套，也可以通过下面的形式进行解构赋值，注意嵌套层次和位置要保持一致 如果需要从一个对象中取出若干属性，也可以使用解构赋值，便于快速获取对象的指定属性 对一个对象进行解构赋值时，同样可以直接对嵌套的对象属性进行赋值，只要保证对应的层次是一致的 使用解构赋值对对象属性进行赋值时，如果要使用的变量名和属性名不一致，可以用下面的语法获取 解构赋值还可以使用默认值，这样就避免了不存在的属性返回undefined的问题 如果变量已经被声明了，再次赋值的时候，正确的写法也会报语法错误, 这是因为JavaScript引擎把{开头的语句当作了块处理，于是=不再合法。解决方法是用小括号括起来：123456789101112var [x, y, z] = ['hello', 'JavaScript', 'ES6'];let [x, [y, z]] = ['hello', ['JavaScript', 'ES6']];var &#123;name, age, passport&#125; = person;var &#123;name, address: &#123;city, zip&#125;&#125; = person;// 把passport属性赋值给变量id:let &#123;name, passport:id&#125; = person;// 如果person对象没有single属性，默认赋值为true:var &#123;name, single=true&#125; = person;var x, y;// 解构赋值:&#123;x, y&#125; = &#123; name: '小明', x: 100, y: 200&#125;; // 语法错误: Uncaught SyntaxError: Unexpected token =(&#123;x, y&#125; = &#123; name: '小明', x: 100, y: 200&#125;); //正确 方法绑定到对象上的函数称为方法，和普通函数也没啥区别，但是它在内部使用了一个this关键字，这个this怎么理解？在一个方法内部，this是一个特殊变量，它始终指向当前的调用对象.JavaScript的函数内部如果调用了this，那么这个this到底指向谁？答案是，视情况而定,根据当前调用者来确定. 且必须保证this指向正确，必须用obj.xxx()的形式调用！123456var fn = xiaoming.age; // 先拿到xiaoming的age函数fn(); // NaN'use strict';var fn = xiaoming.age;fn(); // Uncaught TypeError: Cannot read property 'birth' of undefined 这是一个设计错误，ECMA决定，在strict模式下让函数的this指向undefined，因此，在strict模式下，你会得到一个错误.这个决定只是让错误及时暴露出来，并没有解决this应该指向的正确位置。修复的办法:用一个that变量首先捕获this,用var that = this;，你就可以放心地在方法内部定义其他函数，而不是把所有语句都堆到一个方法中。 另一个解决办法:apply指定函数的this指向哪个对象，可以用函数本身的apply方法，它接收两个参数:第一个参数就是需要绑定的this变量，第二个参数是Array，表示函数本身的参数。12345678910111213function getAge() &#123; var y = new Date().getFullYear(); return y - this.birth;&#125;var xiaoming = &#123; name: '小明', birth: 1990, age: getAge&#125;;xiaoming.age(); // 25getAge.apply(xiaoming, []); // 25, this指向xiaoming, 参数为空 另一个与apply()类似的方法是call()，唯一区别是：apply()把参数打包成Array再传入；call()把参数按顺序传入。12Math.max.apply(null, [3, 5, 4]); // 5Math.max.call(null, 3, 5, 4); // 5 对普通函数调用，我们通常把this绑定为null。 原型链继承方式JavaScript的原型继承实现方式就是： 定义新的构造函数，并在内部用call()调用希望“继承”的构造函数，并绑定this； 借助中间函数F实现原型链继承，最好通过封装的inherits函数完成； 继续在新的构造函数的原型上定义新方法。 类class从ES6开始新的关键字class正式被引入到JavaScript中,class的目的就是让定义类更简单。类的继承使用通过extends来实现. 浏览器对象JavaScript可以获取浏览器提供的很多对象，并进行操作。常用的浏览器对象有: window, navigator, screen, location, document, history window对象充当全局作用域，且表示浏览器窗口. 兼容性：IE&lt;=8不支持。有innerWidth和innerHeight属性，可以获取浏览器窗口的内部宽度和高度。内部宽高是指除去菜单栏、工具栏、边框等占位元素后，用于显示网页的净宽高。outerWidth和outerHeight属性，可以获取浏览器窗口的整个宽高。 navigator对象表示浏览器的信息，最常用的属性包括：navigator.appName：浏览器名称；navigator.appVersion：浏览器版本；navigator.language：浏览器设置的语言；navigator.platform：操作系统类型；navigator.userAgent：浏览器设定的User-Agent字符串。注意: navigator的信息可以很容易地被用户修改，所以JavaScript读取的值不一定是正确的. screen对象表示屏幕的信息，常用的属性有：screen.width：屏幕宽度，以像素为单位；screen.height：屏幕高度，以像素为单位；screen.colorDepth：返回颜色位数，如8、16、24。 location对象表示当前页面的URL信息location.protocol; // ‘http’location.host; // ‘www.example.com’location.port; // ‘8080’location.pathname; // ‘/path/index.html’location.search; // ‘?a=1&amp;b=2’location.hash; // ‘TOP’要加载一个新页面，可以调用location.assign()。如果要重新加载当前页面，则调用location.reload()方法. document对象表示当前页面。由于HTML在浏览器中以DOM形式表示为树形结构，document对象就是整个DOM树的根节点。document的title属性是从HTML文档中的&lt;title&gt;xxx&lt;/title&gt;读取的，但是可以动态改变.document对象提供的getElementById()和getElementsByTagName()可以按ID获得一个DOM节点和按Tag名称获得一组DOM节点.document对象还有一个cookie属性，通过document.cookie读取到当前页面的Cookie.由于JavaScript能读取到页面的Cookie，而用户的登录信息通常也存在Cookie中，这就造成了巨大的安全隐患，因为在HTML页面中引入第三方的JavaScript代码是允许的,为了解决这个问题，服务器在设置Cookie时可以使用httpOnly，设定了httpOnly的Cookie将不能被JavaScript读取。这个行为由浏览器实现，主流浏览器均支持httpOnly选项，IE从IE6 SP1开始支持。为确保安全，服务器端在设置Cookie时，应该始终坚持使用httpOnly。 history对象保存了浏览器的历史记录，JavaScript可以调用history对象的back()或forward ()，相当于用户点击了浏览器的“后退”或“前进”按钮。新手开始设计Web页面时喜欢在登录页登录成功时调用history.back()，试图回到登录前的页面。这是一种错误的方法。任何情况，你都不应该使用history这个对象了。 参考","categories":[{"name":"js","slug":"js","permalink":"http://arvin-he.github.io/categories/js/"}],"tags":[{"name":"js","slug":"js","permalink":"http://arvin-he.github.io/tags/js/"}]},{"title":"proxy一些知识","slug":"proxy-2017-11-28","date":"2017-11-28T14:04:44.000Z","updated":"2017-11-29T01:09:30.919Z","comments":true,"path":"2017/11/28/proxy-2017-11-28/","link":"","permalink":"http://arvin-he.github.io/2017/11/28/proxy-2017-11-28/","excerpt":"","text":"代理有什么用处 对游戏，通过第三方代理，可以提高游戏流畅速度 对师生，通过代理访问国外论文，获取最新研究成果 对开发者，通过代理爬取采集大数据，防止被屏蔽 对极客，通过代理(高匿)隐藏访问痕迹，防止被跟踪 对个人，通过代理自由上网保护隐私，了解外面的世界 代理应具有哪些信息 IP：Port（IP和端口号，默认必选） 类型（协议类型，HTTP/HTTPS/Socks4/Socks5，默认必选） 国家（例如：中国/美国/日本等） 响应时间（ping代理服务器的时间，单位秒） 传输速度（数据请求和返回的时间，单位秒） 验证日期（验证代理可用的时间） 检测成功率（成功率 = 代理检测的可用次数 / 检测总数，衡量代理的可靠性） 什么是代理的类型代理的类型，具体是指代理协议类型，常见的有HTTP、HTTPS、Socks4、Socks5等四种协议类型 HTTP，全称超文本传输协议（HyperText Transfer Protocol)，是互联网数据传输的一种协议； HTTPS，是在HTTP协议基础上加入了SSL加密协议，以https开头，确保传输过程的数据安全； Socks4，是全能代理，支持HTTP，FTP等多种协议请求，传输层只支持UDP协议，数据可能会丢失； Socks5，类似于Socks4，差别是传输层同时支持UDP和TCP协议，支持可靠的身份验证等机制。Socks4和Socks5，都是通过代理IP:Port利用底层传输协议进行网络通信，因此都可视为匿名代理。 适用场景 HTTP：适合一般的网页浏览，例如：浏览新闻，观看视频等； HTTPS：适合一些需要安全验证的场合，例如：网银登录，购物付款等； Socks4：适合一些对数据完整性不高的场合，例如：网络电话，视频聊天等； Socks5：适合对数据完整性较高的场合，例如：网络游戏，微信接入，移动支付等。 HTTP和Socks代理有何区别？HTTP和HTTPS，都是基于可靠的TCP/IP协议，对传输数据都有校验，保障数据不丢失。Socks4和Socks5，分别是基于UDP，UDP和TCP传输协议，通过代理IP:Port请求转发数据。HTTP和HTTPS是在Socks基础上，进行了数据封装，只专注业务，不必考虑底层的数据传输。Socks是基于IP:Port套接字进行底层的数据传输，支持多种HTTP、FTP、ICMP等上层协议。适用场景：对于普通用户，一般使用HTTP/HTTPS即可；对于开发者用户，推荐Socks，如微信开发。 什么是代理的匿名度代理的匿名度，一般分为透明，匿名，高匿，其中匿名又分为普通匿名和欺骗匿名。 透明，代理服务器只是转发请求，并把你的真实IP地址传给服务器，不会隐藏或改变你的IP； 普通匿名，代理服务器转发请求，并把代理服务器的IP地址传给服务器，隐藏了你的真实IP； 欺骗匿名，代理服务器转发请求，并编造了一个假的IP地址传给服务器，隐藏了你的真实IP； 高匿，代理服务器转发请求，并完全隐藏了你的真实IP和其它信息，就像另外一个人在访问。 代理匿名度优先级： 高匿 &gt; 欺骗代理 &gt; 普通匿名 &gt; 透明 &gt; 不使用代理 如果不使用代理，你的请求数据，真实IP地址，以及其它信息（如浏览器参数，cookie等），都会毫无保留的暴露给了远程服务器，他人可以利用这些访问痕迹，跟踪你的位置（如城市/地区/街道），以及盗取你请求数据中的敏感信息（如银行卡帐号和密码，QQ号和密码等），以及你的访问喜好和习惯等个人隐私。 使用代理(高匿)和加密协议(HTTPS)，可以大大提高您访问网络的安全性，有效保护您的个人隐私等敏感信息 高匿、匿名和透明有何区别？高匿，匿名和透明，是针对隐藏用户请求数据而言，例如：隐藏IP地址，隐藏浏览器参数，Cookie等对于一般的访问网络，一共有五种方式：无代理、透明、普通匿名、欺骗匿名、高匿（Elite）五种方式及判断原理如下： 无代理 123REMOTE_ADDR = 您的真实IP HTTP_VIA = 没数值或不显示 HTTP_X_FORWARDED_FOR = 没数值或不显示 透明 123REMOTE_ADDR = 最后一个代理服务器IP HTTP_VIA = 代理服务器IP HTTP_X_FORWARDED_FOR = 您的真实IP，经过多个代理服务器时，这个值类似：123.57.78.101, 120.24.177.48, 47.88.76.11 普通匿名 123REMOTE_ADDR = 最后一个代理服务器IP HTTP_VIA = 代理服务器IP HTTP_X_FORWARDED_FOR = 代理服务器IP，经过多个代理服务器时，这个值类似：123.57.78.101, 120.24.177.48, 47.88.76.11 欺骗匿名 123REMOTE_ADDR = 最后一个代理服务器IP HTTP_VIA = 代理服务器IP HTTP_X_FORWARDED_FOR = 随机的IP，经过多个代理服务器时，这个值类似：123.57.78.101, 120.24.177.48, 47.88.76.11 高匿(Elite) 123REMOTE_ADDR = 代理服务器IP HTTP_VIA = 没数值或不显示 HTTP_X_FORWARDED_FOR = 没数值或不显示 代理的国家/地区代理的国家，具体是指代理IP所属的国家，例如：中国，美国，英国，日本，韩国，俄罗斯等代理的地区，具体是指代理IP所属国家的地区，只支持中国34个省市(含港澳台)，例如：中国北京，中国香港 代理的运营商代理的运营商，具体是指提供代理服务器的运营商，因为大部分的的代理IP，是由电信运营商搭建提供。代理的运营商，主要有移动、铁通、联通、网通、电信，以及其它（主要是一些大公司和港澳台电信运营商，例如：阿里巴巴、中华电信、腾讯集团、鹏博士、教育网等） 代理的响应时间代理的响应时间，具体是指代理检测服务器Ping通代理服务器的时间。Ping命令的原理，是发送一个ICMP(因特网控制报文协议)给远程服务器，并回声收到目标ICMP的应答时间。如: 米扑代理的响应时间，分为五个等级，从低到高依次为： 0 ~ 0.1 ~ 0.3 ~ 1 ~ 5 ~ 9，单位秒 代理的传输速度代理的传输速度，具体是指代理检测服务器发送请求到目标服务器并返回数据到本地的总时间。总时间，包括本地发送请求 -&gt; 代理服务器 -&gt; 目标服务器 -&gt; 返回数据到代理服务器 -&gt; 本地的全部时间。如: 米扑代理的传输速度，分为五个等级，从低到高依次为： 0 ~ 0.3 ~ 1 ~ 5 ~ 10 ~ 30，单位秒。 代理的验证日期代理的验证日期，具体是指检测代理可用的最后时间，必须满足:1）代理可用；2）检测为可用的最后时间。例如：代理 100.12.25.10:8080 可用，最后一次检测日期为 2015-05-20 10:12:56，即为验证日期。 提取的代理都可以用吗？代理的实效性很强，当时提取的可用代理可能一会儿就失效了，因此检测代理的最后验证日期，非常重要！ 如何获取高可靠的代理？高可靠代理，计算公式：代理的检测可用次数 / 总检测次数 = 可靠率，如:米扑代理独创的检测技术。","categories":[{"name":"web","slug":"web","permalink":"http://arvin-he.github.io/categories/web/"}],"tags":[{"name":"web","slug":"web","permalink":"http://arvin-he.github.io/tags/web/"}]},{"title":"redis笔记","slug":"redis-note1-2017-11-25","date":"2017-11-25T13:45:48.000Z","updated":"2017-11-27T01:06:11.174Z","comments":true,"path":"2017/11/25/redis-note1-2017-11-25/","link":"","permalink":"http://arvin-he.github.io/2017/11/25/redis-note1-2017-11-25/","excerpt":"","text":"redis下载与安装 windows下redis下载地址: 下载zip版本,在C盘根目录下(或者你想安装的目录下)解压 添加redis环境变量 注册redis服务redis-server.exe --service-install redis.windows.conf --loglevel verbose 启动redis服务redis-server.exe --service-start 下载redis可视化客户端软件RedisDesktopManager 下载地址: python下安装redis绑定包pip install redis redis, mongodb与memcache对比mongodb 直接持久化redis 半持久化memcache 只能在内存，轻量级缓存 redis简介redis是一个key-value存储系统。和Memcached类似,支持的类型操作有: String操作, Hash操作, List操作, Set操作, Sort Set操作(zset)这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的.redis支持各种不同方式的排序。与memcached一样，为了保证效率，数据都是缓存在内存中。区别的是redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步。 python操作redisedis-py提供两个类Redis和StrictRedis用于实现Redis的命令，StrictRedis用于实现大部分官方的命令，并使用官方的语法和命令，Redis是StrictRedis的子类，用于向后兼容旧版本的redis-py。 redis-py使用connection pool来管理对一个redis server的所有连接，避免每次建立、释放连接的开销。默认，每个Redis实例都会维护一个自己的连接池。可以直接建立一个连接池，然后作为参数Redis，这样就可以实现多个Redis实例共享一个连接池。12345678910import redisr = redis.Redis(host='127.0.0.1', port=6379)r.set('foo', 'Bar')print (r.get('foo'))# 使用连接池pool = redis.ConnectionPool(host='127.0.0.1', port=6379)r = redis.Redis(connection_pool=pool)r.set('foo', 'Bar')print r.get('foo') string操作set(name, value, ex=None, px=None, nx=False, xx=False)setnx 、 setex 、 psetex在Redis中设置值，默认，不存在则创建，存在则修改参数： ex，过期时间（秒） px，过期时间（毫秒） nx，如果设置为True，则只有name不存在时，当前set操作才执行 xx，如果设置为True，则只有name存在时，当前set操作才执行 批量设置mset(args, **kwargs)批量获取mget(keys, args)设置新值并获取原来的值getset(name, value)获取子序列（根据字节获取，非字符）getrange(key, start, end)修改字符串内容，从指定字符串索引开始向后替换（新值太长时，则向后添加）setrange(name, offset, value)对name对应值的二进制进行位操作。setbit(name, offset, value)获取name对应的值的二进制表示中 1 的个数,应用场景:统计在线用户数有多少bitcount(key, start=None, end=None)自增 name对应的值，当name不存在时，则创建name＝amount，否则，则自增。incr(self, name, amount=1)incrbyfloat(self, name, amount=1.0)自减 name对应的值，当name不存在时，则创建name＝amount，否则，则自减。decr(self, name, amount=1)在redis name对应的值后面追加内容append(key, value) Hash操作Hash操作，redis中Hash在内存中的存储格式如下图：12345678name hash |````````````|n1 --------&gt; | k1 --&gt; v1 | | k2 --&gt; v2 | |____________| |````````````|n2 --------&gt; | k7 --&gt; v7 | |____________| name对应的hash中设置一个键值对（不存在，则创建；否则，修改）hset(name, key, value)在name对应的hash中批量设置键值对hmset(name, mapping)在name对应的hash中获取多个key的值hmget(name, keys, args)获取name对应的hash中键值对的个数hlen(name)检查name对应的hash是否存在当前传入的keyhexists(name, key)将name对应的hash中指定key的键值对删除hdel(name,keys)自增name对应的hash中的指定key的值，不存在则创建key=amounthincrby(name, key, amount=1)hincrbyfloat(name, key, amount=1.0)过滤,增量式迭代获取，对于数据大的数据非常有用，hscan可以实现分片的获取数据，并非一次性将数据全部获取完，从而放置内存被撑爆hscan(name, cursor=0, match=None, count=None)利用yield封装hscan创建生成器，实现分批去redis中获取数据hscan_iter(name, match=None, count=None) 列表操作lpush, lrange, rpush, lpushx, llen, linsert, lset, lrem, lpop, lindex, ltrim, rpoplpush, blpop, brpoplpush 集合操作sadd, scard, sdiff, sdiffstore, sinter, sinterstore, sismenber, smove, spop, srandmenber, srem, sunion, sunionstore 有序集合(zset)zadd, zcount, zincrby, zrank, zrem, zremrangebyrank, zremrankbyscore, zremrangebylex, zscore, zinterstore, zunionstore 123zunionstore(dest, keys, aggregate=None)# 获取两个有序集合的并集# aggregate的值为: SUM MIN MAX 其他操作1234567891011121314151617181920212223242526272829303132333435del(*names)# 根据删除redis中的任意数据类型exists(name)# 检测redis的name是否存在keys(pattern=&apos;*&apos;)# 根据模型获取redis的name# 更多： # KEYS * 匹配数据库中所有 key 。 # KEYS h?llo 匹配 hello ， hallo 和 hxllo 等。 # KEYS h*llo 匹配 hllo 和 heeeeello 等。 # KEYS h[ae]llo 匹配 hello 和 hallo ，但不匹配 hilloexpire(name ,time)# 为某个redis的某个name设置超时时间rename(src, dst)# 对redis的name重命名move(name, db))# 将redis的某个值移动到指定的db下，若有则不移动select db_name# 切换到其他db，redis有16个dbrandomkey()# 随机获取一个redis的name（不删除）type(name)# 获取name对应值的类型scan(cursor=0, match=None, count=None)scan_iter(match=None, count=None)# 同字符串操作，用于增量迭代获取key 管道redis-py默认在执行每次请求都会创建（连接池申请连接）和断开（归还连接池）一次连接操作，如果想要在一次请求中指定多个命令，则可以使用pipline实现一次请求指定多个命令，并且默认情况下一次pipline 是原子性操作。 12345678910111213import redisimport timepool = redis.ConnectionPool(host=&apos;10.211.55.4&apos;, port=6379, db=5)r = redis.Redis(connection_pool=pool)# pipe = r.pipeline(transaction=False)pipe = r.pipeline(transaction=True)pipe.set(&apos;name&apos;, &apos;alex&apos;)time.sleep(60)pipe.set(&apos;role&apos;, &apos;sb&apos;)pipe.execute() 发布订阅收音机举例发布订阅123456789101112131415161718import redisclass RedisHelper: def __init__(self): self.__conn = redis.Redis(host=&apos;10.211.55.4&apos;) self.chan_sub = &apos;fm104.5&apos; self.chan_pub = &apos;fm104.5&apos; def public(self, msg): self.__conn.publish(self.chan_pub, msg) return True def subscribe(self): pub = self.__conn.pubsub() # 打开收音机 pub.subscribe(self.chan_sub) # 调频道 pub.parse_response() # 准备接收 return pub 订阅方12345678from RedisHelper import RedisHelperobj = RedisHelper()redis_sub = obj.subscribe()while True: msg= redis_sub.parse_response() print (msg) 发布方1234from RedisHelper import RedisHelperobj = RedisHelper()obj.public(&apos;hello&apos;) 参考","categories":[{"name":"数据库","slug":"数据库","permalink":"http://arvin-he.github.io/categories/数据库/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://arvin-he.github.io/tags/redis/"}]},{"title":"tornado学习笔记(二)","slug":"tornado-note2-2017-11-16","date":"2017-11-16T13:40:47.000Z","updated":"2017-11-27T01:06:11.176Z","comments":true,"path":"2017/11/16/tornado-note2-2017-11-16/","link":"","permalink":"http://arvin-he.github.io/2017/11/16/tornado-note2-2017-11-16/","excerpt":"","text":"一些说明ornado 所谓的异步：就是你调用我之后，我发现数据没准备好，那我就不处理，而是跳到程序的其他地方继续执行，等数据准备好之后再切回来继续执行。Tornado 的 IOLoop 就是一个总调度器，汇总了所有的 events 和 callbacks，然后同步执行。这会整体生提升性能，但不会降低单个请求的响应时间。 一些接口说明tornado.web.asynchronous其中 tornado.web.asynchronous 装饰器很简单，就是设置 self._auto_finish = False，这样当 AsyncHandler.get() 执行完之后，connection socket 不会被 close，需要主动调用 self.finish()。在保持连接不关闭的情况下，把控制权让出去，等数据就绪之后再切回来，使异步实现成为可能。12345678910class AsyncHandler(tornado.web.RequestHandler): @tornado.web.asynchronous def get(self): http_client = AsyncHTTPClient() http_client.fetch(\"http://example.com\", callback=self.on_fetch) def on_fetch(self, response): self.write(\"Downloaded!\") self.finish() SimpleAsyncHTTPClientAsyncHTTPClient 的处理流程，简单概括就是：与 HTTP Server 建立连接，等拿到 response 后再来调用回调函数 on_fetch。首先通过创建非阻塞的 socket 连接，然后放入到 ioloop 中，当数据可写/可读之后再接着处理。 gen.engine 的实现：gen.engine 的作用就是把异步中 callback 的写法通过 yield 替代。以下的代码分析都是基于 Tornado 3.0。tornado.ioloop.IOLoop.current() 创建一个ioloop实例 ###IOLoop 为何没有 __init__函数其实是因为要初始化成为单例，IOLoop 的 new 函数已经被改写了，同时指定了 initialize 做为它的初始化方法，所以没有 __init__ 。 FutureFuture在tornado中是一个很奇妙的对象，它是一个穿梭于协程和调度器之间的信使。提供了回调函数注册(当异步事件完成后，调用注册的回调)、中间结果保存、嵌套协程唤醒父协程(通过Runner实现)等功能。Coroutine和Future是一一对应的，可以从上节gen.coroutine装饰器的实现中看到。每调用一个协程，表达式所返回的就是一个Future对象，它所表达的意义为：这个协程的内部各种异步逻辑执行完毕后，会把结果保存在这个Future中，同时调用这个Future中指定的回调函数，而future中的回调函数是什么时候被注册的呢？那就是当前——你通过调用协程，返回了这个future对象的时候：","categories":[{"name":"python","slug":"python","permalink":"http://arvin-he.github.io/categories/python/"}],"tags":[{"name":"tornado","slug":"tornado","permalink":"http://arvin-he.github.io/tags/tornado/"}]},{"title":"如何去阅读源码","slug":"howtoreadsource-2017-11-16","date":"2017-11-16T13:34:20.000Z","updated":"2017-11-27T01:06:11.171Z","comments":true,"path":"2017/11/16/howtoreadsource-2017-11-16/","link":"","permalink":"http://arvin-he.github.io/2017/11/16/howtoreadsource-2017-11-16/","excerpt":"","text":"阅读源码的方法源码分析的时候，一定要有层级和模块的概念，任何一个系统都可以被认为是许多个层级或者模块通过向外界暴露接口或者调用其他层级模块接口的方式连接在一起。所以没有必要上来就把每一个细节的实现搞明白，这是低效不科学的方法。正确的方法是首先从宏观上对整体框架有一个认识，划分出层级和模块，然后再具体把每一个模块搞透彻。 学习新框架的方法学一个新的框架，文档先浏览一下，然后就是照着教程的例子运行，接着弄懂例子的运行原理（看源码）。抓住在使用框架过程中遇到的问题，并以那个问题为切入点深入分析，这样一方面能解决问题；另一方面能借机对框架有更深入的了解，因为框架内容那么多，也不可能面面俱到，但是至少遇到问题的地方你深挖是有价值的。","categories":[{"name":"思想","slug":"思想","permalink":"http://arvin-he.github.io/categories/思想/"}],"tags":[{"name":"方法","slug":"方法","permalink":"http://arvin-he.github.io/tags/方法/"}]},{"title":"tornado学习笔记(一)","slug":"tornado-note1-2017-11-16","date":"2017-11-16T11:42:00.000Z","updated":"2017-11-27T01:06:11.175Z","comments":true,"path":"2017/11/16/tornado-note1-2017-11-16/","link":"","permalink":"http://arvin-he.github.io/2017/11/16/tornado-note1-2017-11-16/","excerpt":"","text":"说明高性能源于Tornado基于Epoll（unix为kqueue）的异步网络IO。因为tornado的单线程机制，一不小心就容易写出阻塞服务（block）的代码。不但没有性能提高，反而会让性能急剧下降。因此，探索tornado的异步使用方式很有必要。tornado虽然以异步非阻塞高性能著称的框架,但默认不是异步非阻塞的,你需要添加两个装饰器@tornado.web.asynchronous和@tornado.gen.coroutine,这样才算是异步非阻塞的.然而当你用tornado作为http服务器,同时用了requests库发送请求后,你会发现请求还是一个一个的处理,根本不是异步非阻塞的.原因是requests库发送请求是阻塞的,它会阻塞整个tornado服务进程,为什么阻塞,原因是用 requests 的话能会 block 其他 http 请求。因为他无法注册到 ioloop 里面。只要这个 requests 请求结束， tornado 才会处理下一个 http 请求。 Tornado主要模块web - FriendFeed 使用的基础 Web 框架，包含了 Tornado 的大多数重要的功能escape - XHTML, JSON, URL 的编码/解码方法database - 对 MySQLdb 的简单封装，使其更容易使用template - 基于 Python 的 web 模板系统httpclient - 非阻塞式 HTTP 客户端，它被设计用来和 web 及 httpserver 协同工作auth - 第三方认证的实现（包括 Google OpenID/OAuth、Facebook Platform、Yahoo BBAuth、FriendFeed OpenID/OAuth、Twitter OAuth）locale - 针对本地化和翻译的支持options - 命令行和配置文件解析工具，针对服务器环境做了优化 底层模块httpserver - 服务于 web 模块的一个非常简单的 HTTP 服务器的实现iostream - 对非阻塞式的 socket 的简单封装，以方便常用读写操作ioloop - 核心的 I/O 循环 Tornado 异步使用方式简而言之，Tornado的异步包括两个方面，异步服务端和异步客户端。无论服务端和客户端，具体的异步模型又可以分为回调（callback）和协程（coroutine）。具体应用场景，也没有很明确的界限。往往一个请求服务里还包含对别的服务的客户端异步请求。 服务端异步方式服务端异步，可以理解为一个tornado请求之内，需要做一个耗时的任务。直接写在业务逻辑里可能会block整个服务。因此可以把这个任务放到异步处理，实现异步的方式就有两种，一种是yield挂起函数，另外一种就是使用类线程池的方式。请看一个同步例子：同步代码:12345class SyncHandler(tornado.web.RequestHandler): def get(self, *args, **kwargs): # 耗时的代码 os.system(\"ping -c 2 www.google.com\") self.finish('It works') 测试一下：0.99，姑且当成每秒处理一个请求吧。 异步代码:12345678910111213class AsyncHandler(tornado.web.RequestHandler): @tornado.web.asynchronous @tornado.gen.coroutine def get(self, *args, **kwargs): tornado.ioloop.IOLoop.instance().add_timeout(1, callback=functools.partial(self.ping, 'www.google.com')) # do something others self.finish('It works') @tornado.gen.coroutine def ping(self, url): os.system(\"ping -c 2 &#123;&#125;\".format(url)) return 'after' 尽管在执行异步任务的时候选择了timeout 1秒，主线程的返回还是很快的。上述的使用方式，通过tornado的IO循环，把可以把耗时的任务放到后台异步计算，请求可以接着做别的计算。可是，经常有一些耗时的任务完成之后，我们需要其计算的结果。此时这种方式就不行了。车道山前必有路，只需要切换一异步方式即可。下面使用协程来改写：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162class AsyncTaskHandler(tornado.web.RequestHandler): @tornado.web.asynchronous @tornado.gen.coroutine def get(self, *args, **kwargs): # yield 结果 response = yield tornado.gen.Task(self.ping, ' www.google.com') print 'response', response self.finish('hello') @tornado.gen.coroutine def ping(self, url): os.system(\"ping -c 2 &#123;&#125;\".format(url)) return 'after'``` 可以看到异步在处理，而结果值也被返回了。有时候这种协程处理，未必就比同步快。在并发量很小的情况下，IO本身拉开的差距并不大。甚至协程和同步性能差不多。yield挂起函数协程，尽管没有block主线程，因为需要处理返回值，挂起到响应执行还是有时间等待，相对于单个请求而言。另外一种使用异步和协程的方式就是在主线程之外，使用线程池，线程池依赖于futures。Python2需要额外安装。```python下面使用线程池的方式修改为异步处理：from concurrent.futures import ThreadPoolExecutorclass FutureHandler(tornado.web.RequestHandler): executor = ThreadPoolExecutor(10) @tornado.web.asynchronous @tornado.gen.coroutine def get(self, *args, **kwargs): url = 'www.google.com' tornado.ioloop.IOLoop.instance().add_callback(functools.partial(self.ping, url)) self.finish('It works') @tornado.concurrent.run_on_executor def ping(self, url): os.system(\"ping -c 2 &#123;&#125;\".format(url))``` 再切换一下使用方式接口。使用tornado的gen模块下的with_timeout功能（这个功能必须在tornado&gt;3.2的版本）。```pythonclass Executor(ThreadPoolExecutor): _instance = None def __new__(cls, *args, **kwargs): if not getattr(cls, '_instance', None): cls._instance = ThreadPoolExecutor(max_workers=10) return cls._instanceclass FutureResponseHandler(tornado.web.RequestHandler): executor = Executor() @tornado.web.asynchronous @tornado.gen.coroutine def get(self, *args, **kwargs): future = Executor().submit(self.ping, 'www.google.com') response = yield tornado.gen.with_timeout(datetime.timedelta(10), future, quiet_exceptions=tornado.gen.TimeoutError) if response: print 'response', response.result() @tornado.concurrent.run_on_executor def ping(self, url): os.system(\"ping -c 1 &#123;&#125;\".format(url)) return 'after' 线程池的方式也可以通过使用tornado的yield把函数挂起，实现了协程处理。可以得出耗时任务的result，同时不会block住主线程。 ###异步多样化Tornado异步服务的处理大抵如此。现在异步处理的框架和库也很多，借助redis或者celery等，也可以把tonrado中一些业务异步化，放到后台执行。此外，Tornado还有客户端异步功能。该特性主要是在于 AsyncHTTPClient的使用。此时的应用场景往往是tornado服务内，需要针对另外的IO进行请求和处理。顺便提及，上述的例子中，调用ping其实也算是一种服务内的IO处理。接下来，将会探索一下AsyncHTTPClient的使用，尤其是使用AsyncHTTPClient上传文件与转发请求。 异步客户端前面了解Tornado的异步任务的常用做法，姑且归结为异步服务。通常在我们的服务内，还需要异步的请求第三方服务。针对HTTP请求，Python的库Requests是最好用的库，没有之一。官网宣称：HTTP for Human。然而，在tornado中直接使用requests将会是一场恶梦。requests的请求会block整个服务进程。上帝关上门的时候，往往回打开一扇窗。Tornado提供了一个基于框架本身的异步HTTP客户端（当然也有同步的客户端）— AsyncHTTPClient。 AsyncHTTPClient 基本用法AsyncHTTPClient是 tornado.httpclinet 提供的一个异步http客户端。使用也比较简单。与服务进程一样，AsyncHTTPClient也可以callback和yield两种使用方式。前者不会返回结果，后者则会返回response。如果请求第三方服务是同步方式，同样会杀死性能。1234567class SyncHandler(tornado.web.RequestHandler): def get(self, *args, **kwargs): url = 'https://api.github.com/' resp = requests.get(url) print resp.status_code self.finish('It works') 性能相当慢了，换成AsyncHTTPClient再测： 123456789101112class AsyncHandler(tornado.web.RequestHandler): @tornado.web.asynchronous def get(self, *args, **kwargs): url = 'https://api.github.com/' http_client = tornado.httpclient.AsyncHTTPClient() http_client.fetch(url, self.on_response) self.finish('It works') @tornado.gen.coroutine def on_response(self, response): print response.code 提高了很多,同样，为了获取response的结果，只需要yield函数。12345678910class AsyncResponseHandler(tornado.web.RequestHandler): @tornado.web.asynchronous @tornado.gen.coroutine def get(self, *args, **kwargs): url = 'https://api.github.com/' http_client = tornado.httpclient.AsyncHTTPClient() response = yield tornado.gen.Task(http_client.fetch, url) print response.code print response.body AsyncHTTPClient 转发使用Tornado经常需要做一些转发服务，需要借助AsyncHTTPClient。既然是转发，就不可能只有get方法，post，put，delete等方法也会有。此时涉及到一些 headers和body，甚至还有https的waring。 下面请看一个post的例子， yield结果，通常，使用yield的时候，handler是需要 tornado.gen.coroutine。1234567891011headers = self.request.headersbody = json.dumps(&#123;'name': 'rsj217'&#125;)http_client = tornado.httpclient.AsyncHTTPClient()resp = yield tornado.gen.Task( self.http_client.fetch, url, method=\"POST\", headers=headers, body=body, validate_cert=False) AsyncHTTPClient 构造请求如果业务处理并不是在handlers写的，而是在别的地方，当无法直接使用tornado.gen.coroutine的时候，可以构造请求，使用callback的方式。12345678910body = urllib.urlencode(params)req = tornado.httpclient.HTTPRequest( url=url, method='POST', body=body, validate_cert=False) http_client.fetch(req, self.handler_response)def handler_response(self, response): print response.code 用法也比较简单，AsyncHTTPClient中的fetch方法，第一个参数其实是一个HTTPRequest实例对象，因此对于一些和http请求有关的参数，例如method和body，可以使用HTTPRequest先构造一个请求，再扔给fetch方法。通常在转发服务的时候，如果开起了validate_cert，有可能会返回599timeout之类，这是一个warning，官方却认为是合理的。 AsyncHTTPClient 上传图片AsyncHTTPClient 更高级的用法就是上传图片。例如服务有一个功能就是请求第三方服务的图片OCR服务。需要把用户上传的图片，再转发给第三方服务。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162@router.Route('/api/v2/account/upload')class ApiAccountUploadHandler(helper.BaseHandler): @tornado.gen.coroutine @helper.token_require def post(self, *args, **kwargs): upload_type = self.get_argument('type', None) files_body = self.request.files['file'] new_file = 'upload/new_pic.jpg' new_file_name = 'new_pic.jpg' # 写入文件 with open(new_file, 'w') as w: w.write(file_['body']) logging.info('user &#123;&#125; upload &#123;&#125;'.format(user_id, new_file_name)) # 异步请求 上传图片 with open(new_file, 'rb') as f: files = [('image', new_file_name, f.read())] fields = (('api_key', KEY), ('api_secret', SECRET)) content_type, body = encode_multipart_formdata(fields, files) headers = &#123;\"Content-Type\": content_type, 'content-length': str(len(body))&#125; request = tornado.httpclient.HTTPRequest(config.OCR_HOST, method=\"POST\", headers=headers, body=body, validate_cert=False) response = yield tornado.httpclient.AsyncHTTPClient().fetch(request)def encode_multipart_formdata(fields, files): \"\"\" fields is a sequence of (name, value) elements for regular form fields. files is a sequence of (name, filename, value) elements for data to be uploaded as files. Return (content_type, body) ready for httplib.HTTP instance \"\"\" boundary = '----------ThIs_Is_tHe_bouNdaRY_$' crlf = '\\r\\n' l = [] for (key, value) in fields: l.append('--' + boundary) l.append('Content-Disposition: form-data; name=\"%s\"' % key) l.append('') l.append(value) for (key, filename, value) in files: filename = filename.encode(\"utf8\") l.append('--' + boundary) l.append( 'Content-Disposition: form-data; name=\"%s\"; filename=\"%s\"' % ( key, filename ) ) l.append('Content-Type: %s' % get_content_type(filename)) l.append('') l.append(value) l.append('--' + boundary + '--') l.append('') body = crlf.join(l) content_type = 'multipart/form-data; boundary=%s' % boundary return content_type, bodydef get_content_type(filename): import mimetypes return mimetypes.guess_type(filename)[0] or 'application/octet-stream' 对比上述的用法，上传图片仅仅是多了一个图片的编码。将图片的二进制数据按照multipart 方式编码。编码的同时，还需要把传递的相关的字段处理好。相比之下，使用requests 的方式则非常简单：files = {}f = open(‘/Users/ghost/Desktop/id.jpg’)files[‘image’] = fdata = dict(api_key=’KEY’, api_secret=’SECRET’)resp = requests.post(url, data=data, files=files)f.close()print resp.status_Code 总结通过AsyncHTTPClient的使用方式，可以轻松的实现handler对第三方服务的请求。结合前面关于tornado异步的使用方式。无非还是两个key。是否需要返回结果，来确定使用callback的方式还是yield的方式。当然，如果不同的函数都yield，yield也可以一直传递。这个特性，tornado的中的tornado.auth 里面对oauth的认证。大致就是这样的用法。","categories":[{"name":"python","slug":"python","permalink":"http://arvin-he.github.io/categories/python/"}],"tags":[{"name":"tornado","slug":"tornado","permalink":"http://arvin-he.github.io/tags/tornado/"}]},{"title":"Linux IO模式及 select、poll、epoll详解","slug":"someconcept-2017-11-06","date":"2017-11-06T12:49:40.000Z","updated":"2017-11-07T01:18:37.888Z","comments":true,"path":"2017/11/06/someconcept-2017-11-06/","link":"","permalink":"http://arvin-he.github.io/2017/11/06/someconcept-2017-11-06/","excerpt":"","text":"epoll, kqueue, select, iocp的概念epoll 阻塞, 非阻塞忙轮询缓冲区,内核缓冲区缓冲区的引入是为了减少频繁I/O操作而引起频繁的系统调用，当你操作一个流时，更多的是以缓冲区为单位进行操作，这是相对于用户空间而言。对于内核来说，也需要缓冲区。 用户态, 内核态","categories":[{"name":"Linux","slug":"Linux","permalink":"http://arvin-he.github.io/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://arvin-he.github.io/tags/Linux/"}]},{"title":"MongoDB之aggregate, pipeline及map_reduce","slug":"mongodb-aggregate-pipeline","date":"2017-11-05T08:18:15.000Z","updated":"2017-11-07T01:17:17.710Z","comments":true,"path":"2017/11/05/mongodb-aggregate-pipeline/","link":"","permalink":"http://arvin-he.github.io/2017/11/05/mongodb-aggregate-pipeline/","excerpt":"","text":"MongoDB聚合聚合操作处理数据记录并返回计算结果。 聚合操作将多个文档中的值组合在一起，并可对分组数据执行各种操作，以返回单个结果。在SQL中的 count(*)与group by组合相当于mongodb 中的聚合功能。 基本语法: db.COLLECTION_NAME.aggregate(AGGREGATE_OPERATION) 实例讲解数据:12345678910111213141516&#123; _id: 100, title: &apos;MongoDB Overview&apos;, description: &apos;MongoDB is no sql database&apos;, by_user: &apos;Maxsu&apos;, url: &apos;http://www.yiibai.com&apos;, tags: [&apos;mongodb&apos;, &apos;database&apos;, &apos;NoSQL&apos;], likes: 100&#125;,&#123; _id: 101, title: &apos;NoSQL Overview&apos;, description: &apos;No sql database is very fast&apos;, by_user: &apos;Maxsu&apos;, url: &apos;http://www.yiibai.com&apos;, tags: [&apos;mongodb&apos;, &apos;database&apos;, &apos;NoSQL&apos;], likes: 10&#125;,&#123; _id: 102, title: &apos;Neo4j Overview&apos;, description: &apos;Neo4j is no sql database&apos;, by_user: &apos;Kuber&apos;, url: &apos;http://www.neo4j.com&apos;, tags: [&apos;neo4j&apos;, &apos;database&apos;, &apos;NoSQL&apos;], likes: 750&#125;,&#123; _id: 103, title: &apos;MySQL Overview&apos;, description: &apos;MySQL is sql database&apos;, by_user: &apos;Curry&apos;, url: &apos;http://www.yiibai.com/mysql/&apos;, tags: [&apos;MySQL&apos;, &apos;database&apos;, &apos;SQL&apos;], likes: 350&#125; 聚合字段by_user的总数, 其中by_user作为新集合的_id, 统计的总数放在num_tutorial字段的值中.db.article.aggregate([{$group : {_id : &quot;$by_user&quot;, num_tutorial : {$sum : 1}}}])结果如下:123&#123; &quot;_id&quot; : &quot;Curry&quot;, &quot;num_tutorial&quot; : 1 &#125;&#123; &quot;_id&quot; : &quot;Kuber&quot;, &quot;num_tutorial&quot; : 1 &#125;&#123; &quot;_id&quot; : &quot;Maxsu&quot;, &quot;num_tutorial&quot; : 2 &#125; 上述用例的Sql等效查询select by_user, count(*) as num_tutorial fromarticlegroup by by_user; 其他用于聚合的表达式$sum 从集合中的所有文档中求出定义的值。 db.mycol.aggregate([{$group : {_id : “$by_user”, num_tutorial : {$sum : “$likes”}}}])$avg 计算集合中所有文档的所有给定值的平均值。db.mycol.aggregate([{$group : {_id : “$by_user”, num_tutorial : {$avg : “$likes”}}}])$min 从集合中的所有文档获取相应值的最小值。 db.mycol.aggregate([{$group : {_id : “$by_user”, num_tutorial : {$min : “$likes”}}}])$max 从集合中的所有文档获取相应值的最大值。 db.mycol.aggregate([{$group : {_id : “$by_user”, num_tutorial : {$max : “$likes”}}}])$push 将值插入到生成的文档中的数组中。 db.mycol.aggregate([{$group : {_id : “$by_user”, url : {$push: “$url”}}}])$addToSet 将值插入生成的文档中的数组，但不会创建重复项。 db.mycol.aggregate([{$group : {_id : “$by_user”, url : {$addToSet : “$url”}}}])$first 根据分组从源文档获取第一个文档。 通常情况下，这只适用于以前应用的“$sort”阶段。 db.mycol.aggregate([{$group : {_id : “$by_user”, first_url : {$first : “$url”}}}])$last 根据分组从源文档获取最后一个文档。通常情况下，这只适用于以前应用的“$sort”阶段。 db.mycol.aggregate([{$group : {_id : “$by_user”, last_url : {$last : “$url”}}}]) 管道在UNIX命令中，shell管道可以对某些输入执行操作，并将输出用作下一个命令的输入。MongoDB也在聚合框架中支持类似的概念。每一组输出可作为另一组文档的输入，并生成一组生成的文档(或最终生成的JSON文档在管道的末尾)。这样就可以再次用于下一阶段等等。 以下是在聚合框架可能的阶段 - $project - 用于从集合中选择一些特定字段。$match - 这是一个过滤操作，因此可以减少作为下一阶段输入的文档数量。$group - 这是上面讨论的实际聚合。$sort - 排序文档。$skip - 通过这种方式，可以在给定数量的文档的文档列表中向前跳过。$limit - 限制从当前位置开始的给定数量的文档数量。$unwind - 用于展开正在使用数组的文档。使用数组时，数据是预先加入的，此操作将被撤销，以便再次单独使用文档。 因此，在这个阶段，将增加下一阶段的文件数量。 map_reduceMap-reduce是将大量数据合并为有用的聚合结果的数据处理范例。 MongoDB使用mapReduce命令进行map-reduce操作。MapReduce通常用于处理大型数据集。MapReduce命令:123456789101112131415161718192021222324252627db.collection.mapReduce( function() &#123;emit(key,value);&#125;, //map function function(key,values) &#123;return reduceFunction&#125;, //reduce function &#123; query: query, out: out, //指定结果集以什么方式存储，可选参数包括： //replace:如果文档(table)存在，则替换table， //merge:如果文档中存在记录，则覆盖已存在的文档记录 //reduce: 如果文档中存在相同key的记录了，则先计算两条记录，然后覆盖旧记录 // &#123;inline:1&#125; 在内存中存储记录，不写入磁盘(用户数据量少的计算) sort: sort, limit: limit, finalize: function //这个function主要用来在存入out之前可以修改数据，function(key,values) &#123; //return modifiedValues;&#125; scope: document, //设置参数值，在这里设置的值在map，reduce，finalize函数中可见 jsMode:boolean //是否减少执行过程中BSON和JS的转换，默认true] //false时 BSON--&gt;JS--&gt;map--&gt;BSON--&gt;JS--&gt;reduce--&gt;BSON,可处理非常大的mapreduce, //true时BSON--&gt;js--&gt;map--&gt;reduce--&gt;BSON verbose:boolean //是否产生更加详细的服务器日志，默认true keytemp：boolean //true或false，表明结果输出到的collection是否是临时的，如果为true，则会在客户端连接中断后自动删除，如果你用的是MongoDB的mongo客户端连接， //那必须exit后才会删除。如果是脚本执行，脚本退出或调用close会自动删除结果collection &#125;)必备参数：map,reduce, out map: function() {emit(this.cat_id,this.goods_number); }说明: 函数内部要调用内置的emit函数,cat_id代表根据cat_id来进行分组,goods_number代表把文档中的goods_number字段映射到cat_id分组上的数据,其中this是指向向前的文档的,这里的第二个参数可以是一个对象,如果是一个对象的话,也是作为数组的元素压进数组里面; reduce: function(cat_id,all_goods_number) {return Array.sum(all_goods_number)},cat_id代表着cat_id当前的这一组,all_goods_number代表当前这一组的goods_number集合,这部分返回的就是结果中的value值; out: , // 输出到某一个集合中,注意本属性来还支持如果输出的集合如果已经存在了,那是替换,合并还是继续reduce? 另外还支持输出到其他db的分片中,具体用到时查阅文档,筛选出现的键名分别是_id和value; query: , // 一个查询表达式,是先查询出来,再进行mapReduce的 sort: , // 发往map函数前先给文档排序 limit: , // 发往map函数的文档数量上限,该参数貌似不能用在分片模式下的mapreduce finalize: function(key, reducedValue) {return modifiedObject; }, // 从reduce函数中接受的参数key与reducedValue,并且可以访问scope中设定的变量 scope: , // 指定一个全局变量,能应用于finalize和reduce函数 jsMode: , // 布尔值，是否减少执行过程中BSON和JS的转换，默认true,true时BSON–&gt;js–&gt;map–&gt;reduce–&gt;BSON,false时 BSON–&gt;JS–&gt;map–&gt;BSON–&gt;JS–&gt;reduce–&gt;BSON,可处理非常大的mapreduce。 verbose: // 是否产生更加详细的服务器日志，默认true map-reduce函数首先查询集合，然后将结果文档映射到发出的键值对，然后根据具有多个值的键进行减少。 map是一个JavaScript函数，它将一个值与一个键映射并发出一个键值对； reduce是一个javascript函数，可以减少或分组具有相同键的所有文档； out指定map-reduce查询结果的输出位置,一般是输出到另一个新的集合里； query指定选择文档的可选选择条件； sort指定可选的排序条件； limit指定可选的最大文档数； MapReduce查询可用于构建大型复杂聚合查询。 使用自定义JavaScript函数可以使用MapReduce，它非常灵活和强大。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://arvin-he.github.io/categories/数据库/"}],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"http://arvin-he.github.io/tags/MongoDB/"}]},{"title":"libuv与libev,epoll与select","slug":"libuv-libev-epoll-select-2017-10-31","date":"2017-10-31T14:08:37.000Z","updated":"2017-11-07T01:17:17.709Z","comments":true,"path":"2017/10/31/libuv-libev-epoll-select-2017-10-31/","link":"","permalink":"http://arvin-he.github.io/2017/10/31/libuv-libev-epoll-select-2017-10-31/","excerpt":"","text":"libuv与libevepoll与select机制","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[]},{"title":"python中的一些errors","slug":"py-errors-2017-10-29","date":"2017-10-29T09:22:42.000Z","updated":"2017-11-07T01:17:17.722Z","comments":true,"path":"2017/10/29/py-errors-2017-10-29/","link":"","permalink":"http://arvin-he.github.io/2017/10/29/py-errors-2017-10-29/","excerpt":"","text":"builtins.ImportError: cannot import name ‘Empty’当运行python脚本程序后,python解析器会自动将当前脚本的路径加到syspath中,如果当前脚本的路径中含有与标准库同名的脚本queue.py,则报上面的错.所以不要有与标准库同名的脚本.","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Python之psutil模块使用","slug":"py-psutil-2017-10-18","date":"2017-10-18T06:36:01.000Z","updated":"2017-10-18T06:37:03.330Z","comments":true,"path":"2017/10/18/py-psutil-2017-10-18/","link":"","permalink":"http://arvin-he.github.io/2017/10/18/py-psutil-2017-10-18/","excerpt":"","text":"psutil模块","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Linux笔记","slug":"linux-note1-2017-10-18","date":"2017-10-18T06:17:30.000Z","updated":"2017-10-18T06:30:49.753Z","comments":true,"path":"2017/10/18/linux-note1-2017-10-18/","link":"","permalink":"http://arvin-he.github.io/2017/10/18/linux-note1-2017-10-18/","excerpt":"","text":"查看linux下所有的python3进程1ps aux | grep python3 linux下bash脚本执行错误错误: -bash: ./reporteveryday.sh: /bin/bash^M: bad interpreter: No such file or directorywindows下的换行是回车符+换行符，也就是\\r\\n, 而unix下是换行符\\n。linux下不识别\\r为回车符，所以导致每行多了个\\r。并且因为这个是控制字符，所以在输出参数的时候不会打印出来. bash脚本不要在windows下创建,然后在拷贝到Linux下,这样容易导致bash脚本无法执行,且不报错.解决办法:12345vim file# 查看文件的format:set ff# 修改文件format为unix:set ff=unix","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://arvin-he.github.io/tags/Linux/"}]},{"title":"Python 缓存机制与 functools.lru_cache","slug":"py-cache-2017-09-29","date":"2017-09-29T07:37:17.000Z","updated":"2017-09-29T07:47:43.927Z","comments":true,"path":"2017/09/29/py-cache-2017-09-29/","link":"","permalink":"http://arvin-he.github.io/2017/09/29/py-cache-2017-09-29/","excerpt":"","text":"缓存概念缓存是一种将定量数据加以保存以备迎合后续请求的处理方式，目的是为了加快数据的检索速度下面看一个例子:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# -*- coding: utf-8 -*-import datetimeimport randomclass MyCache: \"\"\"\"\"\" def __init__(self): \"\"\"Constructor\"\"\" self.cache = &#123;&#125; self.max_cache_size = 10 def __contains__(self, key): \"\"\" 根据该键是否存在于缓存当中返回True或者False \"\"\" return key in self.cache def update(self, key, value): \"\"\" 更新该缓存字典，您可选择性删除最早条目 \"\"\" if key not in self.cache and len(self.cache) &gt;= self.max_cache_size: self.remove_oldest() self.cache[key] = &#123;'date_accessed': datetime.datetime.now(), 'value': value&#125; def remove_oldest(self): \"\"\" 删除具备最早访问日期的输入数据 \"\"\" oldest_entry = None for key in self.cache: if oldest_entry == None: oldest_entry = key elif self.cache[key]['date_accessed'] &lt; self.cache[oldest_entry]['date_accessed']: oldest_entry = key self.cache.pop(oldest_entry) @property def size(self): \"\"\" 返回缓存容量大小 \"\"\" return len(self.cache)if __name__ == '__main__': #测试缓存 keys = ['test', 'red', 'fox', 'fence', 'junk', \\ 'other', 'alpha', 'bravo', 'cal', 'devo', 'ele'] s = 'abcdefghijklmnop' cache = MyCache() for i, key in enumerate(keys): if key in cache: continue else: value = ''.join([random.choice(s) for i in range(20)]) cache.update(key, value) print(\"#%s iterations, #%s cached entries\" % (i+1, cache.size)) 在 Python 的 3.2 版本中，引入了一个非常优雅的缓存机器，即 functool 模块中的 lru_cache 装饰器。如果要在 python2 中使用 lru_cahce 需要安装 functools32。lru_cache 原型如下：@functools.lru_cache(maxsize=None, typed=False)使用functools模块的lur_cache装饰器，可以缓存最多 maxsize 个此函数的调用结果，从而提高程序执行的效率，特别适合于耗时的函数。参数maxsize为最多缓存的次数，如果为None，则无限制，设置为2n时，性能最佳；被 lru_cache 装饰的函数会有 cache_clear 和 cache_info 两个方法，分别用于清除缓存和查看缓存信息。这里用一个简单的示例演示 lru_cache 效果：12345678910111213141516from functools import lru_cache@lru_cache(None)def add(x, y): print(\"calculating: %s + %s\" % (x, y)) return x + yprint(add(1, 2))print(add(1, 2))print(add(2, 3))#输出结果：calculating: 1 + 233calculating: 2 + 35 从结果可以看出，当第二次调用 add(1, 2) 时，并没有真正执行函数体，而是直接返回缓存的结果。 参考 http://blog.konghy.cn/2016/04/20/python-cache/","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"谷歌浏览器常用快捷键","slug":"chrome-hotkey-2017-09-29","date":"2017-09-29T06:20:11.000Z","updated":"2017-09-29T06:33:46.434Z","comments":true,"path":"2017/09/29/chrome-hotkey-2017-09-29/","link":"","permalink":"http://arvin-he.github.io/2017/09/29/chrome-hotkey-2017-09-29/","excerpt":"","text":"Chrome窗口和标签页快捷键： Ctrl+N 打开新窗口 Ctrl+T 打开新标签页 Ctrl+Shift+N 在隐身模式下打开新窗口 Ctrl+O，然后选择文件，在谷歌浏览器中打开计算机上的文件 按住 Ctrl 键，然后点击链接，从后台在新标签页中打开链接，但您仍停留在当前标签页中 按住 Ctrl+Shift 键，然后点击链接 在新标签页中打开链接，同时切换到新打开的标签页 按住 Shift 键，然后点击链接 在新窗口中打开链接 Alt+F4 关闭当前浏览器窗口 Ctrl+Shift+T 重新打开上次关闭的标签页。谷歌浏览器可记住最近关闭的 10 个标签页。 将链接拖动到标签页内 在指定标签页中打开链接 将链接拖动到两个标签页之间 在标签页横条的指定位置建立一个新标签页，在该标签页中打开链接 Ctrl+1 到 Ctrl+8 切换到指定位置编号的标签页。您按下的数字代表标签页横条上的相应标签位置。 Ctrl+9 切换到最后一个标签页 Ctrl+Tab 或 Ctrl+PgDown 切换到下一个标签页 Ctrl+Shift+Tab 或 Ctrl+PgUp 切换到上一个标签页 Ctrl+W 或 Ctrl+F4 关闭当前标签页或弹出式窗口 Alt+Home 打开主页 Chrome地址栏快捷键 ：在地址栏，进行下列操作之一： 键入搜索字词 使用默认搜索引擎进行搜索 键入网址中”www.”和”.com”之间的部分，然后按Ctrl+Enter 键 为您在地址栏中输入的内容添加”www.”和”.com”，然后打开网址 键入搜索引擎关键字或网址，按 Tab键，然后键入搜索字词 使用与关键字或网址相关联的搜索引擎进行搜索。如果谷歌浏览器可以识别您要使用的搜索引擎，则会提示您按 Tab 键。 F6 或 Ctrl+L 或 Alt+D 选中网址区域中的内容 键入网址，然后按 Alt+Enter 键 在新标签页中打开网址 打开谷歌chrome浏览器各功能的快捷键 Ctrl+B 打开和关闭书签栏 Ctrl+Shift+B 打开书签管理器 Ctrl+H 查看”历史记录”页 Ctrl+J 查看”下载”页 Shift+Escape 查看任务管理器 Shift+Alt+T 将焦点设置在工具栏上。使用键盘上的向右和向左箭头，可导航至工具栏上的不同按钮。 Chrome网页快捷键： Ctrl+P 打印当前页 Ctrl+S 保存当前页 F5 重新加载当前页 Esc 停止加载当前页 Ctrl+F 打开”在网页上查找”框 点击鼠标中键或滚轮（只在谷歌浏览器测试版（只有英文版）中可用） 激活自动滚动。当您移动鼠标时，网页会根据鼠标的移动方向自动滚动。 Ctrl+F5 或 Shift+F5 重新加载当前页，但忽略缓存内容 按住 Alt 键，然后点击链接 下载链接 Ctrl+G 或 F3 查找与您在”在网页上查找”框中输入的内容相匹配的下一个匹配项 Ctrl+Shift+G 或 Shift+F3 查找与您在”在网页上查找”框中输入的内容相匹配的上一个匹配项 Ctrl+U 查看源代码 将链接拖动到书签栏 将链接加入书签 Ctrl+D 将当前网页加入书签 Ctrl++，或者按住 Ctrl 键并向上滚动鼠标滚轮 放大网页上的所有内容 Ctrl+-，或者按住 Ctrl 键并向下滚动鼠标滚轮 缩小网页上的所有内容 Ctrl+0 将网页上的所有内容都恢复到正常大小 空格键 向下滚动网页。 Home 转至网页顶部。 End 转至网页底部。 按住 Shift 键的同时滚动鼠标滚轮。 在网页上横向滚动。 浏览器文本快捷键： Ctrl+C 将突出显示的内容复制到剪贴板中。 Ctrl+V 或 Shift+Insert 从剪贴板中粘贴内容。 Ctrl+Shift+V 从剪贴板中粘贴内容(不带格式)。 Ctrl+X 或 Shift+Delete 删除突出显示的内容并将其复制到剪贴板中。 chrome命令16个非常有用的chrome://命令，操作方法与上述类似。 chrome://downloads 等同于从菜单中查看下载内容，其快捷键是Ctrl+J chrome://extensions 等同于菜单-工具-扩展 chrome://plugins 显示已安装插件 chrome://bookmarks 等同于菜单-书签-书签管理器，快捷键Ctrl+Shift+O chrome://history 等同于从菜单-历史直接访问，快捷键 Ctrl+H chrome://restart 重启chrome浏览器 chrome://apps 打开chrome网上应用商店 chrome://flags 可用来启用或者关闭某些chrome的体验特性 chrome://dns 显示浏览器预抓取的主机名列表，让你随时了解DNS状态 chrome://memory 重定向到chrome://memory-redirect/，显示系统运行中的浏览器内存使用情况，以及浏览器中进程的详细信息。 chrome://net-internals 显示网络相关信息，用来捕获浏览器生成的网络事件，可导出数据，可查看DNS主机解析缓存。 chrome://quota-internals 用来显示浏览器所使用磁盘空间配额的情况。 chrome://sessions 该命令用来显示当前运行的浏览器的会话信息数以及详细列表 chrome://settings 该命令可通过菜单-选项直接访问，可用来控制浏览器各项设置值 chrome://sync-internals 用来显示 chrome 的同步状态 chrome://about/ 查看 chrome 所有的命令","categories":[{"name":"工具","slug":"工具","permalink":"http://arvin-he.github.io/categories/工具/"}],"tags":[{"name":"谷歌","slug":"谷歌","permalink":"http://arvin-he.github.io/tags/谷歌/"}]},{"title":"爬虫笔记","slug":"scrapy-notes2-2017-09-29","date":"2017-09-29T05:40:34.000Z","updated":"2017-09-29T06:57:19.072Z","comments":true,"path":"2017/09/29/scrapy-notes2-2017-09-29/","link":"","permalink":"http://arvin-he.github.io/2017/09/29/scrapy-notes2-2017-09-29/","excerpt":"","text":"一些常识 代理ip会被集体封禁,然后过一段时间再开放 ip被封禁后,有的会过段时间解除封禁 代理ip不是全部可靠的,通常有效代理大概在70%左右 爬虫错误处理方法","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"http://arvin-he.github.io/tags/爬虫/"}]},{"title":"MongoDB配置","slug":"mongodb-config-2017-09-27","date":"2017-09-27T11:59:15.000Z","updated":"2017-11-07T01:17:17.718Z","comments":true,"path":"2017/09/27/mongodb-config-2017-09-27/","link":"","permalink":"http://arvin-he.github.io/2017/09/27/mongodb-config-2017-09-27/","excerpt":"","text":"安装mongodb安装就免了吧,安装好mongodb,然后配置环境变量 创建MongoDB配置文件注意: 配置文件中的所有路径必须要存在, mongodb不会自动给你创建文件夹,所以像data,log,pid等文件夹按照配置文件指定路径手动创建好,否则会报错.先创建一个配置文件,名称为mongodb.cfg,配置内容为:1234567891011121314151617181920212223#数据文件存放位置dbpath=F:/mongodb/data/db#日志文件存放位置logpath=F:/mongodb/data/log/mongodb.log#PID的路径pidfilepath=F:/mongodb/pid/mongodb.pid#端口号port=27017#错误日志采用追加模式，配置这个选项后mongodb的日志会追加到现有的日志文件logappend=true#启用日志文件，默认启用journal=true#这个选项可以过滤掉一些无用的日志信息，若需要调试使用请设置为falsequiet=true#打开28017网页端口（若不开启注释掉即可）rest=true 启动mongodb在终端执行:mongod --config F:/mongodb/config/mongodb.cfg然后在浏览器输入:127.0.0.1:27017,回车会看到网页有”It looks like you are trying to access MongoDB over HTTP on the native driver port.”,则表明启动成功 注册mongodb服务如果每次都按照步骤三那样操作，岂不是很麻烦，按照如下命令来创建并启动MongoDB服务，就可以通过windows服务来管理MongoDB的启动和关闭了.安装mongodb服务,在终端输入: mongod --config F:/mongodb/config/mongodb.cfg --install --serviceName MongoDB启动mongodb服务,在终端输入: net start MongoDB, 回车,然后有提示出来:MongoDB服务正在启动, MongoDB服务已经启动成功 错误: 服务名无效一般由两个原因造成,第一: 可能是你的服务名称拼写错误,第二: 就是没有用管理员权限运行命令.查看mongodb日志发现: Error connecting to the Service Control Manager: 拒绝访问, 这说明没有用管理员权限运行命令.使用管理员权限打开cmd, 然后再输入命令并运行, 然后服务就启动成功了. 去除mongodb服务如果需要去除MongoDB服务，执行如下命令：mongod --remove --serviceName MongoDB 如何创建用户管理员用户管理员是第一个要创建的用户。在没有创建任何用户之前，你可以随意创建用户；但数据库中一旦有了用户，那么未登录的客户端就没有权限做任何操作了，除非使用db.auth(username, password)方法登录。 用户管理员的角色名叫 userAdminAnyDatabase，这个角色只能在 admin 数据库中创建。下面是一个例子：首先,在终端输入:mongo,回车,进入mongo shell, 然后输入命令.1234&gt; use adminswitched to db admin&gt; db.createUser(&#123;user:&quot;root&quot;,pwd:&quot;root&quot;,roles:[&quot;userAdminAnyDatabase&quot;]&#125;)Successfully added user: &#123; &quot;user&quot; : &quot;root&quot;, &quot;roles&quot; : [ &quot;userAdminAnyDatabase&quot; ] &#125; 这个例子创建了一个名为 root 的用户管理员。创建完了这个用户之后，我们应该马上以该用户的身份登录：123&gt; db.auth(&quot;root&quot;,&quot;root123&quot;)1db.auth() 方法返回 1 表示登录成功。接下来我们为指定的数据库创建访问所需的账号。 如何创建数据库用户首先保证你已经以用户管理员的身份登录 admin 数据库。然后用 use 命令切换到目标数据库，同样用 db.createUser() 命令来创建用户，其中角色名为 “readWrite”。 普通的数据库用户角色有两种，read 和 readWrite。顾名思义，前者只能读取数据不能修改，后者可以读取和修改。下面是一个例子：123456&gt; use testswitched to db test&gt; db.createUser(&#123;user:&quot;testuser&quot;,pwd:&quot;testpass&quot;,roles:[&quot;readWrite&quot;]&#125;)Successfully added user: &#123; &quot;user&quot; : &quot;testuser&quot;, &quot;roles&quot; : [ &quot;readWrite&quot; ] &#125;&gt; db.auth(&quot;testuser&quot;,&quot;testpass&quot;)1 这样 MongoDB 的数据安全性就得到保障了，没有登录的客户端将无法执行任何命令。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://arvin-he.github.io/categories/数据库/"}],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"http://arvin-he.github.io/tags/MongoDB/"}]},{"title":"Python定时器","slug":"py-timer-2017-09-20","date":"2017-09-20T12:15:37.000Z","updated":"2017-09-21T00:45:12.220Z","comments":true,"path":"2017/09/20/py-timer-2017-09-20/","link":"","permalink":"http://arvin-he.github.io/2017/09/20/py-timer-2017-09-20/","excerpt":"","text":"python中定时器python中的定时器在threading模块中,而且只执行一次, 那么如何定时循环调用呢?Timer: 隔一定时间调用一个函数,如果想实现每隔一段时间就调用一个函数的话，就要在Timer调用的函数中，再次设置Timer。Timer其实是Thread的一个派生类 123456789101112import threadingimport timedef hello(name): print(\"hello %s\\n\" % name) global timer timer = threading.Timer(2.0, hello, [\"world\"]) timer.start()if __name__ == \"__main__\": timer = threading.Timer(2.0, hello, [\"world\"]) timer.start()","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Linux一些常用命令","slug":"linux-cmds-2017-09-19","date":"2017-09-19T13:46:02.000Z","updated":"2017-10-17T03:54:57.749Z","comments":true,"path":"2017/09/19/linux-cmds-2017-09-19/","link":"","permalink":"http://arvin-he.github.io/2017/09/19/linux-cmds-2017-09-19/","excerpt":"","text":"scp命令scp是secure copy的简写，用于在Linux下进行远程拷贝文件或文件夹.scp传输是加密的。可能会稍微影响一下速度。当你服务器硬盘变为只读 read only system时，用scp可以帮你把文件移出来。另外，scp还非常不占资源，不会提高多少系统负荷，在这一点上，rsync就远远不及它了。虽然 rsync比scp会快一点，但当小文件众多的情况下，rsync会导致硬盘I/O非常高，而scp基本不影响系统正常使用。 命令格式：scp [参数] [原路径] [目标路径] 从本地服务器复制到远程服务器：命令格式：1234567scp local_file remote_username@remote_ip:remote_folder 或者 scp local_file remote_username@remote_ip:remote_file 或者 scp local_file remote_ip:remote_folder 或者 scp local_file remote_ip:remote_file 第1,2个指定了用户名，命令执行后需要输入用户密码，第1个仅指定了远程的目录，文件名字不变，第2个指定了文件名第3,4个没有指定用户名，命令执行后需要输入用户名和密码，第3个仅指定了远程的目录，文件名字不变，第4个指定了文件名 从本地拷贝文件夹到远程服务器：命令格式：scp -r local_folder remote_username@remote_ip:remote_folder或者scp -r local_folder remote_ip:remote_folder第1个指定了用户名，命令执行后需要输入用户密码；第2个没有指定用户名，命令执行后需要输入用户名和密码； 从远程服务器复制到本地服务器：从远程复制到本地的scp命令与上面的命令相似，只要将从本地复制到远程的命令后面2个参数互换顺序就行了。 scp arvin@192.168.120.204:/opt/soft/nginx-0.5.38.tar.gz /opt/soft/ screen命令 当使用SSH 或者 telent 远程登录到 Linux 服务器,经常有一些长时间运行的任务，比如系统备份、ftp 传输等等。通常情况下我们都是为每一个这样的任务开一个远程终端窗口，但是他们执行的时间太长了。必须等待它执行完毕，在此期间可不能关掉终端窗口或者断开连接，也不能关机, 否则这个任务就会被杀掉，一切半途而废了。显然,这不是我们所希望的. screen命令可以远程运行服务器程序并观察程序执行,即使关闭终端或者关闭电脑也不要紧,服务器上的程序也一直在运行.简单来说，Screen是一个可以在多个进程之间多路复用一个物理终端的窗口管理器。Screen中有会话的概念，用户可以在一个screen会话中创建多个screen窗口，在每一个screen窗口中就像操作一个真实的telnet/SSH连接窗口那样。123456789101112131415# ssh登陆. 注意:需要先通过ssh登陆远程服务器才能使用screenssh user@ip# 创建一个screen会话窗口screen -S test# 执行程序python3 test.py# 查看正在运行的程序,会显示程序执行的pidscreen -ls# 查看某个程序在终端的输出, 6245是执行成的pidscreen -r -D 6245# 杀掉screen中的sessionkill -9 6245screen -ls# 清除dead 会话screen -wipe test (Detached)—-&gt;挂起状态，无终端在连接会话(Attached)—-&gt;有终端在连接会话。注意: 如果程序在运行时,不要按下CTRL+C, 这样会中止程序的运行,直接关闭终端窗口就可以了,这样不会关闭程序的运行. 12345678910其他常用的命令选项有：-c file 使用配置文件file，而不使用默认的$HOME/.screenrc-d|-D [pid.tty.host] 不开启新的screen会话，而是断开其他正在运行的screen会话-h num 指定历史回滚缓冲区大小为num行-list|-ls 列出现有screen会话，格式为pid.tty.host-d -m 启动一个开始就处于断开模式的会话-r sessionowner/ [pid.tty.host] 重新连接一个断开的会话。多用户模式下连接到其他用户screen会话需要指定sessionowner，需要setuid-root权限-S sessionname 创建screen会话时为会话指定一个名字-v 显示screen版本信息-wipe [match] 同-list，但删掉那些无法连接的会话 下例显示当前有两个处于detached状态的screen会话，你可以使用screen -r &lt;screen_pid&gt;重新连接上.如果由于某种原因其中一个会话死掉了（例如人为杀掉该会话），这时screen -list会显示该会话为dead状态。使用screen -wipe命令清除该会话. killkill[参数][进程号] init进程是不可杀的,init是Linux系统操作中不可缺少的程序之一。所谓的init进程，它是一个由内核启动的用户级进程。内核自行启动（已经被载入内存，开始运行，并已初始化所有的设备驱动程序和数据结构等）之后，就通过启动一个用户级程序init的方式，完成引导进程。所以,init始终是第一个进程（其进程编号始终为1）。 其它所有进程都是init进程的子孙。init进程是不可杀的！ 常用的信号：只有第9种信号(SIGKILL)才可以无条件终止进程，其他信号进程都有权利忽略1234567HUP 1 终端断线INT 2 中断（同 Ctrl + C）QUIT 3 退出（同 Ctrl + \\）TERM 15 终止KILL 9 强制终止CONT 18 继续（与STOP相反， fg/bg命令）STOP 19 暂停（同 Ctrl + Z） 彻底杀死进程:命令：kill –9 3268 应注意: 信号使进程强行终止，这常会带来一些副作用，如数据丢失或者终端无法恢复到正常状态。发送信号时必须小心，只有在万不得已时，才用kill信号(9)，因为进程不能首先捕获它。 要撤销所有的后台作业，可以输入kill 0。因为有些在后台运行的命令会启动多个进程，跟踪并找到所有要杀掉的进程的PID是件很麻烦的事。这时，使用kill 0来终止所有由当前shell启动的进程，是个有效的方法。","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://arvin-he.github.io/tags/Linux/"}]},{"title":"python之beautifulsoup使用","slug":"py-bs4-2017-09-18","date":"2017-09-18T13:20:12.000Z","updated":"2018-01-15T09:47:58.281Z","comments":true,"path":"2017/09/18/py-bs4-2017-09-18/","link":"","permalink":"http://arvin-he.github.io/2017/09/18/py-bs4-2017-09-18/","excerpt":"","text":"find()/find_all()find() 返回文档中符合条件的tag，如果没找到符合条件的tag返回Nodefind_all()返回文档中全部符合条件的tag的列表，如果不存在返回空列表注意find()函数返回的是符合条件的tag，因此可以进行链式调用，如：12#先查找class属性为‘post-content’的div标签，然后查找该div标签下的所有的img标签soup.find('div', class_='post-content').find_all('img') 而find_all()返回的是列表，列表是不存在find()和find_all()函数的，因此不能进行链式调用 孩子(child)与后代(descendant)子标签: 一个父标签的下一级标签后代标签: 一个父标签下面所有级别的标签,包括子标签所有的子标签都是后代标签,但不是所有后代标签都是子标签 用BeautifulSoup查找属性值未知的标签soup.findAll(&quot;div&quot;, attrs={&quot;aria-lable&quot;: True})特殊值True和None, True匹配给定属性为任意值的标签，None匹配那些给定的属性值为空的标签对于属性值之类的东西，是任意值，不确定的值的话，则都是用True.","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Mongodb笔记(三)","slug":"mongodb-note3-2017-09-18","date":"2017-09-18T13:05:16.000Z","updated":"2017-11-07T01:17:17.721Z","comments":true,"path":"2017/09/18/mongodb-note3-2017-09-18/","link":"","permalink":"http://arvin-he.github.io/2017/09/18/mongodb-note3-2017-09-18/","excerpt":"","text":"mongodb突然无法打开检查mongodb数据所在的文件夹下是否有一个类似”locked file”,删掉这个文件,然后再开启mongodb 再说插入操作单条插入批量插入 find操作查询是用的最多的操作了, 常用的有2类: , &gt;=, &lt;, &lt;=, !=, = And，OR，In，NotIn 这些操作在mongodb里面都有对应封装. “$gt”, “$gte”, “$lt”, “$lte”, “$ne”, “”这些与上面 &gt;, &gt;=, &lt;, &lt;=, !=, = 这6个符号操作一一对应 “”, “$or”, “$in”，”$nin”与 And，OR，In，NotIn 操作一一对应 正则表达式匹配在mongodb中还有一个特殊的匹配，那就是支持正则表达式. $where操作 update操作整体更新局部更新 局部更新:mongodb中已经给我们提供了两个修改器： $inc 和 $set。 $inc修改器$inc也就是increase的缩写，自增$inc指定的值，如果“文档”中没有此key，则会创建key。 $set修改器 upsert操作upsert操作就是说：如果我没有查到，我就在数据库里面新增一条，其实这样也有好处，就是避免了我在数据库里面判断是update还是add操作，使用起来很简单将update的第三个参数设为true即可。 批量更新在mongodb中如果匹配多条，默认的情况下只更新第一条，那么如果我们有需求必须批量更新，那么在mongodb中实现也是很简单的，在update的第四个参数中设为true即可. 查询某一字段重复的记录查询某一字段重复的记录的数目查询和删除某一字段不是数字的记录123456# 查询某一字段不是数字的记录db.getCollection(&apos;phone&apos;).find(&#123;&quot;tel&quot;: &#123;&quot;$regex&quot;: &apos;^[^0-9]+$&apos;&#125;&#125;)# 查询某一字段不是数字的记录的数目db.getCollection(&apos;phone&apos;).find(&#123;&quot;tel&quot;: &#123;&quot;$regex&quot;: &apos;^[^0-9]+$&apos;&#125;&#125;).count()# 删除某一字段不是数字的记录db.getCollection(&apos;phone&apos;).remove(&#123;&quot;tel&quot;: &#123;&quot;$regex&quot;: &apos;^[^0-9]+$&apos;&#125;&#125;) 数据库合并1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071# -*- coding: utf-8 -*-import osimport sysfrom pymongo import MongoClientimport geventfrom gevent import monkeyfrom gevent.pool import Poolimport subprocessfrom logger import Loggingmonkey.patch_all()logname = os.path.splitext(os.path.basename(__file__))[0]logger = Logging(logname)log = logger.logObject# 连接mongodb数据库,并返回数据库对象def connectDB(user, passwd, host, db_name): client = MongoClient( &apos;mongodb://&#123;&#125;:&#123;&#125;@&#123;&#125;/&#123;&#125;&apos;.format(user, passwd, host, db_name)) return client[db_name]db1 = connectDB(&quot;xxx&quot;, &quot;xxxxxx&quot;, &quot;ip:port&quot;, &quot;xxxx&quot;)db2 = connectDB(&quot;xxxxx&quot;, &quot;******&quot;, &quot;ip:port&quot;, &quot;qqqq&quot;)movie1 = db1[&quot;xxx1&quot;]movie2 = db2[&quot;xxx2&quot;]def get_item(): for index, item in enumerate(movie2.find(&#123;&#125;, no_cursor_timeout=True)): log.info(&quot;获取第&#123;&#125;条数据.&quot;.format(index + 1)) item[&quot;time&quot;] = float(&quot;&#123;:.3f&#125;&quot;.format(int(item[&quot;time&quot;] * 1000))) yield itemdef mergedb(item): if movie1.find(&#123;&quot;tel&quot;: item[&quot;tel&quot;], &quot;time&quot;: item[&quot;time&quot;]&#125;).count() &lt; 1: movie1.insert(item) else: log.info(&quot;该数据已经存在!&quot;)def backupdb(): log.info(&quot;开始导出testdb数据库phone集合...&quot;) dst = os.path.join(&quot;data&quot;, &quot;&#123;&#125;.dat&quot;.format(&quot;phone&quot;)) try: subprocess.check_call([&quot;mongoexport&quot;, &quot;-h&quot;, &quot;ip:port&quot;, &quot;-u&quot;, &quot;xxx.xx&quot;, &quot;-p&quot;, &quot;xxxx&quot;, &quot;-d&quot;, &quot;xxxxx&quot;, &quot;-c&quot;, &quot;xxxx&quot;, &quot;-o&quot;, dst]) log.info(&quot;导出&#123;&#125;数据成功&quot;.format(dst)) except Exception as e: log.error(&quot;导出MongoDB数据出错:&#123;&#125;&quot;.format(e)) returnif __name__ == &quot;__main__&quot;: pool = Pool(100) try: pool.map(mergedb, get_item()) except Exception as e: log.error(e) sys.exit()","categories":[{"name":"数据库","slug":"数据库","permalink":"http://arvin-he.github.io/categories/数据库/"}],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"http://arvin-he.github.io/tags/MongoDB/"}]},{"title":"Python笔记","slug":"py-note1-2017-09-18","date":"2017-09-18T12:57:31.000Z","updated":"2017-11-07T01:17:17.723Z","comments":true,"path":"2017/09/18/py-note1-2017-09-18/","link":"","permalink":"http://arvin-he.github.io/2017/09/18/py-note1-2017-09-18/","excerpt":"","text":"python路径操作123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101import os#创建目录os.mkdir(\"D:\\\\python\\\\2\")#删除目录os.rmdir(\"D:\\\\python\\\\2\")#创建多级目录os.makedirs(\"D:\\\\python\\\\oo\\\\2\\\\3\")#删除多级目录os.removedirs(\"D:\\\\python\\\\oo\\\\2\\\\3\")#获取目录下文件夹及文件os.listdir(\"D:\\\\python\")#获取当前目录位置os.getcwd()#切换目录os.chdir(\"D:\\\\python\\\\oo\\\\3\")#遍历所有子目录及文件for root, dirs, files in os.walk('D:'+os.sep+'python'): # 遍历出所有的文件 for f in files: fp=os.path.join(root, f) # 遍历出所有的目录,包括空目录 for d in dirs: dp = os.path.join(root, d)# 返回path规范化的绝对路径。 os.path.abspath(path) #将path分割成目录和文件名二元组返回。 os.path.split(path) &gt;&gt;&gt; os.path.split('c:\\\\csv\\\\test.csv') ('c:\\\\csv', 'test.csv') &gt;&gt;&gt; os.path.split('c:\\\\csv\\\\') ('c:\\\\csv', '') #返回path的目录。其实就是os.path.split(path)的第一个元素。 os.path.dirname(path) # 返回path最后的文件名。如果path以／或\\结尾，那么就会返回空值。即os.path.split(path)的第二个元素。 os.path.basename(path) &gt;&gt;&gt; os.path.basename('c:\\\\test.csv') 'test.csv' &gt;&gt;&gt; os.path.basename('c:\\\\csv') 'csv' （这里csv被当作文件名处理了） &gt;&gt;&gt; os.path.basename('c:\\\\csv\\\\') '' # 返回list中，所有path共有的最长的路径。 os.path.commonprefix(list) &gt;&gt;&gt; os.path.commonprefix(['/home/td','/home/td/ff','/home/td/fff']) '/home/td' # 如果path存在，返回True；如果path不存在，返回False。 os.path.exists(path) # 如果path是绝对路径，返回True。 os.path.isabs(path) # 如果path是一个存在的文件，返回True。否则返回False。 os.path.isfile(path) # 如果path是一个存在的目录，则返回True。否则返回False。 os.path.isdir(path) # 将多个路径组合后返回，第一个绝对路径之前的参数将被忽略。 os.path.join(path1[, path2[, ...]]) &gt;&gt;&gt; os.path.join('c:\\\\', 'csv', 'test.csv') 'c:\\\\csv\\\\test.csv' &gt;&gt;&gt; os.path.join('windows\\temp', 'c:\\\\', 'csv', 'test.csv') 'c:\\\\csv\\\\test.csv' &gt;&gt;&gt; os.path.join('/home/aa','/home/aa/bb','/home/aa/bb/c') '/home/aa/bb/c' # 在Linux和Mac平台上，该函数会原样返回path，在windows平台上会将路径中所有字符转换为小写，并将所有斜杠转换为反斜杠。 os.path.normcase(path) &gt;&gt;&gt; os.path.normcase('c:/windows\\\\system32\\\\') 'c:\\\\windows\\\\system32\\\\' # 规范化路径。 os.path.normpath(path) &gt;&gt;&gt; os.path.normpath('c://windows\\\\System32\\\\../Temp/') 'c:\\\\windows\\\\Temp' # 返回（drivername，fpath）元组 os.path.splitdrive(path) &gt;&gt;&gt; os.path.splitdrive('c:\\\\windows') ('c:', '\\\\windows') # 分离文件名与扩展名；默认返回(fname,fextension)元组，可做分片操作 os.path.splitext(path) &gt;&gt;&gt; os.path.splitext('c:\\\\csv\\\\test.csv') ('c:\\\\csv\\\\test', '.csv') # 返回path的文件的大小（字节）os.path.getsize(path) &gt;&gt;&gt; os.path.getsize('c:\\\\boot.ini') 299L # 返回path所指向的文件或者目录的最后存取时间。 os.path.getatime(path) # 返回path所指向的文件或者目录的最后修改时间 os.path.getmtime(path) python文件压缩操作python数据库连接操作python字符串操作python异常处理python日志操作","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Mongodb笔记(二)","slug":"mongodb-note2-2017-09-13","date":"2017-09-13T13:15:25.000Z","updated":"2018-01-15T09:47:58.277Z","comments":true,"path":"2017/09/13/mongodb-note2-2017-09-13/","link":"","permalink":"http://arvin-he.github.io/2017/09/13/mongodb-note2-2017-09-13/","excerpt":"","text":"基础知识 mongoDB三要素: 数据库，集合，文档，其中“集合”就是对应关系数据库中的“表”，“文档”对应“行”。 mongoDB发布版本: 32bit和64bit 根据业界规则，偶数为“稳定版”(如：1.6.X，1.8.X)，奇数为“开发版”(如：1.7.X，1.9.X) 32bit的mongodb最大只能存放2G的数据，64bit就没有限制 mongoDB安装与启动 安装: 安装就不多说了,注意安装完将mongodb安装目录下的bin目录(C:\\Program Files\\MongoDB\\Server\\3.4\\bin)放到环境变量中去,默认是没有放到环境变量中.这样有一些很好用的工具和命令可以在终端使用. 启动: 启动之前必须给monggodb指定一个文件夹,这里取名为”mongodata”,路径位:C:\\mongodata,用来存放mongodb的数据。如果你将mongodb安装在C:/program File目录下,那么这个mongodata文件夹不要放在C:/program File目录下.因为这需要管理员权限才能添加和删除文件夹. 在终端指定数据存放地点:mongod –dbpath=C:/mongodata 查看是否成功:最后要看下是否开启成功，从图中的信息中获知，mongodb采用27017端口，那么我们就在浏览器里面键入“http://localhost:27017/”，打开后，mongodb告诉我们在27017上Add 1000可以用http模式查看mongodb的管理信息(貌似在新版本3.4.9没有成功)。 基本操作在终端指定数据存放点后,mongod –dbpath=C:/mongodata,不要关闭该终端,再开一个终端，输入mongo命令打开shell，其实这个shell就是mongodb的客户端，同时也是一个js的编译器，默认连接的是“test”数据库。 insert操作 find 操作 这里要注意两点：“_id”： 这个字段是数据库默认给我们加的GUID，目的就是保证数据的唯一性。严格的按照Bson的形式书写文档，不过也没关系，错误提示还是很强大的。 update操作 update方法的第一个参数为“查找的条件”，第二个参数为“更新的值”。 movie.update({‘_id’: xxx}, {‘$set’: {}}, upsert=True) remove操作 删除指定数据 删除所有数据","categories":[{"name":"数据库","slug":"数据库","permalink":"http://arvin-he.github.io/categories/数据库/"}],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"http://arvin-he.github.io/tags/MongoDB/"}]},{"title":"MongoDB笔记","slug":"mongodb-note1-2017-09-12","date":"2017-09-12T01:36:54.000Z","updated":"2017-11-07T01:17:17.719Z","comments":true,"path":"2017/09/12/mongodb-note1-2017-09-12/","link":"","permalink":"http://arvin-he.github.io/2017/09/12/mongodb-note1-2017-09-12/","excerpt":"","text":"常见的关系型数据库关系数据库管理系统(Relational DataBase Management System，RDBMS)MySQL、PostgreSQL、SQLite、Oracle、MS SQLServer mongoDB简介MongoDB(源自单词 humongous)是一种较新的数据库，它没有表、模式、SQL 或行的概念。它没有事务、ACID 兼容性、连接、外键或其他许多容易在凌晨引起问题的特性。 记住：MongoDB 不会尝试为所有人完成所有事情。但对于许多目的(例如构建 Web 应用)，MongoDB 是一个能够实现解决方案的完美工具。 MongoDB 以C++编写，因此迁移相对容易，并且可以在任何位置运行该应用。MongoDB 提供了一个功能丰富的面向文档数据库，并且对运行速度和扩展性做了优化。它也几乎可运行在任何目标上。MongoDB的网站上包含了可运行在 Linux、Mac OS、Windows 和 Solaris 中的安装文件。 警告：32 位版本的 MongoDB 数据库大小被限制为小于等于 2GB，因为 MongoDB 内部使用内存映射文件来实现高性能。在 32 位系统中任何大于 2GB 的文件都需要一些特殊的处理，这样会降低处理速度，也会使应用代码变得复杂。官方关于该限制的观点是：64 位环境很容易获得；因此，增加代码的复杂性并不是很好的权衡之计。64 位版本的 MongoDB 可以实现所有的意图和目的，并且不含任何限制。 关于BSONMongoDB 并未使用 JSON 存储数据，而使用由 MongoDB 团队开发的一种称为BSON(二进制 JSON 的英文简称)的开放数据格式。大多数情况下，使用 BSON 取代 JSON 并不会改变处理数据的方式。BSON 通过使计算机更容易处理和搜索文档的方式，使 MongoDB 处理速度变得更快。BSON 还添加了一些标准 JSON 不支持的特性，包括数字数据(例如 int32 和int64)的许多扩展类型，以及支持处理二进制数据。 BSON 是一个开放标准，在网址 http://bsonspec.org/上可以找到它的规范。当人们听到 BSON是 JSON 的二进制形式时，他们期望 BSON 占用的空间要比 JSON 少得多。不过，事实并不一定是这样的；许多情况下，BSON 版本与相同的 JSON 相比要占用更多的空间。 首先，要记住 MongoDB 的设计目标是快速，而不是节省空间。虽然这并不意味着 MongoDB会浪费空间(它不会)；不过，如果处理数据的速度更快(它确实是这样的)，那么存储文档时的一点开销是完全可以接受的。简单地说，BSON 更易于遍历(即浏览)，遍历索引页非常快。 BSON 支持在一个文档中存储最多 16MB 的二进制数据， 关于唯一键MongoDB 要求每个文档必须有唯一标识符；在 MongoDB 中，该标识符被称为_id。除非为该字段指定某个值，否则 MongoDB 将自动创建唯一值。即使是在已经成熟的 RDBMS 数据库世界中，也存在着是应该自己提供唯一键还是由数据库提供的分歧。最近，由数据库创建唯一键的方式已经变得更加流行。MongoDB 是一个分布式数据库，所以其主要目标之一是消除对共享资源的依赖(例如检查主键是否独一无二)。非分布式的数据库通常使用一个简单的主键，例如自动递增的序列号。MongoDB 的默认_id 格式是一个 ObjectId，它是一个 12 字节的唯一标识符，可以独立地在分布式环境中生成。之前，使用 MongoDB 的大多数开发者似乎更喜欢创建自己的唯一键，由自己来维护键的唯一性。然而，现在人们更愿意使用 MongoDB 创建的默认 ID 值。不过，在使用 RDBMS 数据库时，选择哪种方式更多地取决于个人偏好。我们更愿意使用数据库提供的值，因为这意味着我们可以保证键是唯一的，并且是独立的。最终，你必须决定哪种方式更适合自己。如果有信心保证自己的键一定是唯一的(并且可能不会改变)，那么就可以使用。如果不确定键的唯一性或者不希望担心这件事情，最好还是使用MongoDB 提供的默认键。 关于集合集合有点类似于表，但它们不那么死板。集合非常像一个贴有标签的盒子。最后但并非最不重要的是，集合可以按需求即时创建。尤其是，在第一次尝试保存文档时，MongoDB 将创建引用它的集合。这意味着可以按照需求即时创建集合(但并不是应该这么做)。因为 MongoDB 也允许动态地创建索引，执行其他数据库级别的命令，所以可以利用该特性构建出一些非常动态的应用。 理解 MongoDB 中数据库的最简单方式就是将它看成一个集合的集合 存储二进制数据GridFS 是 MongoDB 在数据库中存储二进制数据的解决方案。GridFS 通过在 files 集合中存储文件的信息(称为元数据)来实现。数据本身被分成多块(称为信息块)存储在 chunks 集合中。这种方式使数据存储既简单又有扩展性；还使范围操作(例如获取文件的特定部分)变得更简单。 实施分片对于涉及大规模部署的应用，自动分片可能是 MongoDB 最重要和最常用的特性。在自动分片场景中，MongoDB 将处理所有数据的分割和重组。它将保证数据进入正确的服务器，并以最高效的方式运行查询和重组结果。事实上，从开发者的角度看，使用含有数百个分片的 MongoDB 数据库和使用单个 MongoDB 数据库并没有区别。 使用 map 和 reduce 函数MongoDB 并不要求使用 map 和 reduce 函数。事实上，MongoDB 只依赖于简单的查询语法，这种语法与 MySQL 中使用的类似。不过，对于希望使用该功能的人，MongoDB 也提供了对这些函数的支持。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://arvin-he.github.io/categories/数据库/"}],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"http://arvin-he.github.io/tags/MongoDB/"}]},{"title":"Python程序打包问题","slug":"py-packproblems-2017-09-01","date":"2017-09-01T06:33:39.000Z","updated":"2017-09-08T03:51:39.874Z","comments":true,"path":"2017/09/01/py-packproblems-2017-09-01/","link":"","permalink":"http://arvin-he.github.io/2017/09/01/py-packproblems-2017-09-01/","excerpt":"","text":"ImportError: DLL load failed: The specified module could not be found.win7-64bit或win10-64bit打包python32位程序在win7-32bit系统上运行报错:ImportError: DLL load failed: The specified module could not be found. Finally,I find the solution:Install Microsoft Visual C++ 2015 Redistributable Update 3 x86. 注意: 选择X86版本 vc_redist.x86.exe 一定要选择update 3版本,之前的版本还是会报错. 参考 stackoverflow","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Python中关于在GUI应用程序读取stdin内容","slug":"py-stdin-2017-08-30","date":"2017-08-30T02:11:08.000Z","updated":"2017-09-08T03:51:39.895Z","comments":true,"path":"2017/08/30/py-stdin-2017-08-30/","link":"","permalink":"http://arvin-he.github.io/2017/08/30/py-stdin-2017-08-30/","excerpt":"","text":"问题键盘输入的字符串是保存在stdin中的,我在程序中如何将stdin中数据拿到并赋给一个变量? 之前我是通过sys.stdin.readline()来读取stdin中的数据的,但是导致界面卡死,我想问一下你有什么办法?我google一下,没有找到我想要的 data = input()用 sys.stdin.readline 或 input, 都只能读取整行数据. 如果没有按回车键, 调用是阻塞不返回的. 这就是为什么程序界面被卡死的原因. Qt 里还有个键盘事件的钩子. 需要在终端键盘输入时, 可能需要配置一下.123QtCore.pyqtRemoveInputHook()code.InteractiveConsole(_locals).interact()QtCore.pyqtRestoreInputHook() 当QtCore模块第一次导入时，它会安装一个Python输入钩子（即它设置Python的PyOS_InputHook变量的值）。这允许在应用程序运行时在解释器提示符处输入命令。然后可以动态创建新的Qt对象并调用任何现有的Qt对象的方法。输入钩子可能会导致某些类型的应用程序出现问题，特别是那些通过不同手段提供类似设备的应用程序。此功能删除PyQt安装的输入钩。 对于图形界面程序, 最合理的做法还是只用输入控件, LineEdit 等, 不用控制台, 也就是不用 sys.stdinQt 处理键盘消息应该用键盘事件","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Linux系统之镜像备份","slug":"linux-backup-2017-08-28","date":"2017-08-28T05:51:53.000Z","updated":"2017-09-08T03:51:39.754Z","comments":true,"path":"2017/08/28/linux-backup-2017-08-28/","link":"","permalink":"http://arvin-he.github.io/2017/08/28/linux-backup-2017-08-28/","excerpt":"","text":"计算文件拷贝的进度12345678910111213141516171819# dd_process.sh#! /bin/bash####dd 命令反映进度####if [ $# -ne 2 ];then echo \"需要 盘符名 镜像名\"fi dupath=`du -m --total / --exclude=proc --exclude=media |grep 总用量 |cut -f 1` echo \"根文件大小为$dupath M\" let SIZE=$dupath+200 while true do dusize=`du -hm /media/Lark/$1/$2 |cut -f 1` echo \"生成文件大小为 $dusize M\" if [ $dusize == $SIZE ] then echo \"文件生成成功！\" exit 0 fi done 将根文件备份到u盘123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169#! /bin/bash#################################### get img to u_disk ### ### 功能：将根文件备份到u盘 ### ##################################卸载备份区，保证/media/Lark下只挂载u盘if [ -d /media/Lark/.linuxroot ];then /bin/umount /media/Lark/.linuxrootfiif [ $UID -ne 0 ];then echo \"请切换root权限执行\" exit -5fiif [ $# -ne 2 ] then echo \"请输入 u盘名 镜像名称!\" exit -7fi#检测出u盘个数及盘符名LS_MEDIA_LARK=`ls /media/Lark`SELECTED_DISK=counter=0for file in `ls /media/Lark`docounter=`expr $counter + 1`done#echo $counterif [ $counter == 0 ] then #没有U盘插入，退出 echo \"没有插入u盘或者没有挂载盘符！！请检测u盘是否可正常识别!\" exit -1fi#echo \"LS_MEDIA_LARK is $LS_MEDIA_LARK \"DISK1=`echo $LS_MEDIA_LARK|awk -F ' ' '&#123;print $1&#125;'`DISK2=`echo $LS_MEDIA_LARK|awk -F ' ' '&#123;print $2&#125;'`#echo \"DISK1 is $DISK1,DISK2 is $DISK2\"echo \"检测目前根文件大小\" dupath=`du -m --total / --exclude=proc --exclude=media |grep 总用量 |cut -f 1` echo \"根文件大小为$dupath M\" #size=2700 #if [ $dupath -gt $size ];then #echo \"注意：当前系统生成镜像大于3GB，生成镜像文件不可使用Lark升级工具烧写，但可使用原厂工具烧写\" # exit 0 #fi #TODO :校验U盘可用空间，与根文件做对比 echo \"####生成根文件镜像####\" let SIZE=$dupath+10 echo \"生成文件大小为$SIZE M\" echo \"步骤一:选择存放镜像的U盘\" if false;then if [ -n \"$DISK2\" ] ;then echo \"共检测出u盘 $counter个：请选择1.$DISK1 2.$DISK2\" read CHOICE case $CHOICE in 1) echo \"你选择的u盘为$DISK1\" SELECTED_DISK=$DISK1 ;; 2) echo \"你选择的u盘为$DISK2\" SELECTED_DISK=$DISK2 ;; *) echo \"选择错误\" exit -2 ;; esac else SELECTED_DISK=$DISK1 fi fi SELECTED_DISK=$1 #检测所选u盘是剩余空间 DISK_SPACE=`df -hm /media/Lark/$SELECTED_DISK | sed -n \"2p\" | awk '&#123;print $4&#125;'` echo \"剩余空间为 $DISK_SPACE M\" if [ $SIZE -gt $DISK_SPACE ];then echo \"根文件大小大于备份区最大空间，请删减可删减的文件进行备份\" exit -3 fi echo \"步骤二:切换到U盘目录，且创建镜像文件，请耐心等待\" cd /media/Lark/$SELECTED_DISK if false;then #后台检测，一旦U盘断开，或者卸载，则退出此次操作 &#123; while true do CHECK_DISK=/media/Lark/$SELECTED_DISK if [ ! -d $CHECK_DISK ];then echo \"u盘已断开，请检测其连接性并重新执行\" echo exit -4 fi if [ $FLAGS == 1 ];then exit 0 fi done &#125;&amp; fi IMAGE_NAME=$2\".tmp\" echo \"步骤三:生成镜像名:$IMAGE_NAME\" touch $IMAGE_NAME echo \"步骤四：生成指定大小空文件\" dd if=/dev/zero of=$IMAGE_NAME bs=1M count=$SIZE if [ $? == 0 ] then echo \"步骤五：格式化镜像文件\" mkfs.ext4 -F -L .linuxroot $IMAGE_NAME else echo \"dd 操作失误\" exit -1; fi if [ $? == 0 ] then echo \"步骤六：挂载镜像文件到mnt目录\" mount -o loop $IMAGE_NAME /mnt if [ $? == 0 ] then echo \"步骤七：同步根分区到mnt\" rsync -axv / /mnt fi fi if [ $? == 0 ];then echo \"同步完成\" else echo \"同步失败，请重新执行\"fi if [ $? == 0 ] then #echo \"请卸载U盘\" cd /tmp umount /mnt if [ $? == 0 ] then echo \"挂载点已卸载\" fi fi echo \" 镜像已生成！\" sleep 3 #fuser -km /media/Lark/$SELECTED_DISK echo \"镜像修正以便烧写\" mv /media/Lark/$SELECTED_DISK/$IMAGE_NAME /media/Lark/$SELECTED_DISK/$2\".img\" umount /media/Lark/$SELECTED_DISK if [ $? == 0 ];then echo \"$SELECTED_DISK 已卸载成功\" exit 0 else echo \"请卸载并拔除U盘\" fi 系统备份123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#! /bin/bashif [ -d /media/Lark/.linuxroot ];then /bin/umount /media/Lark/.linuxrootfiecho \"检测目前根文件大小\" dupath=`du -m --total / --exclude=proc --exclude=media |grep 总用量 |cut -f 1` fssize=$dupath size=2500 if [ $fssize -gt $size ];then echo \"根文件大小大于备份区最大空间，请删减可删减的文件进行备份\" exit 0 fiecho \"检测系统一致性\" /sbin/e2fsck -f -y /dev/mmcblk0p6if [ $? -ne 0 ];then echo \"一致性检测失败，请检测重试\" exit 0fiecho \"扩展备份区到最大限额2.8G\" /sbin/resize2fs /dev/mmcblk0p6 2600Mif [ $? -ne 0 ];then echo \"扩大分区失败，请重试\" exit 0fiecho \"挂载系统备份区\"/bin/mount -o loop /dev/block/mtd/by-name/linuxfsbk /mntif [ $? -ne 0 ];then echo \"挂载系统备份区失败，请重试\" exit 0fiecho \"同步当前系统\"/usr/bin/rsync -axv --delete / /mnt if [ $? -ne 0 ];then echo \"同步当前系统失败，请重试\" echo \"卸载系统备份区\" /bin/umount /mnt if [ $? -ne 0 ];then echo \"卸载系统备份区失败，请重试\" exit 0 fi exit 0fiecho \"同步完成\"echo \"卸载系统备份区\"/bin/umount /mntif [ $? -ne 0 ];then echo \"卸载系统备份区失败，请重试\" exit 0fiecho \"系统备份成功 \"sleep 2","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://arvin-he.github.io/tags/Linux/"}]},{"title":"Web之REST概念","slug":"web-rest-2017-08-25","date":"2017-08-25T08:52:13.000Z","updated":"2017-09-08T03:51:40.204Z","comments":true,"path":"2017/08/25/web-rest-2017-08-25/","link":"","permalink":"http://arvin-he.github.io/2017/08/25/web-rest-2017-08-25/","excerpt":"","text":"REST当中为什么要使用HTTP PUTREST(Representational State Transfer)是网络服务接口的一种风格，并不是一个标准，就web service而言，REST要比SOAP（SOAP是标准，不是风格）轻量得多，容易得多。我记得我最初开始接触web service的时候，所有的材料上来就是一大堆的名词，SOAP, WSDL,看得头都要大了，后来提出来的REST就容易理解得多，虽然目前SOAP在企业级的web service中还有一席之地，但是在公共的Internet上，不是REST的服务实在不好意思和人打招呼，我们经常可以看到评价某某服务是RESTful的，但是从来没有听说某某服务是SOAPful的 :-)微软对REST的支持有点晚，自.NET3.5开始，WCF也可以提供RESTful接口。当然，REST不光限于web service，网页服务也可以RESTful，微软的ASP.NET MVC框架提供了直接的REST支持。 因为REST只是风格，不是标准，所以有的方面容易有误解，比如说创建和更新某个URI代表的资源的时候，是用HTTP的PUT还是POST命令。REST常用的四种HTTP命令，GET、DELETE、PUT和POST，对于GET和DELETE，一个是获取资源，一个是删除资源，没什么异议，问题是PUT和POST，两者都有更改指定URI的语义，那么，究竟是用哪一个呢？ 有的观点认为，应该用POST来创建一个资源，用PUT来更新一个资源；有的观点认为，应该用PUT来创建一个资源，用POST来更新一个资源；还有的观点认为可以用PUT和POST中任何一个来做创建或者更新一个资源。这些观点都只看到了风格，争论起来也只是争论哪种风格更好，其实，用PUT还是POST，不是看这是创建还是更新资源的动作，这不是风格的问题，而是语义的问题。 REST是一种风格，但是还是依赖于HTTP协议，在HTTP中，PUT被定义为idempotent(幂等)的方法，POST则不是，这是一个很重要的区别。 “Methods can also have the property of “idempotence” in that (aside from error or expiration issues) the side-effects of N &gt; 0 identical requests is the same as for a single request.” 上面的话就是说，如果一个方法重复执行多次，产生的效果是一样的，那就是idempotent的。 举一个简单的例子，加入由一个博客系统提供一个Web API，模式是这样http://superblogging/blogs/post/{blog-name}，很简单，将{blog-name}替换为我们的blog名字，往这个URI发送一个HTTP PUT或者POST请求，HTTP的body部分就是博文，这是一个很简单的REST API例子。我们应该用PUT方法还是POST方法？取决于这个REST服务的行为是否是idempotent的，假如我们发送两个http://superblogging/blogs/post/Sample请求，服务器端是什么样的行为？如果产生了两个博客帖子，那就说明这个服务不是idempotent的，因为多次使用产生了副作用了嘛；如果后一个请求把第一个请求覆盖掉了，那这个服务就是idempotent的。前一种情况，应该使用POST方法，后一种情况，应该使用PUT方法。 也许你会觉得这个两个方法的差别没什么大不了的，用错了也不会有什么问题，但是你的服务一放到internet上，如果不遵从HTTP协议的规范，就可能给自己带来麻烦。比如，没准Google Crawler也会访问你的服务，如果让一个不是indempotent的服务可以用indempotent的方法访问，那么你服务器的状态可能就会被Crawler修改，这是不应该发生的。 关于幂等的概念根据HTTP规范，GET用于信息获取，而且应该是安全的和幂等的。 (1).所谓安全的意味着该操作用于获取信息而非修改信息。换句话说，GET 请求一般不应产生副作用。就是说，它仅仅是获取资源信息，就像数据库查询一样，不会修改，增加数据，不会影响资源的状态。 * 注意：这里安全的含义仅仅是指是非修改信息。 (2).幂等的意味着对同一URL的多个请求应该返回同样的结果。这里我再解释一下幂等这个概念： 幂等（idempotent、idempotence）是一个数学或计算机学概念，常见于抽象代数中。幂等有一下几种定义：对于单目运算，如果一个运算对于在范围内的所有的一个数多次进行该运算所得的结果和进行一次该运算所得的结果是一样的，那么我们就称该运算是幂等的。比如绝对值运算就是一个例子，在实数集中，有abs(a)=abs(abs(a))。 对于双目运算，则要求当参与运算的两个值是等值的情况下，如果满足运算结果与参与运算的两个值相等，则称该运算幂等，如求两个数的最大值的函数，有在在实数集中幂等，即max(x,x) = x。看完上述解释后，应该可以理解GET幂等的含义了。 但在实际应用中，以上2条规定并没有这么严格。引用别人文章的例子：比如，新闻站点的头版不断更新。虽然第二次请求会返回不同的一批新闻，该操作仍然被认为是安全的和幂等的，因为它总是返回当前的新闻。从根本上说，如果目标是当用户打开一个链接时，他可以确信从自身的角度来看没有改变资源即可。 参考 REST当中为什么要使用HTTP PUT 浅谈HTTP中Get与Post的区别","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Web","slug":"Web","permalink":"http://arvin-he.github.io/tags/Web/"}]},{"title":"Web之Get和Post区别","slug":"web-getpost-2017-08-25","date":"2017-08-25T07:22:07.000Z","updated":"2017-09-08T03:51:40.201Z","comments":true,"path":"2017/08/25/web-getpost-2017-08-25/","link":"","permalink":"http://arvin-he.github.io/2017/08/25/web-getpost-2017-08-25/","excerpt":"","text":"两种 HTTP 请求方法：GET 和 POST在客户机和服务器之间进行请求-响应时，两种最常被用到的方法是：GET 和 POST。 GET - 从指定的资源请求数据。 POST - 向指定的资源提交要被处理的数据 GET 方法请注意，查询字符串（名称/值对）是在 GET 请求的 URL 中发送的：/test/demo_form.asp?name1=value1&amp;name2=value2 有关 GET 请求的其他一些注释： GET 请求可被缓存 GET 请求保留在浏览器历史记录中 GET 请求可被收藏为书签 GET 请求不应在处理敏感数据时使用 GET 请求有长度限制 GET 请求只应当用于取回数据 POST 方法请注意，查询字符串（名称/值对）是在 POST 请求的 HTTP 消息主体中发送的：123POST /test/demo_form.asp HTTP/1.1Host: w3schools.comname1=value1&amp;name2=value2 有关 POST 请求的其他一些注释： OST 请求不会被缓存 POST 请求不会保留在浏览器历史记录中 POST 不能被收藏为书签 POST 请求对数据长度没有要求 GET 与 POST区别 GET提交的数据会放在URL之后，以?分割URL和传输数据，参数之间以&amp;相连，如EditPosts.aspx?name=test1&amp;id=123456. POST方法是把提交的数据放在HTTP包的Body中. GET提交的数据大小有限制（因为浏览器对URL的长度有限制），而POST方法提交的数据没有限制. GET方式需要使用Request.QueryString来取得变量的值，而POST方式通过Request.Form来获取变量的值。 GET方式提交数据，会带来安全问题，比如一个登录页面，通过GET方式提交数据时，用户名和密码将出现在URL上，如果页面可以被缓存或者其他人可以访问这台机器，就可以从历史记录获得该用户的账号和密码. 一些误区误区一：POST可以比GET提交更多更长的数据？由于使用GET方法提交数据时，以?分割URL和传输数据，参数之间以&amp;相连，在URL后面添加需要提交的参数，有人就会说了，浏览器地址栏输入的参数是有限的，而POST不用再地址栏输入，所以POST就比GET可以提交更多的数据。难道真的是这样的么？而实际上，URL不存在参数上限的问题，HTTP协议规范没有对URL长度进行限制。这个限制是特定的浏览器及服务器对它的限制。IE对URL长度的限制是2083字节(2K+35)。对于其他浏览器，如Netscape、FireFox等，理论上没有长度限制，其限制取决于操作系统的支持。同时，POST是没有大小限制的，HTTP协议规范也没有进行大小限制。POST数据是没有限制的，起限制作用的是服务器的处理程序的处理能力。总归一句话，这个限制是针对所有HTTP请求的，与GET、POST没有多少关系。 误区二：POST比GET安全？首先，我们要承认安全的概念有很多种，要是从最基本的肉眼看到就不安全，肉眼看不到那就是安全的概念说呢，GET确实没有POST安全，毕竟小白用户确实可以看到在URL中带有的数据信息，这个你无法狡辩。那么要是往严谨了说呢，POST是不是要比GET安全呢？其实不是的。上面也说了，GET将提交到服务器的数据添加到URL中了，可见；虽然POST的数据，你肉眼看不到，你抓个包看看，在HTTP包的包体中，我们提交的数据时仍然可见的. 比较GET 与 POST下面的表格比较了两种 HTTP 方法：GET 和 POST。 GET POST 后退按钮/刷新 无害 数据会被重新提交（浏览器应该告知用户数据会被重新提交）。 书签 可收藏为书签 不可收藏为书签 缓存 能被缓存 不能缓存 编码类型 application/x-www-form-urlencoded application/x-www-form-urlencoded 或 multipart/form-data。为二进制数据使用多重编码。 历史 参数保留在浏览器历史中。 参数不会保存在浏览器历史中。 对数据长度的限制 是的。当发送数据时，GET 方法向 URL 添加数据；URL 的长度是受限制的（URL 的最大长度是 2048 个字符）。 无限制。 对数据类型的限制 只允许 ASCII 字符。 没有限制。也允许二进制数据。 安全性 与 POST 相比，GET 的安全性较差，因为所发送的数据是 URL 的一部分。在发送密码或其他敏感信息时绝不要使用 GET ！ POST 比 GET 更安全，因为参数不会被保存在浏览器历史或 web 服务器日志中。 可见性 数据在 URL 中对所有人都是可见的。 数据不会显示在 URL 中。 写在最后很多时候，大家都觉的使用GET很方便，毕竟使用POST要用到Form，但是，你要知道，你使用GET方法时，浏览器可能会缓存你的地址等信息，还会留下历史记录，而对于POST方法呢，则不会进行缓存。在开发中，一定要分清楚GET和POST的使用场合，什么时候要使用GET，什么时候要使用POST，自己做到心中有数。 可能，你在Google类似的文章的时候，可能会看到分析POST和PUT区别的文章，这又是一类纠结的东西，更多的时候，我们分析这种东西都是分实际情景，结合设计者的语义去使用. 参考 w3cschool","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Web","slug":"Web","permalink":"http://arvin-he.github.io/tags/Web/"}]},{"title":"爬虫基础知识(一)","slug":"py-spider1-2017-08-25","date":"2017-08-25T06:12:06.000Z","updated":"2018-01-16T03:47:51.457Z","comments":true,"path":"2017/08/25/py-spider1-2017-08-25/","link":"","permalink":"http://arvin-he.github.io/2017/08/25/py-spider1-2017-08-25/","excerpt":"","text":"1. URLURL的格式由三部分组成：第一部分是协议(或称为服务方式)。第二部分是存有该资源的主机IP地址(有时也包括端口号)。第三部分是主机资源的具体地址，如目录和文件名等。 爬虫爬取数据时必须要有一个目标的URL才可以获取数据，因此，它是爬虫获取数据的基本依据，准确理解它的含义对爬虫学习有很大帮助。 关于urllib2包python 3.X版本是不需要安装urllib2包，urllib和urllib2包集合成在一个包为urllib了.在python3.x版本中，如何使用：urllib2.urlopen()？12345678910import urllibimport urllib.requestresponse = urllib.request.urlopen(\"http://www.baidu.com\")print(response.read())URL = \"http://www.baidu.com\"request = urllib.request.Request(URL)response = urllib.request.urlopen(request)print(response.read()) POST和GET数据传送大多数网站都是动态网页，需要你动态地传递参数给它，它做出对应的响应。所以，在访问时，我们需要传递数据给它。 urlopen一般接受三个参数，它的参数如下：urlopen(url, data, timeout)第一个参数url即为URL，第二个参数data是访问URL时要传送的数据，第三个timeout是设置超时时间。第二,三个参数是可以不传送的，data默认为空None，timeout默认为 socket._GLOBAL_DEFAULT_TIMEOUT POST方式：12345678import urllib values = &#123;\"username\":\"xxxx@qq.com\",\"password\":\"XXXX\"&#125;data = urllib.urlencode(values) url = \"https://passport.csdn.net/account/login?from=http://my.csdn.net/my/mycsdn\"request = urllib.request.Request(url, data)response = urllib.request.urlopen(request)print(response.read()) GET方式：至于GET方式我们可以直接把参数写到网址上面，直接构建一个带参数的URL出来即可。1234567891011import urllib values=&#123;&#125;values['username'] = \"xxxx@qq.com\"values['password']=\"XXXX\"data = urllib.urlencode(values) url = \"http://passport.csdn.net/account/login\"geturl = url + \"?\" + datarequest = urllib.request.Request(geturl)response = urllib.request.urlopen(request)print(response.read()) python3中urllib的模块分4个子模块urllib.request for opening and reading URLsurllib.error containing the exceptions raised by urllib.requesturllib.parse for parsing URLsurllib.robotparser for parsing robots.txt files python3中urllib报错 爬虫过程报错：http.client.RemoteDisconnected: Remote end closed connection without response 利用 urllib 发起的请求，UA 默认是 Python-urllib/3.5 而在 chrome 中访问则 user_agent = ‘Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36’，因为服务器根据 UA 来判断拒绝了 python 爬虫。 在浏览器中可以查看自己浏览器的UA","categories":[{"name":"python","slug":"python","permalink":"http://arvin-he.github.io/categories/python/"}],"tags":[{"name":"scrapy","slug":"scrapy","permalink":"http://arvin-he.github.io/tags/scrapy/"}]},{"title":"Python之jsonrpc","slug":"py-jsonrpc-2017-08-25","date":"2017-08-25T03:38:39.000Z","updated":"2017-09-08T03:51:39.871Z","comments":true,"path":"2017/08/25/py-jsonrpc-2017-08-25/","link":"","permalink":"http://arvin-he.github.io/2017/08/25/py-jsonrpc-2017-08-25/","excerpt":"","text":"服务端123456789101112131415161718192021222324252627282930313233343536373839# serverfrom http.server import BaseHTTPRequestHandler, HTTPServerfrom jsonrpcserver import methods@methods.adddef ping(): return('ping')@methods.adddef hao(): return('hao')@methods.adddef hello(name): return('Hello, %s' % name)@methods.adddef Sum(a, b): return(a + b)class TestHttpServer(BaseHTTPRequestHandler): def do_POST(self): # Process request request = self.rfile.read(int(self.headers['Content-Length'])).decode() response = methods.dispatch(request) # Return response self.send_response(response.http_status) self.send_header('Content-type', 'application/json') self.end_headers() self.wfile.write(str(response).encode())if __name__ == '__main__': HTTPServer(('localhost', 5000), TestHttpServer).serve_forever() 客户端1234567from jsonrpcclient.http_client import HTTPClientHTTPClient('http://localhost:5000').request('ping')HTTPClient('http://localhost:5000').request('hao')HTTPClient('http://localhost:5000').request('hello', 'Nancy')HTTPClient('http://localhost:5000').request('Sum', 5, 7)HTTPClient('http://localhost:5000').request('lid') 先运行服务端,再运行客户端代码 结果12345678910111213141516171819202122--&gt; &#123;&quot;id&quot;: 1, &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;method&quot;: &quot;ping&quot;&#125;&lt;-- &#123;&quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;result&quot;: &quot;ping&quot;, &quot;id&quot;: 1&#125; (200 OK)--&gt; &#123;&quot;id&quot;: 2, &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;method&quot;: &quot;hao&quot;&#125;&lt;-- &#123;&quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;result&quot;: &quot;hao&quot;, &quot;id&quot;: 2&#125; (200 OK)--&gt; &#123;&quot;params&quot;: [&quot;Nancy&quot;], &quot;id&quot;: 3, &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;method&quot;: &quot;hello&quot;&#125;&lt;-- &#123;&quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;result&quot;: &quot;Hello, Nancy&quot;, &quot;id&quot;: 3&#125; (200 OK)--&gt; &#123;&quot;params&quot;: [5, 7], &quot;id&quot;: 4, &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;method&quot;: &quot;Sum&quot;&#125;&lt;-- &#123;&quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;result&quot;: 12, &quot;id&quot;: 4&#125; (200 OK)--&gt; &#123;&quot;id&quot;: 5, &quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;method&quot;: &quot;lid&quot;&#125;&lt;-- &#123;&quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;error&quot;: &#123;&quot;code&quot;: -32601, &quot;message&quot;: &quot;Method not found&quot;&#125;, &quot;id&quot;: 5&#125; (404 Not Found)Traceback (most recent call last): File &quot;js_client.py&quot;, line 7, in &lt;module&gt; HTTPClient(&apos;http://localhost:5000&apos;).request(&apos;lid&apos;) File &quot;C:\\Python34\\lib\\site-packages\\jsonrpcclient\\client.py&quot;, line 200, in request return self.send(Request(method_name, *args, **kwargs)) File &quot;C:\\Python34\\lib\\site-packages\\jsonrpcclient\\client.py&quot;, line 171, in send return self._send_message(request, **kwargs) File &quot;C:\\Python34\\lib\\site-packages\\jsonrpcclient\\http_client.py&quot;, line 82, in _send_message log_format=&apos;&lt;-- %(message)s (%(http_code)s %(http_reason)s)&apos;) File &quot;C:\\Python34\\lib\\site-packages\\jsonrpcclient\\client.py&quot;, line 114, in _process_response response[&apos;error&apos;].get(&apos;data&apos;))jsonrpcclient.exceptions.ReceivedErrorResponse: Method not found","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"正向代理和反向代理","slug":"web-forwardbackagent-2017-08-24","date":"2017-08-24T06:56:13.000Z","updated":"2017-09-08T03:51:40.194Z","comments":true,"path":"2017/08/24/web-forwardbackagent-2017-08-24/","link":"","permalink":"http://arvin-he.github.io/2017/08/24/web-forwardbackagent-2017-08-24/","excerpt":"","text":"正向代理我们常说的代理也就是只正向代理，正向代理的过程，它隐藏了真实的请求客户端，服务端不知道真实的客户端是谁，客户端请求的服务都被代理服务器代替来请求，某些科学上网工具扮演的就是典型的正向代理角色。用浏览器访问 http://www.google.com 时，被残忍的block，于是你可以在国外搭建一台代理服务器，让代理帮我去请求google.com，代理把请求返回的相应结构再返回给我. 反向代理反向代理隐藏了真实的服务端，当我们请求 www.baidu.com 的时候，就像拨打10086一样，背后可能有成千上万台服务器为我们服务，但具体是哪一台，你不知道，也不需要知道，你只需要知道反向代理服务器是谁就好了，www.baidu.com 就是我们的反向代理服务器，反向代理服务器会帮我们把请求转发到真实的服务器那里去。Nginx就是性能非常好的反向代理服务器，用来做负载均衡. 两者的区别在于代理的对象不一样：正向代理代理的对象是客户端，反向代理代理的对象是服务端 参考 知乎","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"web","slug":"web","permalink":"http://arvin-he.github.io/tags/web/"}]},{"title":"Python爬虫总结","slug":"py-scrapysummer-2017-08-23","date":"2017-08-23T03:38:57.000Z","updated":"2018-01-15T09:43:33.961Z","comments":true,"path":"2017/08/23/py-scrapysummer-2017-08-23/","link":"","permalink":"http://arvin-he.github.io/2017/08/23/py-scrapysummer-2017-08-23/","excerpt":"","text":"爬虫需要用到的工具正则表达式XPATHbeautifulsouprequestsurlliburllib2scrapy 分布式爬虫学会怎样维护一个所有集群机器能够有效分享的分布式队列就好。最简单的实现是python-rq: https://github.com/nvie/rq Bloom Filter: Bloom Filters by ExampleBloom Filter. 简单讲它仍然是一种hash的方法，但是它的特点是，它可以使用固定的内存（不随url的数量而增长）以O(1)的效率判定url是否已经在set中。可惜天下没有白吃的午餐，它的唯一问题在于，如果这个url不在set中，BF可以100%确定这个url没有看过。但是如果这个url在set中，它会告诉你：这个url应该已经出现过，不过我有2%的不确定性。注意这里的不确定性在你分配的内存足够大的时候，可以变得很小很少。一个简单的教程:Bloom Filters by Example rq和Scrapy的结合：后续处理，网页析取，存储(Mongodb) 你只有一台机器。不管你的带宽有多大，只要你的机器下载网页的速度是瓶颈的话，那么你只有加快这个速度。用一台机子不够的话——用很多台吧！当然，我们假设每台机子都已经进了最大的效率——使用多线程（python的话，多进程吧）。 我们把这100台中的99台运算能力较小的机器叫作slave，另外一台较大的机器叫作master，那么回顾上面代码中的url_queue，如果我们能把这个queue放到这台master机器上，所有的slave都可以通过网络跟master联通，每当一个slave完成下载一个网页，就向master请求一个新的网页来抓取。而每次slave新抓到一个网页，就把这个网页上所有的链接送到master的queue里去。同样，bloom filter也放到master上，但是现在master只发送确定没有被访问过的url给slave。Bloom Filter放到master的内存里，而被访问过的url放到运行在master上的Redis里，这样保证所有操作都是O(1)。（至少平摊是O(1)，Redis的访问效率见:LINSERT – Redis) 考虑如何用python实现：在各台slave上装好scrapy，那么各台机子就变成了一台有抓取能力的slave，在master上装好Redis和rq用作分布式队列。 chrome浏览器 F12开发者工具 seleniumphantomjs PILopencvpybrainpyspider 代理IP池 不要用1个IP狂抓勤换UA爬取间隔自适应 scrapy/pyspider框架部署 https://www.zhihu.com/question/20899988","categories":[{"name":"python","slug":"python","permalink":"http://arvin-he.github.io/categories/python/"}],"tags":[{"name":"scrapy","slug":"scrapy","permalink":"http://arvin-he.github.io/tags/scrapy/"}]},{"title":"linux开机自启","slug":"linux-bash1-2017-08-18","date":"2017-08-18T01:51:19.000Z","updated":"2017-09-08T03:51:39.757Z","comments":true,"path":"2017/08/18/linux-bash1-2017-08-18/","link":"","permalink":"http://arvin-he.github.io/2017/08/18/linux-bash1-2017-08-18/","excerpt":"","text":"Linux下终端执行自定义命令启动程序在/usr/bin目录下一般会存放一个shell脚本,然后在终端输入该shell脚本的名字,就会在终端执行这个shell脚本.1234567891011#!/bin/sh# 搜索进程中touchpanel的进程数目,这里是为了保持脚本执行的单个实例var=`ps -aux |grep \"/usr/bin/touchpanel\" |wc -l`# 注意空格不能少if [ $var -gt 3 ];then exitficd /opt/touchpanelsudo python3 main.py $@ Linux下如何开机自启应用程序编写一个*.desktop文件,然后将该文件放在/etc/xdg/autostart下,然后就会开机自动启动应用程序123456789[Desktop Entry]Type=ApplicationIcon=Name=TouchPanelComment=xxxCategories=GNOME;GTK;System;Exec=touchpanelStartupNotify=trueTerminal=false 制作deb安装包12345678910111213141516171819202122232425#!/bin/shecho \"1. 获取版本号\"version=`awk 'NR==2&#123;print $2&#125;' deb/DEBIAN/control`echo \"version = $&#123;version&#125;\"echo \"2. 拷贝资源文件\"mkdir -p deb/opt/pun-admin/resmkdir -p deb/usr/binmkdir -p deb/usr/share/applicationsmkdir -p deb/usr/share/pixmapscp res/*.ui deb/opt/pun-admin/res/cp res/config.ini deb/opt/pun-admin/res/cp res/pun.desktop deb/opt/pun-admin/res/cp res/pun-admin.desktop deb/usr/share/applications/cp res/*.png deb/usr/share/pixmaps/cp res/pun-admin deb/usr/bin/cp res/touchpanel.desktop deb/opt/pun-admin/res/cp res/touchpanel deb/usr/bin/echo \"3. 拷贝程序\"cp *.py deb/opt/pun-admin/echo \"4. 添加可执行权限\"chmod +x deb/usr/bin/pun-adminchmod +x deb/usr/bin/touchpanelecho \"5. dpkg打包\"dpkg-deb --build deb pun-admin-$&#123;version&#125;.debecho \"6. 打包结束\"","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://arvin-he.github.io/tags/Linux/"}]},{"title":"Python的sys.path, PYTHONPATH, os.environ的作用","slug":"py-pyhonpath-2017-08-13","date":"2017-08-13T11:06:37.000Z","updated":"2017-09-08T03:51:39.881Z","comments":true,"path":"2017/08/13/py-pyhonpath-2017-08-13/","link":"","permalink":"http://arvin-he.github.io/2017/08/13/py-pyhonpath-2017-08-13/","excerpt":"","text":"Python搜索模块的路径： 程序的主目录 PTYHONPATH目录（如果已经进行了设置） 标准连接库目录（一般在/usr/local/lib/python2.X/） 任何的.pth文件的内容（如果存在的话）.新功能，允许用户把有效果的目录添加到模块搜索路径中去, .pth后缀的文本文件中一行一行的地列出目录。 这四个组建组合起来就变成了sys.path了 关于sys.path在python 环境下使用sys.path.append(path)添加相关的路径，但在退出python环境后自己添加的路径就会自动消失.如何将路径“永久”添加到sys.path? 将自己做的py文件放到 site_packages 目录下,但是这样做会导致一个问题，即各类模块都放到此文件夹的话，会导致乱的问题. 使用pth文件，在 site-packages 文件中创建 .pth文件，将模块的路径写进去，一行一个路径，但存在管理上的问题，而且不能在不同的python版本中共享。 使用PYTHONPATH环境变量，在这个环境变量中输入相关的路径，不同的路径之间用逗号（英文的！)分开，如果PYTHONPATH 变量还不存在，可以创建它.路径会自动加入到sys.path中，而且可以在不同的python版本中共享，应该是一样较为方便的方法。 1234567891011121314In [16]: sys.pathOut[16]:['', 'C:\\\\Program Files\\\\Python36\\\\Scripts\\\\ipython.exe', 'c:\\\\program files\\\\python36\\\\python36.zip', 'c:\\\\program files\\\\python36\\\\DLLs', 'c:\\\\program files\\\\python36\\\\lib', 'c:\\\\program files\\\\python36', 'c:\\\\program files\\\\python36\\\\lib\\\\site-packages', 'c:\\\\program files\\\\python36\\\\lib\\\\site-packages\\\\win32', 'c:\\\\program files\\\\python36\\\\lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\program files\\\\python36\\\\lib\\\\site-packages\\\\Pythonwin', 'c:\\\\program files\\\\python36\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\Arvin\\\\.ipython'] 关于PYTHONPATH关于os.environ1234567891011121314151617environ是一个字符串对应环境的映像对象os.environ.keys() 主目录下所有的keyos.environ 显示key+内容# windows：· os.environ[&apos;HOMEPATH&apos;]:当前用户主目录。os.environ[&apos;TEMP&apos;]:临时目录路径。os.environ[PATHEXT&apos;]:可执行文件。os.environ[&apos;SYSTEMROOT&apos;]:系统主目录。os.environ[&apos;LOGONSERVER&apos;]:机器名。os.environ[&apos;PROMPT&apos;]:设置提示符。# linux：os.environ[&apos;USER&apos;]:当前使用用户。os.environ[&apos;LC_COLLATE&apos;]:路径扩展的结果排序时的字母顺序。os.environ[&apos;SHELL&apos;]:使用shell的类型。os.environ[&apos;LAN&apos;]:使用的语言。os.environ[&apos;SSH_AUTH_SOCK&apos;]:ssh的执行路径。","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"PyQt5加载ui的几种方式","slug":"pyqt-loadui-2017-08-12","date":"2017-08-12T02:52:06.000Z","updated":"2017-09-08T03:51:39.964Z","comments":true,"path":"2017/08/12/pyqt-loadui-2017-08-12/","link":"","permalink":"http://arvin-he.github.io/2017/08/12/pyqt-loadui-2017-08-12/","excerpt":"","text":"前言一般界面的创建有两种方式: 使用纯代码实现 使用designer来拖拽控件两种方式各有各自的好处,视具体的使用场景来选择. 使用纯代码实现时一些属性需要在代码中指定, 或者继承某个控件类并定制添加一些属性和功能.这种方式比较灵活.但是控件太多且是不同种类的控件的话就有点繁琐了. 使用designer的方式是直观,快速,属性可视化,可添加动态属性,这也是使用比较多的方式.在designer中设计好界面后,保存为一个后缀为ui的文件,用文本编辑器打开是一个xml格式的文件,里面指明控件的各个属性. 下面就讲述在代码中加载ui的几种方式. PyQt5中加载ui的方式PyQt5中加载ui的方式主要有3种: 直接加载ui文件 将ui文件转成py文件加载 将所有的资源文件(包括ui,图片等)编译成内容是字节的py文件加载 直接加载ui文件使用uic加载ui文件,看下面代码12345678from PyQt5 import QtWidgets, uic, QtCoreclass MyDialog(QtWidgets.QDialog): def __init__(self): super(MyDialog, self).__init__() uic.loadUi(os.path.join(os.path.dirname(__file__), \"yourDialog.ui\"), self) self.initUI() ui的控件直接通过self来获取访问,比如self.mylabel.setText(&quot;xxx&quot;),这是最直接的方式.适用于简单的界面设计. 将ui文件转成py文件加载Qt Designer默认继承的object类，但不提供show()显示方法.如何将ui文件转为py文件?使用pyqt5中自带的工具pyuic5,pyuic5是一个可执行文件,在控制台可作为命令使用,具体使用参考下面的脚本12345678910111213141516# -*- coding:utf-8 -*-import osimport sysimport subprocessinputFile = os.path.abspath(os.path.join(\"../res\", \"serialCom.ui\"))print(\"input file =&#123;&#125;\".format(inputFile))outputFile = os.path.abspath(\"../serialCom_ui.py\")print(\"output file =&#123;&#125;\".format(outputFile))try: # py3.4.3 subprocess.call([\"pyuic5.bat\", inputFile, \"-o\", outputFile])except: # py3.6 subprocess.call([\"pyuic5\", inputFile, \"-o\", outputFile])print(\"build ui done.\") 根据上面的脚本会根据ui文件生成一个py文件,那么这个py文件有哪些内容呢?12345678910111213141516from PyQt5 import QtCore, QtGui, QtWidgetsclass Ui_serialDlg(object): def setupUi(self, serialDlg): serialDlg.setObjectName(\"serialDlg\") serialDlg.resize(1024, 768) sizePolicy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Fixed, QtWidgets.QSizePolicy.Fixed) # 这里省略了ui控件的属性设定 ... self.retranslateUi(serialDlg) QtCore.QMetaObject.connectSlotsByName(serialDlg) def retranslateUi(self, serialDlg): _translate = QtCore.QCoreApplication.translate # 这里略去了各种翻译的内容 ... 从这个py看出,这个py文件生成了一个类,里面有2个函数,分别是setupUi和retranslateUi.setupUi中主要是控件的各个属性设置, retranslateUi主要是翻译的内容下面如何在你的代码中加载这个py文件呢?有两种方式第一种: 直接继承这个类, python中支持多继承123456from serialCom_ui import Ui_serialDlg as serialDlgclass MainWindow(QDialog, serialDlg): def __init__(self): super(MainWindow, self).__init__() self.setupUi(self) 第二种: 在你的代码中实例化1234567from serialCom_ui import Ui_serialDlg as serialDlgclass MainWindow(QDialog): def __init__(self): super(MainWindow, self).__init__() self.serial_dlg=serialDlg() self.serial_dlg.setupUi(self) 为什么要生成py文件呢?主要是为了实现代码与界面分离。缺点:ui文件有了更改,必须要再次生成对应的py文件,如果你忘记生成了,就会造成ui不同步.优点:不再需要这个ui文件了.这就相当于使用纯代码的实现方式了.但这样的方式显然比纯代码要快,而且能做到逻辑代码和界面代码分离. 生成qrc文件编译资源文件生成py文件加载当有ui文件还有图片等资源文件时,怎么办呢?当图片重命名了怎么办? 当然是利用Qt的资源系统来整合这些资源文件了.Qt 资源系统是一个跨平台的资源机制，用于将程序运行时所需要的资源以二进制的形式存储于可执行文件内部。如果你的程序需要加载特定的资源（图标、文本翻译等），那么，将其放置在资源文件中，就再也不需要担心这些文件的丢失。也就是说，如果你将资源以资源文件形式存储，它是会编译到可执行文件内部。怎么做呢?一般把用到的资源文件放到一个文件夹中,如res/,然后创建一个资源文件*.qrc,该文件生成在res文件夹中qrc文件的内容有,如下:123456&lt;RCC&gt;&lt;qresource prefix=&quot;..&quot;&gt; &lt;file mtime=&quot;1502414194.7463503&quot;&gt;favor.ico&lt;/file&gt; &lt;file mtime=&quot;1494807198.7998164&quot;&gt;favor.png&lt;/file&gt; &lt;file mtime=&quot;1502505175.56&quot;&gt;serialCom.ui&lt;/file&gt; &lt;file mtime=&quot;1502414207.032053&quot;&gt;uninst.ico&lt;/file&gt;&lt;/qresource&gt;&lt;/RCC&gt; python中创建qrc文件,然后通过pyrcc5将资源文件编译到py文件中去这里不仅仅生成qrc文件,还对qrc文件记录了资源文件最后的修改时间,并做了修改时间对比,一旦有ui文件被修改了,就会重新编译生成res_rc.py文件.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# 自动编译加载资源_res_path = os.path.abspath('res')RCC = \"\"\"&lt;RCC&gt;&lt;qresource prefix=\"&#123;&#125;\"&gt;\\n&#123;&#125;&lt;/qresource&gt;&lt;/RCC&gt;\"\"\"FILE = \"\"\" &lt;file mtime=\"&#123;&#125;\"&gt;&#123;&#125;&lt;/file&gt;\\n\"\"\"def _loadRes(res, root): # res文件夹的路径 package = os.path.dirname(res) # 生成资源清单数据 res_files = [] for a, _, files in os.walk(res): for f in files: if f == \"res.qrc\" or f.endswith(\".ts\"): continue ff = os.path.join(a, f) res_files.append((os.path.getmtime(ff), os.path.relpath( ff, res).replace(os.path.sep, \"/\"))) res_qrc_data = RCC.format( os.path.relpath(package, root).replace(os.path.sep, \"/\"), \"\".join([FILE.format(*x) for x in res_files])) # 更新资源清单 res_qrc = os.path.join(res, \"res.qrc\") res_updated = False # 检查现有资源清单是否已是最新 if os.path.exists(res_qrc): with open(res_qrc, \"r\", encoding=\"utf-8\") as f: res_updated = f.read() == res_qrc_data # 更新资源清单 if not res_updated: with open(res_qrc, \"w\", encoding=\"utf-8\") as f: f.write(res_qrc_data) # 编译资源清单 res_rc_py = os.path.join(package, \"res_rc.py\") if not os.path.exists(res_rc_py) or \\ os.path.getmtime(res_rc_py) &lt; os.path.getmtime(res_qrc): # 通过指定 `cwd` 解决 win32 下 pyrcc5 不支持中文路径的问题 rel_res_rc_py = os.path.relpath(res_rc_py, package) rel_res_qrc = os.path.relpath(res_qrc, package) subprocess.check_call( [\"pyrcc5\", \"-o\", rel_res_rc_py, rel_res_qrc], cwd=package)# 加载资源for path, b, c in os.walk(_res_path): if path.endswith(os.path.sep + \"res\"): _loadRes(path, _res_path) 有了res_rc.py文件,然后将res_rc.py文件import进来,然后让问资源文件通过指定路径访问.12345from PyQt5 import QtCoreimport res_rc# :不能少, 路径就是qrc里的prefix+资源文件名pixmap = QPixamp(\":/prefix/download.jpeg\") 或者1234567891011121314151617181920def loadUi(widget, uiFileName): \"\"\"加载 ui. 从 uiFileName 指定的 ui 文件加载.\"\"\" f = QtCore.QFile(uiFileName) f.open(QtCore.QFile.ReadOnly | QtCore.QFile.Text) assert f.isOpen() ts = QtCore.QTextStream(f) ts.setCodec(\"utf-8\") code_string = io.StringIO() winfo = uic.compiler.UICompiler().compileUi(ts, code_string, True, \"_rc\") ui_globals = &#123;\"__name__\": widget.__module__&#125; exec(code_string.getvalue(), ui_globals) Ui = ui_globals[winfo[\"uiclass\"]] ui = Ui() ui.setupUi(widget) return uiclass MainWindow(QDialog, serialDlg): def __init__(self): super(MainWindow, self).__init__() self.ui = loadUi(self, \":../serialCom.ui\") 然后所有ui里的控件对象都可以使用self.ui来访问了.","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"PyQt5","slug":"PyQt5","permalink":"http://arvin-he.github.io/tags/PyQt5/"}]},{"title":"Python代码结构","slug":"py-codestruct-2017-08-11","date":"2017-08-11T09:00:33.000Z","updated":"2017-09-08T03:51:39.834Z","comments":true,"path":"2017/08/11/py-codestruct-2017-08-11/","link":"","permalink":"http://arvin-he.github.io/2017/08/11/py-codestruct-2017-08-11/","excerpt":"","text":"构造项目层次结构文件夹的最佳方式是什么？理想的特性是易于维护，IDE-friendliness，源代码管理分支/合并的适用性，以及易于生成的软件包。特别是： 在哪里放置源代码？ 在哪里放置应用程序启动脚本？ 将IDE项目放在哪里？ 在哪里放置单元/验收测试？ 在哪里放置non-Python数据如配置文件？ 在哪里放置non-Python源(如 C++) 用于 pyd/二进制扩展模块？ 文件系统 python 项目的结构执行： 命名与你的项目相关的目录。 例如如果你的项目名为”Twisted”，则为它的源文件命名为top-level目录 Twisted 。 当你发布时，应该包含版本号后缀： Twisted-2.5 。 创建一个目录 Twisted/bin 并将你的可执行文件放在那里，如果你有任何不给他们一个 .py 扩展，即使它们是 python 源文件。 不要将任何代码放入其中，除非导入和调用在你的项目中定义的主函数。 ( 轻微皱纹：在 Windows 上，解释器是由文件扩展名选择的，你的Windows 用户实际上想要. py扩展。 因此，当你为 Windows 打包时，你可能想要添加它。 不幸的是，我不知道如何让这个过程自动化。 考虑到在POSIX上，. py 扩展是一个惟一的缺点，而在 Windows 上，缺少的是一个实际的Bug，如果你的userbase包含 Windows 用户，那么你可能想要选择. py 扩展。) 如果你的项目是作为单个 python expressable源文件,然后把它放到目录和名称与你的项目相关的东西。 例如 Twisted/twisted.py 。如果你需要多个源文件，请创建一个软件包，并将源文件放入其中。 例如 Twisted/twisted/internet.py 。 把你的单元测试的sub-package ( 注意:这意味着单一 python 源文件选项上面是一个技巧——你总是需要至少一个其他文件为你的单元测试) 你的包。 例如 Twisted/twisted/test/ 。当然，让它成为一个带有 Twisted/twisted/test/__init__.py的包。 将测试放在文件中 Twisted/twisted/test/test_internet.py 添加 Twisted/README 和 Twisted/setup.py 来解释并安装你的软件，如果你觉得不错的话。 不要： 将你的源放在一个名为 src 或者 lib的目录中。 这使得没有安装就很难运行。 将测试放在 python 软件包之外。 这使得对已经安装版本运行测试变得困难。 创建一个包,只有 __init__.py 然后把所有代码放进 __init__.py 。 只是做一个模块而不是一个包，它更简单。 试图让 python 能够导入你的模块或者包，而不让用户将包含它的目录添加到导入路径( 或者通过PYTHONPATH或者其他的机制) 。 你不将正确处理所有情况下,用户会生气你当你的软件并不在他们的环境中工作。 一个项目目录组织方式1234567891011121314Project/|-- bin/| |-- project||-- project/| |-- test/| | |-- __init__.py| | |-- test_main.py| | | |-- __init__.py| |-- main.py||-- setup.py|-- README 另一个项目目录组织方式当设置一个项目时，( 或者目录结构)的布局是很重要的。 合理的布局意味着潜在的贡献者不必花费大量的时间去寻找一段代码；文件位置是直观的。 因为我们正在处理一个现有项目，这意味着你可能需要移动一些东西。让我们从头开始。 大多数项目有许多top-level文件( 像 setup.py, README.md，requirements.txt, 等) 。 然后，每个项目都应该有三个目录：包含项目文档的文档目录名为项目名称的目录，它存储实际的python 包在两个位置中的一个测试目录在包含测试代码和资源的软件包目录下作为一个独立的顶级目录，可以更好地了解你的文件如何组织，下面是一个对我的项目的布局的简化快照，sandman:12345678910111213141516171819202122232425$ pwd~/code/sandman$ tree.|- LICENSE|- README.md|- TODO.md|- docs| |-- conf.py| |-- generated| |-- index.rst| |-- installation.rst| |-- modules.rst| |-- quickstart.rst| |-- sandman.rst|- requirements.txt|- sandman| |-- __init__.py| |-- exception.py| |-- model.py| |-- sandman.py| |-- test| |-- models.py| |-- test_sandman.py|- setup.py 你可以看到，有一些顶级文件，一个文档目录( 生成的是一个空目录，sphinx将在其中放置生成的文档)，一个sandman目录和一个在sandman下的测试目录。 再一个项目目录组织方式假设你的项目名为foo, 我比较建议的最方便快捷目录结构这样就足够了: Foo/ |-- bin/ | |-- foo | |-- foo/ | |-- tests/ | | |-- __init__.py | | |-- test_main.py | | | |-- __init__.py | |-- main.py | |-- docs/ | |-- conf.py | |-- abc.rst | |-- setup.py |-- requirements.txt |-- README 简要解释一下: bin/: 存放项目的一些可执行文件，当然你可以起名script/之类的也行。foo/: 存放项目的所有源代码。(1) 源代码中的所有模块、包都应该放在此目录。不要置于顶层目录。(2) 其子目录tests/存放单元测试代码； (3) 程序的入口最好命名为main.py。docs/: 存放一些文档。setup.py: 安装、部署、打包的脚本。requirements.txt: 存放软件依赖的外部Python包列表。README: 项目说明文件。除此之外，有一些方案给出了更加多的内容。比如LICENSE.txt,ChangeLog.txt文件等，我没有列在这里，因为这些东西主要是项目开源的时候需要用到。如果你想写一个开源软件，目录该如何组织，可以参考这篇文章。 下面，再简单讲一下我对这些目录的理解和个人要求吧。 关于README的内容这个我觉得是每个项目都应该有的一个文件，目的是能简要描述该项目的信息，让读者快速了解这个项目。它需要说明以下几个事项: 软件定位，软件的基本功能。 运行代码的方法: 安装环境、启动命令等。 简要的使用说明。 代码目录结构说明，更详细点可以说明软件的基本原理。 常见问题说明。 我觉得有以上几点是比较好的一个README。在软件开发初期，由于开发过程中以上内容可能不明确或者发生变化，并不是一定要在一开始就将所有信息都补全。但是在项目完结的时候，是需要撰写这样的一个文档的。可以参考Redis源码中Readme的写法，这里面简洁但是清晰的描述了Redis功能和源码结构。 关于requirements.txt和setup.pysetup.py一般来说，用setup.py来管理代码的打包、安装、部署问题。业界标准的写法是用Python流行的打包工具setuptools来管理这些事情。这种方式普遍应用于开源项目中。不过这里的核心思想不是用标准化的工具来解决这些问题，而是说，一个项目一定要有一个安装部署工具，能快速便捷的在一台新机器上将环境装好、代码部署好和将程序运行起来。 这个我是踩过坑的。 我刚开始接触Python写项目的时候，安装环境、部署代码、运行程序这个过程全是手动完成，遇到过以下问题: 安装环境时经常忘了最近又添加了一个新的Python包，结果一到线上运行，程序就出错了。 Python包的版本依赖问题，有时候我们程序中使用的是一个版本的Python包，但是官方的已经是最新的包了，通过手动安装就可能装错了。 如果依赖的包很多的话，一个一个安装这些依赖是很费时的事情。 新同学开始写项目的时候，将程序跑起来非常麻烦，因为可能经常忘了要怎么安装各种依赖。 setup.py可以将这些事情自动化起来，提高效率、减少出错的概率。”复杂的东西自动化，能自动化的东西一定要自动化。”是一个非常好的习惯。 setuptools的文档比较庞大，刚接触的话，可能不太好找到切入点。学习技术的方式就是看他人是怎么用的，可以参考一下Python的一个Web框架，flask是如何写的: setup.py 当然，简单点自己写个安装脚本（deploy.sh）替代setup.py也未尝不可。 requirements.txt这个文件存在的目的是: 方便开发者维护软件的包依赖。将开发过程中新增的包添加进这个列表中，避免在setup.py安装依赖时漏掉软件包。 方便读者明确项目使用了哪些Python包。这个文件的格式是每一行包含一个包依赖的说明，通常是flask&gt;=0.10这种格式，要求是这个格式能被pip识别，这样就可以简单的通过 pip install -r requirements.txt来把所有Python包依赖都装好了。具体格式说明： 点这里。 关于配置文件的使用方法注意，在上面的目录结构中，没有将conf.py放在源码目录下，而是放在docs/目录下。 很多项目对配置文件的使用做法是: 配置文件写在一个或多个python文件中，比如此处的conf.py。 项目中哪个模块用到这个配置文件就直接通过import conf这种形式来在代码中使用配置。 这种做法我不太赞同: 这让单元测试变得困难（因为模块内部依赖了外部配置） 另一方面配置文件作为用户控制程序的接口，应当可以由用户自由指定该文件的路径。 程序组件可复用性太差，因为这种贯穿所有模块的代码硬编码方式，使得大部分模块都依赖conf.py这个文件。 所以，我认为配置的使用，更好的方式是，模块的配置都是可以灵活配置的，不受外部配置文件的影响。程序的配置也是可以灵活控制的。能够佐证这个思想的是，用过nginx和mysql的同学都知道，nginx、mysql这些程序都可以自由的指定用户配置。 所以，不应当在代码中直接import conf来使用配置文件。上面目录结构中的conf.py，是给出的一个配置样例，不是在写死在程序中直接引用的配置文件。可以通过给main.py启动参数指定配置路径的方式来让程序读取配置内容。当然，这里的conf.py你可以换个类似的名字，比如settings.py。或者你也可以使用其他格式的内容来编写配置文件，比如settings.yaml之类的。 对于文档的态度目录结构中有设docs/这个目录，用于存放代码文档。实际过程中，据我观察，80%以上的程序员都没有单独写文档的习惯。一般文档写得比较好的，都是一些开源项目。 在普通的项目中，确实没必要写非常详细的文档，我更赞同的是现在的一种流行的风格: “在代码中写文档”。即在写代码的时候，在代码文件里把软件/模块的简要用法写明。简单有用。 参考 如何设计结构清晰的目录结构","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Python模块和包导入机制","slug":"py-relativeimport-2017-08-11","date":"2017-08-11T07:53:58.000Z","updated":"2017-09-08T03:51:39.884Z","comments":true,"path":"2017/08/11/py-relativeimport-2017-08-11/","link":"","permalink":"http://arvin-he.github.io/2017/08/11/py-relativeimport-2017-08-11/","excerpt":"","text":"将代码封装成包在文件系统上组织你的代码，并确保每个目录都定义了一个__init__.py文件, 关于相对导入当导入模块时,报错:python systemerror parent module ‘’ not loaded cannot perform relative import,这就是相对导入的问题了. 涉及到相对导入时，package所对应的文件夹必须正确的被python解释器视作package，而不是普通文件夹。否则由于不被视作package，无法利用package之间的嵌套关系实现python中包的相对导入。 文件夹被python解释器视作package需要满足两个条件： 文件夹中必须有__init__.py文件，该文件可以为空，但必须存在该文件。 不能作为顶层模块来执行该文件夹中的py文件（即不能作为主函数的入口）。 补充：在”from YY import XX”这样的代码中，无论是XX还是YY，只要被python解释器视作package，就会首先调用该package的__init__.py文件。如果都是package，则调用顺序是YY，XX。 一个问题1234567891011121314151617test|-- a.py|-- b.py`-- __init__.py# a.pyfrom test.b import cprint(c)# b.pyc = \"test\"#运行 a.pypython3 a.pyTraceback (most recent call last):File \"a.py\", line 1, in from test.b import cImportError: No module named 'test.b' test 的上级目录不在 sys.path 中。还有，不要直接执行一个包里边的文件。如果真需要执行一个包里的模块（而又不使用 distribute 提供的 entry point 安装配置），请使用 python3 -m test.a 这样子。 将文件夹加入到 sys.path你无法导入你的 Python 代码因为它所在的目录不在 sys.path 里。你想将添加新目录到 Python 路径，但是不想硬链接到你的代码。有两种常用的方式将新目录添加到 sys.path: 使用 PYTHONPATH环境变量来添加 第二种方法是创建一个.pth 文件，将目录列举出来123# myapplication.pth/some/dir/other/dir 这个.pth 文件需要放在某个 Python 的 site-packages 目录，通常位于/usr/local/lib/python3.3/site-packages 或者 ˜/.local/lib/python3.3/sitepackages。当解释器启动时，.pth 文件里列举出来的存在于文件系统的目录将被添加到 sys.path。安装一个.pth文件可能需要管理员权限，如果它被添加到系统级的 Python 解释器。 import的几种方式 常规导入和重命名导入 12import osimport sys as system 使用from语句导入只想要导入一个模块或库中的某个部分:from functools import lru_cache从一个包中导入多个项： 12from os import path, walk, unlinkfrom os import uname, remove 上面是通过多次从同一个模块中导入实现的。当然，你也可以使用圆括号一次性导入多个项12345678from os import (path, walk, unlink, uname, remove, rename)``` 也可以这样```pythonfrom os import path, walk, unlink, uname, \\ remove, rename 相对导入12345678910my_package/ __init__.py subpackage1/ __init__.py module_x.py module_y.py subpackage2/ __init__.py module_z.py module_a.py 在顶层的__init__.py文件中，输入以下代码：12from . import subpackage1from . import subpackage2 然后进入subpackage1文件夹，编辑其中的__init__.py文件，输入以下代码：12from . import module_xfrom . import module_y 编辑module_x.py文件，输入以下代码：1234from .module_y import spam as hamdef main(): ham() 编辑module_y.py文件，输入以下代码：12def spam(): print('spam ' * 3) 打开终端，cd至my_package包所在的文件夹，但不要进入my_package。在这个文件夹下运行Python解释器。1234567In [1]: import my_packageIn [2]: my_package.subpackage1.module_xOut[2]: In [3]: my_package.subpackage1.module_x.main()spam spam spam 注意: 如果你想要跨越多个文件层级进行导入，只需要使用多个句点即可。不过，PEP 328建议相对导入的层级不要超过两层。还要注意一点，如果你往module_x.py文件中添加了if __name__ == &#39;__main__&#39;:，然后试图运行这个文件，你会碰到一个很难理解的错误。编辑一下文件，试试看吧！12345678from . module_y import spam as hamdef main(): ham()if __name__ == '__main__': # This won't work! main() 从终端进入subpackage1文件夹，执行以下命令：使用的是Python 2，你应该会看到下面的错误信息：1234Traceback (most recent call last): File &quot;module_x.py&quot;, line 1, in from . module_y import spam as hamValueError: Attempted relative import in non-package 使用的是Python 3，错误信息是这样的：1234Traceback (most recent call last): File &quot;module_x.py&quot;, line 1, in from . module_y import spam as hamSystemError: Parent module &apos;&apos; not loaded, cannot perform relative import 这指的是，module_x.py是某个包中的一个模块，而你试图以脚本模式执行，但是这种模式不支持相对导入。如果你想在自己的代码中使用这个模块，那么你必须将其添加至Python的导入检索路径（import search path）。最简单的做法如下：123import syssys.path.append('/path/to/folder/containing/my_package')import my_package 注意，你需要添加的是my_package的上一层文件夹路径，而不是my_package本身。原因是my_package就是我们想要使用的包，所以如果你添加它的路径，那么将无法使用这个包。 可选导入（Optional imports）希望优先使用某个模块或包，但是同时也想在没有这个模块或包的情况下有备选，你就可以使用可选导入这种方式。正如下面示例所示，可选导入的使用很常见，是一个值得掌握的技巧。这样做可以导入支持某个软件的多种版本或者实现性能提升。以github2包中的代码为例：123456789try: # For Python 3 from http.client import responsesexcept ImportError: # For Python 2.5-2.7 try: from httplib import responses # NOQA except ImportError: # For Python 2.4 from BaseHTTPServer import BaseHTTPRequestHandler as _BHRH responses = dict([(k, v[0]) for k, v in _BHRH.responses.items()]) lxml包也有使用可选导入方式：1234567try: from urlparse import urljoin from urllib2 import urlopenexcept ImportError: # Python 3 from urllib.parse import urljoin from urllib.request import urlopen 局部导入当你在局部作用域中导入模块时，你执行的就是局部导入。如果你在Python脚本文件的顶部导入一个模块，那么你就是在将该模块导入至全局作用域，这意味着之后的任何函数或方法都可能访问该模块。12345678910111213import sys # global scopedef square_root(a): # This import is into the square_root functions local scope import math return math.sqrt(a)def my_pow(base_num, power): return math.pow(base_num, power)if __name__ == '__main__': print(square_root(49)) print(my_pow(2, 3)) 我们将sys模块导入至全局作用域，但我们并没有使用这个模块。然后，在square_root函数中，我们将math模块导入至该函数的局部作用域，这意味着math模块只能在square_root函数内部使用。如果我们试图在my_pow函数中使用math，会引发NameError. 使用局部作用域的好处之一，是你使用的模块可能需要很长时间才能导入，如果是这样的话，将其放在某个不经常调用的函数中或许更加合理，而不是直接在全局作用域中导入。老实说，我几乎从没有使用过局部导入，主要是因为如果模块内部到处都有导入语句，会很难分辨出这样做的原因和用途。根据约定，所有的导入语句都应该位于模块的顶部。或者有的函数你只需使用一次可以选择局部导入. 导入注意事项在导入模块方面，有几个程序员常犯的错误。这里介绍两个: 循环导入（circular imports） 覆盖导入（Shadowed imports，暂时翻译为覆盖导入） 循环导入如果你创建两个模块，二者相互导入对方，那么就会出现循环导入。例如：12345678# a.pyimport bdef a_test(): print(\"in a_test\") b.b_test()a_test() 然后在同个文件夹中创建另一个模块，将其命名为b.py。1234567import adef b_test(): print('In test_b\"') a.a_test()b_test() 如果你运行任意一个模块，都会引发AttributeError。这是因为这两个模块都在试图导入对方。简单来说，模块a想要导入模块b，但是因为模块b也在试图导入模块a（这时正在执行），模块a将无法完成模块b的导入。一般来说，你应该做的是重构代码，避免发生这种情况。 覆盖导入当你创建的模块与标准库中的模块同名时，如果你导入这个模块，就会出现覆盖导入。举个例子，创建一个名叫math.py的文件，在其中写入如下代码：123456import mathdef square_root(number): return math.sqrt(number)square_root(72) 现在打开终端，试着运行这个文件，你会得到以下回溯信息（traceback）：12345678Traceback (most recent call last): File \"math.py\", line 1, in import math File \"/Users/michael/Desktop/math.py\", line 6, in square_root(72) File \"/Users/michael/Desktop/math.py\", line 4, in square_root return math.sqrt(number)AttributeError: module 'math' has no attribute 'sqrt' 这到底是怎么回事？其实，你运行这个文件的时候，Python解释器首先在当前运行脚本所处的的文件夹中查找名叫math的模块。在这个例子中，解释器找到了我们正在执行的模块，试图导入它。但是我们的模块中并没有叫sqrt的函数或属性，所以就抛出了AttributeError。 参考 https://juejin.im/entry/570c6b6771cfe40067310370 [cookbook]","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"PyQt5遇到的一些问题","slug":"pyqt-somequestions-2017-08-10","date":"2017-08-10T05:09:10.000Z","updated":"2017-09-08T03:51:39.982Z","comments":true,"path":"2017/08/10/pyqt-somequestions-2017-08-10/","link":"","permalink":"http://arvin-he.github.io/2017/08/10/pyqt-somequestions-2017-08-10/","excerpt":"","text":"关于QButtonGroup的问题在循环中对按钮做属性修改,比如setchecked属性.之前将所有的button对象放到QButtonGroup中,然后在循环中设置属性,代码如下:123for btn in self.buttonGroup.buttons(): btn.setCheckable(True) btn.setChecked(True) 最后结果是在groupbutton中的最后一个button会被设置为checked状态,其他的按钮都没有被设置为checked状态. 解决办法:将按钮对象放在一个list里,然后遍历list里的按钮对象就行了.后来查了文档,放在QButtonGroup中的按钮对象,在放入QButtonGroup之前必须具有SetCheckabled为true这个属性.否则无法设置setchecked这个属性.","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"PyQt5","slug":"PyQt5","permalink":"http://arvin-he.github.io/tags/PyQt5/"}]},{"title":"PyQt5使用QStackedwidget","slug":"pyqt-stackedwidget-2017-08-08","date":"2017-08-08T09:14:14.000Z","updated":"2017-09-08T03:51:39.985Z","comments":true,"path":"2017/08/08/pyqt-stackedwidget-2017-08-08/","link":"","permalink":"http://arvin-he.github.io/2017/08/08/pyqt-stackedwidget-2017-08-08/","excerpt":"","text":"QListWidget和QStackedWidget在ui文件中. 12345678910111213141516171819202122232425262728293031323334353637383940# -*- coding:utf-8 -*-import osimport functoolsfrom PyQt5 import uicfrom PyQt5 import QtWidgetsfrom utils import loadJsonfrom page1 import ControlPanelfrom utils import loadJsonclass ControlPanel2(QtWidgets.QWidget): def __init__(self, parent=None): super(ControlPanel2, self).__init__(parent) self._config = loadJson() self.ctrlpanelWidth = self._config['controlpanel']['width'] self.ctrlpanelHeight = self._config['controlpanel']['height'] self.ctrl_panel = ControlPanel() self.initUI() def initUI(self): self.ui = uic.loadUi(os.path.join( os.path.dirname(__file__), \"res/ctrlpanel.ui\"), self) self.setFixedSize(self.ctrlpanelWidth, self.ctrlpanelHeight) for i, key in enumerate(sorted(self._config[\"panels\"].keys())): item = QtWidgets.QListWidgetItem(self.ui.panellist) item.setText(key) self.ui.panellist.insertItem(i, item) self.ui.stackedWidget.insertWidget(i, QtWidgets.QLabel(\"&#123;&#125;\".format(key))) # 设置qss self.setStyleSheet( \"QListWidget::item&#123;width: 65px; height: 35px; text-align: center;&#125;\") self.ui.panellist.setCurrentRow(0) self.ui.stackedWidget.setCurrentIndex(0) self.ui.panellist.currentRowChanged.connect(self.on_showPage) def on_showPage(self, index): # index = self.ui.panellist.currentIndex() print(\"current index =\", index) self.ui.stackedWidget.setCurrentIndex(index)","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"PyQt5","slug":"PyQt5","permalink":"http://arvin-he.github.io/tags/PyQt5/"}]},{"title":"PyQt5长按按钮循环执行命令","slug":"pyqt-longpressbtn-2017-08-07","date":"2017-08-07T09:39:12.000Z","updated":"2017-09-08T03:51:39.968Z","comments":true,"path":"2017/08/07/pyqt-longpressbtn-2017-08-07/","link":"","permalink":"http://arvin-he.github.io/2017/08/07/pyqt-longpressbtn-2017-08-07/","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768# -*- coding:utf-8 -*-import osimport timeimport functoolsfrom PyQt5 import uicfrom PyQt5 import QtWidgetsfrom utils import loadJsonfrom punggol_rpc import punggol_execclass ControlPanel(QtWidgets.QWidget): def __init__(self, parent=None): super(ControlPanel, self).__init__(parent) self._config = loadJson() self.ctrlpanelWidth = self._config['controlpanel']['width'] self.ctrlpanelHeight = self._config['controlpanel']['height'] self.initUI() def initUI(self): self.ui = uic.loadUi(os.path.join( os.path.dirname(__file__), \"res/ctrlpanel.ui\"), self) self.setFixedSize(self.ctrlpanelWidth, self.ctrlpanelHeight) for attr in dir(self.ui): obj = getattr(self.ui, attr) if isinstance(obj, QtWidgets.QPushButton) or \\ isinstance(obj, QtWidgets.QToolButton): obj.setAutoRepeat(True) obj._repeate = False obj.clicked.connect( functools.partial(self.on_handleClicked, obj)) def on_handleClicked(self, btn): if btn.isDown(): if btn._repeate is False: btn._repeate = True btn.setAutoRepeatInterval(50) else: self.on_pressed(btn) elif btn._repeate is True: btn._repeate = False self.on_released(btn) else: self.on_clicked(btn) def on_clicked(self, btn): try: if btn.property(\"clicked_cmd\") is not None: punggol_exec(btn.property(\"clicked_cmd\")) except Exception as e: print(e) return def on_pressed(self, btn): try: if btn.property(\"pressed_cmd\") is not None: punggol_exec(btn.property(\"pressed_cmd\")) except Exception as e: print(e) return def on_released(self, btn): try: if btn.property(\"released_cmd\") is not None: punggol_exec(btn.property(\"released_cmd\")) except Exception as e: print(e) return","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"PyQt5","slug":"PyQt5","permalink":"http://arvin-he.github.io/tags/PyQt5/"}]},{"title":"Python删除windows下的目录","slug":"py-deteledironwindows-2017-08-07","date":"2017-08-07T01:40:36.000Z","updated":"2017-09-08T03:51:39.868Z","comments":true,"path":"2017/08/07/py-deteledironwindows-2017-08-07/","link":"","permalink":"http://arvin-he.github.io/2017/08/07/py-deteledironwindows-2017-08-07/","excerpt":"","text":"windows启动目录:C:\\Users\\aron\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\Startup在windows下启动目录下添加一个killkingsoft.py脚本,然后每次开机自动执行该脚本.注意:在windows下启动目录下的脚本或者bat文件都会在开机时自动执行. 之前使用shutil.rmtree os.remove os.rmdir都没有成功,都报出如下错误:PermissionError: [WinError 5] 拒绝访问。: &#39;c:\\\\ProgramData\\\\kingsoft&#39;后来找到解决办法,如下:1234567891011121314151617181920212223# usr/bin/python3# -*- coding:utf-8 -*- import errno, os, stat, shutilkingSoft = os.path.join(\"c:\\\\\", \"ProgramData\", \"kingsoft\")def handleRemoveReadonly(func, path, exc): excvalue = exc[1] if func in (os.rmdir, os.remove) and excvalue.errno == errno.EACCES: os.chmod(path, stat.S_IRWXU| stat.S_IRWXG| stat.S_IRWXO) # 0777 func(path) else: raiseif os.path.exists(kingSoft): shutil.rmtree(kingSoft, ignore_errors=False, onerror=handleRemoveReadonly) print(\"delete kingsoft success\")else: print(\"no such dir or file\")","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Python使用cx_freeze打包应用程序","slug":"py-cxfreeze-2017-08-04","date":"2017-08-04T05:20:52.000Z","updated":"2017-09-08T03:51:39.865Z","comments":true,"path":"2017/08/04/py-cxfreeze-2017-08-04/","link":"","permalink":"http://arvin-he.github.io/2017/08/04/py-cxfreeze-2017-08-04/","excerpt":"","text":"python应用程序打包python下应用程序打包有py2exe, pyinstaller和cx_freeze这3个第三方库, 目前python3.6不支持py2exe和pyinstaller,在win7 下 python3.6 使用 py2exe 或 pyinstaller 都报 Indexerror： tuple index out of range. 但pyinstaller和py2exe在python3.4版本可用. 使用cx_freeze打包应用程序用cx_freeze打包出来的包文件很大,一个简单的程序打包出来大概有230M左右.里面包括了python的runtime等各种依赖. 安装cx_freezepip install cx_freeze 创建setup.py脚本在你的工程的根目录下创建setup.py脚本,setup.py脚本可以是其他名字,如setup_cx_freeze.py,通常约定俗成是’setup.py’.只要不要和你的应用程序的脚本命令冲突就行. 123456789101112131415# setup.pyimport sysfrom cx_Freeze import setup, Executable# 依赖关系被自动检测，但可能需要微调build_exe_options = &#123;\"packages\": [\"os\"], \"excludes\": [\"tkinter\"]&#125;# GUI应用程序在Windows上需要不同的基础（默认值为控制台应用程序)base = Noneif sys.platform == \"win32\": base = \"Win32GUI\"setup( name = \"guifoo\", version = \"0.1\", description = \"My GUI application!\", options = &#123;\"build_exe\": build_exe_options&#125;, executables = [Executable(\"guifoo.py\", base=base)]) 创建应用程序打包目录(这是错误的) 打包的应用程序和依赖要放到一个文件夹中去, 这个文件夹必须在打包前创建好,通常在应用程序根目录下新建一个build文件夹 执行打包命令执行打包命令: python setup.py build, 其中setup.py就是上面你写的脚本, build是打包的命令的一个选项.使用python setup_cx_freeze.py --help-commands来查看cx-freeze的命令, setup_cx_freeze.py是打包脚本,也可是是其他的名字12345678910111213141516171819202122232425262728293031python setup_cx_freeze.py --help-commandsStandard commands: build build everything needed to install build_py &quot;build&quot; pure Python modules (copy to build directory) build_ext build C/C++ extensions (compile/link to build directory) build_clib build C/C++ libraries used by Python extensions build_scripts &quot;build&quot; scripts (copy and fixup #! line) clean clean up temporary files from &apos;build&apos; command install install everything from build directory install_lib install all Python modules (extensions and pure Python) install_headers install C/C++ header files install_scripts install scripts (Python or otherwise) install_data install data files sdist create a source distribution (tarball, zip file, etc.) register register the distribution with the Python package index bdist create a built (binary) distribution bdist_dumb create a &quot;dumb&quot; built distribution bdist_rpm create an RPM distribution bdist_wininst create an executable installer for MS Windows check perform some checks on the package upload upload binary package to PyPIExtra commands: install_exe install executables built from Python scripts bdist_msi create a Microsoft Installer (.msi) binary distribution build_exe build executables from Python scriptsusage: setup_cx_freeze.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...] or: setup_cx_freeze.py --help [cmd1 cmd2 ...] or: setup_cx_freeze.py --help-commands or: setup_cx_freeze.py cmd --help 打包成*.msi格式在命令行窗口输入:python setup.py bdist_msi,回车,就会在build目录下生成一个*.msi格式的软件安装包 制作exe安装包windows下通常分发软件都是*.exe格式的,*.msi也可以,python的分发包就是*.msi格式的. 但是python打包出来的文件都在一个文件夹,并不是一个exe文件,而且图标, 配置文件并不会被打包进来.此外该文件夹的体积很大. 考虑到上面的种种情况, windows下需要将上面文件夹的文件再次压缩打包成一个exe, 比较好的工具是NSIS. 安装NSISNSIS有window版和unicode版本, 注意添加相关环境变量 编写打包脚本创建一个打包脚本,如pack.nsi, 然后在该脚本中写脚本 执行命令脚本打包命令: makensis pack.nsi 制作deb包linux下分发软件是deb包的形式 一些问题使用cx_freeze打包python程序,在打包sqlalchemy程序时,C:\\programs File\\Python36\\Lib\\site-packages\\sqlalchemy\\sql\\default_comparator.pyc这个模块没有被打包进来,但是其他模块都被打包进来了.解决办法: 复制default_comparator.py文件或者在__pychae__目录下复制default_comparator.pyc到你的打包目录中对应的目录.然后再通过NSIS打包. 在python3.4中使用cx_freeze打包能将sqlalchemy中的default_comparator.pyc打包,在python3.6却唯独漏掉这个default_comparator.pyc,原因未知,解决办法:在cx_freeze的setup.py脚本中的build_exe_options中的packages中添加sqlalchemy,这样就会将sqlalchemy完成打包进来,不会漏掉一个模块,格式如下:1234567# 依赖会自动检测,但会需要微调build_exe_options = &#123; \"packages\": [\"sqlalchemy\"], \"excludes\": [\"tkinter\"], \"includes\": [], \"include_files\": []&#125; 关于cx_freeze的setup.py的脚本问题使用cx-freeze进行打包时,setup.py必须放在程序运行脚本的根目录下,如果将setup.py放到同级的一个文件夹中(如make文件夹,为了不污染源代码),打包出来后的exe运行报错.提示模块找不到.","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"PyQt5添加动态属性及访问","slug":"pyqt-dynamicproperty-2017-08-04","date":"2017-08-04T01:48:18.000Z","updated":"2017-09-08T03:51:39.897Z","comments":true,"path":"2017/08/04/pyqt-dynamicproperty-2017-08-04/","link":"","permalink":"http://arvin-he.github.io/2017/08/04/pyqt-dynamicproperty-2017-08-04/","excerpt":"","text":"在ui文件中添加动态属性如下图所示:在属性编辑器中点击”+”按钮, 添加的属性有很多类型,一般选择string或者ByteArray, 最好选择ByteArray,如果选择string还会涉及到需要翻译的问题. 然后设置你的动态属性名称: 在你的代码中访问ui中设置的动态属性如何遍历ui对象中的所有按钮对象如何在循环中给btn连接信号槽12345678910def initUI(self): self.ui = uic.loadUi(os.path.join( os.path.dirname(__file__), \"res/ctrlpanel.ui\"), self) self.setFixedSize(self.ctrlpanelWidth, self.ctrlpanelHeight) for attr in dir(self.ui): # getattr 根据属性名称获取属性的值或对象 obj = getattr(self.ui, attr) if isinstance(obj, QtWidgets.QPushButton) or isinstance(obj, QtWidgets.QToolButton): # 注意:这里有一个闭包的问题,这里用functools.partial解决了 obj.clicked.connect(functools.partial(self.on_clicked, obj)) 代码中访问ui设置的动态属性一般思维定势使用’.’来访问对象的属性,但是ui中的动态属性无法通过’.’访问,而是使用property()函数来访问动态属性.如btn.property(&quot;btn_cmd&quot;) 关于QToolButton和QPushButton如果你想在按钮上添加图片,并且让文字显示在图标下面,那么请使用QToolButton,不要使用QPushButton, QPushButton添加图标后,其文字是默认显示在图标右边,而不是下面.1234button = QToolButton()button.setToolButtonStyle(QtCore.Qt.ToolButtonTextUnderIcon)button.setIcon(myIcon)button.setText(\"Sample text\")","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"PyQt5","slug":"PyQt5","permalink":"http://arvin-he.github.io/tags/PyQt5/"}]},{"title":"PyQt5控件提升和插件","slug":"pyqt-promptplugin-2017-08-02","date":"2017-08-02T11:56:13.000Z","updated":"2017-09-08T03:51:39.971Z","comments":true,"path":"2017/08/02/pyqt-promptplugin-2017-08-02/","link":"","permalink":"http://arvin-he.github.io/2017/08/02/pyqt-promptplugin-2017-08-02/","excerpt":"","text":"PyQt控件提升(promotion)常用控件有标准的属性和方法, 但在一些情况下，现有的控件不具备一些你需要的特性或行为或属性时，这就需要你自己继承基础控件，然后添加你自己的特性或属性，比如QTableWidget，当你需要对表格中内容进行右键菜单或者接收键盘事件时.原本的QTableWidget是默认没有右键菜单和接收键盘事件，需要你去重写一些函数，或者重写一些事件，然后提升. 第一步：定义一个类，并继承QTableWidgets第二步：重写一些事件或者添加你定制的属性或方法第三步：在QT Designer中提升 在QT Designer中打开你的ui，然后选中你要提升的控件，右击提升为，填好“提升的类名称”：就是你继承并定义的类头文件：就是你继承定义的类所在的头文件名称点击“添加”，在上面要添加头文件所在的路径最后点击“提升” 如何在QTableWidgets添加右键菜单在属性编辑中，就会发现对象的类名称变为你自定义的类名称了，如上图所示。提升时最好在designer中提升，在代码中做提升不知道怎么做，因为最后，打开ui文件发现，ui文件相比没有提升的是有不同的，如下图所示。 自定义PyQt控件(插件法)自定义控件一般是在原有控件的基础上定制你专有的属性和方法,然后封装成一个控件,可是让你在designer中拖拽这个你封装的控件.最后将# myplugins.py放在C:\\Program Files\\Python36\\Lib\\site-packages\\pyqt5-tools\\plugins\\designer目录下.方法:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183# myplugins.pyfrom PyQt5 import QtCorefrom PyQt5 import QtWidgetsfrom PyQt5 import QtDesignerdef py_property(typeName): \"\"\"定义 Qt 属性\"\"\" values = &#123;&#125; getter = values.get def setter(self, value): values[self] = value def resetter(self): del values[self] return QtCore.pyqtProperty(typeName, getter, setter, resetter)class PyPushButton(QtWidgets.QPushButton): def __init__(self, parent): super(PyPushButton, self).__init__(parent) signal_pressed = QtCore.pyqtSignal(str) signal_released = QtCore.pyqtSignal(str) py_text = py_property(\"QString\") py_clicked = py_property(\"QString\") py_pressed = py_property(\"QString\") py_released = py_property(\"QString\") py_checked = py_property(\"QString\") py_enabled = py_property(\"QString\") py_tag = py_property(\"QString\")class PyButtonPlugin(QtDesigner.QPyDesignerCustomWidgetPlugin): def __init__(self): super(PyButtonPlugin, self).__init__() def createWidget(self, parent): return PyPushButton(parent) def name(self): return \"PyPushButton\" def group(self): return \"MyPlugins\" def includeFile(self): return \"myplugins/widgets/pushbutton.h\" def isContainer(self): return False def domXml(self): return \"\"\"&lt;ui language=\"c++\"&gt; &lt;widget class=\"PyPushButton\" name=\"PyPushButton\"&gt; &lt;property name=\"geometry\"&gt; &lt;rect&gt; &lt;width&gt;100&lt;/width&gt; &lt;height&gt;30&lt;/height&gt; &lt;/rect&gt; &lt;/property&gt; &lt;property name=\"text\"&gt; &lt;string&gt;pushbutton&lt;/string&gt; &lt;/property&gt; &lt;property name=\"py_text\"&gt; &lt;string notr=\"true\"&gt;&lt;/string&gt; &lt;/property&gt; &lt;/widget&gt; &lt;customwidgets&gt; &lt;customwidget&gt; &lt;propertyspecifications&gt; &lt;stringpropertyspecification name=\"py_text\" type=\"multiline\" /&gt; &lt;stringpropertyspecification name=\"py_clicked\" type=\"multiline\" /&gt; &lt;stringpropertyspecification name=\"py_pressed\" type=\"multiline\" /&gt; &lt;stringpropertyspecification name=\"py_released\" type=\"multiline\" /&gt; &lt;stringpropertyspecification name=\"py_enabled\" type=\"multiline\" /&gt; &lt;stringpropertyspecification name=\"py_checked\" type=\"multiline\" /&gt; &lt;stringpropertyspecification name=\"py_tag\" type=\"multiline\" /&gt; &lt;/propertyspecifications&gt; &lt;/customwidget&gt; &lt;/customwidgets&gt;&lt;/ui&gt;\"\"\"# myplugins/widgets/pushbutton.pyimport loggingfrom PyQt5 import QtCorefrom PyQt5 import QtWidgets_logger = logging.getLogger(__name__)class PyPushButton(QtWidgets.QPushButton): py_checked = basic.property(\"QString\") py_clicked = basic.property(\"QString\") py_enabled = basic.property(\"QString\") py_pressed = basic.property(\"QString\") py_released = basic.property(\"QString\") py_shortcut = basic.property(\"QString\") py_tag = basic.property(\"QString\") py_text = basic.property(\"QString\") signal_pressed = QtCore.pyqtSignal(str) signal_released = QtCore.pyqtSignal(str) def __init__(self, parent=None): super(PyPushButton, self).__init__(parent) self._shortcutval = False self.bPress = False self.clicked.connect(self.onClicked) self.pressed.connect(self.onPushed) self.released.connect(self.onUnPushed) basic.signal_UpdateUi.connect(self._update) def onClicked(self): self.bPress = True if self.py_clicked is not None: _logger.debug(\"\"\"点击:\"&#123;&#125;\"按钮\"\"\".format(self.text())) basic._exec(self.py_clicked) def onPushed(self): self.bPress = True if self.py_pressed is not None: _logger.debug(\"\"\"按下:\"&#123;&#125;\"按钮\"\"\".format(self.text())) basic._exec(self.py_pressed) self.signal_pressed.emit(self.objectName()) def onUnPushed(self): self.bPress = False if self.py_released is not None: _logger.debug(\"\"\"松开:\"&#123;&#125;\"按钮\"\"\".format(self.text())) basic._exec(self.py_released) self.signal_released.emit(self.objectName()) def _update(self): if self.py_checked: self.setCheckable(True) self.setChecked(bool(basic._eval(self.py_checked))) if self.py_enabled: self.setEnabled(bool(basic._eval(self.py_enabled))) if self.py_shortcut: shortcutval = bool(basic._eval(self.py_shortcut)) if not self._shortcutval and shortcutval: self.signal_pressed.emit(self.objectName()) elif self._shortcutval and not shortcutval: self.signal_released.emit(self.objectName()) self._shortcutval = shortcutval if self.py_tag: if not hasattr(self, \"py_tag_label\"): self.py_tag_vbox = QtWidgets.QVBoxLayout() self.py_tag_vbox.setContentsMargins(0, 0, 0, 0) self.setLayout(self.py_tag_vbox) self.py_tag_label = QtWidgets.QLabel() self.py_tag_vbox.addWidget(self.py_tag_label, 1) self.py_tag_label.setText(self.py_tag) if self.py_text: self.setText(str(basic._eval(self.py_text))) # 补丁: setText 会清除快捷键, 屏蔽此行为 def setText(self, text): shortcut = self.shortcut() super(PyPushButton, self).setText(text) self.setShortcut(shortcut) def setEnabled(self, b): if not b: if self.bPress: self.bPress = False self.signal_released.emit(self.objectName()) super(PyPushButton, self).setEnabled(b)","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"PyQt5","slug":"PyQt5","permalink":"http://arvin-he.github.io/tags/PyQt5/"}]},{"title":"pyautogui使用","slug":"py-pyautogui-2017-07-27","date":"2017-07-27T01:24:02.000Z","updated":"2017-09-08T03:51:39.877Z","comments":true,"path":"2017/07/27/py-pyautogui-2017-07-27/","link":"","permalink":"http://arvin-he.github.io/2017/07/27/py-pyautogui-2017-07-27/","excerpt":"","text":"PyAutoGUI——让所有GUI都自动化本教程译自大神Al Sweigart的PyAutoGUI项目，Python自动化工具，更适合处理GUI任务，网页任务推荐： Selenium+Firefox记录（Chromedriver和Phantomjs也很给力，Phantomjs虽然是无头浏览器，但有时定位不准），然后用Python写单元测试 request处理get/post请求写一堆代码自动化处理，都在后台运行，不用运行浏览器，非常适合处理表单 简介PyAutoGUI是一个纯Python的GUI自动化工具，其目的是可以用程序自动控制鼠标和键盘操作，多平台支持（Windows，OS X，Linux）。可以用pip安装，Github上有源代码。 PyAutoGUI可以模拟鼠标的移动、点击、拖拽，键盘按键输入、按住操作，以及鼠标+键盘的热键同时按住等操作，可以说手能动的都可以。 让鼠标移到屏幕中央123import pyautoguiscreenWidth, screenHeight = pyautogui.size()pyautogui.moveTo(screenWidth / 2, screenHeight / 2) 一些例子:123456789101112131415161718import pyautoguiscreenWidth, screenHeight = pyautogui.size()currentMouseX, currentMouseY = pyautogui.position()pyautogui.moveTo(100, 150)pyautogui.click()# 鼠标向下移动10像素pyautogui.moveRel(None, 10)pyautogui.doubleClick()# 用缓动/渐变函数让鼠标2秒后移动到(500,500)位置# use tweening/easing function to move mouse over 2 seconds.pyautogui.moveTo(1800, 500, duration=2, tween=pyautogui.easeInOutQuad)# 在每次输入之间暂停0.25秒pyautogui.typewrite('Hello world!', interval=0.25)pyautogui.press('esc')pyautogui.keyDown('shift')pyautogui.press(['left', 'left', 'left', 'left', 'left', 'left'])pyautogui.keyUp('shift')pyautogui.hotkey('ctrl', 'c') 12345678distance = 200while distance &gt; 0: pyautogui.dragRel(distance, 0, duration=0.5) # 向右 distance -= 5 pyautogui.dragRel(0, distance, duration=0.5) # 向下 pyautogui.draIn gRel(-distance, 0, duration=0.5) # 向左 distance -= 5 pyautogui.dragRel(0, -distance, duration=0.5) # 向上 保护措施为了能够及时中断，PyAutoGUI提供了一个保护措施。当pyautogui.FAILSAFE = True时，如果把鼠标光标在屏幕左上角，PyAutoGUI函数就会产生pyautogui.FailSafeException异常。如果失控了，需要中断PyAutoGUI函数，就把鼠标光标在屏幕左上角。要禁用这个特性，就把FAILSAFE设置成False：12import pyautoguipyautogui.FAILSAFE = False 通过把pyautogui.PAUSE设置成float或int时间（秒），可以为所有的PyAutoGUI函数增加延迟。默认延迟时间是0.1秒。在函数循环执行的时候，这样做可以让PyAutoGUI运行的慢一点，非常有用。例如：123import pyautoguipyautogui.PAUSE = 2.5pyautogui.moveTo(100,100); pyautogui.click() 所有的PyAutoGUI函数在延迟完成前都处于阻塞状态（block）。（未来计划增加一个可选的非阻塞模式来调用函数。）建议PAUSE和FAILSAFE一起使用。 Cheat Sheet常用函数12345678import pyautogui# 当前鼠标的坐标pyautogui.position() # (123, 372)# 当前屏幕的分辨率（宽度和高度）pyautogui.size() # (1920, 1080)# (x,y)是否在屏幕上x, y = 122, 244pyautogui.onScreen(x, y) # True 保护措施1234# PyAutoGUI函数增加延迟为2.5秒：pyautogui.PAUSE = 2.5# 当pyautogui.FAILSAFE = True时，如果把鼠标光标在屏幕左上角，PyAutoGUI函数就会产生pyautogui.FailSafeException异常。pyautogui.FAILSAFE = True 鼠标函数坐标系的原点是左上角。X轴（水平）坐标向右增大，Y轴（竖直）坐标向下增大。1234567num_seconds = 1.2# 用num_seconds秒的时间把光标移动到(x, y)位置pyautogui.moveTo(x, y, duration=num_seconds)# 用num_seconds秒的时间把光标的X轴（水平）坐标移动xOffset，# Y轴（竖直）坐标向下移动yOffset。xOffset, yOffset = 50, 100pyautogui.moveRel(xOffset, yOffset, duration=num_seconds) click()函数就是让鼠标点击，默认是单击左键，参数可以设置,其中，button属性可以设置成left，middle和right。1pyautogui.click(x=moveToX, y=moveToY, clicks=num_of_clicks, interval=secs_between_clicks, button='left') 所有的点击都可以用这个函数，不过下面的函数可读性更好：1234pyautogui.rightClick(x=moveToX, y=moveToY)pyautogui.middleClick(x=moveToX, y=moveToY)pyautogui.doubleClick(x=moveToX, y=moveToY)pyautogui.tripleClick(x=moveToX, y=moveToY) scroll函数控制鼠标滚轮的滚动，amount_to_scroll参数表示滚动的格数。正数则页面向上滚动，负数则向下滚动：1pyautogui.scroll(clicks=amount_to_scroll, x=moveToX, y=moveToY) 每个按键按下和松开两个事件可以分开处理：12pyautogui.mouseDown(x=moveToX, y=moveToY, button='left')pyautogui.mouseUp(x=moveToX, y=moveToY, button='left') 键盘函数键盘上可以按的键都可以调用：123# 每次键入的时间间隔secs_between_keys = 0.1pyautogui.typewrite('Hello world!\\n', interval=secs_between_keys) 多个键也可以：1pyautogui.typewrite(['a', 'b', 'c', 'left', 'backspace', 'enter', 'f1'], interval=secs_between_keys) 按键名称列表：pyautogui.KEYBOARD_KEYS[:10][‘\\t’, ‘\\n’, ‘\\r’, ‘ ‘, ‘!’, ‘“‘, ‘#’, ‘$’, ‘%’, ‘&amp;’] 键盘的一些热键像Ctrl-S或Ctrl-Shift-1都可以用hotkey()函数来实现：123pyautogui.hotkey('ctrl', 'a') # 全选pyautogui.hotkey('ctrl', 'c') # 复制pyautogui.hotkey('ctrl', 'v') # 粘贴 每个按键的按下和松开也可以单独调用：12pyautogui.keyDown(key_name)pyautogui.keyUp(key_name) 消息弹窗函数如果你需要消息弹窗，通过单击OK暂停程序，或者向用户显示一些信息，消息弹窗函数就会有类似JavaScript的功能：1234pyautogui.alert('这个消息弹窗是文字+OK按钮')pyautogui.confirm('这个消息弹窗是文字+OK+Cancel按钮')pyautogui.prompt('这个消息弹窗是让用户输入字符串，单击OK')# 在prompt()函数中，如果用户什么都不输入，就会返回None。 截屏函数PyAutoGUI用Pillow/PIL库实现图片相关的识别和操作。在Linux里面，你必须执行sudo apt-get install scrot来使用截屏特性。123# 返回一个Pillow/PIL的Image对象pyautogui.screenshot()pyautogui.screenshot('foo.png') 如果你有一个图片文件想在上面做点击操作，你可以用locateOnScreen()函数来定位。123# 返回(最左x坐标，最顶y坐标，宽度，高度)pyautogui.locateOnScreen('pyautogui/looks.png')# (0, 1040, 48, 40) locateAllOnScreen()函数会寻找所有相似图片，返回一个生成器：12345for i in pyautogui.locateAllOnScreen('pyautogui/looks.png'): print(i)# (0, 1040, 48, 40)list(pyautogui.locateAllOnScreen('pyautogui/looks.png'))# (0, 1040, 48, 40) locateCenterOnScreen()函数会返回图片在屏幕上的中心XY轴坐标值：12pyautogui.locateCenterOnScreen('pyautogui/looks.png')# (24, 1060) 如果没找到图片会返回None。定位比较慢，一般得用1~2秒. 常用函数position()：返回整数元组(x, y)，分别表示鼠标光标所在位置的XY轴坐标size()：返回显示器的尺寸整数元组(x, y)。未来将加入多屏支持 鼠标控制函数屏幕与鼠标位置屏幕位置使用X和Y轴的笛卡尔坐标系。原点(0,0)在左上角，分别向右、向下增大。如果屏幕像素是 1920×1080，那么右下角的坐标是(1919, 1079), 左上角是从(0, 0)开始的。分辨率大小可以通过size()函数返回整数元组。光标的位置用position()返回。例如：1234pyautogui.size()# (1920, 1080)pyautogui.position()# (272, 688) 下面是Python 3版本的光标位置记录程序：1234567891011# ! python 3import pyautoguiprint('Press Ctrl-C to quit')try: while True: x, y = pyautogui.position() positionStr = 'X: &#123;&#125; Y: &#123;&#125;'.format(*[str(x).rjust(4) for x in [x, y]]) print(positionStr, end='') print('\\b' * len(positionStr), end='', flush=True)except KeyboardInterrupt: print('\\n') 要检查XY坐标是否在屏幕上，需要用onScreen()函数来检验，如果在屏幕上返回True：123456import pyautoguipyautogui.onScreen(0, 0) # Truepyautogui.onScreen(0, -1) # Falsepyautogui.onScreen(0, 2080) # Falsepyautogui.onScreen(1920, 1080) # Falsepyautogui.onScreen(1919, 1079) # True 鼠标行为moveTo()函数会把鼠标光标移动到指定的XY轴坐标处。如果传入None值，则表示使用当前光标的对象轴坐标值。12345pyautogui.moveTo(100, 200) # 光标移动到(100, 200)位置pyautogui.moveTo(None, 500) # 光标移动到(100, 500)位置pyautogui.moveTo(600, None) # 光标移动到(600, 500)位置#一般鼠标光标都是瞬间移动到指定的位置，如果你想让鼠标移动的慢点，可以设置持续时间：pyautogui.moveTo(100, 200, duration=2) # 用2秒把光标移动到(100, 200)位置 默认的持续时间pyautogui.MINIMUM_DURATION是0.1秒，如果你设置的时间比默认值还短，那么就会瞬间执行。 如果你想让光标以当前位置为原点，进行相对移动，就用pyautogui.moveRel()函数。例如：1234pyautogui.moveTo(100, 200) #把光标移动到(100, 200)位置pyautogui.moveRel(0, 50) #向下移动50pyautogui.moveRel(30, 0, 2) #向右移动30pyautogui.moveRel(30, None) #向右移动30 鼠标拖拽PyAutoGUI的dragTo()和dragRel()函数与moveTo()和moveRel()函数类似。另外，他们有一个button参数可以设置成left，middle和right三个键。例如：123456# 按住鼠标左键，把鼠标拖拽到(100, 200)位置pyautogui.dragTo(100, 200, button='left')# 按住鼠标左键，用2秒钟把鼠标拖拽到(300, 400)位置pyautogui.dragTo(300, 400, 2, button='left')# 按住鼠标右键，用2秒钟把鼠标拖拽到(30,0)位置pyautogui.dragTo(30, 0, 2, button='right') 缓动/渐变（Tween / Easing）函数缓动/渐变函数的作用是让光标的移动更炫。如果你不需要用到的话，你可以忽略这些。 缓动/渐变函数可以改变光标移动过程的速度和方向。通常鼠标是匀速直线运动，这就是线性缓动/渐变函数。PyAutoGUI有30种缓动/渐变函数，可以通过pyautogui.ease*?查看。其中，pyautogui.easeInQuad()函数可以用于moveTo()，moveRel()，dragTo()和dragRel()函数，光标移动呈现先慢后快的效果，整个过程的时间还是和原来一样。而pyautogui.easeOutQuad函数的效果相反：光标开始移动很快，然后慢慢减速。pyautogui.easeOutElastic是弹簧效果，首先越过终点，然后再反弹回来。例如：12345678910# 开始很慢，不断加速pyautogui.moveTo(100, 100, 2, pyautogui.easeInQuad)# 开始很快，不断减速pyautogui.moveTo(100, 100, 2, pyautogui.easeOutQuad)# 开始和结束都快，中间比较慢pyautogui.moveTo(100, 100, 2, pyautogui.easeInOutQuad)# 一步一徘徊前进pyautogui.moveTo(100, 100, 2, pyautogui.easeInBounce)# 徘徊幅度更大，甚至超过起点和终点pyautogui.moveTo(100, 100, 2, pyautogui.easeInElastic) 这些效果函数是模仿Al Sweigart的PyTweening模块，可以直接使用，不需要额外安装。如果你想创建自己的效果，也可以定义一个函数，其参数是(0.0,1.0)，表示起点和终点，返回值是介于[0.0,1.0]之间的数。 鼠标单击click()函数模拟单击鼠标左键一次的行为。例如：pyautogui.click()如果单击之前要先移动，可以把目标的XY坐标值传入函数：1234# 先移动到(100, 200)再单击pyautogui.click(x=100, y=200, duration=2)# 可以通过button参数设置left，middle和right三个键。例如：pyautogui.click(button='right') 要做多次单击可以设置clicks参数，还有interval参数可以设置每次单击之间的时间间隔。例如：123456# 双击左键pyautogui.click(clicks=2)# 两次单击之间停留0.25秒pyautogui.click(clicks=2, interval=0.25)# 三击右键pyautogui.click(button='right', clicks=2, interval=0.25) 为了操作方便，PyAutoGUI提供了doubleClick()，tripleClick()和rightClick()来实现双击、三击和右击操作。 鼠标按下和松开函数mouseDown()和mouseUp()函数可以实现鼠标按下和鼠标松开的操作。两者参数相同，有x，y和button。例如：123456# 鼠标左键按下再松开pyautogui.mouseDown(); pyautogui.mouseUp() # 按下鼠标右键pyautogui.mouseDown(button='right') # 移动到(100, 200)位置，然后松开鼠标右键pyautogui.mouseUp(button='right', x=100, y=200) 滚轮滚动函数鼠标滚轮滚动可以用scroll()函数和clicks次数参数来模拟。scroll()函数是vscroll()的一个包装（wrapper），执行竖直滚动。不同平台上的clicks次数不太一样。还有x和y参数可以在滚动之前定位到(x, y)位置。例如：1234567891011# 向上滚动10格pyautogui.scroll(10)# 向下滚动10格pyautogui.scroll(-10)# 移动到(100, 100)位置再向上滚动10格pyautogui.scroll(10, x=100, y=100)# 在OS X和Linux平台上，PyAutoGUI还可以用hscroll()实现水平滚动。例如：# 向右滚动10格pyautogui.hscroll(10)# 向左滚动10格pyautogui.hscroll(-10) 键盘控制函数typewrite()输入函数键盘控制的主要函数就是typewrite()。这个函数可以实现字符输入。typewrite()函数只能用于单个字符键，不能按SHITF和F1这些功能键。要在两次输入间增加时间间隔，可以用interval参数。例如：1234# 输入Hello world!pyautogui.typewrite('Hello world!')# 每次输入间隔0.25秒，输入Hello world!pyautogui.typewrite('Hello world!', interval=0.25) press()，keyDown()和keyUp()函数要按那些功能键，可以用press()函数把pyautogui.KEYBOARD_KEYS里面按键对应的字符串输入进去。例如： 123456# ENTER键pyautogui.press('enter')# F1键pyautogui.press('f1')# 左方向键pyautogui.press('left') press()函数其实是keyDown()和keyUp()函数的包装，模拟的按下然后松开两个动作。这两个函数可以单独调用。例如，按下shift键的同时按3次左方向键：1234567# 按下`shift`键pyautogui.keyDown('shift')pyautogui.press('left')pyautogui.press('left')pyautogui.press('left')# 松开`shift`键pyautogui.keyUp('shift') 和typewrite()函数一样，可以用数组把一组键传入press()。例如：pyautogui.press([&#39;left&#39;, &#39;left&#39;, &#39;left&#39;]) hotkey()函数为了更高效的输入热键，PyAutoGUI提供了hotkey()函数来绑定若干按键：pyautogui.hotkey(&#39;ctrl&#39;, &#39;shift&#39;, &#39;ese&#39;)等价于：123456pyautogui.keyDown('ctrl')pyautogui.keyDown('shift')pyautogui.keyDown('esc')pyautogui.keyUp('esc')pyautogui.keyUp('shift')pyautogui.keyUp('ctrl') KEYBOARD_KEYS下面就是press()，keyDown()，keyUp()和hotkey()函数可以输入的按键名称：print(pyautogui.KEYBOARD_KEYS)1[&apos;\\t&apos;, &apos;\\n&apos;, &apos;\\r&apos;, &apos; &apos;, &apos;!&apos;, &apos;&quot;&apos;, &apos;#&apos;, &apos;$&apos;, &apos;%&apos;, &apos;&amp;&apos;, &quot;&apos;&quot;, &apos;(&apos;, &apos;)&apos;, &apos;*&apos;, &apos;+&apos;, &apos;,&apos;, &apos;-&apos;, &apos;.&apos;, &apos;/&apos;, &apos;0&apos;, &apos;1&apos;, &apos;2&apos;, &apos;3&apos;, &apos;4&apos;, &apos;5&apos;, &apos;6&apos;, &apos;7&apos;, &apos;8&apos;, &apos;9&apos;, &apos;:&apos;, &apos;;&apos;, &apos;&lt;&apos;, &apos;=&apos;, &apos;&gt;&apos;, &apos;?&apos;, &apos;@&apos;, &apos;[&apos;, &apos;\\\\&apos;, &apos;]&apos;, &apos;^&apos;, &apos;_&apos;, &apos;`&apos;, &apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;, &apos;f&apos;, &apos;g&apos;, &apos;h&apos;, &apos;i&apos;, &apos;j&apos;, &apos;k&apos;, &apos;l&apos;, &apos;m&apos;, &apos;n&apos;, &apos;o&apos;, &apos;p&apos;, &apos;q&apos;, &apos;r&apos;, &apos;s&apos;, &apos;t&apos;, &apos;u&apos;, &apos;v&apos;, &apos;w&apos;, &apos;x&apos;, &apos;y&apos;, &apos;z&apos;, &apos;&#123;&apos;, &apos;|&apos;, &apos;&#125;&apos;, &apos;~&apos;, &apos;accept&apos;, &apos;add&apos;, &apos;alt&apos;, &apos;altleft&apos;, &apos;altright&apos;, &apos;apps&apos;, &apos;backspace&apos;, &apos;browserback&apos;, &apos;browserfavorites&apos;, &apos;browserforward&apos;, &apos;browserhome&apos;, &apos;browserrefresh&apos;, &apos;browsersearch&apos;, &apos;browserstop&apos;, &apos;capslock&apos;, &apos;clear&apos;, &apos;convert&apos;, &apos;ctrl&apos;, &apos;ctrlleft&apos;, &apos;ctrlright&apos;, &apos;decimal&apos;, &apos;del&apos;, &apos;delete&apos;, &apos;divide&apos;, &apos;down&apos;, &apos;end&apos;, &apos;enter&apos;, &apos;esc&apos;, &apos;escape&apos;, &apos;execute&apos;, &apos;f1&apos;, &apos;f10&apos;, &apos;f11&apos;, &apos;f12&apos;, &apos;f13&apos;, &apos;f14&apos;, &apos;f15&apos;, &apos;f16&apos;, &apos;f17&apos;, &apos;f18&apos;, &apos;f19&apos;, &apos;f2&apos;, &apos;f20&apos;, &apos;f21&apos;, &apos;f22&apos;, &apos;f23&apos;, &apos;f24&apos;, &apos;f3&apos;, &apos;f4&apos;, &apos;f5&apos;, &apos;f6&apos;, &apos;f7&apos;, &apos;f8&apos;, &apos;f9&apos;, &apos;final&apos;, &apos;fn&apos;, &apos;hanguel&apos;, &apos;hangul&apos;, &apos;hanja&apos;, &apos;help&apos;, &apos;home&apos;, &apos;insert&apos;, &apos;junja&apos;, &apos;kana&apos;, &apos;kanji&apos;, &apos;launchapp1&apos;, &apos;launchapp2&apos;, &apos;launchmail&apos;, &apos;launchmediaselect&apos;, &apos;left&apos;, &apos;modechange&apos;, &apos;multiply&apos;, &apos;nexttrack&apos;, &apos;nonconvert&apos;, &apos;num0&apos;, &apos;num1&apos;, &apos;num2&apos;, &apos;num3&apos;, &apos;num4&apos;, &apos;num5&apos;, &apos;num6&apos;, &apos;num7&apos;, &apos;num8&apos;, &apos;num9&apos;, &apos;numlock&apos;, &apos;pagedown&apos;, &apos;pageup&apos;, &apos;pause&apos;, &apos;pgdn&apos;, &apos;pgup&apos;, &apos;playpause&apos;, &apos;prevtrack&apos;, &apos;print&apos;, &apos;printscreen&apos;, &apos;prntscrn&apos;, &apos;prtsc&apos;, &apos;prtscr&apos;, &apos;return&apos;, &apos;right&apos;, &apos;scrolllock&apos;, &apos;select&apos;, &apos;separator&apos;, &apos;shift&apos;, &apos;shiftleft&apos;, &apos;shiftright&apos;, &apos;sleep&apos;, &apos;stop&apos;, &apos;subtract&apos;, &apos;tab&apos;, &apos;up&apos;, &apos;volumedown&apos;, &apos;volumemute&apos;, &apos;volumeup&apos;, &apos;win&apos;, &apos;winleft&apos;, &apos;winright&apos;, &apos;yen&apos;, &apos;command&apos;, &apos;option&apos;, &apos;optionleft&apos;, &apos;optionright&apos;] 消息弹窗函数PyAutoGUI通过Tkinter实现了4种纯Python的消息弹窗函数，和JavaScript类似。 alert()函数12pyautogui.alert(text='', title='', button='OK')# 'OK' 显示一个简单的带文字和OK按钮的消息弹窗。用户点击后返回button的文字。 confirm() 函数1234# OK和Cancel按钮的消息弹窗pyautogui.confirm(text='', title='', buttons=['OK', 'Cancel'])# 10个按键0-9的消息弹窗pyautogui.confirm(text='', title='', buttons=range(10)) 显示一个简单的带文字、OK和Cancel按钮的消息弹窗，用户点击后返回被点击button的文字，支持自定义数字、文字的列表。 prompt() 函数pyautogui.prompt(text=&#39;&#39;, title=&#39;&#39; , default=&#39;&#39;)可以输入的消息弹窗，带OK和Cancel按钮。用户点击OK按钮返回输入的文字，点击Cancel按钮返回None。 password() 函数pyautogui.password(text=&#39;&#39;, title=&#39;&#39;, default=&#39;&#39;, mask=&#39;*&#39;)样式同prompt()，用于输入密码，消息用*表示。带OK和Cancel按钮。用户点击OK按钮返回输入的文字，点击Cancel按钮返回None。 截屏函数PyAutoGUI可以截屏并保存为图片文件，然后定位这些截屏在屏幕上的位置。与sikuli类似，把屏幕上的按键截取下来，然后定位，就可以执行点击等操作了。 截屏功能需要安装Pillow模块。OS X用screencapture命令，是系统自带的。Linux用户用scrot命令，可以通过sudo apt-get install scrot安装。 Ubuntu注意事项由于Ubuntu上安装Pillow时缺少PNG和JPEG依赖，所以安装比较复杂，具体可以看Ubuntu论坛。不过用miniconda可以解决这些问题，如果Ubuntu或Mint上安装了miniconda，可以直接conda install pillow来安装。 screenshot()函数screenshot()函数会返回Image对象（参考Pillow或PIL模块文档），也可以设置文件名：1234567import pyautoguiim1 = pyautogui.screenshot()im2 = pyautogui.screenshot('my_screenshot.png')# 在一个 1920×10801920×1080 的屏幕上，screenshot()函数要消耗100微秒——不快也不慢。#如果你不需要截取整个屏幕，还有一个可选的region参数。你可以把截取区域的左上角XY坐标值和宽度、高度传入截取。im = pyautogui.screenshot(region=(0, 0, 300 ,400)) 定位函数可以定位截图在屏幕上的坐标位置。比如，你需要在计算器里输入： 如果你不知道按钮的位置，就不能用moveTo()定位和click()点击。而且每次计算器的位置可能会变化，这时即使有来坐标也不好用了。但是如果你有要点击按钮的截图，比如数字7： 你可以调用pyautogui.locateOnScreen(‘calc7key.png’)函数来获得7的屏幕坐标。返回的是一个元组(top, left, width, height)。这个元组可以用pyautogui.center()函数来获取截图屏幕的中心坐标。如果截图没找到，pyautogui.locateOnScreen()函数返回None：12345678import pyautoguibutton7location = pyautogui.locateOnScreen('pyautogui/calc7key.png')button7location# (1226, 546, 29, 28)button7x, button7y = pyautogui.center(button7location)button7x, button7y# (1240, 560)pyautogui.click(button7x, button7y) locateCenterOnScreen()等价于上面的前两布操作，直接获得截屏屏幕中心坐标：123import pyautoguix, y = pyautogui.locateCenterOnScreen('pyautogui/calc7key.png')pyautogui.click(x, y) 在 1920×10801920×1080 的屏幕上，定位函数需要1~2秒时间。对视频游戏（LOL、DOTA）来说就太慢了，但是上班干活还是绰绰有余。 还是几个定位函数。都是从左上角原点开始向右向下搜索截图位置： locateOnScreen(image, grayscale=False)：返回找到的第一个截图Image对象在屏幕上的坐标(left, top, width, height)，如果没找到返回None locateCenterOnScreen(image, grayscale=False)：返回找到的第一个截图Image对象在屏幕上的中心坐标(x, y)，如果没找到返回None locateAllOnScreen(image, grayscale=False)：返回找到的所有相同截图Image对象在屏幕上的坐标(left, top, width, height)的生成器 locate(needleImage, haystackImage, grayscale=False)：返回找到的第一个截图Image对象在haystackImage里面的坐标(left, top, width, height)，如果没找到返回None locateAll(needleImage, haystackImage, grayscale=False)：返回找到的所有相同截图Image对象在haystackImage里面的坐标(left, top, width, height)的生成器 两个locateAll*函数都可以用for循环和list()输出：12345for pos in pyautogui.locateAllOnScreen('pyautogui/calc7key.png'): print(pos)# (1227, 546, 29, 28)list(pyautogui.locateAllOnScreen('pyautogui/calc7key.png'))# [(1227, 546, 29, 28)] 灰度值匹配可以把grayscale参数设置为True来加速定位（大约提升30%），默认为False。这种去色（desaturate）方法可以加速定位，但是也可能导致假阳性（false-positive）匹配：1234import pyautoguibutton7location = pyautogui.locateOnScreen('pyautogui/calc7key.png', grayscale=True)button7location# (1227, 546, 29, 28) 像素匹配要获取截屏某个位置的RGB像素值，可以用Image对象的getpixel()方法：1234567import pyautoguiim = pyautogui.screenshot()im.getpixel((100, 200))# (255, 255, 255)# 也可以用PyAutoGUI的pixel()函数，是之前调用的包装：pyautogui.pixel(100, 200)# (255, 255, 255) 如果你只是要检验一下指定位置的像素值，可以用pixelMatchesColor()函数，把X、Y和RGB元组值穿入即可：123456789101112pyautogui.pixelMatchesColor(100, 200, (255, 255, 255))# Truepyautogui.pixelMatchesColor(100, 200, (255, 255, 245))# False# tolerance参数可以指定红、绿、蓝3种颜色误差范围：pyautogui.pixelMatchesColor(100, 200, (255, 255, 245), tolerance=10)# Truepyautogui.pixelMatchesColor(100, 200, (248, 250, 245), tolerance=10)# Truepyautogui.pixelMatchesColor(100, 200, (205, 255, 245), tolerance=10)# False 参考 https://muxuezi.github.io/posts/doc-pyautogui.html","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Javascript之this用法","slug":"js-this-2017-07-22","date":"2017-07-22T07:23:53.000Z","updated":"2017-12-04T00:54:14.554Z","comments":true,"path":"2017/07/22/js-this-2017-07-22/","link":"","permalink":"http://arvin-he.github.io/2017/07/22/js-this-2017-07-22/","excerpt":"","text":"this是Javascript语言的一个关键字。随着使用场合的不同，this的值会发生变化。但是有一个总的原则，那就是this始终指的是，调用函数的那个对象。 在全局作用域下在浏览器环境下：全局作用域下，this 指向 Window 对象.1234console.log(this);// Window &#123; .. &#125;this === window;// true 在 node 环境下：全局作用域下，this 指向 global 对象。1234console.log(this);// globalthis === global;// true 严格模式，在 node 环境下：遵循严格模式的规范，this 不再指向全局对象。123'use strict';console.log(this);// &#123;&#125; 函数对象作用域下12345function foo() &#123; console.log(this);&#125;foo();// global / Window 严格模式，在 node 环境下：123456'use strict';function foo() &#123; console.log(this);&#125;foo();// undefined 作为对象方法的调用作为对象方法时，this 指向该对象。12345678let obj = &#123; foo: function() &#123; console.log(this); &#125;&#125;;obj.foo();// &#123; foo: [Function] &#125;// obj 的值实际上是个匿名类的对象，foo 的值实际上是个匿名函数 注意到：在函数体内使用的、在函数体外定义（声明）的变量，是 传引用 的。123456789101112function func() &#123; console.log(this);&#125;let obj = &#123; foo: func&#125;;obj.foo();// &#123; foo: [Function func] &#125;let foo1 = obj.foo;foo1();// global 在回调函数里面会遇到一些坑1234567var obj = &#123; foo2: function() &#123; console.log(this); setTimeout(this.foo, 1000); &#125;&#125;obj.foo2(); 执行这段代码我们会发现两次打印出来的 this 是不一样的：第一次是 foo2 中直接打印 this，这里指向 obj 这个对象,但是在 setTimeout 中执行的 this.foo ，却指向了全局对象.把 this.foo 当作一个参数传给 setTimeout 这个函数，就像它需要一个 fun 参数，在传入参数的时候，其实做了个这样的操作 fun = this.foo，这里我们直接把 fun 指向 this.foo 的引用；执行的时候其实是执行了 fun() 所以已经和 obj 无关了，它是被当作普通函数直接调用的，因此 this 指向全局对象。 解决:为了解决这个问题，我们可以利用 闭包 的特性来处理：123456789101112var obj = &#123; name: 'qiutc', foo2: function() &#123; console.log(this); var _this = this; setTimeout(function() &#123; console.log(this); // Window console.log(_this); // Object &#123;name: \"qiutc\"&#125; &#125;, 1000); &#125;&#125;obj.foo2(); 可以看到直接用 this 仍然是 Window；因为 foo2 中的 this 是指向 obj，我们可以先用一个变量 _this 来储存，然后在回调函数中使用 _this，就可以指向当前的这个对象了； setTimeout 的另一个坑如果直接执行回调函数而没有绑定作用域，那么它的 this 是指向全局对象(window)，在严格模式下会指向 undefined，然而在 setTimeout 中的回调函数在严格模式下却表现出不同：123456'use strict';function foo() &#123; console.log(this);&#125;setTimeout(foo, 1);// window 按理说我们加了严格模式，foo 调用也没有指定 this，应该是出来 undefined，但是这里仍然出现了全局对象，难道是严格模式失效了吗？ 并不，即使在严格模式下，setTimeout 方法在调用传入函数的时候，如果这个函数没有指定了的 this，那么它会做一个隐式的操作—-自动地注入全局上下文，等同于调用 foo.apply(window) 而非 foo()； 当然，如果我们在传入函数的时候已经指定 this，那么就不会被注入全局对象，比如： setTimeout(foo.bind(obj), 1);； 箭头函数在 ES6 的新规范中，加入了箭头函数，它和普通函数最不一样的一点就是 this 的指向了，上文我们使用闭包来解决 this 的指向问题，但如果用上了箭头函数就可以更完美的解决了：12345678910111213var obj = &#123; name: 'qiutc', foo: function() &#123; console.log(this); &#125;, foo2: function() &#123; console.log(this); setTimeout(() =&gt; &#123; console.log(this); // Object &#123;name: \"qiutc\"&#125; &#125;, 1000); &#125;&#125;obj.foo2(); 可以看到，在 setTimeout 执行的函数中，本应该打印出在 Window，但是在这里 this 却指向了 obj，原因就在于，给 setTimeout 传入的函数（参数）是一个箭头函数： 函数体内的this对象，就是定义时所在的对象，而不是使用时所在的对象。关键点就是，箭头函数内的 this 执行定义时所在的对象，就是指向定义这个箭头函数时作用域内的 this，也就是 obj.foo2 中的 this，即 obj；所以在执行箭头函数的时候，它的 this -&gt; obj.foo2 中的 this -&gt; obj； 简单来说， 箭头函数中的 this 只和定义它时候的作用域的 this 有关，而与在哪里以及如何调用它无关，同时它的 this 指向是不可改变的。 call / apply / bindjs 中的函数对象，其 prototype 中定义了如下三个函数：123456func.call(thisArg[, arg1[, arg2[, ...]]]);// 执行函数 func，使用第一个参数作为 this，其他参数作为 func 的实参，一一对应。func.apply(thisArg[, [arg1, arg2, ...]]);// 执行函数 func，使用第一个参数作为 this，第二个参数为数组，数组中的每个元素作为 func 的实参，一一对应。var foo = func.bind(thisArg[, arg1[, arg2[, ...]]]);// 绑定 func 的 this 和所有参数，返回一个新的函数，但不执行它。 bind 的 this 对 new 关键字无效，但其他实参有效：12345678910111213function A(name) &#123; console.log(this.name); this.name = name; console.log(this.name);&#125;var obj = &#123; name: \"obj\"&#125;;var B = A.bind(obj, \"B\");var b = new B('b');// undefined Bconsole.log(obj.name);// obj 要注意，=&gt; 语法下的 this 不受影响，该语法下 this 视为 const 变量，不接受修改。","categories":[{"name":"js","slug":"js","permalink":"http://arvin-he.github.io/categories/js/"}],"tags":[{"name":"js","slug":"js","permalink":"http://arvin-he.github.io/tags/js/"}]},{"title":"C++之Map","slug":"cpp-map-2017-07-21","date":"2017-07-21T07:45:25.000Z","updated":"2017-09-08T03:51:39.314Z","comments":true,"path":"2017/07/21/cpp-map-2017-07-21/","link":"","permalink":"http://arvin-he.github.io/2017/07/21/cpp-map-2017-07-21/","excerpt":"","text":"map说明Map是STL的一个关联容器，它提供一对一的数据处理能力，map内部自建一颗红黑树(一种非严格意义上的平衡二叉树)，这颗树具有对数据自动排序的功能，所以在map内部所有的数据都是有序的.搜索效率是O(lgN). C++中的map类似python中的dict, 只不过python中的dict使用散列表实现的, 用时(N).它的特点是增加和删除节点对迭代器的影响很小，除了那个操作节点，对其他的节点都没有什么影响。对于迭代器来说，可以修改实值，而不能修改key。C++ STL中的标准规定： map 有序, 用红黑树实现 unordered_map，无序，用散列表实现 关于has_maphash_map 其实就是使用 hash 表来实现的 map。注意，二叉树，哈希表仅仅是 dictionary 的实现方式，不能说 hash 就等于 dictionary，实现方式可以有多种多样。 map的功能 自动建立Key － value的对应。key 和 value可以是任意你需要的类型 根据key值快速查找记录，查找的复杂度基本是Log(N)，如果有1000个记录，最多查找10次，1,000,000个记录，最多查找20次 快速插入Key - Value 记录 快速删除记录 根据Key 修改value记录 遍历所有记录 map使用123456789101112131415161718192021222324252627282930313233343536373839#include &lt;map&gt; #include &lt;string&gt; #include &lt;iostream&gt; using namespace std;int main()&#123; //定义map对象，当前没有任何元素 map&lt;string,float&gt; m; //插入元素，按键值的由小到大放入黑白树中 m[\"Jack\"] = 98.5 ; m[\"Bomi\"] = 96.0 ; m[\"Kate\"] = 97.5 ; //删除键值为\"Jack\"的元素 m.erase(\"Jack\") ; //先前遍历元素 map&lt;string,float&gt; :: iterator it ; for(it = m.begin(); it != m.end(); it ++) &#123; cout &lt;&lt; (*it).first &lt;&lt; \" : \" &lt;&lt; (*it).second &lt;&lt; endl ; &#125; //反向遍历元素 map&lt;int, char&gt; :: reverse_iterator rit ; for( rit = m.rbegin() ; rit != m.rend() ; rit ++) &#123; //输入键值与映照数据 cout &lt;&lt; (*rit).first &lt;&lt; \" : \" &lt;&lt; (*rit).second &lt;&lt; endl ; &#125; // 元素搜索 map&lt;int, char&gt; :: iterator it ; it = m.find(\"Bomi\") ; if(it != m.end()) //搜索到该键值 cout &lt;&lt; (*it).first &lt;&lt; \" : \" &lt;&lt; ( *it ).second &lt;&lt; endl ; else cout &lt;&lt; \"not found it\" &lt;&lt; endl ; return 0 ;&#125; 参考 https://my.oschina.net/gddyl/blog/113744","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"C/C++","slug":"C-C","permalink":"http://arvin-he.github.io/tags/C-C/"}]},{"title":"Linux之IO网络模型","slug":"linux-iomodel-2017-07-20","date":"2017-07-20T08:26:21.000Z","updated":"2017-09-08T03:51:39.772Z","comments":true,"path":"2017/07/20/linux-iomodel-2017-07-20/","link":"","permalink":"http://arvin-he.github.io/2017/07/20/linux-iomodel-2017-07-20/","excerpt":"","text":"前言IO有内存IO、网络IO和磁盘IO三种，通常我们说的IO指的是后两者.Linux的内核将所有外部设备都看做一个文件来操作，对一个文件的读写操作会调用内核提供的系统命令，返回一个file descriptor（fd，文件描述符 ）。而对一个socket的读写也会有相应的描述符，称为socketfd（socket描述符），描述符就是一个数字，它指向内核中的一个结构体（文件路径，数据区等一些属性）。 IO模型分类在Unix(Linux)下，可用的I/O模型有五种： 阻塞I/O 非阻塞I/O I/O多路复用：select和poll是属于这种I/O模型。 信号（或事件）驱动I/O 异步I/O 网络IO的本质就是socket流的读取，通常一次IO读操作会涉及到两个对象和两个阶段。两个对象分别是：用户进程（线程）Process（Thread）内核对象 Kernel 两个阶段：等待流数据准备（wating for the data to be ready）;从内核向进程复制数据（copying the data from the kernel to the process）; 对于socket流而已： 第一步通常涉及等待网络上的数据分组到达，然后被复制到内核的某个缓冲区。第二步把数据从内核缓冲区复制到应用进程缓冲区。 对于网络数据的接收操作而言，五种I/O模型都是分为两个阶段： 等待数据准备好。 将准备好的数据，从内核空间考到进程空间。 对于第一步，就是等待数据到达，到达之后，数据就被复制到内核缓冲区；对于第二步，将数据从内核缓冲区复制到进程缓冲区中。 阻塞I/O模型阻塞I/O模型属于最常见的I/O模型，在这五种I/O模型中都可以看到阻塞I/O的身影。默认情况下，所有的网络socket都是阻塞的。下面，我们就演示一下具体的数据处理过程： 进程对内核发起系统调用（recvfrom），当数据到达网卡并最终被复制到进程空间（或中途发生错误，比如对进程发送一个中断信号等）后，系统调用（recvfrom）就会返回信息给进程，之后，进程再根据返回的信息来进行相应的处理。而进程在收到recvfrom返回信息之前的整个时间段内，我们称，进程被阻塞。当recvfrom返回成功信息时，进程就开始对数据进行处理。 非阻塞I/O模型当I/O模型为非阻塞I/O时，那么就相当于告诉内核，当进程请求的数据没完成时，这个进程就不会进入睡眠状态，而是返回一个错误信息。 在此，对上图的流程做简单的介绍:前三次调用recvfrom，数据都未准备就绪，因此内核会立即返回一个EWOULDBLOCK的错误信息。第四次调用recvfrom时，数据已经准备就绪。然后数据被复制到进程缓冲区，并且recvfrom返回成功信息。最后，进程对数据进行处理。像这样，在非阻塞模型中一个进程反复调用recvfrom的过程，我们将它称为polling。此时，进程会不断的询问内核：是否某个操作已经准备就绪。而通常这又会浪费CPU时间片，所以，使用这种模型的很少见。 I/O多路复用模型在I/O多路复用模型下，我们可以使用select或poll系统调用，而此时发生的阻塞是由select或poll产生的，而不是在真正的I/O系统调用上。Linux提供select/poll（I/O复用模型会用到select或者poll函数，这两个函数也会使进程阻塞，但是和阻塞I/O所不同的是，这两个函数可以同时阻塞多个I/O操作。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时，才真正调用I/O操作函数），进程通过将一个或多个fd传递给select或poll系统调用，阻塞在select操作上，这样select/poll可以帮我们侦测多fd是否处于就绪状态。select/poll是顺序扫描fd是否就绪，而且支持的fd数量有限，因此它的使用受到了一些制约。Linux还提供了一个epoll系统调用，epoll使用基于事件驱动方式代替顺序扫描，因此性能更高。当有fd就绪时，立即回调函数rollback。 在此，对上图的流程做简单的介绍:在调用select，进程的一个请求就阻塞了，直到数据准备就绪。当select返回数据就绪信息（readable）时，然后，在调用recvfrom将数据复制到进程缓冲区。通过与第一张阻塞I/O模型的图的比较，我们并没有发现多路复用I/O模型有什么优点，并且事实上，还有一个小的缺点，因为使用select时需要两种不同的系统调用。但是使用select的好处是，我们可以同时等待多个I/O的完成。 信号驱动I/O模型我们可以使用信号，来告诉内核当数据准备就绪的时候，使用SIGIO信号来通知我们。我们将此称为信号驱动的I/O。 在此，对上图的流程做简单的介绍:首先，使用sigaction系统调用安装信号处理器。然后，立即从系统调用中返回，从而进程在继续执行，而不会被阻塞。当数据准备就绪的时候，就会生成SIGIO信号并发送给进程的信号处理器，然后再通过调用recvfrom来读取数据，并最终返回OK由进程对数据进行处理。 异步I/O模型：一般来说，异步I/O模型的实现是从操作步骤的开始到通知整个操作完成（包括将数据从内核复制到进程缓冲区中）。它和信号驱动I/O的主要不同是：信号I/O是在I/O操作正要开始的时候通知我们的，而异步I/O是当I/O操作完成时通知我们的。 在此，对上图的流程做简单的介绍:当调用aio_read时，会同时向内核传递描述符，缓冲区指针，缓冲区大小，文件偏移量和当整个操作完成时该如何通知我们等信息。然后，系统调用立即返回，并且进程在等待I/O完成的时候，不会发生阻塞。直到当操作完成的时候内核就会产生相应的信号，并通知给进程。 总结 程序空间与内核空间在Linux中，对于一次读取IO的操作，数据并不会直接拷贝到程序的程序缓冲区。它首先会被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的缓冲区。p.s: 最后一句话非常重要，重复一遍。 Waiting for the data to be ready(等待数据到达内核缓冲区)Copying the data from the kernel to the process(从内核缓冲区拷贝数据到程序缓冲区) 阻塞与非阻塞区别调用blocking IO会一直block住对应的进程直到操作完成，而non-blocking IO在kernel还准备数据的情况下会立刻返回。区分阻塞和非阻塞只要区分函数调用之后是否挂起返回就可以了 synchronous IO和asynchronous IO区别区分异步和同步，则是函数调用之后，数据或条件满足之后如何通知函数。等待数据返回则是同步，通过回调则是异步。 select/poll/epoll即使现在的各个Linux版本普遍引入了copy on write和线程，但实际上进程/线程之间的切换依然还是一笔很大的开销，这个时候我们可以考虑使用上面提到到多路IO复用，回顾一下我们上面提到的多路IO复用模型的基本原理：一个进程可以监视多个文件描述符，一旦某个文件描述符就绪（读/写准备就绪），能够信号通知程序进行相应的读写操作。下面我们就来简单的看一下多路IO复用的三种方式。 select12345678910int select (int maxfdp1, fd_set *readset, fd_set *writeset, fd_set *exceptset, const struct timeval *timeout);``` 如上面的方法声明所示, select监听三类描述符: readset(读), writeset(写), exceptset(异常), 我们编程的时候可以制定这三个参数监听对应的文件描述符。正如前面提到的,select调用后进程会阻塞, 当select返回后，可以通过遍历fdset，来找到就绪的描述符。select优点在于它的跨平台，但是也有显著的缺点单个进程能够监视的文件描述符的数量存在最大限制，默认设置为1024/2048，虽然设置可以超过这一限制，但是这样也可能会造成效率的降低。而且select扫描的时候也是采用的轮循，算法复杂度为O(n)，这在fdset很多时效率会较低。* poll```cppint poll (struct pollfd *fdarray, unsigned long nfds, int timeout); poll和select并没有太大的区别，但是它是基于链表实现的所以并没有最大数量限制，它将用户传入的数据拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次的遍历。算法复杂度也是O(n)。 epoll123int epoll_create(int size);int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); select和poll都只提供了一个函数。而epoll提供了三个函数: epoll_create是创建一个epoll句柄, epoll_ctl是注册要监听的事件类型, epoll_wait则是等待事件的产生。与select相比，epoll几乎没有描述符限制(cat /proc/sys/fs/file-max可查看)。它采用一个文件描述符管理多个描述符，将用户的文件描述符的事件存放到kernel的一个事件表中，这样在程序空间和内核空间的只要做一次拷贝。它去掉了遍历文件描述符这一步骤，采用更加先进的回调(callback)机制，算法复杂度降到了O(1)。p.s: 虽然表面看起来epoll非常好，但是对于连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，因为epoll是建立在大量的函数回调的基础之上。 参考 linux中的“5种网络 IO 模型” https://www.ziwenxie.site/2017/01/02/unix-network-programming-asynchronous/ http://blog.leanote.com/post/joesay/Concurrency-Model-Part-1-IO-Concurrency","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://arvin-he.github.io/tags/Linux/"}]},{"title":"C++的vertor实现","slug":"cpp-vector-2017-07-20","date":"2017-07-20T07:01:28.000Z","updated":"2017-09-08T03:51:39.379Z","comments":true,"path":"2017/07/20/cpp-vector-2017-07-20/","link":"","permalink":"http://arvin-he.github.io/2017/07/20/cpp-vector-2017-07-20/","excerpt":"","text":"C++的vector实现新增元素：Vector通过一个连续的数组存放元素，如果集合已满，在新增数据的时候，就要分配一块更大的内存，将原来的数据复制过来，释放之前的内存，在插入新增的元素。插入元素: 插入新的数据分在最后插入push_back和通过迭代器在任何位置插入，这里说一下通过迭代器插入，通过迭代器与第一个元素的距离知道要插入的位置，即int index=iter-begin()。这个元素后面的所有元素都向后移动一个位置，在空出来的位置上存入新增的元素。12345678910111213141516171819202122232425262728293031void insert(const_iterator iter,const T&amp; t )&#123; int index=iter-begin(); if (index&lt;size_) &#123; if (size_==capacity_) &#123; int capa=calculateCapacity(); newCapacity(capa); &#125; memmove(buf+index+1,buf+index,(size_-index)*sizeof(T)); buf[index]=t; size_++; &#125; &#125;``` 删除元素：删除和新增差不多，也分两种，删除最后一个元素pop_back和通过迭代器删除任意一个元素erase(iter)。通过迭代器删除还是先找到要删除元素的位置，即int index=iter-begin();这个位置后面的每个元素都想前移动一个元素的位置。同时我们知道erase不释放内存只初始化成默认值。删除全部元素clear：只是循环调用了erase，所以删除全部元素的时候，不释放内存。内存是在析构函数中释放的。```cppiterator erase(const_iterator iter)&#123; int index=iter-begin(); if (index&lt;size_ &amp;&amp; size_&gt;0) &#123; memmove(buf+index ,buf+index+1,(size_-index)*sizeof(T)); buf[--size_]=T(); &#125; return iterator(iter); &#125; 迭代器迭代器iteraotr是STL的一个重要组成部分,通过iterator可以很方便的存储集合中的元素.STL为每个集合都写了一个迭代器, 迭代器其实是对一个指针的包装,实现一些常用的方法,如++,--,!=,==,*,-&gt;等, 通过这些方法可以找到当前元素或是别的元素. vector是STL集合中比较特殊的一个,因为vector中的每个元素都是连续的,所以在自己实现vector的时候可以用指针代替,如typedef T* iterator;typedef const T* const_iterator，如果STL中的函数能方便的操作自己写的集合，实现的迭代器最好继承std::iterator&lt;std::forward_iterator_tag,T&gt;。std::iterator&lt;std::forward_iterator_tag,T&gt;的源码如下：123456789101112131415template&lt;class _Category, class _Ty, class _Diff = ptrdiff_t, class _Pointer = _Ty *, class _Reference = _Ty&amp;&gt; struct iterator&#123; // base type for all iterator classes typedef _Category iterator_category; typedef _Ty value_type; typedef _Diff difference_type; typedef _Diff distance_type; // retained typedef _Pointer pointer; typedef _Reference reference;&#125;; Iterator其中没有任何成员，只是定义了一组类型，所以继承它并不会让你的struct变大，这组类型是STL的内部契约，STL中的函数假设每个迭代器都定义了这些类型，所以只要你的迭代器定义了这些类型，就可以和STL函数集合一起使用。","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"C/C++","slug":"C-C","permalink":"http://arvin-he.github.io/tags/C-C/"}]},{"title":"C++的new/delete操作符","slug":"cpp-newdel-2017-07-20","date":"2017-07-20T06:20:11.000Z","updated":"2017-09-08T03:51:39.317Z","comments":true,"path":"2017/07/20/cpp-newdel-2017-07-20/","link":"","permalink":"http://arvin-he.github.io/2017/07/20/cpp-newdel-2017-07-20/","excerpt":"","text":"new/delete operator 和 operator new/delete 区别new/delete/new[]/delete[] operatoroperator new/delete/new[]/delete[]以new为例子new operator 即new 操作符分配内存就使用 operator new C++的new是怎么实现的123Class *pc = new Class;// ...delete pc; 上面代码的第一行即为 new operator ，而第三行即为 delete operator ，代码很简单，但对编译器来说，它需要做额外的工作，将上述代码翻译为近似于下面的代码： 123456void *p = operator new(sizeof(Class));// 对p指向的内存调用Class的构造函数，此处无法用直观的代码展现Class *pc = static_cast&lt;Class*&gt;(p);// ...pc-&gt;~Class();operator delete(pc); 面代码中，第一行即为 operator new ，而最后一行即为 operator delete new operator 实际上做了两件事情： 调用 operator new 分配内存 在分配好的内存上初始化对象，并返回指向该对象的指针 它可能会调用malloc, 但是具体如何分配内存要取决于实现. 相比于malloc, new默认在申请失败的时候会抛出异常而不是直接返回0.和new对应的是delete, 它们必须成对出现. new[] 则要和 delete[] 同时出现. 而 delete operator 类似，调用析构函数，再调用 operator delete 释放内存 C++标准库的实现之一——Clang的libcxx是如何实现全局的 operator new/delete 的（去掉了一些控制编译选项的宏定义，只留下了核心代码）：123456789101112131415161718void * operator new(std::size_t size) throw(std::bad_alloc) &#123; if (size == 0) size = 1; void* p; while ((p = ::malloc(size)) == 0) &#123; std::new_handler nh = std::get_new_handler(); if (nh) nh(); else throw std::bad_alloc(); &#125; return p;&#125;void operator delete(void* ptr) &#123; if (ptr) ::free(ptr);&#125; 神秘的 operator new/delete 在背后也不过是调用C函数库的 malloc/free. 当然，这跟实现有关，libcxx这样实现，不代表其它实现也是如此。 new与malloc区别new可以认为是一种封装，有一个全局函数叫operator new(size_t)就是一般意义上的new，你可以重写它，自己来实现分配内存并调用构造,一般认为new和malloc最大的区别就在于是否调用构造函数,除了会调用构造函数，new 还可以抛出bad_alloc异常. 参考深入探究C++的new/delete操作符","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"C/C++","slug":"C-C","permalink":"http://arvin-he.github.io/tags/C-C/"}]},{"title":"Python之加密与签名","slug":"py-crypto-2017-07-19","date":"2017-07-19T05:10:30.000Z","updated":"2017-09-08T03:51:39.838Z","comments":true,"path":"2017/07/19/py-crypto-2017-07-19/","link":"","permalink":"http://arvin-he.github.io/2017/07/19/py-crypto-2017-07-19/","excerpt":"","text":"密码与通信密码技术是一门历史悠久的技术。信息传播离不开加密与解密。密码技术的用途主要源于两个方面，加密/解密和签名/验签 python中的加密库hashlib与pycryptoPython的hashlib提供了常用的摘要算法，比如md5, sha1, sha224, sha256, sha384, sha512等。摘要算法又称哈希算法、散列算法。它通过一个函数，把任意长度的数据转换为一个长度固定的数据串（通常用16进制的字符串表示）。摘要算法就是通过摘要函数f()对任意长度的数据data计算出固定长度的摘要digest，目的是为了发现原始数据是否被人篡改过。摘要算法之所以能指出数据是否被篡改过，就是因为摘要函数是一个单向函数，计算f(data)很容易，但通过digest反推data却非常困难。而且，对原始数据做一个bit的修改，都会导致计算出的摘要完全不同。常见的摘要算法MD5. 摘要算法应用 存储用户登录的用户名和口令时, 存储用户口令的摘要 对配置文件某些配置生成签名,防止篡改 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465import hashlibdef getHash(file_path): f = open(file_path, \"rb\") #以二进制读模式打开 line = f.readline() hash = hashlib.md5() while(line): hash.update(line.encode('utf8')) line = f.readline() f.close() return hash.hexdigest()def IsHashEqual(file_path1, file_path2): str1 = getHash(file_path1) str2 = getHash(file_path2) return str1 == str2if __name__ == '__main__': if IsHashEqual(\"E:\\\\GIT\\\\1.txt\", \"E:\\\\GIT\\\\2.txt\"): print \"文件内容相同!\" else: print \"文件内容不同!\"# 例子: 对配置文件中配置选项进行加密, 这里加密的不一定非得是文件,或者文件中某一个字符串, 也可以是你组合生成的字符串,但是# 组合生成的字符串格式内容是固定的.# 自动记录设备hash值def _record_device_hash(device_ini_path, base_ini_path): ini = load_config(device_ini_path) if not ini.has_section('DeviceSignature'): ini.add_section('DeviceSignature') ini.write(open(device_ini_path, \"w\", encoding=\"utf-8\")) device_hash = _get_device_hash(device_ini_path, base_ini_path) write_config(device_ini_path, \"DeviceSignature\", \"signature\", device_hash)# 配置文件配置选项签名,防篡改# 获取设备信息的hash值def _get_device_hash(): import hashlib axis_cards = _get_axiscards() ini = basic.sysData(\"ini/base.ini\") manufacturer = ini['sys']['manufacturer'] axis_cards.append(manufacturer) model = ini['sys']['model'] axis_cards.append(model) secret_key = 'you never guess' axis_cards.append(secret_key) devices_str = ','.join(axis_cards) device_hash = hashlib.md5() device_hash.update(devices_str.encode('utf-8')) return device_hash.hexdigest()# 判断hash值是否相等def _is_hash_equal(): hash1 = _get_device_hash() ini = basic.sysData(\"ini/device.ini\") if ini.has_option('DeviceSignature', 'signature'): hash2 = ini['DeviceSignature']['signature'] if hash2 is None: return False return hash1 == hash2 else: return False 关于pycrypto加密PyCrypto是一个免费的加密算法库，支持常见的DES、AES加密以及MD5、SHA各种HASH运算. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849from Crypto.Cipher import AESfrom binascii import b2a_hex, a2b_hexclass Mycrypto(): def __init__(self, key='keyskeyskeyskeys', iv = 'keyskeyskeyskeys'): self.key = key # iv 长度必须是16字节, iv可以与key不一样 self.iv = iv self.mode = AES.MODE_CBC # 加密函数，如果text不是16的倍数【加密文本text必须为16的倍数！】，那就补足为16的倍数 def encrypt(self, text): cryptor = AES.new(self.key, self.mode, self.iv) # 这里密钥key 长度必须为16（AES-128）、24（AES-192）、或32（AES-256）Bytes 长度.目前AES-128足够用 my_add = 16 - (len(text) % 16) text = text + ('\\0' * my_add) self.ciphertext = cryptor.encrypt(text) # 因为AES加密时候得到的字符串不一定是ascii字符集的，输出到终端或者保存时候可能存在问题 # 所以这里统一把加密后的字符串转化为16进制字符串 return b2a_hex(self.ciphertext) # 解密后，去掉补足的空格用strip() 去掉 def decrypt(self, text): cryptor = AES.new(self.key, self.mode, self.iv) plain_text = cryptor.decrypt(a2b_hex(text)) return plain_text.decode('utf-8').rstrip('\\0')# 创建加密对象mycrypto = Mycrypto()# 加密信息device_ini_path = os.path.join(sysDir, \"ini\", \"device.ini\")device_info = load_config(device_ini_path)if device_info.has_section(\"DeviceDetail\"): for k, v in device_info[\"DeviceDetail\"].items(): encrypt_text = mycrypto.encrypt(v) print(\"encrypt_text = &#123;&#125;\".format(encrypt_text)) write_config(device_ini_path, \"DeviceDetail\", k, str(encrypt_text)[2:-1])# 获取解密后的配置信息def _get_axiscards_decrypto_config(): import mycrypto mycrypto_ = mycrypto.Mycrypto() axiscards_detail = &#123;&#125; ini = basic.sysData(\"ini/device.ini\") for k, v in ini[\"DeviceDetail\"].items(): plain_text = mycrypto_.decrypt(v) print(\"plain_text = &#123;&#125;\".format(plain_text)) axiscards_detail[k] = int(plain_text) return axiscards_detail","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Http读书笔记第十一章","slug":"http-note11-2017-07-17","date":"2017-07-17T02:50:09.000Z","updated":"2017-09-08T03:51:39.585Z","comments":true,"path":"2017/07/17/http-note11-2017-07-17/","link":"","permalink":"http://arvin-he.github.io/2017/07/17/http-note11-2017-07-17/","excerpt":"","text":"Web 的攻击技术目前，来自互联网的攻击大多是冲着 Web 站点来的，它们大多把Web 应用作为攻击目标。 HTTP 不具备必要的安全功能几乎现今所有的 Web 网站都会使用会话（session）管理、加密处理等安全性方面的功能，而 HTTP 协议内并不具备这些功能。 在客户端即可篡改请求在 Web 应用中，从浏览器那接收到的 HTTP 请求的全部内容，都可以在客户端自由地变更、篡改。所以 Web 应用可能会接收到与预期数据不相同的内容。在 HTTP 请求报文内加载攻击代码，就能发起对 Web 应用的攻击。通过 URL 查询字段或表单、HTTP 首部、Cookie 等途径把攻击代码传入，若这时 Web 应用存在安全漏洞，那内部信息就会遭到窃取，或被攻击者拿到管理权限。 针对 Web 应用的攻击模式对 Web 应用的攻击模式有以下两种。 主动攻击 被动攻击 主动攻击（active attack）是指攻击者通过直接访问 Web 应用，把攻击代码传入的攻击模式。由于该模式是直接针对服务器上的资源进行攻击，因此攻击者需要能够访问到那些资源。 主动攻击模式里具有代表性的攻击是 SQL 注入攻击和 OS 命令注入攻击。 被动攻击（passive attack）是指利用圈套策略执行攻击代码的攻击模式。在被动攻击过程中，攻击者不直接对目标 Web 应用访问发起攻击。步骤 1： 攻击者诱使用户触发已设置好的陷阱，而陷阱会启动发送已嵌入攻击代码的 HTTP 请求。步骤 2： 当用户不知不觉中招之后，用户的浏览器或邮件客户端就会触发这个陷阱。步骤 3： 中招后的用户浏览器会把含有攻击代码的 HTTP 请求发送给作为攻击目标的 Web 应用，运行攻击代码。步骤 4： 执行完攻击代码，存在安全漏洞的 Web 应用会成为攻击者的跳板，可能导致用户所持的 Cookie 等个人信息被窃取，登录状态中的用户权限遭恶意滥用等后果。 被动攻击模式中具有代表性的攻击是跨站脚本攻击和跨站点请求伪造。 因输出值转义不完全引发的安全漏洞实施 Web 应用的安全对策可大致分为以下两部分。 客户端的验证 Web 应用端（服务器端）的验证 输入值验证 输出值转义 跨站脚本攻击跨站脚本攻击（Cross-Site Scripting，XSS）是指通过存在安全漏洞的Web 网站注册用户的浏览器内运行非法的 HTML 标签或 JavaScript 进行的一种攻击。 SQL 注入攻击SQL 注入（SQL Injection）是指针对 Web 应用使用的数据库，通过运行非法的 SQL 而产生的攻击。该安全隐患有可能引发极大的威胁，有时会直接导致个人信息及机密信息的泄露。SQL 注入攻击有可能会造成以下等影响: 非法查看或篡改数据库内的数据 规避认证 执行和数据库服务器业务关联的程序等 何为 SQLSQL 是用来操作关系型数据库管理系统（Relational DataBase Management System，RDBMS）的数据库语言，可进行操作数据或定义数据等。RDBMS 中有名的数据库有 Oracle Database、Microsoft SQL Server、IBM DB2、MySQL 和 PostgreSQL 等。这些数据库系统都可以把 SQL 作为数据库语言使用。 OS 命令注入攻击OS 命令注入攻击（OS Command Injection）是指通过 Web 应用，执行非法的操作系统命令达到攻击的目的。只要在能调用 Shell 函数的地方就有存在被攻击的风险。 HTTP 首部注入攻击HTTP 首部注入攻击（HTTP Header Injection）是指攻击者通过在响应首部字段内插入换行，添加任意响应首部或主体的一种攻击。属于被动攻击模式。向首部主体内添加内容的攻击称为 HTTP 响应截断攻击(HTTP Response Splitting Attack). 邮件首部注入攻击邮件首部注入（Mail Header Injection）是指 Web 应用中的邮件发送功能，攻击者通过向邮件首部 To 或 Subject 内任意添加非法内容发起的攻击。利用存在安全漏洞的 Web 网站，可对任意邮件地址发送广告邮件或病毒邮件。 目录遍历攻击目录遍历（Directory Traversal）攻击是指对本无意公开的文件目录，通过非法截断其目录路径后，达成访问目的的一种攻击。这种攻击有时也称为路径遍历（Path Traversal）攻击。 远程文件包含漏洞远程文件包含漏洞（Remote File Inclusion）是指当部分脚本内容需要从其他文件读入时，攻击者利用指定外部服务器的 URL 充当依赖文件，让脚本读取之后，就可运行任意脚本的一种攻击。 因设置或设计上的缺陷引发的安全漏洞因设置或设计上的缺陷引发的安全漏洞是指，错误设置 Web 服务器，或是由设计上的一些问题引起的安全漏洞。 强制浏览强制浏览（Forced Browsing）安全漏洞是指，从安置在 Web 服务器的公开目录下的文件中，浏览那些原本非自愿公开的文件。 不正确的错误消息处理不正确的错误消息处理（Error Handling Vulnerability）的安全漏洞是指，Web 应用的错误信息内包含对攻击者有用的信息。与 Web 应用有关的主要错误信息如下所示: Web 应用抛出的错误消息 数据库等系统抛出的错误消息Web 应用不必在用户的浏览画面上展现详细的错误消息。对攻击者来说，详细的错误消息有可能给他们下一次攻击以提示。 开放重定向开放重定向（Open Redirect）是一种对指定的任意 URL 作重定向跳转的功能。而于此功能相关联的安全漏洞是指，假如指定的重定向 URL到某个具有恶意的 Web 网站，那么用户就会被诱导至那个 Web 网站。 因会话管理疏忽引发的安全漏洞会话劫持会话劫持（Session Hijack）是指攻击者通过某种手段拿到了用户的会话 ID，并非法使用此会话 ID 伪装成用户，达到攻击的目的。 会话固定攻击对以窃取目标会话 ID 为主动攻击手段的会话劫持而言，会话固定攻击（Session Fixation）攻击会强制用户使用攻击者指定的会话 ID，属于被动攻击。 跨站点请求伪造跨站点请求伪造（Cross-Site Request Forgeries，CSRF）攻击是指攻击者通过设置好的陷阱，强制对已完成认证的用户进行非预期的个人信息或设定信息等某些状态更新，属于被动攻击。 其他安全漏洞密码破解密码破解攻击（Password Cracking）即算出密码，突破认证。攻击不仅限于 Web 应用，还包括其他的系统（如 FTP 或 SSH 等） 点击劫持点击劫持（Clickjacking）是指利用透明的按钮或链接做成陷阱，覆盖在 Web 页面之上。然后诱使用户在不知情的情况下，点击那个链接访问内容的一种攻击手段。这种行为又称为界面伪装（UI Redressing）。 DoS 攻击DoS 攻击（Denial of Service attack）是一种让运行中的服务呈停止状态的攻击。有时也叫做服务停止攻击或拒绝服务攻击。DoS 攻击的对象不仅限于 Web 网站，还包括网络设备及服务器等。集中利用访问请求造成资源过载，资源用尽的同时，实际上服务也就呈停止状态。通过攻击安全漏洞使服务停止 后门程序后门程序（Backdoor）是指开发设置的隐藏入口，可不按正常步骤使用受限功能。利用后门程序就能够使用原本受限制的功能。通常的后门程序分为以下 3 种类型: 开发阶段作为 Debug 调用的后门程序 开发者为了自身利益植入的后门程序 攻击者通过某种方法设置的后门程序","categories":[{"name":"Web","slug":"Web","permalink":"http://arvin-he.github.io/categories/Web/"}],"tags":[{"name":"http","slug":"http","permalink":"http://arvin-he.github.io/tags/http/"}]},{"title":"Http读书笔记第十章","slug":"http-note10-2017-07-17","date":"2017-07-17T00:06:17.000Z","updated":"2017-09-08T03:51:39.582Z","comments":true,"path":"2017/07/17/http-note10-2017-07-17/","link":"","permalink":"http://arvin-he.github.io/2017/07/17/http-note10-2017-07-17/","excerpt":"","text":"构建 Web 内容的技术HTML由 HTML 构成的文档经过浏览器的解析、渲染后，呈现出来的结果就是 Web 页面。 设计应用 CSSCSS（Cascading Style Sheets，层叠样式表）可以指定如何展现 HTML内的各种元素，属于样式表标准之一。CSS的理念就是让文档的结构和设计分离，达到解耦的目的。 动态 HTML动态 HTML 技术是通过调用客户端脚本语言 JavaScript，实现对HTML 的 Web 页面的动态改造。利用 DOM（Document Object Model，文档对象模型）可指定欲发生动态变化的 HTML 元素。 Web 服务器及程序协作的 CGICGI（Common Gateway Interface，通用网关接口）是指 Web 服务器在接收到客户端发送过来的请求后转发给程序的一组机制。 因 Java 而普及的 ServletServlet 1 是一种能在服务器上创建动态内容的程序。Servlet 是用 Java语言实现的一个接口，属于面向企业级 Java（JavaEE，Java Enterprise Edition）的一部分。 数据发布的格式及语言XML（eXtensible Markup Language，可扩展标记语言）是一种可按应用目标进行扩展的通用标记语言。旨在通过使用 XML，使互联网数据共享变得更容易。 JavaScript 衍生的轻量级易用 JSONJSON（JavaScript Object Notation）是一种以JavaScript（ECMAScript）的对象表示法为基础的轻量级数据标记语言。能够处理的数据类型有 false/null/true/ 对象 / 数组 / 数字 / 字符串，这 7 种类型。JSON 让数据更轻更纯粹，并且 JSON 的字符串形式可被 JavaScript 轻易地读入。","categories":[{"name":"Web","slug":"Web","permalink":"http://arvin-he.github.io/categories/Web/"}],"tags":[{"name":"http","slug":"http","permalink":"http://arvin-he.github.io/tags/http/"}]},{"title":"Http读书笔记第九章","slug":"http-note9-2017-07-14","date":"2017-07-13T23:49:57.000Z","updated":"2017-09-08T03:51:39.688Z","comments":true,"path":"2017/07/14/http-note9-2017-07-14/","link":"","permalink":"http://arvin-he.github.io/2017/07/14/http-note9-2017-07-14/","excerpt":"","text":"##基于 HTTP 的功能追加协议 HTTP 的瓶颈在 Facebook 和 Twitter 等 SNS 网站上，几乎能够实时观察到海量用户公开发布的内容，为了尽可能实时地显示这些更新的内容，服务器上一有内容更新，就需要直接把那些内容反馈到客户端的界面上。使用 HTTP 协议探知服务器上是否有内容更新，就必须频繁地从客户端到服务器端进行确认。如果服务器上没有内容更新，那么就会产生徒劳的通信。若想在现有 Web 实现所需的功能，以下这些 HTTP 标准就会成为瓶颈。 一条连接上只可发送一个请求。 请求只能从客户端开始。客户端不可以接收除响应以外的指令。 请求 / 响应首部未经压缩就发送。首部信息越多延迟越大。 发送冗长的首部。每次互相发送相同的首部造成的浪费较多。 可任意选择数据压缩格式。非强制压缩发送。 Ajax 的解决方法Ajax（Asynchronous JavaScript and XML， 异 步 JavaScript 与 XML 技术）是一种有效利用 JavaScript 和 DOM（Document Object Model，文档对象模型）的操作，以达到局部 Web 页面替换加载的异步通信手段。Ajax 的核心技术是名为 XMLHttpRequest 的 API，通过 JavaScript 脚本语言的调用就能和服务器进行 HTTP 通信。而利用 Ajax 实时地从服务器获取内容，有可能会导致大量请求产生。另外，Ajax 仍未解决 HTTP 协议本身存在的问题。 Comet 的解决方法一旦服务器端有内容更新了，Comet 不会让请求等待，而是直接给客户端返回响应。这是一种通过延迟应答，模拟实现服务器端向客户端推送（Server Push）的功能。通常，服务器端接收到请求，在处理完毕后就会立即返回响应，但为了实现推送功能，Comet 会先将响应置于挂起状态，当服务器端有内容更新时，再返回该响应。因此，服务器端一旦有更新，就可以立即反馈给客户端。内容上虽然可以做到实时更新，但为了保留响应，一次连接的持续时间也变长了。期间，为了维持连接会消耗更多的资源。另外，Comet也仍未解决 HTTP 协议本身存在的问题。 SPDY 的设计与功能SPDY 没有完全改写 HTTP 协议，而是在 TCP/IP 的应用层与运输层之间通过新加会话层的形式运作。同时，考虑到安全性问题，SPDY 规定通信中使用 SSL。SPDY 以会话层的形式加入,控制对数据的流动,但还是采用 HTTP建立通信连接。因此,可照常使用 HTTP 的 GET 和 POST 等方法,Cookie 以及 HTTP 报文等。使用 SPDY 后，HTTP 协议额外获得以下功能。多路复用流通过单一的 TCP 连接，可以无限制处理多个 HTTP 请求。所有请求的处理都在一条 TCP 连接上完成，因此 TCP 的处理效率得到提高。赋予请求优先级SPDY 不仅可以无限制地并发处理请求，还可以给请求逐个分配优先级顺序。这样主要是为了在发送多个请求时，解决因带宽低而导致响应变慢的问题。压缩 HTTP 首部压缩 HTTP 请求和响应的首部。这样一来，通信产生的数据包数量和发送的字节数就更少了。推送功能支持服务器主动向客户端推送数据的功能。这样，服务器可直接发送数据，而不必等待客户端的请求。服务器提示功能服务器可以主动提示客户端请求所需的资源。由于在客户端发现资源之前就可以获知资源的存在，因此在资源已缓存等情况下，可以避免发送不必要的请求。 SPDY 基本上只是将单个域名（ IP 地址）的通信多路复用，所以当一个 Web 网站上使用多个域名下的资源，改善效果就会受到限制。SPDY 的确是一种可有效消除 HTTP 瓶颈的技术，但很多 Web 网站存在的问题并非仅仅是由 HTTP 瓶颈所导致。对 Web 本身的速度提升，还应该从其他可细致钻研的地方入手，比如改善 Web 内容的编写方式等。 使用浏览器进行全双工通信的WebSocketWebSocket，即 Web 浏览器与 Web 服务器之间全双工通信标准。其中，WebSocket 协议由 IETF 定为标准，WebSocket API 由 W3C 定为标准。仍在开发中的 WebSocket 技术主要是为了解决 Ajax 和 Comet里 XMLHttpRequest 附带的缺陷所引起的问题。由于是建立在 HTTP 基础上的协议，因此连接的发起方仍是客户端，而一旦确立 WebSocket 通信连接，不论服务器还是客户端，任意一方都可直接向对方发送报文。WebSocket 协议的主要特点:推送功能支持由服务器向客户端推送数据的推送功能。这样，服务器可直接发送数据，而不必等待客户端的请求。减少通信量只要建立起 WebSocket 连接，就希望一直保持连接状态。和 HTTP 相比，不但每次连接时的总开销减少，而且由于 WebSocket 的首部信息很小，通信量也相应减少了。为了实现 WebSocket 通信，在 HTTP 连接建立之后，需要完成一次“握手”（Handshaking）的步骤。 握手·请求为了实现 WebSocket 通信，需要用到 HTTP 的 Upgrade 首部字段，告知服务器通信协议发生改变，以达到握手的目的。 握手·响应对于之前的请求，返回状态码 101 Switching Protocols 的响应。 期盼已久的 HTTP/2.0HTTP/2.0 围绕着主要的 7 项技术进行讨论，现阶段（2012 年 8 月 13日），大都倾向于采用以下协议的技术。但是，讨论仍在持续，所以不能排除会发生重大改变的可能性。 压缩 SPDY、Friendly 多路复用 SPDY TLS 义务化 Speed＋ Mobility 协商 Speed＋ Mobility，Friendly 客户端拉曳（Client Pull）/服务器推送（Server Push）Speed＋ Mobility 流量控制 SPDY WebSocket Speed＋ Mobility Web 服务器管理文件的 WebDAVWebDAV（Web-based Distributed Authoring and Versioning，基于万维网的分布式创作和版本控制）是一个可对 Web 服务器上的内容直接进行文件复制、编辑等操作的分布式文件系统。它作为扩展 HTTP/1.1的协议定义在 RFC4918。除了创建、删除文件等基本功能，它还具备文件创建者管理、文件编辑过程中禁止其他用户内容覆盖的加锁功能，以及对文件内容修改的版本控制功能。使用 HTTP/1.1 的 PUT 方法和 DELETE 方法，就可以对 Web 服务器上的文件进行创建和删除操作。可是出于安全性及便捷性等考虑，一般不使用。 扩展 HTTP/1.1 的 WebDAV针对服务器上的资源，WebDAV 新增加了一些概念集合（Collection）：是一种统一管理多个资源的概念。以集合为单位可进行各种操作。也可实现类似集合的集合这样的叠加。资源（Resource）：把文件或集合称为资源。属性（Property）：定义资源的属性。定义以“名称 = 值”的格式执行。锁（Lock）：把文件设置成无法编辑状态。多人同时编辑时，可防止在同一时间进行内容写入。 WebDAV 内新增的方法及状态码PROPFIND ：获取属性PROPPATCH ：修改属性MKCOL ：创建集合COPY ：复制资源及属性MOVE ：移动资源LOCK ：资源加锁UNLOCK ：资源解锁 为配合扩展的方法，状态码也随之扩展。102 Processing ：可正常处理请求，但目前是处理中状态207 Multi-Status ：存在多种状态422 Unprocessible Entity ：格式正确，内容有误423 Locked ：资源已被加锁424 Failed Dependency ：处理与某请求关联的请求失败，因此不再维持依赖关系507 Insufficient Storage ：保存空间不足","categories":[{"name":"Web","slug":"Web","permalink":"http://arvin-he.github.io/categories/Web/"}],"tags":[{"name":"http","slug":"http","permalink":"http://arvin-he.github.io/tags/http/"}]},{"title":"HTML笔记二","slug":"html-notes2-2017-07-13","date":"2017-07-13T07:31:02.000Z","updated":"2017-09-08T03:51:39.511Z","comments":true,"path":"2017/07/13/html-notes2-2017-07-13/","link":"","permalink":"http://arvin-he.github.io/2017/07/13/html-notes2-2017-07-13/","excerpt":"","text":"HTML 列表1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;!--无序列表--&gt;&lt;ul&gt; &lt;li&gt;咖啡&lt;/li&gt; &lt;li&gt;茶&lt;/li&gt; &lt;li&gt;牛奶&lt;/li&gt;&lt;/ul&gt;&lt;!--指定类型的无序列表--&gt;&lt;ul type=\"circle\"&gt; &lt;li&gt;苹果&lt;/li&gt; &lt;li&gt;香蕉&lt;/li&gt; &lt;li&gt;柠檬&lt;/li&gt; &lt;li&gt;桔子&lt;/li&gt;&lt;/ul&gt; &lt;!--有序列表--&gt;&lt;ol&gt; &lt;li&gt;咖啡&lt;/li&gt; &lt;li&gt;牛奶&lt;/li&gt; &lt;li&gt;茶&lt;/li&gt;&lt;/ol&gt;&lt;!--设定起始索引的有序列表--&gt;&lt;ol start=\"50\"&gt; &lt;li&gt;咖啡&lt;/li&gt; &lt;li&gt;牛奶&lt;/li&gt; &lt;li&gt;茶&lt;/li&gt;&lt;/ol&gt;&lt;!--嵌套列表--&gt;&lt;ul&gt; &lt;li&gt;咖啡&lt;/li&gt; &lt;li&gt;茶 &lt;ul&gt; &lt;li&gt;红茶&lt;/li&gt; &lt;li&gt;绿茶&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;牛奶&lt;/li&gt;&lt;/ul&gt;&lt;!--自定义列表--&gt;&lt;dl&gt; &lt;dt&gt;计算机&lt;/dt&gt; &lt;dd&gt;用来计算的仪器 ... ...&lt;/dd&gt; &lt;dd&gt;用来计算的仪器2 ... ...&lt;/dd&gt; &lt;dt&gt;显示器&lt;/dt&gt; &lt;dd&gt;以视觉方式显示信息的装置 ... ...&lt;/dd&gt;&lt;/dl&gt; HTML 表单与输入123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;!--文本域(Text fields)--&gt;&lt;form&gt;名：&lt;input type=\"text\" name=\"firstname\"&gt;&lt;br /&gt;姓：&lt;input type=\"text\" name=\"lastname\"&gt;&lt;/form&gt;&lt;!--密码域--&gt;&lt;form&gt;用户：&lt;input type=\"text\" name=\"user\"&gt;&lt;br /&gt;密码：&lt;input type=\"password\" name=\"password\"&gt;&lt;/form&gt;&lt;!--复选框--&gt;&lt;form&gt;我喜欢自行车：&lt;input type=\"checkbox\" name=\"Bike\"&gt;&lt;br /&gt;我喜欢汽车：&lt;input type=\"checkbox\" name=\"Car\"&gt;&lt;/form&gt;&lt;!--单选按钮--&gt;&lt;form&gt;男性：&lt;input type=\"radio\" checked=\"checked\" name=\"Sex\" value=\"male\" /&gt;&lt;br /&gt;女性：&lt;input type=\"radio\" name=\"Sex\" value=\"female\" /&gt;&lt;/form&gt;&lt;!--下拉列表, 指定初始显示值的下拉列表,如果没有指定默认第一个为初始显示值--&gt;&lt;form&gt;&lt;select name=\"cars\"&gt;&lt;option value=\"volvo\"&gt;Volvo&lt;/option&gt;&lt;option value=\"saab\"&gt;Saab&lt;/option&gt;&lt;option value=\"fiat\" selected=\"selected\"&gt;Fiat&lt;/option&gt;&lt;option value=\"audi\"&gt;Audi&lt;/option&gt;&lt;/select&gt;&lt;/form&gt;&lt;!--创建一个文本域（多行文本输入控件）。用户可以在文本域中写入文本。在文本域中，可写入的字符字数不受限制。--&gt;&lt;textarea cols=\"30\" rows=\"5\"&gt;领先的 Web 技术教程 - 全部免费在w3school，你可以找到你所需要的所有的网站建设教程。从基础的HTML到XHTML，乃至进阶的XML、SQL、数据库、多媒体和WAP。&lt;/textarea&gt;&lt;!--创建按钮--&gt;&lt;form&gt;&lt;input type=\"button\" value=\"Hello world!\"&gt;&lt;/form&gt;&lt;!--创建group box--&gt;&lt;form&gt; &lt;fieldset&gt; &lt;legend&gt;健康信息&lt;/legend&gt; 身高：&lt;input type=\"text\" /&gt; 体重：&lt;input type=\"text\" /&gt; &lt;/fieldset&gt;&lt;/form&gt; 表单实例1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;!--如果您点击提交，表单数据会被发送到名为 demo_form.asp 的页面。--&gt;&lt;form action=\"/demo/demo_form.asp\"&gt;First name:&lt;br&gt;&lt;input type=\"text\" name=\"firstname\" value=\"Mickey\"&gt;&lt;br&gt;Last name:&lt;br&gt;&lt;input type=\"text\" name=\"lastname\" value=\"Mouse\"&gt;&lt;br&gt;&lt;br&gt;&lt;input type=\"submit\" value=\"Submit\"&gt;&lt;/form&gt; &lt;!--如果您点击 \"Submit\" 按钮，您将把输入传送到名为 html_form_action.asp 的新页面。--&gt;&lt;form name=\"input\" action=\"/html/html_form_action.asp\" method=\"get\"&gt;I have a bike:&lt;input type=\"checkbox\" name=\"vehicle\" value=\"Bike\" checked=\"checked\" /&gt;&lt;br /&gt;I have a car: &lt;input type=\"checkbox\" name=\"vehicle\" value=\"Car\" /&gt;&lt;br /&gt;I have an airplane: &lt;input type=\"checkbox\" name=\"vehicle\" value=\"Airplane\" /&gt;&lt;br /&gt;&lt;br /&gt;&lt;input type=\"submit\" value=\"Submit\" /&gt;&lt;/form&gt; &lt;!--带有单选按钮的表单--&gt;&lt;form&gt;&lt;input type=\"radio\" name=\"sex\" value=\"male\" checked&gt;Male&lt;br&gt;&lt;input type=\"radio\" name=\"sex\" value=\"female\"&gt;Female&lt;/form&gt; &lt;!--从表单发送电子邮件--&gt;&lt;form action=\"MAILTO:someone@w3school.com.cn\" method=\"post\" enctype=\"text/plain\"&gt;&lt;h3&gt;这个表单会把电子邮件发送到 W3School。&lt;/h3&gt;姓名：&lt;br /&gt;&lt;input type=\"text\" name=\"name\" value=\"yourname\" size=\"20\"&gt;&lt;br /&gt;电邮：&lt;br /&gt;&lt;input type=\"text\" name=\"mail\" value=\"yourmail\" size=\"20\"&gt;&lt;br /&gt;内容：&lt;br /&gt;&lt;input type=\"text\" name=\"comment\" value=\"yourcomment\" size=\"40\"&gt;&lt;br /&gt;&lt;br /&gt;&lt;input type=\"submit\" value=\"发送\"&gt;&lt;input type=\"reset\" value=\"重置\"&gt;&lt;/form&gt; HTML 图像12345678910111213141516171819202122232425262728&lt;img src=\"/i/eg_mouse.jpg\" width=\"128\" height=\"128\" /&gt;&lt;img src=\"/i/eg_cute.gif\" width=\"50\" height=\"50\" /&gt;&lt;img src=\"/i/ct_netscape.jpg\" /&gt;&lt;img src=\"http://www.w3school.com.cn/i/w3school_logo_white.gif\" /&gt;&lt;body background=\"/i/eg_background.jpg\"&gt;&lt;!--图像背景, gif 和 jpg 文件均可用作 HTML 背景,如果图像小于页面，图像会进行重复--&gt;&lt;body background=\"/i/eg_background.jpg\"&gt;&lt;/body&gt;&lt;!--图片对齐方式, 请注意，bottom 对齐方式是默认的对齐方式。--&gt;&lt;img src=\"/i/eg_cute.gif\" align=\"middle\"&gt;&lt;!--带有图像的一个段落。图像的 align 属性设置为 \"left\"。图像将浮动到文本的左侧--&gt;&lt;img src =\"/i/eg_cute.gif\" align =\"left\"&gt; &lt;p&gt;通过改变 img 标签的 \"height\" 和 \"width\" 属性的值，您可以放大或缩小图像。&lt;/p&gt;为图片显示替换文本。在浏览器无法载入图像时，替换文本属性alt告诉读者们失去的信息。为页面上的图像都加上替换文本属性是个好习惯。&lt;img src=\"/i/eg_goleft.gif\" alt=\"向左转\" /&gt;制作图像链接&lt;a href=\"/example/html/lastpage.html\"&gt;&lt;img border=\"0\" src=\"/i/eg_buttonnext.gif\" /&gt;&lt;/a&gt;创建带有可供点击区域的图像地图。其中的每个区域都是一个超级链接。注释：img 元素中的 \"usemap\" 属性引用 map 元素中的 \"id\" 或 \"name\" 属性（根据浏览器），所以我们同时向 map 元素添加了 \"id\" 和 \"name\" 属性。&lt;img src=\"/i/eg_planets.jpg\" border=\"0\" usemap=\"#planetmap\" alt=\"Planets\" /&gt;&lt;map name=\"planetmap\" id=\"planetmap\"&gt;&lt;area shape=\"circle\" coords=\"180,139,14\" href =\"/example/html/venus.html\" target =\"_blank\" alt=\"Venus\" /&gt;&lt;area shape=\"circle\" coords=\"129,161,10\" href =\"/example/html/mercur.html\" target =\"_blank\" alt=\"Mercury\" /&gt;&lt;area shape=\"rect\" coords=\"0,0,110,260\" href =\"/example/html/sun.html\" target =\"_blank\" alt=\"Sun\" /&gt;&lt;/map&gt;把一幅普通的图像设置为图像映射&lt;a href=\"/example/html/html_ismap.html\"&gt;&lt;img src=\"/i/eg_planets.jpg\" ismap /&gt;&lt;/a&gt; HTML 背景如果图像小于页面，图像会进行重复12&lt;body bgcolor=\"#d0d0d0\"&gt;&lt;/body&gt;&lt;body background=\"/i/eg_bg_06.gif\"&gt;&lt;/body&gt; HTML 样式(style)123456789101112131415161718192021222324&lt;head&gt;&lt;style type=\"text/css\"&gt;h1 &#123;color: red&#125;p &#123;color: blue&#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;header 1&lt;/h1&gt;&lt;p&gt;A paragraph.&lt;/p&gt;&lt;/body&gt;没有下划线的链接&lt;a href=\"/example/html/lastpage.html\" style=\"text-decoration:none\"&gt;这是一个没有下划线的链接！&lt;/a&gt;引用外部样式&lt;head&gt;&lt;link rel=\"stylesheet\" type=\"text/css\" href=\"/html/csstest1.css\" &gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;我通过外部样式表进行格式化。&lt;/h1&gt;&lt;p&gt;我也一样！&lt;/p&gt;&lt;/body&gt; HTML 头部(head)1234567891011121314151617181920212223&lt;head&gt;&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=gb2312\" /&gt;&lt;meta http-equiv=\"Content-Language\" content=\"zh-cn\" /&gt;&lt;title&gt;标题不会显示在文档区&lt;/title&gt;&lt;/head&gt;一个 target，所有的链接使用 base 标签使页面中的所有标签在新窗口中打开。&lt;head&gt;&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=gb2312\" /&gt;&lt;meta http-equiv=\"Content-Language\" content=\"zh-cn\" /&gt;&lt;base target=\"_blank\" /&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;&lt;a href=\"http://www.w3school.com.cn\" target=\"_blank\"&gt;这个连接&lt;/a&gt; 将在新窗口中加载，因为 target 属性被设置为 \"_blank\"。&lt;/p&gt;&lt;p&gt;&lt;a href=\"http://www.w3school.com.cn\"&gt;这个连接&lt;/a&gt; 也将在新窗口中加载，即使没有 target 属性。&lt;/p&gt;&lt;/body&gt; HTML 元信息(meta)123456789101112131415161718192021本文档的 meta 属性标识了创作者和编辑软件。&lt;head&gt;&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=gb2312\" /&gt;&lt;meta name=\"author\" content=\"w3school.com.cn\"&gt;&lt;meta name=\"revised\" content=\"David Yang,8/1/07\"&gt;&lt;meta name=\"generator\" content=\"Dreamweaver 8.0en\"&gt;&lt;/head&gt;本文档的 meta 属性描述了该文档和它的关键词。&lt;meta name=\"description\" content=\"HTML examples\"&gt;&lt;meta name=\"keywords\" content=\"HTML, DHTML, CSS, XML, XHTML, JavaScript, VBScript\"&gt;在网址已经变更的情况下，将用户重定向到另外一个地址&lt;head&gt;&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=gb2312\" /&gt;&lt;meta http-equiv=\"Refresh\" content=\"5;url=http://www.w3school.com.cn\" /&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;对不起。我们已经搬家了。您的 URL 是 &lt;a href=\"http://www.w3school.com.cn\"&gt;http://www.w3school.com.cn&lt;/a&gt;&lt;/p&gt;&lt;p&gt;您将在 5 秒内被重定向到新的地址。&lt;/p&gt;&lt;p&gt;如果超过 5 秒后您仍然看到本消息，请点击上面的链接。&lt;/p&gt;&lt;/body&gt; HTML 脚本(script)运行于不支持脚本的浏览器12&lt;script type=\"text/javascript\"&gt; document.write(\"Hello World!\") &lt;/script&gt;&lt;noscript&gt;Sorry, your browser does not support JavaScript!&lt;/noscript&gt;","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"HTML","slug":"HTML","permalink":"http://arvin-he.github.io/tags/HTML/"}]},{"title":"Http读书笔记第八章","slug":"http-note8-2017-07-12","date":"2017-07-12T07:59:07.000Z","updated":"2017-09-08T03:51:39.684Z","comments":true,"path":"2017/07/12/http-note8-2017-07-12/","link":"","permalink":"http://arvin-he.github.io/2017/07/12/http-note8-2017-07-12/","excerpt":"","text":"确认访问用户身份的认证为了弄清究竟是谁在访问服务器，就得让对方的客户端自报家门,身份是否属实这点却也无从谈起,为确认 操作者是否真的具有访问系统的权限，就需要核对“登录者本人才知道的信息”、“登录者本人才会有的信息”。核对的信息通常是指以下这些: 密码：只有本人才会知道的字符串信息。 动态令牌：仅限本人持有的设备内显示的一次性密码。 数字证书：仅限本人（终端）持有的信息。 生物认证：指纹和虹膜等本人的生理信息。 IC 卡等：仅限本人持有的信息。但是，即便对方是假冒的用户，只要能通过用户验证，那么计算机就会默认是出自本人的行为。 HTTP 使用的认证方式HTTP/1.1 使用的认证方式如下: BASIC 认证（基本认证） DIGEST 认证（摘要认证） SSL 客户端认证 FormBase 认证（基于表单认证） 还有 Windows 统一认证（Keberos 认证、NTLM 认证） BASIC 认证步骤 1： 当请求的资源需要 BASIC 认证时，服务器会随状态码 401 Authorization Required，返回带 WWW-Authenticate 首部字段的响应。该字段内包含认证的方式（BASIC） 及 Request-URI 安全域字符串（realm）。步骤 2： 接收到状态码 401 的客户端为了通过 BASIC 认证，需要将用户 ID 及密码发送给服务器。发送的字符串内容是由用户 ID 和密码构成，两者中间以冒号（:）连接后，再经过 Base64 编码处理。假设用户 ID 为 guest，密码是 guest，连接起来就会形成 guest:guest 这样的字符串。然后经过 Base64 编码，最后的结果即是Z3Vlc3Q6Z3Vlc3Q=。把这串字符串写入首部字段 Authorization 后，发送请求。当用户代理为浏览器时，用户仅需输入用户 ID 和密码即可，之后，浏览器会自动完成到 Base64 编码的转换工作。步骤 3： 接收到包含首部字段 Authorization 请求的服务器，会对认证信息的正确性进行验证。如验证通过，则返回一条包含 Request-URI资源的响应。BASIC 认证虽然采用 Base64 编码方式，但这不是加密处理。不需要任何附加信息即可对其解码。另外，除此之外想再进行一次 BASIC 认证时，一般的浏览器却无法实现认证注销操作，这也是问题之一。BASIC 认证使用上不够便捷灵活，且达不到多数 Web 网站期望的安全性等级，因此它并不常用。 DIGEST 认证DIGEST 认证同样使用质询 / 响应的方式（challenge/response），但不会像 BASIC 认证那样直接发送明文密码。所谓质询响应方式是指，一开始一方会先发送认证要求给另一方，接着使用从另一方那接收到的质询码计算生成响应码。最后将响应码返回给对方进行认证的方式。步骤 1： 请求需认证的资源时，服务器会随着状态码 401 Authorization Required，返 回带 WWW-Authenticate 首部字段的响应。该字段内包含质问响应方式认证所需的临时质询码（随机数，nonce）。首部字段 WWW-Authenticate 内必须包含 realm 和 nonce 这两个字段的信息。客户端就是依靠向服务器回送这两个值进行认证的。nonce 是一种每次随返回的 401 响应生成的任意随机字符串。该字符串通常推荐由 Base64 编码的十六进制数的组成形式，但实际内容依赖服务器的具体实现。步骤 2： 接收到 401 状态码的客户端，返回的响应中包含 DIGEST 认证必须的首部字段 Authorization 信息。首部字段 Authorization 内必须包含 username、realm、nonce、uri 和response 的字段信息。其中，realm 和 nonce 就是之前从服务器接收到的响应中的字段。username 是 realm 限定范围内可进行认证的用户名。uri（digest-uri）即 Request-URI 的值，但考虑到经代理转发后Request-URI 的值可能被修改，因此事先会复制一份副本保存在 uri内。response 也可叫做 Request-Digest，存放经过 MD5 运算后的密码字符串，形成响应码。步骤 3： 接收到包含首部字段 Authorization 请求的服务器，会确认认证信息的正确性。认证通过后则返回包含 Request-URI 资源的响应。并且这时会在首部字段 Authentication-Info 写入一些认证成功的相关信息。DIGEST 认证提供了高于 BASIC 认证的安全等级，但是和 HTTPS 的客户端认证相比仍旧很弱。DIGEST 认证提供防止密码被窃听的保护机制，但并不存在防止用户伪装的保护机制。DIGEST 认证和 BASIC 认证一样，使用上不那么便捷灵活，且仍达不到多数 Web 网站对高度安全等级的追求标准。因此它的适用范围也有所受限。 SSL 客户端认证从使用用户 ID 和密码的认证方式方面来讲，只要二者的内容正确，即可认证是本人的行为。但如果用户 ID 和密码被盗，就很有可能被第三者冒充。利用 SSL 客户端认证则可以避免该情况的发生。SSL 客户端认证是借由 HTTPS 的客户端证书完成认证的方式。为达到 SSL 客户端认证的目的，需要事先将客户端证书分发给客户端，且客户端必须安装此证书。 SSL 客户端认证的认证步骤步骤 1： 接收到需要认证资源的请求，服务器会发送 Certificate Request 报文，要求客户端提供客户端证书。步骤 2： 用户选择将发送的客户端证书后，客户端会把客户端证书信息以 Client Certificate 报文方式发送给服务器。步骤 3： 服务器验证客户端证书验证通过后方可领取证书内客户端的公开密钥，然后开始 HTTPS 加密通信。 SSL 客户端认证采用双因素认证多数情况下，SSL 客户端认证不会仅依靠证书完成认证，一般会和基于表单认证（稍后讲解）组合形成一种双因素认证（Two-factor authentication）来使用。所谓双因素认证就是指，认证过程中不仅需要密码这一个因素，还需要申请认证者提供其他持有信息，从而作为另一个因素，与其组合使用的认证方式。换言之，第一个认证因素的 SSL 客户端证书用来认证客户端计算机，另一个认证因素的密码则用来确定这是用户本人的行为。 基于表单认证基于表单的认证方法并不是在 HTTP 协议中定义的。客户端会向服务器上的 Web 应用程序发送登录信息（Credential），按登录信息的验证结果认证。根据 Web 应用程序的实际安装，提供的用户界面及认证方式也各不相同。多数情况下，输入已事先登录的用户 ID（通常是任意字符串或邮件地址）和密码等登录信息后，发送给 Web 应用程序，基于认证结果来决定认证是否成功。认证多半为基于表单认证,由于使用上的便利性及安全性问题，HTTP 协议标准提供的 BASIC 认证和 DIGEST 认证几乎不怎么使用。另外，SSL 客户端认证虽然具有高度的安全等级，但因为导入及维持费用等问题，还尚未普及。SSH 和 FTP 协议，服务器与客户端之间的认证是合乎标准规范的，并且满足了最基本的功能需求上的安全使用级别，因此这些协议的认证可以拿来直接使用。但是对于 Web 网站的认证功能，能够满足其安全使用级别的标准规范并不存在，所以只好使用由 Web 应用程序各自实现基于表单的认证方式。 Session 管理及 Cookie 应用基于表单认证的标准规范尚未有定论，一般会使用 Cookie 来管理Session（会话）。以弥补 HTTP 协议中不存在的状态管理功能.步骤 1： 客户端把用户 ID 和密码等登录信息放入报文的实体部分，通常是以 POST 方法把请求发送给服务器。而这时，会使用 HTTPS通信来进行 HTML 表单画面的显示和用户输入数据的发送。步骤 2： 服务器会发放用以识别用户的 Session ID。通过验证从客户端发送过来的登录信息进行身份认证，然后把用户的认证状态与Session ID 绑定后记录在服务器端。向客户端返回响应时，会在首部字段 Set-Cookie 内写入 SessionID,你可以把 Session ID 想象成一种用以区分不同用户的等位号。另外，为减轻跨站脚本攻击（XSS）造成的损失，建议事先在 Cookie内加上 httponly 属性。步骤 3： 客户端接收到从服务器端发来的 Session ID 后，会将其作为Cookie 保存在本地。下次向服务器发送请求时，浏览器会自动发送Cookie，所以 Session ID 也随之发送到服务器。服务器端可通过验证接收到的 Session ID 识别用户和其认证状态。 通常，一种安全的保存方法是，先利用给密码加盐（salt） 1 的方式增加额外信息，再使用散列（hash）函数计算出散列值后保存。但是我们也经常看到直接保存明文密码的做法，而这样的做法具有导致密码泄露的风险。 salt 其实就是由服务器随机生成的一个字符串，但是要保证长度足够长，并且是真正随机生成的。然后把它和密码字符串相连接（前后都可以）生成散列值。当两个用户使用了同一个密码时，由于随机生成的 salt 值不同，对应的散列值也将是不同的。这样一来，很大程度上减少了密码特征，攻击者也就很难利用自己手中的密码特征库进行破解。","categories":[{"name":"Web","slug":"Web","permalink":"http://arvin-he.github.io/categories/Web/"}],"tags":[{"name":"http","slug":"http","permalink":"http://arvin-he.github.io/tags/http/"}]},{"title":"Http读书笔记第七章","slug":"http-note7-2017-07-12","date":"2017-07-12T05:12:59.000Z","updated":"2017-09-08T03:51:39.635Z","comments":true,"path":"2017/07/12/http-note7-2017-07-12/","link":"","permalink":"http://arvin-he.github.io/2017/07/12/http-note7-2017-07-12/","excerpt":"","text":"http的不足 通信使用明文（不加密），内容可能会被窃听 不验证通信方的身份，因此有可能遭遇伪装 无法证明报文的完整性，所以有可能已遭篡改 加密处理方式 通信的加密HTTP 协议中没有加密机制，但可以通过和 SSL（Secure Socket Layer，安全套接层）或TLS（Transport Layer Security，安全层传输协议）的组合使用，加密 HTTP 的通信内容。用 SSL 建立安全通信线路之后，就可以在这条线路上进行 HTTP通信了。与 SSL 组合使用的 HTTP 被称为 HTTPS（HTTP Secure，超文本传输安全协议）或 HTTP over SSL。 内容的加密即把HTTP 报文里所含的内容进行加密处理, 为了做到有效的内容加密，前提是要求客户端和服务器同时具备加密和解密机制。该方式不同于 SSL 或 TLS 将整个通信线路加密处理，所以内容仍有被篡改的风险。(虽然劫持者看不到内容,但可以篡改劫持信息的内容) 不验证通信方的身份HTTP 协议中的请求和响应不会对通信方进行确认任何人都可发起请求, 服务器只要接收到请求，不管对方是谁都会返回一个响应（但也仅限于发送端的 IP 地址和端口号没有被 Web 服务器设定限制访问的前提下）查明对手的证书SSL 不仅提供加密处理，而且还使用了一种被称为证书的手段，可用于确定方.证书由值得信任的第三方机构颁发，用以证明服务器和客户端是实际存在的。另外，伪造证书从技术角度来说是异常困难的一件事。所以只要能够确认通信方（服务器或客户端）持有的证书，即可判断通信方的真实意图。另外，客户端持有证书即可完成个人身份的确认，也可用于对Web 网站的认证环节。 证明报文完整性，可能已遭篡改中间人攻击（Man-in-the-Middle attack，MITM）:请求或响应在传输途中，遭攻击者拦截并篡改内容的攻击.HTTP 协议确定报文完整性的方法，但事实上并不便捷、可靠。其中常用的是 MD5 和 SHA-1 等散列值校验的方法，以及用来确认文件的数字签名方法。提供文件下载服务的 Web 网站也会提供相应的以 PGP（Pretty Good Privacy，完美隐私）创建的数字签名及 MD5 算法生成的散列值。PGP 是用来证明创建文件的数字签名，MD5 是由单向函数生成的散列值。不论使用哪一种方法，都需要操纵客户端的用户本人亲自检查验证下载的文件是否就是原来服务器上的文件。浏览器无法自动帮用户检查。可惜的是，用这些方法也依然无法百分百保证确认结果正确。因为 PGP 和 MD5 本身被改写的话，用户是没有办法意识到的。为了有效防止这些弊端，有必要使用 HTTPS。SSL 提供认证和加密处理及摘要功能。 HTTPS = HTTP+ 加密 + 认证 + 完整性保护使用HTTPS 通信时，不再用 http://，而是改用https://。另外，当浏览器访问 HTTPS 通信有效的 Web 网站时，浏览器的地址栏内会出现一个带锁的标记。对 HTTPS 的显示方式会因浏览器的不同而有所改变。HTTPS 是身披 SSL 外壳的 HTTP,HTTPS 并非是应用层的一种新协议。只是 HTTP 通信接口部分用SSL（Secure Socket Layer）和 TLS（Transport Layer Security）协议代替而已。通常，HTTP 直接和 TCP 通信。当使用 SSL 时，则演变成 http 先和 SSL 通信，再由 SSL 和 TCP 通信了。如下图所示 SSL 是独立于 HTTP 的协议，所以不光是 HTTP 协议，其他运行在应用层的 SMTP 和 Telnet 等协议均可配合 SSL 协议使用。可以说 SSL 是当今世界上应用最为广泛的网络安全技术。 相互交换密钥的公开密钥加密技术SSL 采用一种叫做公开密钥加密（Public-key cryptography）的加密处理方式。近代的加密方法中加密算法是公开的，而密钥却是保密的。通过这种方式得以保持加密方法的安全性。加密和解密都会用到密钥。没有密钥就无法对密码解密，反过来说，任何人只要持有密钥就能解密了。如果密钥被攻击者获得，那加密也就失去了意义。 对称密钥加密加密和解密同用一个密钥的方式称为共享密钥加密（Common key crypto system）也被叫做对称密钥加密, 以共享密钥方式加密时必须将密钥也发给对方。 使用两把密钥的公开密钥加密公开密钥加密方式很好地解决了共享密钥加密的困难, 公开密钥加密使用一对非对称的密钥。一把叫做私有密钥（private key），另一把叫做公开密钥（public key）。顾名思义，私有密钥不能让其他任何人知道，而公开密钥则可以随意发布，任何人都可以获得。使用公开密钥加密方式，发送密文的一方使用对方的公开密钥进行加密处理，对方收到被加密的信息后，再使用自己的私有密钥进行解密。利用这种方式，不需要发送用来解密的私有密钥，也不必担心密钥被攻击者窃听而盗走。另外，要想根据密文和公开密钥，恢复到信息原文是异常困难的，因为解密过程就是在对离散对数进行求值，这并非轻而易举就能办到。退一步讲，如果能对一个非常大的整数做到快速地因式分解，那么密码破解还是存在希望的。但就目前的技术来看是不太现实的。 HTTPS 采用混合加密机制HTTPS 采用共享密钥加密和公开密钥加密两者并用的混合加密机制。公开密钥加密与共享密钥加密相比，其处理速度要慢。所以应充分利用两者各自的优势，将多种方法组合起来用于通信。在交换密钥环节使用公开密钥加密方式，之后的建立通信交换报文阶段则使用共享密钥加密方式。 证明公开密钥正确性的证书公开密钥加密方式还是存在一些问题的。那就是无法证明公开密钥本身就是货真价实的公开密钥。比如，正准备和某台服务器建立公开密钥加密方式下的通信时，如何证明收到的公开密钥就是原本预想的那台服务器发行的公开密钥。或许在公开密钥传输途中，真正的公开密钥已经被攻击者替换掉了。为了解决上述问题，可以使用由数字证书认证机构（CA，Certificate Authority）和其相关机关颁发的公开密钥证书。数字证书认证机构处于客户端与服务器双方都可信赖的第三方机构的立场上。首先，服务器的运营人员向数字证书认证机构提出公开密钥的申请。数字证书认证机构在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公钥证书后绑定在一起。服务器会将这份由数字证书认证机构颁发的公钥证书发送给客户端，以进行公开密钥加密方式通信。公钥证书也可叫做数字证书或直接称为证书。接到证书的客户端可使用数字证书认证机构的公开密钥，对那张证书上的数字签名进行验证，一旦验证通过，客户端便可明确两件事：一，认证服务器的公开密钥的是真实有效的数字证书认证机构。二，服务器的公开密钥是值得信赖的。此处认证机关的公开密钥必须安全地转交给客户端。使用通信方式时，如何安全转交是一件很困难的事，因此，多数浏览器开发商发布版本时，会事先在内部植入常用认证机关的公开密钥。 可证明组织真实性的 EV SSL 证书证书的一个作用是用来证明作为通信一方的服务器是否规范，另外一个作用是可确认对方服务器背后运营的企业是否真实存在。拥有该特性的证书就是 EV SSL 证书（Extended Validation SSL Certificate）。EV SSL 证书是基于国际标准的认证指导方针颁发的证书。其严格规定了对运营组织是否真实的确认方针，因此，通过认证的Web 网站能够获得更高的认可度。持有 EV SSL 证书的 Web 网站的浏览器地址栏处的背景色是绿色的，从视觉上就能一眼辨别出。而且在地址栏的左侧显示了 SSL证书中记录的组织名称以及颁发证书的认证机构的名称。 用以确认客户端的客户端证书HTTPS 中还可以使用客户端证书,以客户端证书进行客户端认证，证明服务器正在通信的对方始终是预料之内的客户端，其作用跟服务器证书如出一辙。 由自认证机构颁发的证书称为自签名证书如果使用 OpenSSL 这套开源程序，每个人都可以构建一套属于自己的认证机构，从而自己给自己颁发服务器证书。但该服务器证书在互联网上不可作为证书使用.独立构建的认证机构叫做自认证机构，由自认证机构颁发的“无用”证书也被戏称为自签名证书。自认证机构颁发的服务器证书之所以不起作用，是因为它无法消除伪装的可能性。自认证机构能够产生的作用顶多也就是自己对外宣称“我是○○”的这种程度。即使采用自签名证书，通过 SSL加密之后，可能偶尔还会看见通信处在安全状态的提示，可那也是有问题的。因为 就算加密通信，也不能排除正在和已经过伪装的假服务器保持通信。值得信赖的第三方机构介入认证，才能让已植入在浏览器内的认证机构颁布的公开密钥发挥作用，并借此证明服务器的真实性。多数浏览器内预先已植入备受信赖的认证机构的证书，但也有一小部分浏览器会植入中级认证机构的证书。对于中级认证机构颁发的服务器证书，某些浏览器会以正规的证书来对待，可有的浏览器会当作自签名证书。 HTTPS 的安全通信机制HTTPS 通信过程步骤 1： 客户端通过发送 Client Hello 报文开始 SSL 通信。报文中包含客户端支持的 SSL 的指定版本、加密组件（Cipher Suite）列表（所使用的加密算法及密钥长度等）。步骤 2： 服务器可进行 SSL 通信时，会以 Server Hello 报文作为应答。和客户端一样，在报文中包含 SSL 版本以及加密组件。服务器的加密组件内容是从接收到的客户端加密组件内筛选出来的。步骤 3： 之后服务器发送 Certificate 报文。报文中包含公开密钥证书。步骤 4： 最后服务器发送 Server Hello Done 报文通知客户端，最初阶段的 SSL 握手协商部分结束。步骤 5： SSL 第一次握手结束之后，客户端以 Client Key Exchange 报文作为回应。报文中包含通信加密中使用的一种被称为 Pre-master secret 的随机密码串。该报文已用步骤 3 中的公开密钥进行加密。步骤 6： 接着客户端继续发送 Change Cipher Spec 报文。该报文会提示服务器，在此报文之后的通信会采用 Pre-master secret 密钥加密。步骤 7： 客户端发送 Finished 报文。该报文包含连接至今全部报文的整体校验值。这次握手协商是否能够成功，要以服务器是否能够正确解密该报文作为判定标准。步骤 8： 服务器同样发送 Change Cipher Spec 报文。步骤 9： 服务器同样发送 Finished 报文.步骤 10： 服务器和客户端的 Finished 报文交换完毕之后，SSL 连接就算建立完成。当然，通信会受到 SSL 的保护。从此处开始进行应用层协议的通信，即发送 HTTP 请求。步骤 11： 应用层协议通信，即发送 HTTP 响应。步骤 12： 最后由客户端断开连接。断开连接时，发送 close_notify 报文。上图做了一些省略，这步之后再发送 TCP FIN 报文来关闭与 TCP的通信。在以上流程中，应用层发送数据时会附加一种叫做 MAC（Message Authentication Code）的报文摘要。MAC 能够查知报文是否遭到篡改，从而保护报文的完整性。 CBC 模式（Cipher Block Chaining）又名密码分组链接模式。在此模式下，将前一个明文块加密处理后和下一个明文块做 XOR 运算，使之重叠，然后再对运算结果做加密处理。对第一个明文块做加密时，要么使用前一段密文的最后一块，要么利用外部生成的初始向量（initial vector，IV） SSL 和 TLSHTTPS 使用 SSL（Secure Socket Layer） 和 TLS（Transport Layer Security）这两个协议。SSL 技术最初是由浏览器开发商网景通信公司率先倡导的，开发过 SSL3.0 之前的版本。目前主导权已转移到 IETF（Internet Engineering Task Force，Internet 工程任务组）的手中. IETF 以 SSL3.0 为基准，后又制定了 TLS1.0、TLS1.1 和 TLS1.2。TSL 是以 SSL 为原型开发的协议，有时会统一称该协议为 SSL。当前主流的版本是 SSL3.0 和 TLS1.0。 SSL 速度慢HTTPS 也存在一些问题，那就是当使用 SSL 时，它的处理速度会变慢。SSL 的慢分两种。一种是指通信慢。另一种是指由于大量消耗CPU 及内存等资源，导致处理速度变慢。 和使用 HTTP 相比，网络负载可能会变慢 2 到 100 倍。除去和TCP 连接、发送 HTTP 请求 • 响应以外，还必须进行 SSL 通信，因此整体上处理通信量不可避免会增加。另一点是 SSL 必须进行加密处理。在服务器和客户端都需要进行加密和解密的运算处理。因此从结果上讲，比起 HTTP 会更多地消耗服务器和客户端的硬件资源，导致负载增强。针对速度变慢这一问题，并没有根本性的解决方案，我们会使用SSL 加速器这种（专用服务器）硬件来改善该问题。该硬件为SSL 通信专用硬件，相对软件来讲，能够提高数倍 SSL 的计算速度。仅在 SSL 处理时发挥 SSL 加速器的功效，以分担负载。 为什么不一直使用 HTTPS 与纯文本通信相比，加密通信会消耗更多的CPU 及内存资源。如果每次通信都加密，会消耗相当多的资源，平摊到一台计算机上时，能够处理的请求数量必定也会随之减少。因此，如果是非敏感信息则使用 HTTP 通信，只有在包含个人信息等敏感数据时，才利用 HTTPS 加密通信。并非对所有内容都进行加密处理，而是仅在那些需要信息隐藏时才会加密，以节约资源。 此外, 要进行 HTTPS 通信，证书是必不可少的。而使用的证书必须向认证机构（CA）购买。","categories":[{"name":"Web","slug":"Web","permalink":"http://arvin-he.github.io/categories/Web/"}],"tags":[{"name":"http","slug":"http","permalink":"http://arvin-he.github.io/tags/http/"}]},{"title":"HTML笔记一","slug":"html-notes1-2017-07-11","date":"2017-07-11T06:48:20.000Z","updated":"2017-09-08T03:51:39.508Z","comments":true,"path":"2017/07/11/html-notes1-2017-07-11/","link":"","permalink":"http://arvin-he.github.io/2017/07/11/html-notes1-2017-07-11/","excerpt":"","text":"HTML 基础标签 title 元素的内容会显示在浏览器的标题栏中。&lt;title&gt;我的第一个 HTML 页面&lt;/title&gt; body 元素的内容会显示在浏览器中。 段落标签: &lt;p&gt;这是段落。&lt;/p&gt; ,段落元素由 p 标签定义。这个段落在源代码中包含许多行但是浏览器忽略了它们。段落的行数依赖于浏览器窗口的大小。如果调节浏览器窗口的大小，将改变段落中的行数。 注意: 浏览器忽略了源代码中的排版,即忽略多余的空格和换行。 换行使用&lt;br&gt;标签 关于&lt;h1&gt;~&lt;h6&gt;标题标签,请仅仅把标题标签用于标题文本。不要仅仅为了产生粗体文本而使用它们。请使用其它标签或 CSS 代替 居中排列标题: &lt;h1 align=&quot;center&quot;&gt;This is heading 1&lt;/h1&gt; hr 标签定义水平线 12&lt;p&gt;这是段落。&lt;/p&gt;&lt;hr /&gt; 注释: &lt;!--这是一段注释。注释不会在浏览器中显示。--&gt; 背景颜色: &lt;body bgcolor=&quot;yellow&quot;&gt; HTML 文本格式化常用的格式化12345678910&lt;b&gt;This text is bold&lt;/b&gt;&lt;br /&gt;&lt;strong&gt;This text is strong&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;This text is emphasized&lt;/em&gt;&lt;br /&gt;&lt;i&gt;This text is italic&lt;/i&gt;&lt;br /&gt;&lt;big&gt;This text is big&lt;/big&gt;&lt;br /&gt;&lt;small&gt;This text is small&lt;/small&gt;&lt;br /&gt;This text contains&lt;sub&gt;subscript&lt;/sub&gt;&lt;br /&gt;This text contains&lt;sup&gt;superscript&lt;/sup&gt; 一些说明:&lt;b&gt;标签与&lt;strong&gt;标签的区别:两者在网页中显示效果一样，但实际目的不同。&lt;b&gt;这个标签对应 bold,即文本加粗,目的仅仅是为了加粗显示文本,是一种样式/风格需求&lt;strong&gt;这个标签意思是加强，表示该文本比较重要，提醒读者/终端注意。为了达到这个目的，浏览器等终端将其加粗显示；总结：&lt;b&gt;为了加粗而加粗，&lt;strong&gt;为了标明重点而加粗。 HTML5 的一个最大的特性 – 语义化&lt;b&gt; 和 &lt;i&gt; 创建之初就是简单地表示粗体和斜体样式，但现在是 HTML5 的天下。语义化是 HTML5 最大的特性之一，而所有被 HTML5 保留的标签都带有其特有的语义，&lt;b&gt; 和 &lt;i&gt; 也不例外，它们分别被重新赋予了语义。相比较而言，标签的样式反而变得无足轻重，所以上面所讲的两组标签，虽然样式上表现极其相似，但其实语义上各有侧重。在默认的 HTML 样式表定义中，b 和 strong 的样式一样，为 { font-weight: bolder }而 em 的默认样式为 { font-style: italic }，与 i 相同。在 HTML 4 中，em 表示 emphasized text，strong 表示 strong emphasized text，故 strong 的强度要更强。而在 HTML 5 中，strong 的定义改成了 important text。当然 emphasized 和 strong emphasized 乃至 important 之间怎么界定很模糊，关键是在自己编写 HTML 代码的时候保持使用上一致。b 和 i 仅仅表示这里应该用粗体或者斜体显示. &lt;big&gt; 和 &lt;small&gt; 显示大号和小号字体&lt;sub&gt; 和&lt;sup&gt;分别表示下标和上标.&lt;tt&gt; 呈现类似打字机或者等宽的文本效果。 文本预格式化文本预格式化使用&lt;pre&gt;标签被包围在 pre 元素中的文本通常会保留空格和换行符。而文本也会呈现为等宽字体。&lt;pre&gt; 标签的一个常见应用就是用来表示计算机的源代码。 “计算机输出”标签12345&lt;code&gt;Computer code&lt;/code&gt;&lt;kbd&gt;Keyboard input&lt;/kbd&gt;&lt;tt&gt;Teletype text&lt;/tt&gt;&lt;samp&gt;Sample text&lt;/samp&gt;&lt;var&gt;Computer variable&lt;/var&gt; 这些标签常用于显示计算机/编程代码。 在 HTML 文件中写地址1234567&lt;address&gt;Written by &lt;a href=\"mailto:webmaster@example.com\"&gt;Donald Duck&lt;/a&gt;.&lt;br&gt; Visit us at:&lt;br&gt;Example.com&lt;br&gt;Box 564, Disneyland&lt;br&gt;USA&lt;/address&gt; 关于缩写和首字母缩写,即缩词略写12&lt;abbr title=\"etcetera\"&gt;etc.&lt;/abbr&gt;&lt;acronym title=\"World Wide Web\"&gt;WWW&lt;/acronym&gt; 在某些浏览器中，当您把鼠标移至缩略词语上时，title 可用于展示表达的完整版本。title仅对于 IE 5 中的 acronym 元素有效。但对于 Netscape 6.2 中的 abbr 和 acronym 元素都有效。 文字方向如果您的浏览器支持 bi-directional override (bdo)，下一行会从右向左输出 (rtl)即right to left.123&lt;bdo dir=\"rtl\"&gt;Here is some Hebrew text&lt;/bdo&gt; 块引用长引用和短引用长引用使用&lt;blockquote&gt;标签, 使用 blockquote 元素的话，浏览器会插入换行和外边距.短引用使用&lt;q&gt;标签, 使用q 元素不会有任何特殊的呈现。 删除字效果和插入字效果删除文本使用&lt;del&gt;标签, 插入文本使用&lt;ins&gt;标签,&lt;p&gt;一打有 &lt;del&gt;二十&lt;/del&gt; &lt;ins&gt;十二&lt;/ins&gt; 件。&lt;/p&gt;大多数浏览器会改写为删除文本和下划线文本。一些老式的浏览器会把删除文本和下划线文本显示为普通文本。 HTML 链接创建超级链接123456&lt;p&gt;&lt;a href=\"/index.html\"&gt;本文本&lt;/a&gt; 是一个指向本网站中的一个页面的链接。&lt;/p&gt;&lt;p&gt;&lt;a href=\"http://www.microsoft.com/\"&gt;本文本&lt;/a&gt; 是一个指向万维网上的页面的链接。&lt;/p&gt; 将图像作为链接12345&lt;p&gt; &lt;a href=\"/example/html/lastpage.html\"&gt; &lt;img border=\"0\" src=\"/i/eg_buttonnext.gif\" /&gt; &lt;/a&gt;&lt;/p&gt; 点击链接打开新的标签页12&lt;a href=\"http://www.w3school.com.cn/\" target=\"_blank\"&gt;Visit W3School!&lt;/a&gt;&lt;p&gt;如果把链接的 target 属性设置为 \"_blank\"，该链接会在新标签页中打开。&lt;/p&gt; 链接到同一个页面的不同位置1234567891011121314151617&lt;p&gt;&lt;a href=\"#C4\"&gt;查看 Chapter 4。&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;Chapter 1&lt;/h2&gt;&lt;p&gt;This chapter explains ba bla bla&lt;/p&gt;&lt;h2&gt;Chapter 2&lt;/h2&gt;&lt;p&gt;This chapter explains ba bla bla&lt;/p&gt;&lt;h2&gt;Chapter 3&lt;/h2&gt;&lt;p&gt;This chapter explains ba bla bla&lt;/p&gt;&lt;h2&gt;&lt;a name=\"C4\"&gt;Chapter 4&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;This chapter explains ba bla bla&lt;/p&gt;&lt;h2&gt;Chapter 5&lt;/h2&gt;&lt;p&gt;This chapter explains ba bla bla&lt;/p&gt;.... 跳出框架1&lt;a href=\"/index.html\" target=\"_top\"&gt; 跳出框架,请点击这里！&lt;/a&gt; 创建电子邮件链接123456789&lt;p&gt;这是邮件链接：&lt;a href=\"mailto:someone@microsoft.com?subject=Hello%20again\"&gt;发送邮件&lt;/a&gt;&lt;/p&gt;&lt;p&gt;这是另一个 mailto 链接：&lt;a href=\"mailto:someone@microsoft.com?cc=someoneelse@microsoft.com&amp;bcc=andsomeoneelse2@microsoft.com&amp;subject=Summer%20Party&amp;body=You%20are%20invited%20to%20a%20big%20summer%20party!\"&gt;发送邮件！&lt;/a&gt;&lt;/p&gt; 注意：应该使用 %20 来替换单词之间的空格，这样浏览器就可以正确地显示文本了。 HTML 框架垂直与水平框架123456789101112131415161718192021&lt;!--使用三份不同的文档制作一个垂直框架--&gt;&lt;!--垂直框架--&gt;&lt;frameset cols=\"25%,50%,25%\"&gt; &lt;frame src=\"/example/html/frame_a.html\"&gt; &lt;frame src=\"/example/html/frame_b.html\"&gt; &lt;frame src=\"/example/html/frame_c.html\"&gt;&lt;/frameset&gt;&lt;!--水平框架--&gt;&lt;frameset rows=\"25%,50%,25%\"&gt; &lt;frame src=\"/example/html/frame_a.html\"&gt; &lt;frame src=\"/example/html/frame_b.html\"&gt; &lt;frame src=\"/example/html/frame_c.html\"&gt;&lt;/frameset&gt;&lt;!--水平垂直混合框架--&gt;&lt;frameset rows=\"50%,50%\"&gt; &lt;frame src=\"/example/html/frame_a.html\"&gt;&lt;frameset cols=\"25%,75%\"&gt; &lt;frame src=\"/example/html/frame_b.html\"&gt; &lt;frame src=\"/example/html/frame_c.html\"&gt;&lt;/frameset&gt;&lt;/frameset&gt; 使用 标签noframes 元素可为那些不支持框架的浏览器显示文本。noframes 元素位于 frameset 元素内部。注释：如果浏览器有能力处理框架，就不会显示出 frameset 元素中的文本。重要事项：如果您希望 frameset 添加 &lt;noframes&gt; 标签，就必须把其中的文本包装在 &lt;body&gt;&lt;/body&gt; 标签中！12345678&lt;frameset cols=\"25%,50%,25%\"&gt; &lt;frame src=\"/example/html/frame_a.html\"&gt; &lt;frame src=\"/example/html/frame_b.html\"&gt; &lt;frame src=\"/example/html/frame_c.html\"&gt;&lt;noframes&gt;&lt;body&gt;您的浏览器无法处理框架！&lt;/body&gt;&lt;/noframes&gt;&lt;/frameset&gt; 含有 noresize=”noresize” 属性的框架结构noresize 属性使框架是不可调整尺寸的。在框架间的边框上拖动鼠标，你会发现边框是无法移动的。12345&lt;frameset cols=\"50%,*,25%\"&gt; &lt;frame src=\"/example/html/frame_a.html\" noresize=\"noresize\" /&gt; &lt;frame src=\"/example/html/frame_b.html\" /&gt; &lt;frame src=\"/example/html/frame_c.html\" /&gt;&lt;/frameset&gt; 导航框架导航框架包含一个将第二个框架作为目标的链接列表。名为 “contents.htm” 的文件包含三个链接.1234&lt;frameset cols=\"120,*\"&gt; &lt;frame src=\"/example/html/html_contents.html\"&gt; &lt;frame src=\"/example/html/frame_a.html\" name=\"showframe\"&gt;&lt;/frameset&gt; 内联框架一些老的浏览器不支持 iframe。如果得不到支持，iframe 是不可见的。&lt;iframe src=&quot;/i/eg_landscape.jpg&quot;&gt;&lt;/iframe&gt; 跳转至框架内的一个指定的节其中的一个框架设置了指向另一个文件内指定的节的链接。这个”link.htm”文件内指定的节使用 &lt;a name=&quot;C10&quot;&gt; 进行标识。1234&lt;frameset cols=\"20%,80%\"&gt; &lt;frame src=\"/example/html/frame_a.html\"&gt; &lt;frame src=\"/example/html/link.html#C10\"&gt;&lt;/frameset&gt; 使用框架导航跳转至指定的节左侧的导航框架包含了一个链接列表，这些链接将第二个框架作为目标。第二个框架显示被链接的文档。导航框架其中的链接指向目标文件中指定的节。1234&lt;frameset cols=\"180,*\"&gt;&lt;frame src=\"/example/html/content.html\"&gt;&lt;frame src=\"/example/html/link.html\" name=\"showframe\"&gt;&lt;/frameset&gt; HTML 表格每个表格由 table 标签开始, 每个表格行由 tr 标签开始, 每个表格数据由 td 标签开始.border控制表格边框宽度,当不指定border或者指定border=”0”时,则表示无边框.1234567891011121314151617181920212223242526272829# 一列表格&lt;table border=\"1\"&gt;&lt;tr&gt; &lt;td&gt;100&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;# 一行三列表格&lt;table border=\"1\"&gt;&lt;tr&gt; &lt;td&gt;100&lt;/td&gt; &lt;td&gt;200&lt;/td&gt; &lt;td&gt;300&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;# 两行三列表格&lt;table border=\"1\"&gt;&lt;tr&gt; &lt;td&gt;100&lt;/td&gt; &lt;td&gt;200&lt;/td&gt; &lt;td&gt;300&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;400&lt;/td&gt; &lt;td&gt;500&lt;/td&gt; &lt;td&gt;600&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; 表格中的表头(Heading)123456789101112131415161718192021222324252627&lt;table border=\"1\"&gt;&lt;tr&gt; &lt;th&gt;姓名&lt;/th&gt; &lt;th&gt;电话&lt;/th&gt; &lt;th&gt;电话&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;Bill Gates&lt;/td&gt; &lt;td&gt;555 77 854&lt;/td&gt; &lt;td&gt;555 77 855&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;table border=\"1\"&gt;&lt;tr&gt; &lt;th&gt;姓名&lt;/th&gt; &lt;td&gt;Bill Gates&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;电话&lt;/th&gt; &lt;td&gt;555 77 854&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt;电话&lt;/th&gt; &lt;td&gt;555 77 855&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; 空单元格12345678910&lt;table border=\"1\"&gt;&lt;tr&gt; &lt;td&gt;Some text&lt;/td&gt; &lt;td&gt;Some text&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;&lt;/td&gt; &lt;td&gt;Some text&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; 其中一个单元没有边框。这是因为它是空的。在该单元中插入一个空格后，仍然没有边框。我们的技巧是在单元中插入一个 no-breaking 空格。no-breaking 空格是一个字符实体。no-breaking 空格由 “&amp;” 符号开始，然后是字符”nbsp”，并以分号结尾(“;”)。 带有标题的表格12345678910111213&lt;table border=\"6\"&gt;&lt;caption&gt;我的标题&lt;/caption&gt;&lt;tr&gt; &lt;td&gt;100&lt;/td&gt; &lt;td&gt;200&lt;/td&gt; &lt;td&gt;300&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;400&lt;/td&gt; &lt;td&gt;500&lt;/td&gt; &lt;td&gt;600&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; 跨行或跨列的表格单元格(合并单元格)123456789101112131415161718192021222324252627# 横跨两列的单元格：&lt;table border=\"1\"&gt;&lt;tr&gt; &lt;th&gt;姓名&lt;/th&gt; &lt;th colspan=\"2\"&gt;电话&lt;/th&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;Bill Gates&lt;/td&gt; &lt;td&gt;555 77 854&lt;/td&gt; &lt;td&gt;555 77 855&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;# 横跨两行的单元格：&lt;table border=\"1\"&gt;&lt;tr&gt; &lt;th&gt;姓名&lt;/th&gt; &lt;td&gt;Bill Gates&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th rowspan=\"2\"&gt;电话&lt;/th&gt; &lt;td&gt;555 77 854&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;555 77 855&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; 表格内的包括段落, 表格, 列表和文本123456789101112131415161718192021222324252627282930&lt;table border=\"1\"&gt;&lt;tr&gt; &lt;td&gt; &lt;p&gt;这是一个段落。&lt;/p&gt; &lt;p&gt;这是另一个段落。&lt;/p&gt; &lt;/td&gt; &lt;td&gt;这个单元包含一个表格： &lt;table border=\"1\"&gt; &lt;tr&gt; &lt;td&gt;A&lt;/td&gt; &lt;td&gt;B&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;C&lt;/td&gt; &lt;td&gt;D&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;这个单元包含一个列表： &lt;ul&gt; &lt;li&gt;苹果&lt;/li&gt; &lt;li&gt;香蕉&lt;/li&gt; &lt;li&gt;菠萝&lt;/li&gt; &lt;/ul&gt; &lt;/td&gt; &lt;td&gt;HELLO&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; 单元格边距(Cell padding)12345678910&lt;table border=\"1\" cellpadding=\"10\"&gt;&lt;tr&gt; &lt;td&gt;First&lt;/td&gt; &lt;td&gt;Row&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Second&lt;/td&gt; &lt;td&gt;Row&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; 表格的单元格间距(Cell spacing)12345678910&lt;table border=\"1\" cellspacing=\"10\"&gt;&lt;tr&gt; &lt;td&gt;First&lt;/td&gt; &lt;td&gt;Row&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Second&lt;/td&gt; &lt;td&gt;Row&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; 向表格添加背景颜色或背景图像123456789101112131415161718192021&lt;table border=\"1\" bgcolor=\"red\"&gt;&lt;tr&gt; &lt;td&gt;First&lt;/td&gt; &lt;td&gt;Row&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Second&lt;/td&gt; &lt;td&gt;Row&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;table border=\"1\" background=\"/i/eg_bg_07.gif\"&gt;&lt;tr&gt; &lt;td&gt;First&lt;/td&gt; &lt;td&gt;Row&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Second&lt;/td&gt; &lt;td&gt;Row&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; 向表格单元添加背景颜色或者背景图像12345678910&lt;table border=\"1\"&gt;&lt;tr&gt; &lt;td bgcolor=\"red\"&gt;First&lt;/td&gt; &lt;td&gt;Row&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt; &lt;td background=\"/i/eg_bg_07.gif\"&gt;Second&lt;/td&gt; &lt;td&gt;Row&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; 在表格单元中排列内容对齐方式123456789101112131415161718192021222324252627&lt;table width=\"400\" border=\"1\"&gt; &lt;tr&gt; &lt;th align=\"left\"&gt;消费项目....&lt;/th&gt; &lt;th align=\"right\"&gt;一月&lt;/th&gt; &lt;th align=\"right\"&gt;二月&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align=\"left\"&gt;衣服&lt;/td&gt; &lt;td align=\"right\"&gt;$241.10&lt;/td&gt; &lt;td align=\"right\"&gt;$50.20&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align=\"left\"&gt;化妆品&lt;/td&gt; &lt;td align=\"right\"&gt;$30.00&lt;/td&gt; &lt;td align=\"right\"&gt;$44.45&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td align=\"left\"&gt;食物&lt;/td&gt; &lt;td align=\"right\"&gt;$730.40&lt;/td&gt; &lt;td align=\"right\"&gt;$650.00&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th align=\"left\"&gt;总计&lt;/th&gt; &lt;th align=\"right\"&gt;$1001.50&lt;/th&gt; &lt;th align=\"right\"&gt;$744.65&lt;/th&gt; &lt;/tr&gt;&lt;/table&gt; 表格的框架(frame)属性注释：frame 属性无法在 Internet Explorer 中正确地显示。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;p&gt;Table with frame=\"box\":&lt;/p&gt;&lt;table frame=\"box\"&gt; &lt;tr&gt; &lt;th&gt;Month&lt;/th&gt; &lt;th&gt;Savings&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;January&lt;/td&gt; &lt;td&gt;$100&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;p&gt;Table with frame=\"above\":&lt;/p&gt;&lt;table frame=\"above\"&gt; &lt;tr&gt; &lt;th&gt;Month&lt;/th&gt; &lt;th&gt;Savings&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;January&lt;/td&gt; &lt;td&gt;$100&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;p&gt;Table with frame=\"below\":&lt;/p&gt;&lt;table frame=\"below\"&gt; &lt;tr&gt; &lt;th&gt;Month&lt;/th&gt; &lt;th&gt;Savings&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;January&lt;/td&gt; &lt;td&gt;$100&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;p&gt;Table with frame=\"hsides\":&lt;/p&gt;&lt;table frame=\"hsides\"&gt; &lt;tr&gt; &lt;th&gt;Month&lt;/th&gt; &lt;th&gt;Savings&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;January&lt;/td&gt; &lt;td&gt;$100&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;p&gt;Table with frame=\"vsides\":&lt;/p&gt;&lt;table frame=\"vsides\"&gt; &lt;tr&gt; &lt;th&gt;Month&lt;/th&gt; &lt;th&gt;Savings&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;January&lt;/td&gt; &lt;td&gt;$100&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"HTML","slug":"HTML","permalink":"http://arvin-he.github.io/tags/HTML/"}]},{"title":"Linux环境搭建指南(debian9)","slug":"linux-envconfig-2017-07-08","date":"2017-07-08T02:15:18.000Z","updated":"2017-09-11T00:52:10.821Z","comments":true,"path":"2017/07/08/linux-envconfig-2017-07-08/","link":"","permalink":"http://arvin-he.github.io/2017/07/08/linux-envconfig-2017-07-08/","excerpt":"","text":"关于virtualbox 安装增强功能 设置共享文件夹 virtualbox快捷键 安装增强功能打开终端, 挂载目录:, 执行安装, 需要root权限123mount /dev/cdrom /media/cdromcd /media/cdrom0sh ./VBoxLinuxAdditions.run 在xubuntu上安装编译环境，执行如下命令sudo apt-get install build-essential映射设备sudo mount /dev/cdrom /media/cdrom进入cd /media/cdrom执行 sudo ./VBoxLinuxAdditions.run完成后重启 然后设置切换显示模式,注意使用快捷键切换 设置共享文件夹点击虚拟机菜单栏上的”设备-&gt;分配数据空间”，固定分配一个文件夹，比如分配名为share的文件夹，该文件夹存在于物理机上，我一般放在和虚拟机在同一目录下, 然后设置后将由你的虚拟机和物理机共享。把数据空间挂载到vshare上，就是我在第一步中物理机里的share文件夹然后挂载目录:mount -t vboxsf share /home/debian/vshare注意:vshare是linux下的一个文件夹,目录就是/home/debian/vshare要勾选自动挂载, 如下图所示. VirtualBox显示切换快捷键Right Ctrl + F – 切换到全屏模式Right Ctrl + L – 切换到无缝模式Right Ctrl + C – 切换到比例模式Right Ctrl + Home – 显示控制菜单 关于debian环境搭建sudo command not founddebian没有内置sudo这个工具,切换到su,apt-get install sudosudo vi /etc/sudoers 123456789101112131415161718192021222324252627282930## This file MUST be edited with the &apos;visudo&apos; command as root.## Please consider adding local content in /etc/sudoers.d/ instead of# directly modifying this file.## See the man page for details on how to write a sudoers file.#Defaults| env_resetDefaults| mail_badpassDefaults| secure_path=&quot;/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&quot;# Host alias specification# User alias specification# Cmnd alias specification# User privilege specification(在这一行, 添加一个用户)root| ALL=(ALL:ALL) ALL# Members of the admin group may gain root privileges%admin ALL=(ALL) ALL# Allow members of group sudo to execute any command%sudo| ALL=(ALL:ALL) ALL# See sudoers(5) for more information on &quot;#include&quot; directives:#includedir /etc/sudoers.d 更新源列表cd /etc/apt/cp source.list source.list.bak 输入法安装1.先安装，这四个apt-get install fcitx，apt-get install fcitx-ui-classicapt-get install fcitx-ui-lightapt install ttf-wqy-*2.百度sogo输入法linux.deb ,然后双击。。。 安装vim, gedit, vscode更改时间和时区修改主机名查看一下当前的hostname有2种方法 打开一个终端，在命令提示符中可以看到主机名，主机名通常位于“@”符号后 在终端输入hostname指令要修改hostname，需要root权限如果是Ubuntu/Debian修改步骤和上面类似：（1）修改/etc/hosts，将/etc/hosts内出现的h93都改成vm93。（2）修改/etc/hostname，将该文件内容由h93修改为vm93。（3）执行“hostname vm93”，临时修改一下。当下次重启系统，则真正生效。 在终端输入reboot,结果到了重新安装镜像的界面了Virtualbox安装好debian ,在终端输入reboot,结果到了重新安装镜像的界面了。这是因为安装的磁盘iso还在光驱中。所以，reboot会从光驱驱动，重新进入安装界面。这个时候，我一般不点击reboot。而是直接点击virtualbox的poweroff键。让他关闭虚拟机。然后在关闭虚拟机后，先弹出光驱中的iso。然后再重启virtualbox中的linux OS。 ###arvin is not in the sudoers filethis incident will be reportedyou have mail in /var/mail/arvin","categories":[{"name":"工具","slug":"工具","permalink":"http://arvin-he.github.io/categories/工具/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://arvin-he.github.io/tags/Linux/"}]},{"title":"C++之virtual","slug":"cpp-virtual-2017-07-07","date":"2017-07-07T09:16:17.000Z","updated":"2017-09-08T03:51:39.420Z","comments":true,"path":"2017/07/07/cpp-virtual-2017-07-07/","link":"","permalink":"http://arvin-he.github.io/2017/07/07/cpp-virtual-2017-07-07/","excerpt":"","text":"virtual是什么为什么虚析构函数要加virtualvirtual使用1) 虚函数是动态绑定的，也就是说，使用虚函数的指针和引用能够正确找到实际类的对应函数，而不是执行定义类的函数。这是虚函数的基本功能，就不再解释了。 2) 构造函数不能是虚函数。而且，在构造函数中调用虚函数，实际执行的是父类的对应函数，因为自己还没有构造好, 多态是被disable的。 3) 析构函数可以是虚函数，而且，在一个复杂类结构中，这往往是必须的。 4) 将一个函数定义为纯虚函数，实际上是将这个类定义为抽象类，不能实例化对象。 5) 纯虚函数通常没有定义体，但也完全可以拥有。 6) 析构函数可以是纯虚的，但纯虚析构函数必须有定义体，因为析构函数的调用是在子类中隐含的。 7) 非纯的虚函数必须有定义体，不然是一个错误。 8) 派生类的override虚函数定义必须和父类完全一致。除了一个特例，如果父类中返回值是一个指针或引用，子类override时可以返回这个指针（或引用）的派生。例如，在上面的例子中，在Base中定义了 virtual Base clone(); 在Derived中可以定义为 virtual Derived clone()。可以看到，这种放松对于Clone模式是非常有用的。 参考 http://www.cnblogs.com/chio/archive/2007/09/10/888260.html","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"C/C++","slug":"C-C","permalink":"http://arvin-he.github.io/tags/C-C/"}]},{"title":"设计模式之工厂方法模式","slug":"dp-factorymethod-2017-07-07","date":"2017-07-07T08:47:59.000Z","updated":"2017-09-08T03:51:39.428Z","comments":true,"path":"2017/07/07/dp-factorymethod-2017-07-07/","link":"","permalink":"http://arvin-he.github.io/2017/07/07/dp-factorymethod-2017-07-07/","excerpt":"","text":"工厂方法模式工厂方法模式(Factory Method Pattern)又称为工厂模式，也叫虚拟构造器(Virtual Constructor)模式或者多态工厂(Polymorphic Factory)模式，它属于类创建型模式。在工厂方法模式中，工厂父类负责定义创建产品对象的公共接口，而工厂子类则负责生成具体的产品对象，这样做的目的是将产品类的实例化操作延迟到工厂子类中完成，即通过工厂子类来确定究竟应该实例化哪一个具体产品类。 模式结构工厂方法模式包含如下角色：Product：抽象产品ConcreteProduct：具体产品Factory：抽象工厂ConcreteFactory：具体工厂 模式分析工厂方法模式是简单工厂模式的进一步抽象和推广。由于使用了面向对象的多态性，工厂方法模式保持了简单工厂模式的优点，而且克服了它的缺点。在工厂方法模式中，核心的工厂类不再负责所有产品的创建，而是将具体创建工作交给子类去做。这个核心类仅仅负责给出具体工厂必须实现的接口，而不负责哪一个产品类被实例化这种细节，这使得工厂方法模式可以允许系统在不修改工厂角色的情况下引进新产品。 python 实现文件结构1234567C:\\USERS\\ARON\\DESKTOP\\DESIGNPATTERNS\\FACTORYMETHOD concretefactory.py concreteproduct.py factory.py main.py product.py __init__.py 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# factory.pyclass Factory(object): def __init__(self): pass def factoryMethod(self): return None# product.pyclass Product(object): def __init__(self): pass def use(self): pass# concretefactory.pyfrom factory import Factoryfrom concreteproduct import ConcreteProductclass ConcreteFactory(Factory): def __init__(self): super(ConcreteFactory, self).__init__() def factoryMethod(self): return ConcreteProduct()# concreteproduct.pyfrom product import Productclass ConcreteProduct(Product): def __init__(self): super(ConcreteProduct, self).__init__() def use(self): print(\"use product A\")# main.pyfrom product import Productfrom concretefactory import ConcreteFactoryfrom concretefactory import ConcreteFactoryif __name__ == \"__main__\": fac = ConcreteFactory() prod = fac.factoryMethod() prod.use() 最后运行结果: C++ 实现123456789101112131415161718192021222324252627// factory.h#ifndef FACTORY_H#define FACTORY_H#include \"product.h\"class Factory&#123;public: Factory(); virtual ~Factory(); virtual Product* factoryMethod();&#125;;#endif // FACTORY_H// factory.cpp#include \"factory.h\"#include &lt;stdio.h&gt;Factory::Factory() &#123;&#125;Factory::~Factory() &#123;&#125;Product* Factory::factoryMethod()&#123; return NULL;&#125; 12345678910111213141516171819202122// product.h#ifndef PRODUCT_H#define PRODUCT_Hclass Product&#123;public: Product(); virtual ~Product(); virtual void use();&#125;;#endif // PRODUCT_H// product.cpp#include \"product.h\"Product::Product() &#123;&#125;Product::~Product() &#123;&#125;void Product::use() &#123;&#125; 12345678910111213141516171819202122232425262728// concretefactory.h#ifndef CONCRETEFACTORY_H#define CONCRETEFACTORY_H#include \"product.h\"#include \"factory.h\"class ConcreteFactory : public Factory&#123;public: ConcreteFactory(); virtual ~ConcreteFactory(); virtual Product* factoryMethod();&#125;;#endif // CONCRETEFACTORY_H// concretefactory.cpp#include \"concretefactory.h\"#include \"concreteproduct.h\"ConcreteFactory::ConcreteFactory() &#123;&#125;ConcreteFactory::~ConcreteFactory() &#123;&#125;Product* ConcreteFactory::factoryMethod()&#123; return new ConcreteProduct();&#125; 12345678910111213141516171819202122232425262728// concreteproduct.h#ifndef CONCRETEPRODUCT_H#define CONCRETEPRODUCT_H#include \"product.h\"class ConcreteProduct : public Product&#123;public: ConcreteProduct(); virtual ~ConcreteProduct(); virtual void use();&#125;;#endif // CONCRETEPRODUCT_H// concreteproduct.cpp#include \"concreteproduct.h\"#include &lt;iostream&gt;using namespace std;ConcreteProduct::ConcreteProduct() &#123;&#125;ConcreteProduct::~ConcreteProduct() &#123;&#125;void ConcreteProduct::use()&#123; cout&lt;&lt;\"use product A\"&lt;&lt;endl;&#125; 123456789101112131415161718// main.cpp#include \"factory.h\"#include \"concretefactory.h\"#include \"product.h\"#include &lt;iostream&gt;using namespace std;int main(int argc, char *argv[])&#123; Factory* fac = new ConcreteFactory(); Product* prod = fac-&gt;factoryMethod(); prod-&gt;use(); delete fac; delete prod; return 0;&#125; 运行结果: 工厂方法模式的优点在工厂方法模式中，工厂方法用来创建客户所需要的产品，同时还向客户隐藏了哪种具体产品类将被实例化这一细节，用户只需要关心所需产品对应的工厂，无须关心创建细节，甚至无须知道具体产品类的类名。基于工厂角色和产品角色的多态性设计是工厂方法模式的关键。它能够使工厂可以自主确定创建何种产品对象，而如何创建这个对象的细节则完全封装在具体工厂内部。工厂方法模式之所以又被称为多态工厂模式，是因为所有的具体工厂类都具有同一抽象父类。使用工厂方法模式的另一个优点是在系统中加入新产品时，无须修改抽象工厂和抽象产品提供的接口，无须修改客户端，也无须修改其他的具体工厂和具体产品，而只要添加一个具体工厂和具体产品就可以了。这样，系统的可扩展性也就变得非常好，完全符合“开闭原则”。 工厂方法模式的缺点在添加新产品时，需要编写新的具体产品类，而且还要提供与之对应的具体工厂类，系统中类的个数将成对增加，在一定程度上增加了系统的复杂度，有更多的类需要编译和运行，会给系统带来一些额外的开销。由于考虑到系统的可扩展性，需要引入抽象层，在客户端代码中均使用抽象层进行定义，增加了系统的抽象性和理解难度，且在实现时可能需要用到DOM、反射等技术，增加了系统的实现难度。 适用环境在以下情况下可以使用工厂方法模式： 一个类不知道它所需要的对象的类：在工厂方法模式中，客户端不需要知道具体产品类的类名，只需要知道所对应的工厂即可，具体的产品对象由具体工厂类创建；客户端需要知道创建具体产品的工厂类。 一个类通过其子类来指定创建哪个对象：在工厂方法模式中，对于抽象工厂类只需要提供一个创建产品的接口，而由其子类来确定具体要创建的对象，利用面向对象的多态性和里氏代换原则，在程序运行时，子类对象将覆盖父类对象，从而使得系统更容易扩展。 将创建对象的任务委托给多个工厂子类中的某一个，客户端在使用时可以无须关心是哪一个工厂子类创建产品子类，需要时再动态指定，可将具体工厂类的类名存储在配置文件或数据库中。 模式扩展 使用多个工厂方法：在抽象工厂角色中可以定义多个工厂方法，从而使具体工厂角色实现这些不同的工厂方法，这些方法可以包含不同的业务逻辑，以满足对不同的产品对象的需求。 产品对象的重复使用：工厂对象将已经创建过的产品保存到一个集合（如数组、List等）中，然后根据客户对产品的请求，对集合进行查询。如果有满足要求的产品对象，就直接将该产品返回客户端；如果集合中没有这样的产品对象，那么就创建一个新的满足要求的产品对象，然后将这个对象在增加到集合中，再返回给客户端。 多态性的丧失和模式的退化：如果工厂仅仅返回一个具体产品对象，便违背了工厂方法的用意，发生退化，此时就不再是工厂方法模式了。一般来说，工厂对象应当有一个抽象的父类型，如果工厂等级结构中只有一个具体工厂类的话，抽象工厂就可以省略，也将发生了退化。当只有一个具体工厂，在具体工厂中可以创建所有的产品对象，并且工厂方法设计为静态方法时，工厂方法模式就退化成简单工厂模式。","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://arvin-he.github.io/tags/设计模式/"}]},{"title":"理解回调函数(callback)","slug":"callback-2017-07-07","date":"2017-07-07T06:57:11.000Z","updated":"2017-09-08T03:51:39.252Z","comments":true,"path":"2017/07/07/callback-2017-07-07/","link":"","permalink":"http://arvin-he.github.io/2017/07/07/callback-2017-07-07/","excerpt":"","text":"回调函数一个知乎上的比喻:你到一个商店买东西，刚好你要的东西没有货，于是你在店员那里留下了你的电话，过了几天店里有货了，店员就打了你的电话，然后你接到电话后就到店里去取了货。在这个例子里，你的电话号码就叫回调函数，你把电话留给店员就叫登记回调函数，店里后来有货了叫做触发了回调关联的事件，店员给你打电话叫做调用回调函数，你到店里去取货叫做响应回调事件。简而言之，回调函数就是一个通过函数指针调用的函数。如果你把函数的指针（地址）作为参数传递给另一个函数，当这个指针被用来调用它所指向的函数时，我们就说这是回调函数。 函数指针函数指针就是函数的地址, 回调函数是函数指针的应用.一个函数指针是一个指针变量了，它所指向的是一个函数，它的值就是所指向函数的入口地址。 python中的回调函数123456789101112131415def my_callback(input): print \"function my_callback was called with %s input\" % (input,) def caller(input, func): func(input) for i in range(5): caller(i, my_callback) &gt;&gt;&gt;function my_callback was called with 0 inputfunction my_callback was called with 1 inputfunction my_callback was called with 2 inputfunction my_callback was called with 3 inputfunction my_callback was called with 4 input js中的回调函数JavaScript中，回调函数具体的定义为：函数A作为参数(函数引用)传递到另一个函数B中，并且这个函数B执行函数A。我们就说函数A叫做回调函数。如果没有名称(函数表达式)，就叫做匿名回调函数。因此callback 不一定用于异步，一般同步(阻塞)的场景下也经常用到回调，比如要求执行某些操作后执行回调函数。例子1: 同步(阻塞)中使用回调，目的是在func1代码执行完成后执行func2。12345678var func1=function(callback)&#123; //do something. (callback &amp;&amp; typeof(callback) === \"function\") &amp;&amp; callback();&#125;func1(func2); var func2=function()&#123;&#125; 例子2: 异步回调12345678910111213$(document).ready(callback);$.ajax(&#123; url: \"test.html\", context: document.body&#125;).done(function() &#123; $(this).addClass(\"done\");&#125;).fail(function() &#123; alert(\"error\");&#125;).always(function() &#123; alert(\"complete\"); &#125;);/**注意的是，ajax请求确实是异步的,不过这请求是由浏览器新开一个线程请求,当请求的状态变更时,如果先前已设置回调,这异步线程就产生状态变更事件放到 JavaScript引擎的处理队列中等待处理。见：http://www.phpv.net/html/1700.html*/ 回调什么时候执行回调函数，一般在同步情境下是最后执行的，而在异步情境下有可能不执行，因为事件没有被触发或者条件不满足。 回调函数的使用场合 资源加载：动态加载js文件后执行回调，加载iframe后执行回调，ajax操作回调，图片加载完成执行回调，AJAX等等。 DOM事件及Node.js事件基于回调机制(Node.js回调可能会出现多层回调嵌套的问题)。 setTimeout的延迟时间为0，这个hack经常被用到，settimeout调用的函数其实就是一个callback的体现 链式调用：链式调用的时候，在赋值器(setter)方法中(或者本身没有返回值的方法中)很容易实现链式调用，而取值器(getter)相对来说不好实现链式调用，因为你需要取值器返回你需要的数据而不是this指针，如果要实现链式方法，可以用回调函数来实现 setTimeout、setInterval的函数调用得到其返回值。由于两个函数都是异步的，即：他们的调用时序和程序的主流程是相对独立的，所以没有办法在主体里面等待它们的返回值，它们被打开的时候程序也不会停下来等待，否则也就失去了setTimeout及setInterval的意义了，所以用return已经没有意义，只能使用callback。callback的意义在于将timer执行的结果通知给代理函数进行及时处理。 回调函数的传递回调函数的传递是通过将函数引用或者函数表达式作为参数传递。12345$.get('myhtmlpage.html', myCallBack);//这是对的$.get('myhtmlpage.html', myCallBack('foo', 'bar'));//这是错的，那么要带参数呢？$.get('myhtmlpage.html', function()&#123;//带参数的使用函数表达式myCallBack('foo', 'bar');&#125;); 另外，最好保证回调存在且必须是函数引用或者函数表达式： (callback &amp;&amp; typeof(callback) === “function”) &amp;&amp; callback(); 如何使用回调函数使用回调函数，我们需要做三件事： 声明 定义 设置触发条件：在你的函数种把你的回调函数名称转化为地址作为一个参数，以便于系统调用。声明和定义时应注意，回调函数由系统调用，所以可以认为它属于windows系统，不要把它当作你的某个类的成员函数。回调函数是一个程序员不能显示调用的函数，通过将回调函数的地址传给调用者从而实现调用。回调函数是十分有必要的，在我们想通过一个统一接口实现不同的内容，这时回调函数非常合适。 调用约定在visual c++中，可以在函数类型前加_cdecl,_stdcall或者_pascal来表示调用规范（默认为_cdecl）。调用规范影响编译器产生的给定函数名，参数传递的顺序，堆栈清理责任以及参数传递机制。不过，在win32的程序中，我见得比较多的是CALLBACK，这个宏定义在windef.h中，#define CALLBACK __stdcall 它约定了函数在它们返回到调用者之前，都会从堆栈中移除掉参数。 事实上回掉函数和普通函数是没区别的. 你同样可以使用定义的回调函数做其它事情. 调用约定是有调用者规定的(函数参数中规定了回调函数的类型, 函数类型包括了函数的调用约定, 参数, 返回值), CALLBACK 是 win16 一个遗留宏定义, 当初是定义成的 pascal 约定, 现在都是定义成 WINAPI宏, 使用的是 __stdcall 约定.类静态成员函数可以作回调函数, 不用成员函数做回调函数的原因是成员函数的参数比参数表中列出的多了一个this指针(其实也是可以用的, 那种技巧没什么好处) 参考 回调函数（callback）是什么?","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"计算机基础","slug":"计算机基础","permalink":"http://arvin-he.github.io/tags/计算机基础/"}]},{"title":"算法系列之希尔排序","slug":"algo-shellsort-2017-07-07","date":"2017-07-07T06:25:55.000Z","updated":"2017-09-08T03:51:39.245Z","comments":true,"path":"2017/07/07/algo-shellsort-2017-07-07/","link":"","permalink":"http://arvin-he.github.io/2017/07/07/algo-shellsort-2017-07-07/","excerpt":"","text":"希尔排序希尔排序(Shell Sort)是插入排序的一种。也称缩小增量排序或递减增量排序算法，是直接插入排序算法的一种更高效的改进版本。希尔排序是非稳定排序算法。该方法因DL．Shell于1959年提出而得名。希尔排序是把记录按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止。 原理插入排序的改进版，是基于插入排序的以下2点性质而提出的改进方法： 插入排序对几乎已排好序的数据操作时，效率很高，可以达到线性排序的效率。但插入排序在每次往前插入时只能将数据移动一位，效率比较低。所以希尔排序的思想是： 先是取一个合适的gap&lt;n作为间隔，将全部元素分为gap个子序列，所有距离为gap的元素放入同一个子序列，再对每个子序列进行直接插入排序；缩小间隔gap，例如去gap=ceil(gap/2)，重复上述子序列划分和排序直到，最后gap=1时，将所有元素放在同一个序列中进行插入排序为止。 性能开始时，gap取值较大，子序列中的元素较少，排序速度快，克服了直接插入排序的缺点；其次，gap值逐渐变小后，虽然子序列的元素逐渐变多，但大多元素已基本有序，所以继承了直接插入排序的优点，能以近线性的速度排好序。 python实现1234arr = [3, 5, 2, 6, 14, 9, 7, 1, 6]def shell_sort(arr): pass","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://arvin-he.github.io/tags/算法/"}]},{"title":"Linux之gcc命令","slug":"linux-gcccmd-2017-07-06","date":"2017-07-06T01:29:44.000Z","updated":"2017-09-08T03:51:39.769Z","comments":true,"path":"2017/07/06/linux-gcccmd-2017-07-06/","link":"","permalink":"http://arvin-he.github.io/2017/07/06/linux-gcccmd-2017-07-06/","excerpt":"","text":"在linux 下生成.so共享库要生成共享库，您需要先使用-fPIC（position independent code 位置无关代码）标志来编译C代码,gcc -c -fPIC hello.c -o hello.o这将生成一个目标文件（.o），现在你拿它并创建.so文件：gcc hello.o -shared -o libhello.so你也可以使用:gcc -shared -o libhello.so -fPIC hello.c 一步生成.so文件我还建议添加 -Wall选项获取所有的警告，和-g选项获取调试信息，到你的gcc命令。","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://arvin-he.github.io/tags/Linux/"}]},{"title":"cookbook之C 语言扩展","slug":"ck-CExtends-2017-07-06","date":"2017-07-06T00:28:17.000Z","updated":"2017-09-08T03:51:39.255Z","comments":true,"path":"2017/07/06/ck-CExtends-2017-07-06/","link":"","permalink":"http://arvin-he.github.io/2017/07/06/ck-CExtends-2017-07-06/","excerpt":"","text":"使用C扩展开发者有三种方法可以在自己的Python代码中来调用C编写的函数: ctypes，SWIG，Python/C API。每种方式也都有各自的利弊。首先，我们要明确为什么要在Python中调用C？常见原因如下： 你要提升代码的运行速度，而且你知道C要比Python快50倍以上 C语言中有很多传统类库，而且有些正是你想要的，但你又不想用Python去重写它们 想对从内存到文件接口这样的底层资源进行访问 … 使用 ctypes 访问 C 代码你有一些 C 函数已经被编译到共享库或 DLL 中。你希望可以使用纯 Python 代码调用这些函数，而不用编写额外的 C 代码或使用第三方扩展工具.对于需要调用 C 代码的一些小的问题，通常使用 Python 标准库中的 ctypes 模块就足够了123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// sample.c#include &lt;math.h&gt;int my_add(int x, int y)&#123; return x + y;&#125;int gcd(int x, int y)&#123; int g = y; while (x &gt; 0) &#123; g = x; x = y % x; y = g; &#125; return g;&#125;int in_mandel(double x0, double y0, int n)&#123; double x = 0, y = 0, xtemp; while (n &gt; 0) &#123; xtemp = x*x - y*y + x0; y = 2*x*y + y0; x = xtemp; n -= 1; if (x*x + y*y &gt; 4) return 0; &#125; return 1;&#125;int divide(int a, int b, int *remainder)&#123; int quot = a / b; *remainder = a % b; return quot;&#125;double avg(double *a, int n) &#123; int i; double total = 0.0; for (i = 0; i &lt; n; i++) &#123; total += a[i]; &#125; return total / n;&#125;typedef struct Point&#123; double x, y;&#125;Point;double distance(Point *p1, Point *p2)&#123; return hypot(p1-&gt;x - p2-&gt;x, p1-&gt;y - p2-&gt;y);&#125; 然后将sample.c编译成libsample.so: gcc -shared -o libsample.so -fPIC sample.c注意:对于 C 和 Python 代码一起打包的问题，如果你在使用 ctypes 来访问编译后的 C 代码，那么需要确保这个共享库放在sample.py 模块同一个地方.如果 C 函数库被安装到其他地方，那么你就要修改相应的路径。如果 C 函数库在你机器上被安装为一个标准库了，那么可以使用 ctypes.util.find_library() 函数来查找.123&gt;&gt;&gt; from ctypes.util import find_library&gt;&gt;&gt; find_library('sample')'/usr/local/lib/libsample.so' 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576# sample.pyimport ctypesimport os_file = \"libsample.so\"_path = os.path.join(os.path.abspath(\".\"), _file)# _path = os.path.join(*(os.path.split(__file__)[:-1]+(_file,)))_mod = ctypes.cdll.LoadLibrary(_path)my_add = _mod.my_addmy_add.argtypes = (ctypes.c_int, ctypes.c_int)my_add.restype = ctypes.c_intgcd = _mod.gcdgcd.argtypes = (ctypes.c_int, ctypes.c_int)gcd.restype = ctypes.c_intin_mandel = _mod.in_mandelin_mandel.argtypes = (ctypes.c_double, ctypes.c_double, ctypes.c_int)in_mandel.restype = ctypes.c_int_divide = _mod.divide_divide.argtypes = (ctypes.c_int, ctypes.c_int, ctypes.POINTER(ctypes.c_int))_divide.restype = ctypes.c_intdef divide(x, y): rem = ctypes.c_int() quot = _divide(x, y, rem) return quot, rem.valueclass DoubleArrayType: def from_param(self, param): typename = type(param).__name__ if hasattr(self, \"from_\" + typename): return getattr(self, \"from_\" + typename) elif isinstance(param, ctypes.Array): return param else: raise TypeError(\"can't convert %s\" % typename) def from_array(self, param): if param.typecode != 'd': raise TypeError(\"must be an array of doubles\") ptr, _ = param.buffer_info() return ctypes.cast(ptr, ctypes.POINTER(ctypes.c_double)) def from_list(self, param): val = ((ctypes.c_double)*len(param))(*param) return val from_tuple = from_list def from_ndarray(self, param): return param.ctypes.data_as(ctypes.POINTER(ctypes.c_double))DoubleArray = DoubleArrayType()_avg = _mod.avg_avg.argtypes = (DoubleArray, ctypes.c_int)_avg.restype = ctypes.c_doubledef avg(values): return _avg(values, len(values))class Point(ctypes.Structure): _fields_ =[('x', ctypes.c_double), ('y', ctypes.c_double)]distance = _mod.distancedistance.argtypes = (ctypes.POINTER(Point), ctypes.POINTER(Point))distance.restype = ctypes.c_double 12345678910111213141516# main.pyimport sampleprint(sample.gcd(35, 42))print(sample.my_add(10, 20))print(sample.in_mandel(0,0,500))print(sample.divide(42, 8))print(sample.avg([1,2,3]))&gt;&gt;&gt;aron@aron-VirtualBox:~/Desktop/pycallc$ python3 main.py7301(5, 2)2.0 一旦你知道了C函数库的位置，那么就可以像下面这样使用ctypes.cdll.LoadLibrary() 来加载它，其中 _path 是标准库的全路径,加载模块_mod = ctypes.cdll.LoadLibrary(_path),函数库被加载后，你需要编写几个语句来提取特定的符号并指定它们的类型1234# int in_mandel(double, double, int)in_mandel = _mod.in_mandelin_mandel.argtypes = (ctypes.c_double, ctypes.c_double, ctypes.c_int)in_mandel.restype = ctypes.c_int argtypes 属性是一个元组，包含了某个函数的输入参数类型restype 是相应的返回类型想让 Python 能够传递正确的参数类型并且正确的转换数据的话，那么这些类型签名的绑定是很重要的一步。如果你没有这么做，不但代码不能正常运行，还可能会导致整个解释器进程挂掉。使用ctypes 有一个麻烦点的地方是原生的 C 代码使用的术语可能跟 Python 不能明确的对应上来。 divide() 函数是一个很好的例子，它通过一个参数除以另一个参数返回一个结果值。尽管这是一个很常见的 C 技术，但是在 Python 中却不知道怎样清晰的表达出来。 最后一些小的提示：如果你想在 Python 中访问一些小的 C 函数，那么 ctypes 是一个很有用的函数库。尽管如此，如果你想要去访问一个很大的库，那么可能就需要其他的方法了，比如 Swig 或 Cython. 由于 ctypes 并不是完全自动化，那么你就必须花费大量时间来编写所有的类型签名，如果函数库够复杂，你还得去编写很多小的包装函数和支持类。作为 ctypes 的一个替代，你还可以考虑下 CFFI。CFFI 提供了很多类似的功能，但是使用 C 语法并支持更多高级的 C 代码类型。 Python/C API不依靠其他工具，直接使用 Python 的扩展 API 来编写一些简单的 C 扩展模块。Python/C API可能是被最广泛使用的方法。它不仅简单，而且可以在C代码中操作你的Python对象。这种方法需要以特定的方式来编写C代码以供Python去调用它。所有的Python对象都被表示为一种叫做PyObject的结构体，并且Python.h头文件中提供了各种操作它的函数。 123456789101112131415161718192021222324252627282930313233343536#include &lt;Python.h&gt; static PyObject* add(PyObject* self, PyObject* args)&#123; int a = 0; int b = 0; if(!PyArg_ParseTuple(args, \"i|i\", &amp;a, &amp;b)) return NULL; return Py_BuildValue(\"i\", a+b);&#125; static PyObject* sub(PyObject* self, PyObject* args)&#123; int a = 0; int b = 0; if(!PyArg_ParseTuple(args, \"i|i\", &amp;a, &amp;b)) return NULL; return Py_BuildValue(\"i\", a-b);&#125; static PyMethodDef addMethods[]=&#123; &#123;\"add\", add, METH_VARARGS&#125;, &#123;\"sub\", sub, METH_VARARGS&#125;, &#123;NULL, NULL, 0, NULL&#125;&#125;;/* Module structure */static struct PyModuleDef mytestmodule = &#123; PyModuleDef_HEAD_INIT, \"mytest\", /* name of module */ \"A sample module\", /* Doc string (may be NULL) */ -1, /* Size of per-interpreter state or -1 */ addMethods /* Method table */&#125;; PyMODINIT_FUNC PyInit_mytest(void) &#123; return PyModule_Create(&amp;mytestmodule);&#125; mytest.c编写好后就使用命令或者使用setup.py生成.so文件方法1:使用命令生成.sogcc -shared -I /usr/include/python3.5 -o mytest.so -fPIC mytest.c方法2: 编写setup.py生成.so文件123456789# setup.pyfrom distutils.core import setup, Extensionsetup(name='mytest', ext_modules=[ Extension('mytest', ['mytest.c'], include_dirs = ['/usr/include/python3.5'], )]) 注意:使用setup.py生成的.so文件名字会变成mytest.cpython-35m-x86_64-linux-gnu.so,不是mytest.so,重命名mytest.cpython-35m-x86_64-linux-gnu.so为mytest.so,不然会报找不到Error:ImportError: No module named mytest. 生成好.so文件,就直接在python代码中import,然后调用函数了1234567import mytestprint(mytest.add(5, 5))print(mytest.sub(20, 6))&lt;&lt;&lt; 10&lt;&lt;&lt; 14 从 C 语言中调用 Python 代码想在 C 语言中使用某个 Python 函数作为一个回调。在 C 语言中调用 Python，要记住最重要的是 C 语言会是主体。也就是说，C 语言负责构造参数、调用 Python 函数、检查异常、检查类型、提取返回值等. 用 WSIG 包装 C 代码首先要说明的是swig可以进行很多语言的调用转换，不止是可以让python调用c。swig和sip都被称作wrapper，就是说他对你的原有函数进行了包装。看到之前用python c api的方式里，我们必须严格按照python c api的方式来写代码，破坏了原有c程序的可读性，于是wrapper的思想就是把原生c程序包装成python c api那种方式的代码，再去生成so文件。因此我们要做的是首先写c文件。123456int add(int a, int b)&#123; return a+b;&#125;int sub(int a, int b)&#123; return a-b;&#125; 然后再去写一个swig格式的接口文件。12345678%module mytest%&#123;extern int add(int a, int b);extern int sub(int a, int b);%&#125; extern int add(int a, int b);extern int sub(int a, int b); 然后就可以运行swig，他会自动生成python c api写的代码，并且会自动编译出so文件来调用。 用 sip 包装 C 代码sip是swig发展而来是方便python调用c的，所以基本使用方式都是差不多，只不过接口文件略有差异. cfficffi类似于ctypes直接在python程序中调用c程序，但是比ctypes更方便不要求编译成so再调用，注意到上面的所有方式都是需要去编译成so文件后再在python中调用，而cffi允许你直接调用c文件来使用里面的函数了，为什么这么神奇呢，其实是cffi在解释过程中才帮你把c编译为so文件.12345678from cffi import FFIffi = FFI()ffi.cdef(\"\"\"int add(int a, int b);int sub(int a, int b);\"\"\")lib = ffi.verify('#include \"mytest.c\"')print(lib.add(1,2))","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"cookbook之测试,调试和异常","slug":"ck-testdebugexception-2017-07-05","date":"2017-07-05T08:47:21.000Z","updated":"2017-09-08T03:51:39.269Z","comments":true,"path":"2017/07/05/ck-testdebugexception-2017-07-05/","link":"","permalink":"http://arvin-he.github.io/2017/07/05/ck-testdebugexception-2017-07-05/","excerpt":"","text":"在单元测试中给对象打补丁写的单元测试中需要给指定的对象打补丁，用来断言它们在测试中的期望行为（比如，断言被调用时的参数个数，访问指定的属性等）unittest.mock.patch() 函数可被用来解决这个问题。 patch() 还可被用作一个装饰器、上下文管理器或单独使用，尽管并不常见。 将测试输出用日志记录到文件中1234567import unittestclass MyTest(unittest.TestCase): passif __name__ == '__main__': unittest.main() 这样的话测试文件就是可执行的，并且会将运行测试的结果打印到标准输出上。如果你想重定向输出，就需要像下面这样修改 main() 函数：12345678910import sysdef main(out=sys.stderr, verbosity=2): loader = unittest.TestLoader() suite = loader.loadTestsFromModule(sys.modules[__name__]) unittest.TextTestRunner(out,verbosity=verbosity).run(suite)if __name__ == '__main__': with open('testing.out', 'w') as f: main(f) 忽略或期望测试失败在单元测试中忽略或标记某些测试会按照预期运行失败。unittest 模块有装饰器可用来控制对指定测试方法的处理1234567891011121314151617181920212223242526import unittestimport osimport platformclass Tests(unittest.TestCase): def test_0(self): self.assertTrue(True) @unittest.skip('skipped test') def test_1(self): self.fail('should have failed!') @unittest.skipIf(os.name=='posix', 'Not supported on Unix') def test_2(self): import winreg @unittest.skipUnless(platform.system() == 'Darwin', 'Mac specific test') def test_3(self): self.assertTrue(True) @unittest.expectedFailure def test_4(self): self.assertEqual(2+2, 5)if __name__ == '__main__': unittest.main() kip() 装饰器能被用来忽略某个你不想运行的测试。 skipIf() 和 skipUnless()对于你只想在某个特定平台或 Python 版本或其他依赖成立时才运行测试的时候非常有用。使用 @expected 的失败装饰器来标记那些确定会失败的测试，并且对这些测试你不想让测试框架打印更多信息。 处理多个异常有一个代码片段可能会抛出多个不同的异常,可以用单个代码块处理不同的异常，可以将它们放入一个元组中1234try: client_obj.get_url(url)except (URLError, ValueError, SocketTimeout): client_obj.remove_url(url) 如果你想对其中某个异常进行不同的处理，可以将其放入另外一个 except 语句中：123456try: client_obj.get_url(url)except (URLError, ValueError): client_obj.remove_url(url)except SocketTimeout: client_obj.handle_url_timeout(url) 很多的异常会有层级关系，对于这种情况，你可能使用它们的一个基类来捕获所有的异常。1234567891011121314151617181920212223try: f = open(filename)except (FileNotFoundError, PermissionError): pass# 用基类来捕获所有的异常try: f = open(filename)except OSError: pass``` 使用 as 关键字来获得被抛出异常的引用```pythontry: f = open(filename)except OSError as e: if e.errno == errno.ENOENT: logger.error('File not found') elif e.errno == errno.EACCES: logger.error('Permission denied') else: logger.error('Unexpected error: %d', e.errno) 捕获所有异常捕获所有的异常，可以直接捕获 Exception 即可, 这个将会捕获除了 SystemExit 、 KeyboardInterrupt 和 GeneratorExit 之外的所有异常。如果你还想捕获这三个异常，将 Exception 改成 BaseException 即可.12345try: ...except Exception as e: ... log('Reason:', e) # Important! 捕获异常后抛出另外的异常链接异常，使用 raise from 语句来代替简单的 raise 语句, 同时保留两个异常的信息1234567891011121314&gt;&gt;&gt; def example():... try:... int('N/A')... except ValueError as e:... raise RuntimeError('A parsing error occurred') from e&gt;&gt;&gt;example()Traceback (most recent call last):File \"&lt;stdin&gt;\", line 3, in exampleValueError: invalid literal for int() with base 10: 'N/A'Traceback (most recent call last):File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;File \"&lt;stdin&gt;\", line 5, in exampleRuntimeError: A parsing error occurred 输出警告信息在你维护软件，提示用户某些信息，但是又不需要将其上升为异常级别，那么输出警告信息就会很有用了.希望程序能生成警告信息（比如废弃特性或使用问题）,可使用 warning.warn() 函数.12345import warningsdef func(x, y, logfile=None, debug=False): if logfile is not None: warnings.warn('logfile argument deprecated', DeprecationWarning) warn() 的参数是一个警告消息和一个警告类，警告类有如下几种：UserWarning, DeprecationWarning, SyntaxWarning, RuntimeWarning, ResourceWarning, 或 Future-Warning.对警告的处理取决于你如何运行解释器以及一些其他配置。例如，如果你使用 -W all 选项去运行 Python，你会得到如下的输出：123bash % python3 -W all example.pyexample.py:5: DeprecationWarning: logfile argument is deprecatedwarnings.warn(&apos;logfile argument is deprecated&apos;, DeprecationWarning) 通常来讲，警告会输出到标准错误上。如果你想讲警告转换为异常，可以使用 -W error 选项：1234567bash % python3 -W error example.pyTraceback (most recent call last):File &quot;example.py&quot;, line 10, in &lt;module&gt;func(2, 3, logfile=&apos;log.txt&apos;)File &quot;example.py&quot;, line 5, in funcwarnings.warn(&apos;logfile argument is deprecated&apos;, DeprecationWarning)DeprecationWarning: logfile argument is deprecated 默认情况下，并不是所有警告消息都会出现。-W 选项能控制警告消息的输出。 -W all 会输出所有警告消息，-W ignore 忽略掉所有警告，-W error 将警告转换成异常。另外一种选择，你还可以使用 warnings.simplefilter() 函数控制输出。 always 参数会让所有警告消息出现，`ignore 忽略调所有的警告，error 将警告转换成异常。warnings 模块对过滤和警告消息处理提供了大量的更高级的配置选项。 调试基本的程序崩溃错误程序奔溃后该怎样去调试它？运行 python3 -i someprogram.py 可执行简单的调试。 -i 选项可让程序结束后打开一个交互式 shell。然后你就能查看环境.可以在程序奔溃后打开 Python 的调试器12345678910111213&gt;&gt;&gt; import pdb&gt;&gt;&gt; pdb.pm()&gt; sample.py(4)func()-&gt; return n + 10(Pdb) wsample.py(6)&lt;module&gt;()-&gt; func('Hello')&gt; sample.py(4)func()-&gt; return n + 10(Pdb) print n'Hello'(Pdb) q&gt;&gt;&gt; 代码所在的环境很难获取交互 shell（比如在某个服务器上面），通常可以捕获异常后自己打印跟踪信息1234567import tracebackimport systry: func(arg)except: print('**** AN ERROR OCCURRED ****') traceback.print_exc(file=sys.stderr) 要是你的程序没有奔溃，而只是产生了一些你看不懂的结果，你在感兴趣的地方插入一下 print() 语句也是个不错的选择。不过，要是你打算这样做，有一些小技巧可以帮助你。首先，traceback.print stack() 函数会你程序运行到那个点的时候创建一个跟踪栈。另外，你还可以像下面这样使用 pdb.set trace() 在任何地方手动的启动调试器12345import pdbdef func(arg): ... pdb.set_trace() .... 给程序做性能测试测试程序运行所花费的时间并做性能测试。只是简单的想测试下你的程序整体花费的时间，通常使用 Unix 时间函数就行了.需要一个程序各个细节的详细报告，使用 cProfile 模块.通常情况是介于这两个极端之间。比如你已经知道代码运行时在少数几个函数中花费了绝大部分时间。对于这些函数的性能测试，可以使用一个简单的装饰器：123456789101112131415161718192021# timethis.pyimport timefrom functools import wrapsdef timethis(func): @wraps(func) def wrapper(*args, **kwargs): start = time.perf_counter() r = func(*args, **kwargs) end = time.perf_counter() print('&#123;&#125;.&#123;&#125; : &#123;&#125;'.format(func.__module__, func.__name__, end - start)) return r return wrapper&gt;&gt;&gt; @timethis... def countdown(n):... while n &gt; 0:... n -= 1...&gt;&gt;&gt; countdown(10000000)__main__.countdown : 0.803001880645752 要测试某个代码块运行时间，你可以定义一个上下文管理器1234567891011121314151617from contextlib import contextmanager@contextmanagerdef timeblock(label): start = time.perf_counter() try: yield finally: end = time.perf_counter() print('&#123;&#125; : &#123;&#125;'.format(label, end - start))&gt;&gt;&gt; with timeblock('counting'):... n = 10000000... while n &gt; 0:... n -= 1...counting : 1.5551159381866455 对于测试很小的代码片段运行性能，使用 timeit 模块会很方便12345678910&gt;&gt;&gt; from timeit import timeit&gt;&gt;&gt; timeit('math.sqrt(2)', 'import math')0.1432319980012835&gt;&gt;&gt; timeit('sqrt(2)', 'from math import sqrt')0.10836604500218527&gt;&gt;&gt; timeit('math.sqrt(2)', 'import math', number=10000000)1.434852126003534&gt;&gt;&gt; timeit('sqrt(2)', 'from math import sqrt', number=10000000)1.0270336690009572 timeit 会执行参数中语句 100 万次并计算运行时间。第二个参数是运行测试之前配置环境。如果你想改变循环执行次数，可以设置 number 参数. 当执行性能测试的时候，需要注意的是你获取的结果都是近似值。time.perf_counter() 函数会在给定平台上获取最高精度的计时值。不过，它仍然还是基于时钟时间，很多因素会影响到它的精确度，比如机器负载。如果你对于cpu执行时间更感兴趣，使用 time.process_time() 来代替它。1234567891011from functools import wrapsdef timethis(func): @wraps(func) def wrapper(*args, **kwargs): start = time.process_time() r = func(*args, **kwargs) end = time.process_time() print('&#123;&#125;.&#123;&#125; : &#123;&#125;'.format(func.__module__, func.__name__, end - start)) return r return wrapper 加速程序运行你的程序运行太慢，你想在不使用复杂技术比如 C 扩展或 JIT 编译器的情况下加快程序运行速度.关于程序优化的第一个准则是“不要优化”，第二个准则是“不要优化那些无关紧要的部分”。通常会发现你得程序在少数几个热点地方花费了大量时间 使用函数定义在全局范围的代码运行起来要比定义在函数中运行慢的多。这种速度差异是由于局部变量和全局变量的实现方式（使用局部变量要更快些）。因此，如果你想让程序运行更快些，只需要将脚本语句放入函数中即可,速度的差异取决于实际运行的程序，不过根据经验，使用函数带来 15-30% 的性能提升是很常见的。 尽可能去掉属性访问每一次使用点 (.) 操作符来访问属性的时候会带来额外的开销。它会触发特定的方法，比如 __getattribute__ () 和 __getattr__ () ，这些方法会进行字典操作操作。可以使用 from module import name 这样的导入形式，以及使用绑定的方法.12345# 方式1import mathmath.sqrt(n)# 方式2from math import sqrt 方式2消除了属性访问,用sqrt() 代替了 math.sqrt() 理解局部变量局部变量会比全局变量运行速度快,在内部循环中，可以将某个需要频繁访问的属性放入到一个局部变量中.对于类中的属性访问也同样适用于这个原理。通常来讲，查找某个值比如self.name 会比访问一个局部变量要慢一些。 避免不必要的抽象任何时候当你使用额外的处理层（比如装饰器、属性访问、描述器）去包装你的代码时，都会让程序运行变慢. 使用内置的容器内置的数据类型比如字符串、元组、列表、集合和字典都是使用 C 来实现的，运行起来非常快。如果你想自己实现新的数据结构（比如链接列表、平衡树等），那么要想在性能上达到内置的速度几乎不可能，因此，还是乖乖的使用内置的吧. 避免创建不必要的数据结构或复制理解或信任 Python 的内存模型，不要滥用 copy.deepcopy() 之类的函数 作为一般准则，不要对程序的每一个部分都去优化, 因为这些修改回导致代码难以阅读和理解。你应该专注于优化产生性能瓶颈的地方，比如内部循环。引用John Ousterhout 说过的话：“最好的性能优化时从不工作到工作状态的迁移”。直到你真的需要优化的时候再去考虑它。确保你程序正确的运行通常比让它运行更快要更重要一些（至少开始是这样的）.","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"cookbook之脚本编程与系统管理","slug":"ck-sysmanager-2017-07-05","date":"2017-07-05T06:33:20.000Z","updated":"2017-09-08T03:51:39.264Z","comments":true,"path":"2017/07/05/ck-sysmanager-2017-07-05/","link":"","permalink":"http://arvin-he.github.io/2017/07/05/ck-sysmanager-2017-07-05/","excerpt":"","text":"通过重定向/管道/文件接受输入命令行的输出通过管道传递给该脚本、重定向文件到该脚本，在命令行中传递一个文件名或文件名列表给该脚本。Python 内置的 fileinput 模块让这个变得简单 终止程序并给出错误信息123import syssys.stderr.write('It failed!\\n')raise SystemExit(1) 解析命令行选项argparse 模块可被用来解析命令行选项, argparse 模块是标准库中最大的模块之一，拥有大量的配置选项。 运行时弹出密码输入提示你写了个脚本，运行时需要一个密码。此脚本是交互式的，因此不能将密码在脚本中硬编码，而是需要弹出一个密码输入提示，让用户自己输入.Python 的 getpass 模块正是你所需要的.123456789import getpassuser = getpass.getuser()passwd = getpass.getpass()if svc_login(user, passwd): # You must write svc_login() print('Yay!')else: print('Boo!') 注意在前面代码中 getpass.getuser() 不会弹出用户名的输入提示。它会根据该用户的 shell 环境或者会依据本地系统的密码库（支持 pwd 模块的平台）来使用当前用户的登录名，如果你想显示的弹出用户名输入提示，使用内置的 input 函数：user = input(&#39;Enter your username: &#39;)还有一点很重要，有些系统可能不支持 getpass() 方法隐藏输入密码。这种情况下，Python 会提前警告你这些问题（例如它会警告你说密码会以明文形式显示） 获取终端的大小使用 os.get terminal size() 函数来做到这一点 执行外部命令并获取它的输出使用 subprocess.check output() 函数,12import subprocessout_bytes = subprocess.check_output(['netstat','-a']) 这段代码执行一个指定的命令并将执行结果以一个字节字符串的形式返回。如果你需要文本形式返回，加一个解码步骤即可。123out_text = out_bytes.decode('utf-8')# 或者直接将输出解码out_text = subprocess.check_output(['netstat','-a']).decode('utf-8') 默认情况下，check output() 仅仅返回输入到标准输出的值。如果你需要同时收集标准输出和错误输出，使用 stderr 参数：out_bytes = subprocess.check_output([&#39;cmd&#39;,&#39;arg1&#39;,&#39;arg2&#39;], stderr=subprocess.STDOUT)如果你需要用一个超时机制来执行命令，使用 timeout 参数：1234try: out_bytes = subprocess.check_output(['cmd','arg1','arg2'], timeout=5)except subprocess.TimeoutExpired as e: ... 你想让命令被一个shell 执行，传递一个字符串参数，并设置参数 shell=True . 有时候你想要 Python 去执行一个复杂的 shell 命令的时候这个就很有用了，比如管道流、I/O 重定向和其他特性。例如：out_bytes = subprocess.check_output(&#39;grep python | wc &gt; out&#39;, shell=True)使用 check output() 函数是执行外部命令并获取其返回值的最简单方式,如果你需要对子进程做更复杂的交互，比如给它发送输入，你得采用另外一种方法。这时候可直接使用 subprocess.Popen 类。 复制或者移动文件和目录你想要复制或移动文件和目录，但是又不想调用 shell 命令,shutil 模块有很多便捷的函数可以复制文件和目录.123456789import shutil# Copy src to dst. (cp src dst)shutil.copy(src, dst)# Copy files, but preserve metadata (cp -p src dst)shutil.copy2(src, dst)# Copy directory tree (cp -R src dst)shutil.copytree(src, dst)# Move src to dst (mv src dst)shutil.move(src, dst) 如果源文件是一个符号链接，那么目标文件将会是符号链接指向的文件。如果你只想复制符号链接本身，那么需要指定关键字参数 follow symlinks,如果你想保留被复制目录中的符号链接shutil.copytree(src, dst, symlinks=True).copytree() 可以让你在复制过程中选择性的忽略某些文件或目录,1234def ignore_pyc_files(dirname, filenames): return [name in filenames if name.endswith('.pyc')]shutil.copytree(src, dst, ignore=ignore_pyc_files) 对于文件元数据信息，copy2() 这样的函数只能尽自己最大能力来保留它。访问时间、创建时间和权限这些基本信息会被保留，但是对于所有者、ACLs、资源 fork 和其他更深层次的文件元信息就说不准了，这个还得依赖于底层操作系统类型和用户所拥有的访问权限。你通常不会去使用 shutil.copytree() 函数来执行系统备份。当处理文件名的时候，最好使用 os.path 中的函数来确保最大的可移植性（特别是同时要适用于 Unix 和Windows）。 使用 copytree() 复制文件夹的一个棘手的问题是对于错误的处理。例如，在复制过程中，函数可能会碰到损坏的符号链接，因为权限无法访问文件的问题等等。为了解决这个问题，所有碰到的问题会被收集到一个列表中并打包为一个单独的异常，到了最后再抛出。12345678try: shutil.copytree(src, dst)except shutil.Error as e: for src, dst, msg in e.args[0]: # src is source name # dst is destination name # msg is error message from exception print(dst, src, msg) 如果你提供关键字参数 ignore dangling symlinks=True ，这时候 copytree() 会忽略掉无效符号链接。 创建和解压归档文件shutil 模块拥有两个函数—— make archive() 和 unpack archive() 可派上用场.1234&gt;&gt;&gt; import shutil&gt;&gt;&gt; shutil.unpack_archive('Python-3.3.0.tgz')&gt;&gt;&gt; shutil.make_archive('py33','zip','Python-3.3.0')'/Users/beazley/Downloads/py33.zip' make archive() 的第二个参数是期望的输出格式。可以使用get_archive_formats() 获取所有支持的归档格式列表。1234&gt;&gt;&gt; shutil.get_archive_formats()[('bztar', \"bzip2'ed tar-file\"), ('gztar', \"gzip'ed tar-file\"),('tar', 'uncompressed tar file'), ('zip', 'ZIP file')]&gt;&gt;&gt; Python 还有其他的模块可用来处理多种归档格式（比如 tarfile, zipfile, gzip, bz2）的底层细节。 通过文件名查找文件查找文件，可使用 os.walk() 函数，传一个顶级目录名给它.查找特定的文件名并答应所有符合条件的文件全路径1234567891011#!/usr/bin/env python3.3import osdef findfile(start, name): for relpath, dirs, files in os.walk(start): if name in files: full_path = os.path.join(start, relpath, name) print(os.path.normpath(os.path.abspath(full_path)))if __name__ == '__main__': findfile(sys.argv[1], sys.argv[2]) os.walk() 方法为我们遍历目录树，每次进入一个目录，它会返回一个三元组，包含相对于查找目录的相对路径，一个该目录下的目录名列表，以及那个目录下面的文件名列表。对于每个元组，只需检测一下目标文件名是否在文件列表中。如果是就使用os.path.join() 合并路径。为了避免奇怪的路径名比如 ././foo//bar ，使用了另外两个函数来修正结果。第一个是 os.path.abspath() , 它接受一个路径，可能是相对路径，最后返回绝对路径。第二个是 os.path.normpath() ，用来返回正常路径，可以解决双斜杆、对目录的多重引用的问题等。 读取配置文件读取普通.ini 格式的配置文件, configparser 模块能被用来读取配置文件, 使用 cfg.write() 方法将其写回到文件注意:配置文件中的名字是不区分大小写的. 但可以指定是否对大小写敏感(通过指定configparser示例对象的optionxform属性cf.optionxform = str).配置文件并不是从上而下的顺序执行,是一个整体被读取.如果碰到了变量替换，它实际上已经被替换完成了,在下面这个配置中，prefix 变量在使用它的变量之前后之后定义都是可以的12345[installation]library=%(prefix)s/libinclude=%(prefix)s/includebin=%(prefix)s/binprefix=/usr/local ConfigParser 有个容易被忽视的特性是它能一次读取多个配置文件然后合并成一个配置。 给简单脚本增加日志功能12345678910111213141516171819import loggingdef main(): # Configure the logging system logging.basicConfig(filename='app.log', level=logging.ERROR) # Variables (to make the calls that follow work) hostname = 'www.python.org' item = 'spam' filename = 'data.csv' mode = 'r' # Example logging calls (insert into your program) logging.critical('Host %s unknown', hostname) logging.error(\"Couldn't find %r\", item) logging.warning('Feature is deprecated') logging.info('Opening file %r, mode=%r', filename, mode) logging.debug('Got here')if __name__ == '__main__': main() 上面的日志配置都是硬编码到程序中的。如果你想使用配置文件，可以像下面这样修改 basicConfig() 调用：1234567import loggingimport logging.configdef main(): # Configure the logging system logging.config.fileConfig('logconfig.ini') ... 创建一个下面这样的文件，名字叫 logconfig.ini ,如果你想修改配置，可以直接编辑文件 logconfig.ini 即可。123456789101112131415161718192021[loggers]keys=root[handlers]keys=defaultHandler[formatters]keys=defaultFormatter[logger_root]level=INFOhandlers=defaultHandlerqualname=root[handler_defaultHandler]class=FileHandlerformatter=defaultFormatterargs=(&apos;app.log&apos;, &apos;a&apos;)[formatter_defaultFormatter]format=%(levelname)s:%(name)s:%(message)s 实现一个计时器记录程序执行多个任务所花费的时间1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import timeclass Timer: def __init__(self, func=time.perf_counter): self.elapsed = 0.0 self._func = func self._start = None def start(self): if self._start is not None: raise RuntimeError('Already started') self._start = self._func() def stop(self): if self._start is None: raise RuntimeError('Not started') end = self._func() self.elapsed += end - self._start self._start = None def reset(self): self.elapsed = 0.0 @property def running(self): return self._start is not None def __enter__(self): self.start() return self def __exit__(self, *args): self.stop()def countdown(n): while n &gt; 0: n -= 1# Use 1: Explicit start/stopt = Timer()t.start()countdown(1000000)t.stop()print(t.elapsed)# Use 2: As a context managerwith t: countdown(1000000) print(t.elapsed)with Timer() as t2: countdown(1000000) print(t2.elapsed) 限制内存和 CPU 的使用量对在 Unix 系统上面运行的程序设置内存或 CPU 的使用限制。resource 模块能同时执行这两个任务 启动一个 WEB 浏览器通过脚本启动浏览器并打开指定的 URL 网页,webbrowser 模块能被用来启动一个浏览器，并且与平台无关.123&gt;&gt;&gt; import webbrowser&gt;&gt;&gt; webbrowser.open('http://www.python.org')True 它会使用默认浏览器打开指定网页。如果你还想对网页打开方式做更多控制，还可以使用下面这些函数：打开一个新的浏览器窗口或者标签，只要浏览器支持就行。123456&gt;&gt;&gt; # Open the page in a new browser window&gt;&gt;&gt; webbrowser.open_new('http://www.python.org')True&gt;&gt;&gt; # Open the page in a new browser tab&gt;&gt;&gt; webbrowser.open_new_tab('http://www.python.org')True 如果你想指定浏览器类型，可以使用 webbrowser.get() 函数来指定某个特定浏览器。12345&gt;&gt;&gt; c = webbrowser.get('firefox')&gt;&gt;&gt; c.open('http://www.python.org')True&gt;&gt;&gt; c.open_new_tab('http://docs.python.org')True","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"cookbook之并发编程","slug":"ck-multi-program-2017-07-05","date":"2017-07-05T02:44:40.000Z","updated":"2017-09-08T03:51:39.259Z","comments":true,"path":"2017/07/05/ck-multi-program-2017-07-05/","link":"","permalink":"http://arvin-he.github.io/2017/07/05/ck-multi-program-2017-07-05/","excerpt":"","text":"启动与停止线程12345678910111213# Code to execute in an independent threadimport timedef countdown(n): while n &gt; 0: print('T-minus', n) n -= 1 time.sleep(5)# Create and launch a threadfrom threading import Threadt = Thread(target=countdown, args=(10,))t.start() 当你创建好一个线程对象后，该对象并不会立即执行，除非你调用它的 start()方法（当你调用 start() 方法时，它会调用你传递进来的函数，并把你传递进来的参数传递给该函数）。Python 中的线程会在一个单独的系统级线程中执行（比如说一个POSIX 线程或者一个 Windows 线程），这些线程将由操作系统来全权管理。线程一旦启动，将独立执行直到目标函数返回。你可以查询一个线程对象的状态，看它是否还在执行：1234if t.is_alive(): print('Still running')else: print('Completed') 你也可以将一个线程加入到当前线程，并等待它终止：t.join()Python 解释器在所有线程都终止后才继续执行代码剩余的部分。对于需要长时间运行的线程或者需要一直运行的后台任务，你应当考虑使用后台线程。123# 后台线程, 指定daemon为truet = Thread(target=countdown, args=(10,), daemon=True)t.start() 后台线程无法等待，不过，这些线程会在主线程终止时自动销毁。 判断线程是否已经启动使用 threading 库中的 Event 对象。Event 对象包含一个可由线程设置的信号标志，它允许线程等待某些事件的发生。在初始情况下，event 对象中的信号标志被设置为假。如果有线程等待一个 event 对象，而这个 event 对象的标志为假，那么这个线程将会被一直阻塞直至该标志为真。一个线程如果将一个 event 对象的信号标志设置为真，它将唤醒所有等待这个 event 对象的线程。如果一个线程等待一个已经被设置为真的 event 对象，那么它将忽略这个事件，继续执行。 event 对象最好单次使用，就是说，你创建一个 event 对象，让某个线程等待这个对象，一旦这个对象被设置为真，你就应该丢弃它。尽管可以通过 clear() 方法来重置 event 对象，但是很难确保安全地清理 event 对象并对它重新赋值。很可能会发生错过事件、死锁或者其他问题（特别是，你无法保证重置 event 对象的代码会在线程再次等待这个 event 对象之前执行）。如果一个线程需要不停地重复使用 event 对象，你最好使用 Condition 对象来代替。 event 对象的一个重要特点是当它被设置为真时会唤醒所有等待它的线程。如果你只想唤醒单个线程，最好是使用信号量或者 Condition 对象来替代。 编写涉及到大量的线程间同步问题的代码会让你痛不欲生。比较合适的方式是使用队列来进行线程间通信或者每个把线程当作一个 Actor，利用 Actor 模型来控制并发。 线程间通信从一个线程向另一个线程发送数据最安全的方式可能就是使用 queue 库中的队列了。创建一个被多个线程共享的 Queue 对象，这些线程通过使用 put() 和 get() 操作来向队列中添加或者删除元素。Queue 对象已经包含了必要的锁，所以你可以通过它在多个线程间多安全地共享数据。当使用队列时，协调生产者和消费者的关闭问题可能会有一些麻烦。一个通用的解决方法是在队列中放置一个特殊的值，当消费者读到这个值的时候，终止执行。123456789101112131415161718192021222324from queue import Queuefrom threading import Thread# Object that signals shutdown_sentinel = object()# A thread that produces datadef producer(out_q): while running: # Produce some data ... out_q.put(data) # Put the sentinel on the queue to indicate completion out_q.put(_sentinel)# A thread that consumes datadef consumer(in_q): while True: # Get some data data = in_q.get() # Check for termination if data is _sentinel: in_q.put(_sentinel) break # Process the data ... 本例中有一个特殊的地方：消费者在读到这个特殊值之后立即又把它放回到队列中，将之传递下去。这样，所有监听这个队列的消费者线程就可以全部关闭了。 创建一个线程安全的优先级队列1234567891011121314151617181920import heapqimport threadingclass PriorityQueue: def __init__(self): self._queue = [] self._count = 0 self._cv = threading.Condition() def put(self, item, priority): with self._cv: heapq.heappush(self._queue, (-priority, self._count, item)) self._count += 1 self._cv.notify() def get(self): with self._cv: while len(self._queue) == 0: self._cv.wait() return heapq.heappop(self._queue)[-1] 使用队列来进行线程间通信是一个单向、不确定的过程。通常情况下，你没有办法知道接收数据的线程是什么时候接收到的数据并开始工作的。使用线程队列有一个要注意的问题是，向队列中添加数据项时并不会复制此数据项，线程间通信实际上是在线程间传递对象引用。如果你担心对象的共享状态，那你最好只传递不可修改的数据结构（如：整型、字符串或者元组）或者一个对象的深拷贝。 给关键部分加锁使用 threading 库中的 Lock 对象1234567891011121314151617181920212223import threadingclass SharedCounter:'''A counter object that can be shared by multiple threads.'''def __init__(self, initial_value = 0): self._value = initial_value self._value_lock = threading.Lock()def incr(self,delta=1):'''Increment the counter with locking''' with self._value_lock: self._value += deltadef decr(self,delta=1):'''Decrement the counter with locking''' with self._value_lock: self._value -= delta Lock 对象和 with 语句块一起使用可以保证互斥执行，就是每次只有一个线程可以执行 with 语句包含的代码块。with 语句会在这个代码块执行前自动获取锁，在执行结束后自动释放锁。 线程调度本质上是不确定的，因此，在多线程程序中错误地使用锁机制可能会导致随机数据损坏或者其他的异常行为，我们称之为竞争条件。为了避免竞争条件，最好只在临界区（对临界资源进行操作的那部分代码）使用锁。 关于信号量信号量对象是一个建立在共享计数器基础上的同步原语。如果计数器不为 0，with 语句将计数器减 1，线程被允许执行。with 语句执行结束后，计数器加１。如果计数器为 0，线程将被阻塞，直到其他线程结束将计数器加 1。尽管你可以在程序中像标准锁一样使用信号量来做线程同步，但是这种方式并不被推荐，因为使用信号量为程序增加的复杂性会影响程序性能。相对于简单地作为锁使用，信号量更适用于那些需要在线程之间引入信号或者限制的程序。比如，你需要限制一段代码的并发访问量，你就可以像下面这样使用信号量完成：123456789from threading import Semaphoreimport urllib.request# At most, five threads allowed to run at once_fetch_url_sema = Semaphore(5)def fetch_url(url): with _fetch_url_sema: return urllib.request.urlopen(url) 防止死锁的加锁机制在多线程程序中，死锁问题很大一部分是由于线程同时获取多个锁造成的.举个例子：一个线程获取了第一个锁，然后在获取第二个锁的时候发生阻塞，那么这个线程就可能阻塞其他线程的执行，从而导致整个程序假死。解决死锁问题的一种方案是为程序中的每一个锁分配一个唯一的 id，然后只允许按照升序规则来使用多个锁，这个规则使用上下文管理器是非常容易实现的，示例如下：1234567891011121314151617181920212223242526272829import threadingfrom contextlib import contextmanager# Thread-local state to stored information on locks already acquired_local = threading.local()@contextmanagerdef acquire(*locks): # Sort locks by object identifier locks = sorted(locks, key=lambda x: id(x)) # Make sure lock order of previously acquired locks is not violated acquired = getattr(_local,'acquired',[]) if acquired and max(id(lock) for lock in acquired) &gt;= id(locks[0]): raise RuntimeError('Lock Order Violation') # Acquire all of the locks acquired.extend(locks) _local.acquired = acquired try: for lock in locks: lock.acquire() yield finally: # Release locks in reverse order of acquisition for lock in reversed(locks): lock.release() del acquired[-len(locks):] 12345678910111213141516171819202122232425262728293031323334353637import threadingx_lock = threading.Lock()y_lock = threading.Lock()def thread_1(): while True: with acquire(x_lock, y_lock): print('Thread-1')def thread_2(): while True: with acquire(y_lock, x_lock): print('Thread-2')t1 = threading.Thread(target=thread_1)t1.daemon = Truet1.start()t2 = threading.Thread(target=thread_2)t2.daemon = Truet2.start()# 下面的写法会导致线程崩溃,发生崩溃的原因在于，每个线程都记录着自己已经获取到的锁。 # acquire() 函数会检查之前已经获取的锁列表，由于锁是按照升序排列获取的，# 所以函数会认为之前已获取的锁的 id 必定小于新申请到的锁，这时就会触发异常。def thread_1(): while True: with acquire(x_lock): with acquire(y_lock): print('Thread-1')def thread_2(): while True: with acquire(y_lock): with acquire(x_lock): print('Thread-2') 死锁是每一个多线程程序都会面临的一个问题,根据经验来讲，尽可能保证每一个线程只能同时保持一个锁，这样程序就不会被死锁问题所困扰。一旦有线程同时申请多个锁，一切就不可预料了。 死锁的检测与恢复是一个几乎没有优雅的解决方案的扩展话题。一个比较常用的死锁检测与恢复的方案是引入看门狗计数器。当线程正常运行的时候会每隔一段时间重置计数器，在没有发生死锁的情况下，一切都正常进行。一旦发生死锁，由于无法重置计数器导致定时器超时，这时程序会通过重启自身恢复到正常状态。 避免死锁是另外一种解决死锁问题的方式，在进程获取锁的时候会严格按照对象 id升序排列获取，经过数学证明，这样保证程序不会进入死锁状态。避免死锁的主要思想是，单纯地按照对象 id 递增的顺序加锁不会产生循环依赖，而循环依赖是死锁的一个必要条件，从而避免程序进入死锁状态。 要特别注意到，为了避免死锁，所有的加锁操作必须使用 acquire() 函数。如果代码中的某部分绕过 acquire 函数直接申请锁，那么整个死锁避免机制就不起作用了。 创建一个线程池通常，你应该只在 I/O 处理相关代码中使用线程池,创建大的线程池的一个可能需要关注的问题是内存的使用. 实现消息发布/订阅模型要实现发布/订阅的消息通信模式，你通常要引入一个单独的“交换机”或“网关”对象作为所有消息的中介。也就是说，不直接将消息从一个任务发送到另一个，而是将其发送给交换机，然后由交换机将它发送给一个或多个被关联任务。","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"SVN命令使用","slug":"svncmd-2017-06-29","date":"2017-06-29T01:12:09.000Z","updated":"2017-09-08T03:51:40.183Z","comments":true,"path":"2017/06/29/svncmd-2017-06-29/","link":"","permalink":"http://arvin-he.github.io/2017/06/29/svncmd-2017-06-29/","excerpt":"","text":"简介版本管理基本上是多人协作开发中必不可少的工具，常用的版本管理工具有：svn和git。虽然都有可视化的工具帮助我们使用这些工具，然而当你用上命令行之后，我想你会选择抛弃这些可视化工具。下面是我整理的一些常用的svn命令。 SVN命令格式svn命令格式: svn &lt;subcommand&gt; [options] [args]subcommand 是子命令options 是选项,可选args 是参数,可选 SVN常用命令说明: 绝大部分svn命令都是在svn的工作目录下执行的, 只有少数几个例外. 1. 帮助和日志查看1234567svn help/h --查看帮助信息svn help &lt;subcommand&gt; --查看子命令的帮助信息svn --version -- 查看程序版本信息和RA模块svn --version --quiet --仅查看snv的版本号svn log --查看所有日志svn log -l 10 --查看最新10条日志svn info --show-item revision --查看工程的版本号 2. 检出/查看/导入1234567891011121314151617# 检出代码svn checkout/co [directory] project(本地目录名，可选)# 检出版本3svn checkout/co –revision/r 3 [directory] project(本地目录名，可选)# 查看检出版本信息(注意:要进入到svn的工作目录中去)svn info# 导入(import)项目,项目尚未创建，将本地的目录放到SVN版本仓库中svn import project(本地目录名) [directory] # 查看svn工作目录下的文件和目录svn list/ls# 查看svn最新修改的最新版本号svn info yourdir --show-item last-changed-revision 3. 更新/增加/修改/删除/重命名/拷贝/创建目录1234567891011121314151617181920# 更新仓库内容到本地svn update/up# 更新到版本3svn update/up –revision/r 3# 增加一些新的文件，纳入项目的版本控制svn add a.py b.py ...# 删除废弃的不用的文件svn delete/del/remove/rm a.py# 重命名文件svn move/mv a.py aa.py# 新增目录svn mkdir mydir# 拷贝svn copy/cp srcdir/a.py dstdir/a.py 4. 检查/查看差异1234567891011# 检查修改状态svn status/stat/st# 对比一个目录下的差异svn diff/di folder(本地目录名，可选，默认当前目录)# 对比具体文本差异svn diff/di –revision/r 3 index.html# 查看index.html版本3和版本4的差别svn diff/di –revision/r 3:4 index.html 5. 取消修改12345# 回滚整个目录的修改svn revert . -R/--recursive # 撤销某个文件的修改svn revert a.py 6. 分支操作12345678# 创建分支svn copy/cp svn://xxx.com/repo/trunk svn://xxx.com/repo/branches/test -m &apos;make branch test&apos;# 将工作目录转到分支svn switch/sw svn://xxx.com/repo/branches/test# 将工作目录转到主干svn switch/sw svn://xxx.com/repo/trunk 7. 合并一个分支到主干1234567891011# 查询出自创建分支以后分支上的所有修改，最下面的那个版本号就是我们要找的版本号cd branches/test(分支目录) svn log –stop-on-copy # 查询出自创建分支以后分支上的所有修改，最下面的那个版本号就是我们要找的版本号cd trunk(主干目录) svn -q –stop-on-copy svn://xxx.com/repo/branches/test(分支url) # 合并到主干cd trunk（主干目录） svn merge -r 11340(分支版本):HEAD svn://xxx.com/repo/branches/test(分支url) 8. 两个分支合并12345678910# 假设99是从旧主干引出，100打完tag，表示是新主干。合并最新代码的意思是：将新主干与旧主干比对，并添加到99中。这样99既有自己的新增的代码，也同时有最新线上的代码。cd 99_Branch svn merge svn://xxx.com/repo/tags/project_Old_BL svn://xxx.com/repo/tags/project_New_BL svn ci -m &apos;merge 100 trunk&apos;# 但是后来，其他人又向100提了代码，所以还需要将100分支（即打了tag后的100，打了tag前的100已是主干）合并至99中。合并办法：找出100分支，比对与新主干之间的差别，并添加到99中。这样99就有最新的全部代码了。cd 99_Branch svn merge svn://xxx.com/repo/tags/project_New_BL svn:/xxx.com/repo/branches/100_Branch svn ci -m &apos;merge 100 branch&apos; # 合并主干到分支svn merge -r LastRevisionMergedFromTrunkToBranch:HEAD svn:/xxx.com/repo/branches/99_Branch 9. 发布12# 给当前主干打个标签，并且这个标签不再改动了，但是实际上标签和分支是一个意思，你可以在标签上继续做改动，但这不推荐。svn copy/cp svn://xxx.com/repo/trunk svn://xxx.com/repo/tags/RB-1.0 10. 提交/导出代码12345# 提交代码svn commit/ci -m &apos;message&apos; # 导出代码, 不包含svn版本信息svn export svn://xxx.com/repo/branches/test folder(本地目录) 11. 解决冲突当发生冲突的时候，会提示如下信息： Conflict discovered in ‘index.html’.Select: (p) postpone, (df) diff-full, (e) edit,(mc) mine-conflict, (tc) theirs-conflict,(s) show all options:svn detects that theres a conflict here and require you to take some kind of action. 123456789101112131415161718192021222324252627如果你输入s选项，则会列出所有svn解决冲突的选项，如下所示：(e) edit - change merged file in an editor #直接进入编辑(df) diff-full -show all changes made to merged file #显示更改至目标文件的所有变化(r) resolved -accept merged version of file(dc) display-conflict -show all conflicts(ignoring merged version) #显示所有冲突(mc) mine-conflict -accept my version for all conflicts (same) #冲突以本地为准(tc) theirs-conflict -accept their version for all conflicts (same) #冲突以服务器为准(mf) mine-full -accept my version of entire file (even non-conflicts) #完全以本地为准(tf) theirs-full -accept their version of entire file (same) #完全以服务器为准(p) postpone -mark the conflict to be resolved later #标记冲突，稍后解决(l) launch -launch external tool to resolve conflict(s) show all -show this list一般我们会选择p稍后解决冲突，这样会生成三个文件：.mine, .rOLDREV, .rNEWREV。比如：index.html index.html.mine index.html.r1 index.html.r2 解决冲突方法大致有一下几种：1).手工修改index.html文件，然后将当前index.html作为最后提交的版本svn resolve index.html –-accept working 2).选择base版本，即index.html.rOLDREV作为最后提交的版本svn resolve index.html –-accept base 3).使用index.html.rNEWREV作为最后提交的版本svn resolve index.html –-accept theirs-full 4).使用index.html.mine作为最后提交的版本svn resolve index.html –-accept mine-full # 或者用下面这条命令也可以 svn resolve index.html –-accept theirs-conflict 12. 查看最近svn几次的版本号通过查看svn日志,然后用正则表达式匹配出版本号12345678910111213141516171819202122# 获取最近几次提交的版本号def get_commit_revisions(svn_path, commit_times=\"5\"): output = subprocess.check_output( [\"svn\", \"log\", svn_path, \"-v\", \"--limit\", commit_times]).decode(\"gbk\").strip() svn_logs = [item.strip() for item in output.splitlines() if item] # 存放最近几次提交的版本号 revisions_info = [] # 匹配版本号 pattern1 = re.compile(r'^r[0-9]* ') for msg in svn_logs: match1 = pattern1.match(msg) if match1: revision = match1.group().strip() revisions_info.append(revision[1:]) return revisions_info# 获取最新修改的版本号def get_base_revision(svn_path): revision = subprocess.check_output( [\"svn\", \"info\", svn_path, \"--show-item\", \"last-changed-revision\"]).decode(\"gbk\").strip() print(\"revision = &#123;&#125;\".format(revision)) return revision 参考 常用的svn和git命令","categories":[{"name":"工具","slug":"工具","permalink":"http://arvin-he.github.io/categories/工具/"}],"tags":[{"name":"SVN","slug":"SVN","permalink":"http://arvin-he.github.io/tags/SVN/"}]},{"title":"常用软件列表","slug":"softwarelist-2017-06-27","date":"2017-06-27T05:11:25.000Z","updated":"2017-09-08T03:51:40.179Z","comments":true,"path":"2017/06/27/softwarelist-2017-06-27/","link":"","permalink":"http://arvin-he.github.io/2017/06/27/softwarelist-2017-06-27/","excerpt":"","text":"Windows软件列表日常常用软件列表 办公 Office 下载 迅雷 浏览器 Chrome FireFox国际版 截图 ShareX 音视频 QQ影音 foobar2000 PotPlayer 压缩 7-Zip PDF SumatraPDF 输入法 QQ拼音 必应拼音 邮件客户端 Foxmail 文件搜索 Everything Listary 文件管理 Total Commander Clover 剪贴板 Ditto 强制解锁 unlocker 科学上网 Hosts lantern 开发常用软件列表 文本编辑器 VS Code Sublime Text3 Atom Notepad++ 命令行工具 cmder 编译工具 MSYS2 Mingw Mingw-w64 Cygwin CMake GYP Ninja Microsoft Build Tools 虚拟机 VirtualBox VmWare 代码阅读 Source Insight SlickEdit Understand UML建模 Enterprise Architect StarUML IDE Visual Studio Jetbrains全家桶 Qt Creator 版本控制 Git SVN 文件对比 BeyondCompare 数据库客户端 Navicat 网络抓包 wireshark Fiddler Linux软件列表","categories":[{"name":"工具","slug":"工具","permalink":"http://arvin-he.github.io/categories/工具/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://arvin-he.github.io/tags/Tools/"}]},{"title":"算法系列之插入排序","slug":"algo-insertsort-2017-06-23","date":"2017-06-23T05:22:52.000Z","updated":"2017-09-08T03:51:39.240Z","comments":true,"path":"2017/06/23/algo-insertsort-2017-06-23/","link":"","permalink":"http://arvin-he.github.io/2017/06/23/algo-insertsort-2017-06-23/","excerpt":"","text":"简介插入排序（Insertion Sort）的算法描述是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。插入排序在实现上，通常采用in-place排序（即只需用到O(1)的额外空间的排序），因而在从后向前扫描过程中，需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。 步骤：从第一个元素开始，该元素可以认为已经被排序取出下一个元素，在已经排序的元素序列中从后向前扫描如果该元素（已排序）大于新元素，将该元素移到下一位置重复步骤3，直到找到已排序的元素小于或者等于新元素的位置将新元素插入到该位置中重复步骤2 性能时间复杂度为O(N^2)，空间复杂度为O(1)。算法是稳定的，比较次数和交换次数都与初始序列有关。 优化直接插入排序每次往前插入时，是按顺序依次往前找，可在这里进行优化，往前找合适的插入位置时采用二分查找的方式，即折半插入。折半插入排序相对直接插入排序而言：平均性能更快，时间复杂度降至O(NlogN)，排序是稳定的，但排序的比较次数与初始序列无关，总是需要foor(log(i))+1次排序比较。 使用场景当数据基本有序时，采用插入排序可以明显减少数据交换和数据移动次数，进而提升排序效率。 Python实现123456789101112131415arr = [3, 5, 2, 6, 14, 9, 7, 1, 6]def insert_sort(arr): count = len(arr) for i in range(1, count): temp = arr[i] j = i-1 while j &gt;= 0: if arr[j] &gt; temp: arr[j], arr[j+1] = temp, arr[j] j -= 1 print(arr) return arrinsert_sort(arr) 运行结果: C++实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879#include &lt;iostream&gt;using namespace std;// 法1void insert_sort1(int arr[], int len)&#123; for (int i=1; i&lt;len; i++) &#123; if (arr[i] &lt; arr[i-1]) &#123; int temp = arr[i]; int j; for (j=i-1; j&gt;=0 &amp;&amp; arr[j]&gt;temp; j--) &#123; arr[j+1] = arr[j]; &#125; arr[j+1] = temp; &#125; &#125;&#125;// 法2, 似乎更好理解void insert_sort(int arr[], int len)&#123; for (int i=1; i&lt;len; i++) &#123; int temp = arr[i]; int j = i-1; while (j&gt;=0) &#123; if (arr[j] &gt; temp) &#123; arr[j+1] = arr[j]; arr[j] = temp; &#125; j -= 1; &#125; &#125;&#125;//改进的插入排序，往前插入比较时，进行二分查找void insert_binary_sort(int arr[], int len)&#123; for (int i=1; i&lt;len; i++) &#123; if (arr[i] &lt; arr[i-1]) &#123; int temp = arr[i]; int low = 0, high = i-1, mid; while (low&lt;=high) &#123; mid = (low+high)/2; if (temp &lt; arr[mid]) &#123; high = mid - 1; &#125; else &#123; low = mid + 1; &#125; &#125; for (int j = i; j&gt;low; j--) &#123; arr[j] = arr[j-1]; &#125; arr[low] = temp; &#125; &#125;&#125;int main(int argc, char *argv[])&#123; int arr[] = &#123;3, 5, 2, 6, 14, 9, 7, 1, 6&#125;; insert_sort(arr, 9); for (int i=0; i&lt;9; i++) cout &lt;&lt; arr[i] &lt;&lt;\" \"; return 0;&#125; 运行结果: 参考 https://segmentfault.com/a/1190000004994003","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://arvin-he.github.io/tags/算法/"}]},{"title":"设计模式之简单工厂模式","slug":"dp-simplefactory-2017-06-22","date":"2017-06-22T03:43:34.000Z","updated":"2017-09-08T03:51:39.433Z","comments":true,"path":"2017/06/22/dp-simplefactory-2017-06-22/","link":"","permalink":"http://arvin-he.github.io/2017/06/22/dp-simplefactory-2017-06-22/","excerpt":"","text":"简单工厂模式(Simple Factory Pattern)简单工厂模式(Simple Factory Pattern)：又称为静态工厂方法(Static Factory Method)模式，它属于类创建型模式。在简单工厂模式中，可以根据参数的不同返回不同类的实例。简单工厂模式专门定义一个类来负责创建其他类的实例，被创建的实例通常都具有共同的父类。 Python 实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# prodcut.pyclass Product(object): def __init__(self): pass def use(self): pass# productA.pyfrom product import Productclass ProductA(Product): product_type = \"A\" def __init__(self): super(ProductA, self).__init__() def use(self): print(\"prodcut A\")# productB.pyfrom product import Productclass ProductB(Product): product_type = \"B\" def __init__(self): super(ProductB, self).__init__() def use(self): print(\"product B\")# factory.pyfrom productA import ProductAfrom productB import ProductBdef createProduct(product_type): prod = None if product_type == \"A\": prod = ProductA() elif product_type == \"B\": prod = ProductB() return prod# main.pyfrom factory import createProductif __name__ == \"__main__\": prodA = createProduct(\"A\") prodB = createProduct(\"B\") prodA.use() prodB.use() 运行结果: C++ 实现123456789101112131415161718192021222324252627282930313233343536373839// 工厂类//factory.h#ifndef FACTORY_H#define FACTORY_H#include \"product.h\"#include &lt;string&gt;using namespace std;class Factory&#123;public: Factory(); virtual ~Factory(); static Product* createProduct(string proname);&#125;;#endif // FACTORY_H// factory.cpp#include \"factory.h\"#include \"concreateproducta.h\"#include \"concreateproductb.h\"Factory::Factory()&#123;&#125;Factory::~Factory()&#123;&#125;Product* Factory::createProduct(string proname)&#123; if (proname == \"A\") &#123; return new ConcreateProductA(); &#125; else if (proname == \"B\") &#123; return new ConcreateProductB(); &#125; return NULL;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889// 产品基类//product.h#ifndef PRODUCT_H#define PRODUCT_Hclass Product&#123;public: Product(); virtual ~Product(); virtual void Use() = 0;&#125;;#endif // PRODUCT_H//product.cpp#include \"product.h\"Product::Product()&#123;&#125;Product::~Product()&#123;&#125;//产品A派生类//concreateproducta.h #ifndef CONCREATEPRODUCTA_H#define CONCREATEPRODUCTA_H#include \"product.h\"class ConcreateProductA: public Product&#123;public: ConcreateProductA(); virtual ~ConcreateProductA(); virtual void Use();&#125;;#endif // CONCREATEPRODUCTA_H//concreateproducta.cpp#include \"concreateproducta.h\"#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;ConcreateProductA::ConcreateProductA()&#123;&#125;ConcreateProductA::~ConcreateProductA()&#123;&#125;void ConcreateProductA::Use()&#123; cout &lt;&lt; \"use product A\" &lt;&lt; endl;&#125;//产品B派生类//concreateproductb.h#ifndef CONCREATEPRODUCTB_H#define CONCREATEPRODUCTB_H#include \"product.h\"class ConcreateProductB: public Product&#123;public: ConcreateProductB(); virtual ~ConcreateProductB(); virtual void Use();&#125;;#endif // CONCREATEPRODUCTB_H//concreateproductb.cpp#include \"concreateproductb.h\"#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;ConcreateProductB::ConcreateProductB()&#123;&#125;ConcreateProductB::~ConcreateProductB()&#123;&#125;void ConcreateProductB::Use()&#123; cout&lt;&lt; \"use product B\"&lt;&lt;endl;&#125; 1234567891011121314151617// main.cpp#include &lt;iostream&gt;#include \"factory.h\"#include \"product.h\"using namespace std;int main(int argc, char *argv[])&#123; Product* prodA = Factory::createProduct(\"A\"); Product* prodB = Factory::createProduct(\"B\"); prodA-&gt;Use(); prodB-&gt;Use(); delete prodA; delete prodB; return 0;&#125; 运行结果: 模式分析 将对象的创建和对象本身业务处理分离可以降低系统的耦合度，使得两者修改起来都相对容易。 在调用工厂类的工厂方法时，由于工厂方法是静态方法，使用起来很方便，可通过类名直接调用，而且只需要传入一个简单的参数即可，在实际开发中，还可以在调用时将所传入的参数保存在XML等格式的配置文件中，修改参数时无须修改任何源代码。 简单工厂模式最大的问题在于工厂类的职责相对过重，增加新的产品需要修改工厂类的判断逻辑，这一点与开闭原则是相违背的。 简单工厂模式的要点在于：当你需要什么，只需要传入一个正确的参数，就可以获取你所需要的对象，而无须知道其创建细节。 简单工厂模式的优点 工厂类含有必要的判断逻辑，可以决定在什么时候创建哪一个产品类的实例，客户端可以免除直接创建产品对象的责任，而仅仅“消费”产品；简单工厂模式通过这种做法实现了对责任的分割，它提供了专门的工厂类用于创建对象。 客户端无须知道所创建的具体产品类的类名，只需要知道具体产品类所对应的参数即可，对于一些复杂的类名，通过简单工厂模式可以减少使用者的记忆量。 通过引入配置文件，可以在不修改任何客户端代码的情况下更换和增加新的具体产品类，在一定程度上提高了系统的灵活性。 简单工厂模式的缺点 由于工厂类集中了所有产品创建逻辑，一旦不能正常工作，整个系统都要受到影响。 使用简单工厂模式将会增加系统中类的个数，在一定程序上增加了系统的复杂度和理解难度。 系统扩展困难，一旦添加新产品就不得不修改工厂逻辑，在产品类型较多时，有可能造成工厂逻辑过于复杂，不利于系统的扩展和维护。 简单工厂模式由于使用了静态工厂方法，造成工厂角色无法形成基于继承的等级结构。 适用环境在以下情况下可以使用简单工厂模式： 工厂类负责创建的对象比较少：由于创建的对象较少，不会造成工厂方法中的业务逻辑太过复杂。 客户端只知道传入工厂类的参数，对于如何创建对象不关心：客户端既不需要关心创建细节，甚至连类名都不需要记住，只需要知道类型所对应的参数。 总结 简单工厂模式包含三个角色：工厂角色负责实现创建所有实例的内部逻辑；抽象产品角色是所创建的所有对象的父类，负责描述所有实例所共有的公共接口；具体产品角色是创建目标，所有创建的对象都充当这个角色的某个具体类的实例。 简单工厂模式的要点在于：当你需要什么，只需要传入一个正确的参数，就可以获取你所需要的对象，而无须知道其创建细节。 参考 图说设计模式","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://arvin-he.github.io/tags/设计模式/"}]},{"title":"算法系列之冒泡排序","slug":"algo-bubblesort-2017-06-21","date":"2017-06-21T06:12:42.000Z","updated":"2017-09-08T03:51:39.228Z","comments":true,"path":"2017/06/21/algo-bubblesort-2017-06-21/","link":"","permalink":"http://arvin-he.github.io/2017/06/21/algo-bubblesort-2017-06-21/","excerpt":"","text":"原理冒泡排序（Bubble Sort）是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端。 步骤：比较相邻的元素。如果第一个比第二个大，就交换他们两个。对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。在这一点，最后的元素应该会是最大的数。针对所有的元素重复以上的步骤，除了最后一个。持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。 性能时间复杂度为O(N^2)，空间复杂度为O(1)。排序是稳定的，排序比较次数与初始序列无关，但交换次数与初始序列有关。 优化若初始序列就是排序好的，对于冒泡排序仍然还要比较O(N^2)次，但无交换次数。可根据这个进行优化，设置一个flag，当在一趟序列中没有发生交换，则该序列已排序好，但优化后排序的时间复杂度没有发生量级的改变。 Python实现1234567891011arr = [3, 5, 2, 6, 14, 9, 7, 1, 6]def bubble_sort(raw_list): count = len(arr) for i in range(0, count): for j in range(i+1, count): if arr[i] &gt; arr[j]: arr[i], arr[j] = arr[j], arr[i] #temp = arr[j] #arr[j] = arr[i] #arr[i] = temp return arr 运行结果: C++实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include &lt;iostream&gt;using namespace std;void bubble_sort(int arr[], int len)&#123; for (int i=0; i&lt;len; i++) &#123; for (int j=i+1; j&lt;len; j++) &#123; if (arr[i] &gt; arr[j]) &#123; int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp; &#125; &#125; &#125;&#125;// 改进的冒泡排序//每次从后往前冒一个最小值，且每次能确定一个数在序列中的最终位置void bubble_sort(int arr[], int len)&#123; //比较n-1次 for (int i = 0; i &lt; len-1; i++) &#123; bool exchange = true; // 冒泡的改进，若在一趟中没有发生逆序，则该序列已有序 for (int j = len-1; j &gt;i; j--) // 每次从后边冒出一个最小值 &#123; if (arr[j] &lt; arr[j - 1]) // 发生逆序，则交换 &#123; swap(arr[j], arr[j - 1]); exchange = false; &#125; &#125; if (exchange)&#123; return; &#125; &#125;&#125;int main(int argc, char *argv[])&#123; int arr[] = &#123;3, 5, 2, 6, 14, 9, 7, 1, 6&#125;; bubble_sort(arr, 9); for (int i=0; i&lt;9; i++) cout &lt;&lt; arr[i] &lt;&lt;\" \"; return 0;&#125; 运行结果: 参考 https://segmentfault.com/a/1190000004994003","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://arvin-he.github.io/tags/算法/"}]},{"title":"Python之yield与yield from理解","slug":"python-yield-2017-06-20","date":"2017-06-20T07:24:39.000Z","updated":"2017-09-08T03:51:40.173Z","comments":true,"path":"2017/06/20/python-yield-2017-06-20/","link":"","permalink":"http://arvin-he.github.io/2017/06/20/python-yield-2017-06-20/","excerpt":"","text":"yield为了理解什么是 yield, 你必须理解什么是生成器(generator)。在函数中使用yield关键字，函数就变成了一个generator。函数里有了yield后，执行到yield就会停住，当需要再往下算时才会再往下算。所以生成器函数即使是有无限循环也没关系，它需要算到多少就会算多少，不需要就不往下算。 yield fromyield from &lt;expr&gt; 其中&lt;expr&gt;是一个可迭代的表达式，自动调用 iter()，获取迭代器。所以要求&lt;expr&gt;是可迭代对象。此外, yield from是可以实现嵌套生成器的使用. yield from 包含几个概念： 委派生成器: 包含yield from表达式的生成器函数 子生成器: 从yield from部分获取的生成器。 调用方: 调用委派生成器的(调用方)代码 yield from 可用于简化for循环中的yield表达式。 yield from 是 Python3.3 后新加的语言结构。和其他语言的await关键字类似，它表示：在生成器 gen 中使用 yield from subgen()时，subgen 会获得控制权，把产出的值传个gen的调用方，即调用方可以直接控制subgen。于此同时，gen会阻塞，等待subgen执行完毕, 然后在接着运行gen.123456789In [1]: def gen(): ...: for c in 'AB': ...: yield c ...: for i in range(1, 3): ...: yield i ...:In [2]: list(gen())Out[2]: ['A', 'B', 1, 2] 改写为:1234567In [3]: def gen(): ...: yield from 'AB' ...: yield from range(1, 3) ...:In [4]: list(gen())Out[4]: ['A', 'B', 1, 2] 下面看一个cookbook的例子:1234567891011121314151617181920# Example of flattening a nested sequence using subgeneratorsfrom collections import Iterabledef flatten(items, ignore_types=(str, bytes)): for x in items: if isinstance(x, Iterable) and not isinstance(x, ignore_types): yield from flatten(x) # 这里递归调用，如果x是可迭代对象，继续分解 else: yield xitems = [1, 2, [3, 4, [5, 6], 7], 8]# Produces 1 2 3 4 5 6 7 8for x in flatten(items): print(x)items = ['Dave', 'Paula', ['Thomas', 'Lewis']]for x in flatten(items): print(x) yield from 的主要功能是打开双向通道，把最外层的调用方与最内层的子生成器连接起来，使两者可以直接发送和产出值，还可以直接传入异常，而不用在中间的协程添加异常处理的代码。 委派生成器在 yield from 表达式处暂停时，调用方可以直接把数据发给子生成器，子生成器再把产出的值发送给调用方。子生成器返回之后，解释器会抛出StopIteration异常，并把返回值附加到异常对象上，指示委派生成器恢复。 此外，当迭代器是另一个生成器时，允许子生成器执行return语句返回一个值，该值将成为yield from表达式的值。 PEP380 分6点说明了yield from 的行为: 子生成器产出的值都直接传给委派生成器的调用方 使用send() 方法发给委派生成器的值都直接传给迭代器。如果发送的值是None，那么会调用子迭代器的 __next__()方法。如果发送的值不是None，那么会调用迭代器的send()方法。如果调用的方法抛出StopIteration异常，那么委派生成器恢复运行。任何其他异常都传给委派生成器。 引发委托生成器的GeneratorExit以外的异常传递给迭代器的throw（）方法。如果调用throw()方法时抛出 StopIteration 异常，委派生成器恢复运行。StopIteration之外的异常会向上传给委派生成器。 如果把 GeneratorExit 异常传入委派生成器，或者在委派生成器上调用close() 方法，那么在迭代器上调用close() 方法，如果迭代器有的话。如果调用close() 方法导致异常抛出，那么异常会向上传给委派生成器；否则，委派生成器抛出 GeneratorExit 异常。 yield from表达式的值是迭代器终止时迭代器抛出StopIteration异常的第一个参数。 生成器退出时，生成器（或子生成器）中的return expr 表达式会触发 StopIteration(expr) 异常抛出。 参考 pep-0380","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Unix/Linux命令参考","slug":"linux-cheatsheet-2017-06-19","date":"2017-06-19T08:22:46.000Z","updated":"2017-09-08T03:51:39.760Z","comments":true,"path":"2017/06/19/linux-cheatsheet-2017-06-19/","link":"","permalink":"http://arvin-he.github.io/2017/06/19/linux-cheatsheet-2017-06-19/","excerpt":"","text":"文件命令ls – 列出目录ls -al – 使用格式化列出隐藏文件cd dir - 更改目录到 dircd – 更改到 home 目录pwd – 显示当前目录mkdir dir – 创建目录 dirrm file – 删除 filerm -r dir – 删除目录 dirrm -f file – 强制删除 filerm -rf dir – 强制删除目录 dir *cp file1 file2 – 将 file1 复制到 file2cp -r dir1 dir2 – 将 dir1 复制到 dir2; 如果 dir2 不存在则创建它mv file1 file2 – 将 file1 重命名或移动到 file2; 如果file2 是一个存在的目录则将 file1 移动到目录 file2 中ln -s file link – 创建 file 的符号连接 linktouch file – 创建 filecat &gt; file – 将标准输入添加到 filemore file – 查看 file 的内容head file – 查看 file 的前 10 行tail file – 查看 file 的后 10 行tail -f file – 从后 10 行开始查看 file 的内容 进程管理ps – 显示当前的活动进程top – 显示所有正在运行的进程kill pid – 杀掉进程 id pidkillall proc – 杀掉所有名为 proc 的进程 *bg – 列出已停止或后台的作业fg – 将最近的作业带到前台fg n – 将作业 n 带到前台 文件权限chmod octal file – 更改 file 的权限● 4 – 读 (r)● 2 – 写 (w)● 1 – 执行 (x)示例:chmod 777 – 为所有用户添加读、写、执行权限chmod 755 – 为所有者添加 rwx 权限, 为组和其他用户添加rx 权限更多选项参阅 man chmod. SSHssh user@host – 以 user 用户身份连接到 hostssh -p port user@host – 在端口 port 以 user 用户身份连接到 hostssh-copy-id user@host – 将密钥添加到 host 以实现无密码登录 搜索grep pattern files – 搜索 files 中匹配 pattern 的内容grep -r pattern dir – 递归搜索 dir 中匹配 pattern 的内容command | grep pattern – 搜索 command 输出中匹配pattern 的内容 系统信息date – 显示当前日期和时间cal – 显示当月的日历uptime – 显示系统从开机到现在所运行的时间w – 显示登录的用户whoami – 查看你的当前用户名finger user – 显示 user 的相关信息uname -a – 显示内核信息cat /proc/cpuinfo – 查看 cpu 信息cat /proc/meminfo – 查看内存信息man command – 显示 command 的说明手册df – 显示磁盘占用情况du – 显示目录空间占用情况free – 显示内存及交换区占用情况 压缩tar cf file.tar files – 创建包含 files 的 tar 文件file.tartar xf file.tar – 从 file.tar 提取文件tar czf file.tar.gz files – 使用 Gzip 压缩创建tar 文件tar xzf file.tar.gz – 使用 Gzip 提取 tar 文件tar cjf file.tar.bz2 – 使用 Bzip2 压缩创建 tar 文件tar xjf file.tar.bz2 – 使用 Bzip2 提取 tar 文件gzip file – 压缩 file 并重命名为 file.gzgzip -d file.gz – 将 file.gz 解压缩为 file 网络ping host – ping host 并输出结果whois domain – 获取 domain 的 whois 信息dig domain – 获取 domain 的 DNS 信息dig -x host – 逆向查询 hostwget file – 下载 filewget -c file – 断点续传 安装从源代码安装:./configuremakemake installdpkg -i pkg.deb – 安装包 (Debian)rpm -Uvh pkg.rpm – 安装包 (RPM) 快捷键Ctrl+C – 停止当前命令Ctrl+Z – 停止当前命令，并使用 fg 恢复Ctrl+D – 注销当前会话，与 exit 相似Ctrl+W – 删除当前行中的字Ctrl+U – 删除整行!! - 重复上次的命令exit – 注销当前会话 小心使用。 补充 tree命令windows和linux都有tree命令，主要功能是创建文件列表，将所有文件以树的形式列出来.windows下的tree功能比较弱，只有两个参数，/F 是递归显示每个文件夹的名称；如tree /F . 显示当前目录文件树形结构/A 是使用ASCII字符而不是扩展字符","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://arvin-he.github.io/tags/Linux/"}]},{"title":"怎样避免陷入无止境地看教程的陷阱","slug":"learn-minds-2017-06-19","date":"2017-06-19T07:23:53.000Z","updated":"2017-11-27T01:06:11.173Z","comments":true,"path":"2017/06/19/learn-minds-2017-06-19/","link":"","permalink":"http://arvin-he.github.io/2017/06/19/learn-minds-2017-06-19/","excerpt":"","text":"我们可能都曾遇到过这样的情况：学习编程的时候，一个教程接着一个教程地学，但是不清楚自己学到什么了程度。然后你开始自我怀疑：“这太难了。”或“也许编程不适合我。”我知道你懂这种感受。 我自己在最近就切身体会到了这种感觉。我本身算是个比较自信的PHP攻城狮，打算学习Python—尤其是Django。 我搜索了一些相关资料并找到了看似完美的教程，足够复杂富有挑战，又足够简单不至于击垮我的兴趣。 作为一个基于项目实战的教程，我对完成后的项目相当喜欢。我认为将它添加到我的成长作品集会是很酷的一件事。 跟着教程做到接近80%的时候，我突然产生了一股自我怀疑。我已经看了视频教程并一个个字敲了所有的代码，我已经有了一个简单的项目可以展示给他人，可为什么我感觉反倒没有刚开始那样好？ 跟着这个教程又花了几个星期的晚上，我有了一个漂亮的完工项目。即便如此，我还是觉得在没有指南的情况下我是不具备重新实现这个项目的技能的。所以，将它放到我的作品集里真的好吗？ 将一个在外观和功能上与别人的一模一样的项目展示出来真的说服力吗？而且代码和GitHub教程上的一模一样。 如你所见，跟着教程学习，接触到新的技能，是很棒的。但是只跟着教程学习，你无法掌握作为一名合格的初级工程师所需的更多技能，我指的是： 设计和组织项目 了解哪些工具对于一个具体项目是最佳选择 尝试通过搜索来解决遇到的一些问题 解决在实际项目开发中无可避免的一些问题 教程是快速上手的好办法 为了避免大家误解，交代一下相关背景，我是一个29岁的初级码农，目前在一家软件开发公司工作。我在一年前转行进入编程行业， 很多新手码农一样，在开始学习高级教程之前我先完成基础的教程。我主要是学习PHP（因为在我开始学习编程的时候听说PHP是全世界最好的语言），我很快就熟悉了语法和一些基本用法。 大概花了9个月的时间，我完成了足够多的教程，有了足够的理解，也有了足够的动力去说服一家软件开发公司给我提供一份工作。（你可以通过这篇文章了解到我是如何说服老板给我工作机会的 take a chance on me and pay me to learn to code.） 让我能在如此短的时间内得到一份编程工作，得益于我创建的可以展示的实际项目。值得注意的是，是我自己的项目，而不是跟着教程复制粘贴的那种。 教程也只能帮你到这里了 之后你需要开发实际项目 不要理解错了我的意思–教程是很棒的，尤其是在新手学习基础的情况下。当然，教程的质量是良莠不齐的，解释的详细程度也大相径庭。但是一个教程接着一个教程的学习是无法让你成为一个专业的开发者的。 你必须开发自己的项目。一旦你对你选择的语言的语法和基本的实现有了一定的认识，你就可以开始开发属于自己的东西了，不再是“手把手”式的学习。 当我向别人说这些的时候，通常得到的回应是：“开发什么呢？我一点想法都没有。” 额，实际上没人指望你创造出什么牛逼的东西来，而且你应该不具备这样的技能去做这样的事情，就算你有想法。 这里有一份清单，列出了你可以开发的500个项目，有例子: http://rosettacode.org/wiki/Category:Programming_Tasks 。 你也可以开发类似博客这样的项目。是的，有无数个教程都是基于构建博客的。你可能还会复制、粘贴一些代码，这也许不是一个令人印象深刻的项目，但是。。。 开发属于你自己的博客。坐下来，在开始之前，制定好每一步的计划和特色功能。搜索并选择一门你想用的语言和框架。了解怎么安装需要的工具，构建开发环境，通过包管理工具安装所需的依赖等。当你卡在某个环节时，Google或者通过可靠的技术社区去解决你遇到的一些问题。 通过这样的方式你的学习效率可能比跟着任何一个教程学习都快很多,你自己开发的项目的在你作品中的价值也远远大于其他几十个跟着教程做的项目的总和。 取决于你选择的项目的复杂程度，在你找工作的时候你的个人作品集里可能就不再需要其他的东西了，只是可能。你的代码可能不是非常出色，但这是你自己写的代码。你可以解释每一行代码的意义，你可以解释你是如何实现的和为什么这样做。 同时，你也证明了你可以管理一个项目，单独完成，学习需要的新技能，并递交最终完成的产品。对于潜在的雇主而言，你现在拥有了几项有价值的技能。 如果花12到18月的时间去学习，还没有找到一份工作，或者说你总感觉实际尚未成熟，别灰心，不要放弃。不要开始有这样的想法：你需要花动辄上万的学费去参加什么牛逼的培训班。只需要开始开发你自己的东西你就会惊讶于你进步的速度！ 通过freeCodeCamp找到工作的人数在不断增长可能也是因为它基于项目的学习方式。freeCodeCamp是一个不错的学习平台，不过本文就不替原作者多做宣传了。本文翻译自 https://medium.freecodecamp.com/how-to-dig-yourself-out-of-the-coding-tutorial-rut-7d3b2232f234","categories":[{"name":"随笔","slug":"随笔","permalink":"http://arvin-he.github.io/categories/随笔/"}],"tags":[{"name":"方法","slug":"方法","permalink":"http://arvin-he.github.io/tags/方法/"}]},{"title":"JavaScript笔记(一)","slug":"js-notes1-2017-06-17","date":"2017-06-17T07:39:12.000Z","updated":"2017-12-04T01:35:25.909Z","comments":true,"path":"2017/06/17/js-notes1-2017-06-17/","link":"","permalink":"http://arvin-he.github.io/2017/06/17/js-notes1-2017-06-17/","excerpt":"","text":"Number类型JavaScript不区分整数和浮点数，统一用Number表示，以下是特殊的Number类型：123456// 科学计数法表示1.2345x1000，等同于1234.5-991.2345e3; // NaN表示Not a Number，当无法计算结果时用NaN表示NaN; // Infinity表示无限大，当数值超过了JavaScript的Number所能表示的最大值时，就表示为InfinityInfinity; 关于判断相等JavaScript有两种比较相等运算符：第一种是==比较，它会自动转换数据类型再比较，很多时候，会得到非常诡异的结果；第二种是===比较，它不会自动转换数据类型，如果数据类型不一致，返回false，如果一致，再比较。由于JavaScript这个设计缺陷，不要使用==比较，始终坚持使用===比较。 另一个例外是NaN这个特殊的Number与所有其他值都不相等，包括它自己：NaN === NaN; // false,唯一能判断NaN的方法是通过isNaN()函数：isNaN(NaN); // true. 最后要注意浮点数的相等比较：1 / 3 === (1 - 2 / 3); // false这不是JavaScript的设计缺陷。浮点数在运算过程中会产生误差，因为计算机无法精确表示无限循环小数。要比较两个浮点数是否相等，只能计算它们之差的绝对值，看是否小于某个阈值：Math.abs(1 / 3 - (1 - 2 / 3)) &lt; 0.0000001; // true null和undefinednull表示一个“空”的值，它和0以及空字符串’’不同，0是一个数值，’’表示长度为0的字符串，而null表示“空”。在其他语言中，也有类似的表示，如Python中的None。 undefined，它表示“未定义”。JavaScript的设计者希望用null表示一个空的值，而undefined表示值未定义。事实证明，区分两者的意义不大。大多数情况下，我们都应该用null。undefined仅仅在判断函数参数是否传递的情况下有用。 数组数组是一组按顺序排列的集合，集合的每个值称为元素。JavaScript的数组可以包括任意数据类型。如:[1, 2, 3.14, &#39;Hello&#39;, null, true];另一种创建数组的方法是通过Array()函数实现: new Array(1, 2, 3); // 创建了数组[1, 2, 3],出于代码的可读性考虑，强烈建议直接使用[]。注意: 直接给Array的length赋一个新的值会导致Array大小的变化 如果通过索引赋值时，索引超过了范围，同样会引起Array大小的变化：大多数其他编程语言不允许直接改变数组的大小，越界访问索引会报错。然而，JavaScript的Array却不会有任何错误。在编写代码时，不建议直接修改Array的大小，访问索引时要确保索引不会越界。123456789var arr = [1, 2, 3];arr.length; // 3arr.length = 6;arr; // arr变为[1, 2, 3, undefined, undefined, undefined]arr.length = 2;arr; // arr变为[1, 2]var arr = [1, 2, 3];arr[5] = 'x';arr; // arr变为[1, 2, 3, undefined, undefined, 'x'] 对象JavaScript的对象是一组由键-值组成的无序集合，例如：12345678var person = &#123; name: 'Bob', age: 20, tags: ['js', 'web', 'mobile'], city: 'Beijing', hasCar: true, zipcode: null&#125;; JavaScript对象的键都是字符串类型，值可以是任意数据类型。相当于python中的字典. 循环遍历(for … of/for … in)Array可以采用下标循环，遍历Map和Set就无法使用下标.为了统一集合类型，ES6标准引入了新的iterable类型，Array、Map和Set都属于iterable类型。具有iterable类型的集合可以通过新的for … of循环来遍历。 for … of循环和for … in循环有何区别？for … in循环由于历史遗留问题，它遍历的实际上是对象的属性名称。一个Array数组实际上也是一个对象，它的每个元素的索引被视为一个属性。当我们手动给Array对象添加了额外的属性后，for … in循环将带来意想不到的意外效果：12345var a = ['A', 'B', 'C'];a.name = 'Hello';for (var x in a) &#123; alert(x); // '0', '1', '2', 'name'&#125; for … in循环将把name包括在内，但Array的length属性却不包括在内。 for … of循环则完全修复了这些问题，它只循环集合本身的元素.然而，更好的方式是直接使用iterable内置的forEach方法，它接收一个函数，每次迭代就自动回调该函数。以Array为例：1234567var a = ['A', 'B', 'C'];a.forEach(function (element, index, array) &#123; // element: 指向当前元素的值 // index: 指向当前索引 // array: 指向Array对象本身 alert(element);&#125;); set和MapSet与Array类似，但Set没有索引，因此回调函数的前两个参数都是元素本身：1234var s = new Set(['A', 'B', 'C']);s.forEach(function (element, sameElement, set) &#123; alert(element);&#125;); Map的回调函数参数依次为value、key和map本身：1234var m = new Map([[1, 'x'], [2, 'y'], [3, 'z']]);m.forEach(function (value, key, map) &#123; alert(value);&#125;); 如果对某些参数不感兴趣，由于JavaScript的函数调用不要求参数必须一致，因此可以忽略它们。例如，只需要获得Array的element：1234var a = ['A', 'B', 'C'];a.forEach(function (element) &#123; alert(element);&#125;); 函数定义1234567function abs(x) &#123; if (x &gt;= 0) &#123; return x; &#125; else &#123; return -x; &#125;&#125; 请注意，函数体内部的语句在执行时，一旦执行到return时，函数就执行完毕，并将结果返回.如果没有return语句，函数执行完毕后也会返回结果，只是结果为undefined,就像python中不写return,默认return None。 匿名函数(lambda表达式)1234567 // 六种语言中的简单函数示例function (a) &#123; return a &gt; 0; &#125; // JS[](int a) &#123; return a &gt; 0; &#125; // C++(lambda (a) (&gt; a 0)) ;; Lisplambda a: a &gt; 0 # Pythona =&gt; a &gt; 0 // C#a -&gt; a &gt; 0 // Java 关于argumentsJavaScript有一个关键字arguments，它只在函数内部起作用，并且永远指向当前函数的调用者传入的所有参数。利用arguments，你可以获得调用者传入的所有参数。也就是说，即使函数不定义任何参数，还是可以拿到参数的值： 箭头函数(=&gt;)ES6中引入了一种编写函数的新语法, 允许使用“箭头”（=&gt;）定义函数。12345678910111213141516171819202122var f = v =&gt; v;//上面的箭头函数等同于：var f = function(v) &#123; return v;&#125;;//如果箭头函数不需要参数或需要多个参数，就使用一个圆括号代表参数部分。var f = () =&gt; 5;// 等同于var f = function () &#123; return 5 &#125;;var sum = (num1, num2) =&gt; num1 + num2;// 等同于var sum = function(num1, num2) &#123; return num1 + num2;&#125;;// 如果箭头函数的代码块部分多于一条语句，就要使用大括号将它们括起来，并且使用return语句返回。var sum = (num1, num2) =&gt; &#123; return num1 + num2; &#125;// 由于大括号被解释为代码块，所以如果箭头函数直接返回一个对象，必须在对象外面加上括号，否则会报错。// 报错let getTempItem = id =&gt; &#123; id: id, name: \"Temp\" &#125;;// 不报错let getTempItem = id =&gt; (&#123; id: id, name: \"Temp\" &#125;); 当需要只有一个参数的简单函数时，可以使用新标准中的箭头函数，它的语法：标识符=&gt;表达式。你无需输入function和return，一些小括号、大括号以及分号也可以省略。如果要写一个接受多重参数（也可能没有参数，或者是不定参数、默认参数、参数解构）的函数，则需要用小括号包裹参数list。 小提示：当使用箭头函数创建普通对象时，你总是需要将对象包裹在小括号里。 普通function函数和箭头函数的行为有一个微妙的区别:箭头函数没有它自己的this值，箭头函数内的this值继承自外围作用域。 箭头函数的一个用处是简化回调函数。 箭头函数有几个使用注意点:（1）函数体内的this对象，就是定义时所在的对象，而不是使用时所在的对象。（2）不可以当作构造函数，也就是说，不可以使用new命令，否则会抛出一个错误。（3）不可以使用arguments对象，该对象在函数体内不存在。如果要用，可以用 rest 参数代替。（4）不可以使用yield命令，因此箭头函数不能用作 Generator 函数。上面四点中，第一点尤其值得注意。this对象的指向是可变的，但是在箭头函数中，它是固定的。","categories":[{"name":"js","slug":"js","permalink":"http://arvin-he.github.io/categories/js/"}],"tags":[{"name":"js","slug":"js","permalink":"http://arvin-he.github.io/tags/js/"}]},{"title":"设计模式之单例模式","slug":"dp-singleton-2017-06-16","date":"2017-06-16T09:21:49.000Z","updated":"2017-09-08T03:51:39.439Z","comments":true,"path":"2017/06/16/dp-singleton-2017-06-16/","link":"","permalink":"http://arvin-he.github.io/2017/06/16/dp-singleton-2017-06-16/","excerpt":"","text":"单例模式单例模式（Singleton Pattern）是一种常用的软件设计模式，该模式的主要目的是确保某一个类只有一个实例存在。单例模式的要点有三个： 某个类只能有一个实例； 它必须自行创建这个实例； 它必须自行向整个系统提供这个实例。单例模式是一种对象创建型模式。单例模式又名单件模式或单态模式。 python中的单例模式在python中可以有多种方法实现单例模式: 使用模块 使用__new__ 使用装饰器(decorator) 使用元类 使用模块其实，Python 的模块就是天然的单例模式，因为模块在第一次导入时，会生成 .pyc 文件，当第二次导入时，就会直接加载 .pyc 文件，而不会再次执行模块代码。因此，我们只需把相关的函数和数据定义在一个模块中，就可以获得一个单例对象了。如果我们真的想要一个单例类，可以考虑这样做：123456# mysingleton.pyclass My_Singleton(object): def foo(self): passmy_singleton = My_Singleton() 将上面的代码保存在文件 mysingleton.py 中，然后这样使用：1234# 从mysingleton模块导入实例my_singletonfrom mysingleton import my_singletonmy_singleton.foo() 使用__new__为了使类只能出现一个实例，我们可以使用 __new__ 来控制实例的创建过程，代码如下：123456789class Singleton(object): _instance = None def __new__(cls, *args, **kw): if not cls._instance: cls._instance = super(Singleton, cls).__new__(cls, *args, **kw) return cls._instanceclass MyClass(Singleton): a = 1 在上面的代码中，我们将类的实例和一个类变量 _instance 关联起来，如果 cls._instance 为 None 则创建实例，否则直接返回 cls._instance。执行情况如下:123456789101112In [4]: one = MyClass()In [5]: two = MyClass()In [6]: one == twoOut[6]: TrueIn [7]: id(one)Out[7]: 64402928In [8]: id(two)Out[8]: 64402928 使用装饰器装饰器（decorator）可以动态地修改一个类或函数的功能。这里，我们也可以使用装饰器来装饰某个类，使其只能生成一个实例，代码如下：1234567891011121314from functools import wrapsdef singleton(cls): instances = &#123;&#125; @wraps(cls) def getinstance(*args, **kw): if cls not in instances: instances[cls] = cls(*args, **kw) return instances[cls] return getinstance@singletonclass MyClass(object): a = 1 在上面，我们定义了一个装饰器 singleton，它返回了一个内部函数 getinstance，该函数会判断某个类是否在字典 instances 中，如果不存在，则会将 cls 作为 key，cls(args, *kw) 作为 value 存到 instances 中，否则，直接返回 instances[cls]。 使用metaclass元类（metaclass）可以控制类的创建过程，它主要做三件事： 拦截类的创建 修改类的定义 返回修改后的类使用元类实现单例模式,代码如下:1234567891011121314class Singleton(type): _instances = &#123;&#125; def __call__(cls, *args, **kwargs): if cls not in cls._instances: cls._instances[cls] = super(Singleton, cls).__call(*args, **kwargs) return cls._instance[cls]# py2#class MyClass(object):# __metaclass__ = Singleton# py3class MyClass(metaclass=Singleton): pass 以上是python中实现单例模式的一些方法 C++中的单例模式代码分析:123456789101112// main.cpp#include &lt;iostream&gt;#include \"Singleton.h\"using namespace std;int main(int argc, char *argv[])&#123; Singleton * sg = Singleton::getInstance(); sg-&gt;singletonOperation(); return 0;&#125; 1234567891011121314151617181920// singleton.h#ifndef SINGLETON_H#define SINGLETON_Hclass Singleton&#123;public: virtual ~Singleton(); // 提供一个公有的静态工厂方法 static Singleton* getinstance(); void SingletonOperation();private: // 提供一个自身的静态私有成员变量 static Singleton *instance; // 构造函数私有化 Singleton();&#125;;#endif // SINGLETON_H 123456789101112131415161718192021222324252627282930// singleton.cpp#include \"singleton.h\"#include &lt;iostream&gt;using namespace std;Singleton *Singleton::instance = NULL;Singleton::Singleton()&#123;&#125;Singleton::~Singleton()&#123; delete instance;&#125;Singleton* Singleton::getinstance()&#123; if (instance == NULL) &#123; instance = new Singleton(); &#125; return instance;&#125;void Singleton::SingletonOperation()&#123; cout&lt;&lt; \"SingletonOperation\" &lt;&lt; endl;&#125; 运行结果: 模式分析单例模式的目的是保证一个类仅有一个实例，并提供一个访问它的全局访问点。单例模式包含的角色只有一个，就是单例类——Singleton。单例类拥有一个私有构造函数，确保用户无法通过new关键字直接实例化它。除此之外，该模式中包含一个静态私有成员变量与静态公有的工厂方法，该工厂方法负责检验实例的存在性并实例化自己，然后存储在静态成员变量中，以确保只有一个实例被创建。 在单例模式的实现过程中，需要注意如下三点： 单例类的构造函数为私有； 提供一个自身的静态私有成员变量； 提供一个公有的静态工厂方法。 优点提供了对唯一实例的受控访问。因为单例类封装了它的唯一实例，所以它可以严格控制客户怎样以及何时访问它，并为设计及开发团队提供了共享的概念。由于在系统内存中只存在一个对象，因此可以节约系统资源，对于一些需要频繁创建和销毁的对象，单例模式无疑可以提高系统的性能。允许可变数目的实例。我们可以基于单例模式进行扩展，使用与单例控制相似的方法来获得指定个数的对象实例。 缺点由于单例模式中没有抽象层，因此单例类的扩展有很大的困难。单例类的职责过重，在一定程度上违背了“单一职责原则”。因为单例类既充当了工厂角色，提供了工厂方法，同时又充当了产品角色，包含一些业务方法，将产品的创建和产品的本身的功能融合到一起。滥用单例将带来一些负面问题，如为了节省资源将数据库连接池对象设计为单例类，可能会导致共享连接池对象的程序过多而出现连接池溢出；现在很多面向对象语言(如Java、C#)的运行环境都提供了自动垃圾回收的技术，因此，如果实例化的对象长时间不被利用，系统会认为它是垃圾，会自动销毁并回收资源，下次利用时又将重新实例化，这将导致对象状态的丢失。 适用环境在以下情况下可以使用单例模式： 系统只需要一个实例对象，如系统要求提供一个唯一的序列号生成器，或者需要考虑资源消耗太大而只允许创建一个对象。客户调用类的单个实例只允许使用一个公共访问点，除了该公共访问点，不能通过其他途径访问该实例。在一个系统中要求一个类只有一个实例时才应当使用单例模式。反过来，如果一个类可以有几个实例共存，就需要对单例模式进行改进，使之成为多例模式 参考 http://funhacks.net/2017/01/17/singleton/ 图说设计模式","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://arvin-he.github.io/tags/设计模式/"}]},{"title":"Python之super理解","slug":"python-super-2017-06-16","date":"2017-06-16T07:29:08.000Z","updated":"2017-09-08T03:51:40.162Z","comments":true,"path":"2017/06/16/python-super-2017-06-16/","link":"","permalink":"http://arvin-he.github.io/2017/06/16/python-super-2017-06-16/","excerpt":"","text":"super使用场景在类的继承中，如果重写某个方法，该方法会覆盖父类的同名方法，但有时，我们希望能调用子类的方法的同时也能调用父类的同名方法，这时，可通过使用 super 来实现，比如：1234567891011121314151617181920class Animal(object): def __init__(self, name): self.name = name def greet(self): print('Hello, I am %s.' % self.name)class Dog(Animal): def greet(self): super(Dog, self).greet() # Python3 可使用 super().greet() print('WangWang...')``` 在上面，Animal 是父类，Dog 是子类，我们在 Dog 类重定义了 greet 方法，为了能同时实现父类的功能，我们又调用了父类的方法，看下面的使用：```python&gt;&gt;&gt; dog = Dog('dog')&gt;&gt;&gt; dog.greet()Hello, I am dog.WangWang.. super最常用的用法super 的一个最常见用法可以说是在子类中调用父类的初始化方法了，比如：1234567891011121314151617181920212223242526272829303132333435363738class Base(object): def __init__(self, a, b): self.a = a self.b = bclass A(Base): def __init__(self, a, b, c): # Python3 可使用 super().__init__(a, b) super(A, self).__init__(a, b) self.c = c``` ### 深入理解super看了上面的例子，你可能会觉得 super 的使用就是获取了父类，并调用父类的方法。其实，在上面的情况下，super 获得的类刚好是父类，但在其他情况就不一定了，super 其实和父类没有实质性的关联。下面看一个稍微复杂的例子，涉及到多重继承，代码如下：```pythonclass Base(object): def __init__(self): print(\"enter Base\") print(\"leave Base\")class A(Base): def __init__(self): print(\"enter A\") super(A, self).__init__() print(\"leave A\")class B(Base): def __init__(self): print(\"enter B\") super(B, self).__init__() print(\"leave B\")class C(A, B): def __init__(self): print(\"enter C\") super(C, self).__init__() print(\"leave C\") 实例化子类C看看结果:123456789&gt;&gt;&gt; c = C()enter Center Aenter Benter Baseleave Baseleave Bleave Aleave C 如果 super 代表『调用父类的方法』，那么为什么 enter A 的下一句不是 enter Base 而是 enter B。原因是: super 和父类没有实质性的关联，下面请看 super 是怎么运作的。 MRO列表事实上，对于你定义的每一个类，Python 会计算出一个方法解析顺序列表(Method Resolution Order, MRO)，它表明了类继承的顺序，我们使用下面的方法获得某个类的 MRO 列表：12&gt;&gt;&gt; C.mro() # or C.__mro__ or C().__class__.mro()[__main__.C, __main__.A, __main__.B, __main__.Base, object] 那么这个 MRO 列表的顺序是怎么定的呢?它是通过一个 C3 线性化算法来实现的，这里不深究这个算法，感兴趣的可以自己去了解，总之，一个类的 MRO 列表就是合并所有父类的 MRO 列表，并遵循以下三条原则： 子类永远在父类前面 如果有多个父类，会根据它们在列表中的顺序被检查 如果对下一个类存在两个合法的选择，选择第一个父类 super原理及实现super 的定义如下：123def super(cls, inst): mro = inst.__class__.mro() return mro[mro.index(cls) + 1] 其中, 第一个参数 cls 代表类, 第二个参数 inst 代表实例, 上面的代码做了两件事: 获取 inst 的 MRO 列表 查找 cls 在当前 MRO 列表中的 index, 并返回它的下一个类，即 mro[index + 1] 当你调用 super(cls, inst) 时，Python 会在 inst 的 MRO 列表上搜索 cls 的下一个类。下面就详细分析一下:首先看类 C 的__init__方法：super(C, self).__init__().这里的 self 是当前 C 的实例，self.class.mro() 结果是：[__main__.C, __main__.A, __main__.B, __main__.Base, object]可以看到，C 的下一个类是 A，于是，跳到了 A 的__init__，这时会打印出 enter A，并执行下面一行代码：super(A, self).__init__(),注意: 这里的 self 也是当前 C 的实例，MRO 列表跟上面是一样的，搜索 A 在 MRO 中的下一个类，发现是 B，于是，跳到了 B 的__init__，这时会打印出 enter B，而不是 enter Base。打印出enter B后, 搜索 B 在 MRO 中的下一个类是Base, 调用Base的__init__, 打印出enter Base 和 leave Base, 然后又跳到B的__init__,执行完 B 的__init__, 再然后是 A 的__init__, 最后是 C 的__init__. 整个过程还是比较清晰的，关键是要理解 super 的工作方式，而不是想当然地认为 super 调用了父类的方法。 总结: super 和父类没有实质性的关联。 super(cls, inst) 获得的是 cls 在 inst 的 MRO 列表中的下一个类。 参考 你不知道的super","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Python之Matplotlib绘图","slug":"python-matplotlib-2017-06-16","date":"2017-06-16T02:17:22.000Z","updated":"2017-09-08T03:51:40.098Z","comments":true,"path":"2017/06/16/python-matplotlib-2017-06-16/","link":"","permalink":"http://arvin-he.github.io/2017/06/16/python-matplotlib-2017-06-16/","excerpt":"","text":"Matplotlib简介Matplotlib 可能是 Python 2D-绘图领域使用最广泛的包了。它能让使用者轻松地将数据图形化，并提供多样化的输出格式。这里将会探索 matplotlib 的常见用法。 IPython和pylabIPython 是 Python 的一个增强shell。它在下列方面有所增强： named inputs and outputs、shell commands、debug. 在命令行终端给 IPython 加上参数 -pylab （0.12 以后的版本是 –pylab）之后，就可以像 Matlab/Mathematica 那样以交互的方式绘图。 pylab 是 matplotlib 面向对象绘图库的一个接口。它的语法和 Matlab 十分相近。也就是说，它主要的绘图命令和 Matlab 对应的命令有相似的参数。 简单绘制这里将先尝试用默认配置在同一张图上绘制正弦和余弦函数图像，然后逐步添加各项功能来美化。第一步: 获取正弦函数和余弦函数的值,并绘制正弦和余弦曲线 12345678910import numpy as npimport matplotlib.pyplot as pltX = np.linspace(-np.pi, np.pi, 256, endpoint=True)C, S = np.cos(X), np.sin(X)plt.plot(X, C)plt.plot(X, S)plt.show() X是一个numpy数组,并从[-π, π]中等间距取256个值, 即坐标系的X轴上的取值C是余弦曲线上对应于X轴各个取值的余弦值,即坐标系上y轴的取值S是正弦曲线上对应于X轴各个取值的正弦值,即坐标系上y轴的取值运行结果: Matplotlib有一系列默认设置允许定制各种属性,你可以控制mayplotlib几乎所有的属性,如:图像尺寸, dpi(分辨率), 线宽, 颜色, 样式, 坐标轴, 坐标轴和网格属性, 文本, 字体等属性. 不过，matplotlib 的默认配置在大多数情况下已经做得足够好，你可能只在很少的情况下才会想更改这些默认配置。 在下面的脚本中，我们已经实例化了(并注释了)影响曲线外观的设置。这些设置已被明确设置为默认值，但现在您可以交互地设置这些值来探索其影响(请参阅下面的线条属性和线条样式).1234567891011121314151617181920212223242526272829303132333435import numpy as npimport matplotlib.pyplot as plt# 创建一个大小为8x6 inch的新图形，每英寸使用80点plt.figure(figsize=(8,6), dpi=80)# 从1x1的网格创建一个新的子图plt.subplot(111)X = np.linspace(-np.pi, np.pi, 256,endpoint=True)C,S = np.cos(X), np.sin(X)# Plot cosine using blue color with a continuous line of width 1 (pixels)plt.plot(X, C, color=\"blue\", linewidth=1.0, linestyle=\"-\")# Plot sine using green color with a continuous line of width 1 (pixels)plt.plot(X, S, color=\"green\", linewidth=1.0, linestyle=\"-\")# Set x 上下限plt.xlim(-4.0,4.0)# Set x 刻度plt.xticks(np.linspace(-4,4,9,endpoint=True))# Set y limitsplt.ylim(-1.0,1.0)# Set y ticksplt.yticks(np.linspace(-1,1,5,endpoint=True))# Save figure using 72 dots per inch# savefig(\"../figures/exercice_2.png\",dpi=72)# Show result on screenplt.show() 参考 Matplotlib教程","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"设计模式简介","slug":"dp-brief-2017-06-15","date":"2017-06-15T07:00:49.000Z","updated":"2017-09-08T03:51:39.426Z","comments":true,"path":"2017/06/15/dp-brief-2017-06-15/","link":"","permalink":"http://arvin-he.github.io/2017/06/15/dp-brief-2017-06-15/","excerpt":"","text":"设计模式在软件工程中，设计模式（design pattern）是对软件设计中普遍存在（反复出现）的各种问题，所提出的解决方案。这个术语是由埃里希·伽玛（Erich Gamma）等人在1990年代从建筑设计领域引入到计算机科学的。设计模式并不直接用来完成代码的编写，而是描述在各种不同情况下，要怎么解决问题的一种方案。面向对象设计模式通常以类别或对象来描述其中的关系和相互作用，但不涉及用来完成应用程序的特定类别或对象。设计模式能使不稳定依赖于相对稳定、具体依赖于相对抽象，避免会引起麻烦的紧耦合，以增强软件设计面对并适应变化的能力。并非所有的软件模式都是设计模式，设计模式特指软件“设计”层次上的问题。还有其它非设计模式的模式，如架构模式。同时，算法不能算是一种设计模式，因为算法主要是用来解决计算上的问题，而非设计上的问题。 设计模式分类设计模式主要分3大类,每一类中又有几个不同的模式 创建型模式 结构型模式 行为型模式 创建型模式 简单工厂模式 工厂方法模式 抽象工厂模式 建造者模式 单例模式 结构型模式 适配器模式 桥接模式 装饰模式 外观模式 享元模式 代理模式 行为型模式 命令模式 中介者模式 观察者模式 状态模式 策略模式","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"http://arvin-he.github.io/tags/设计模式/"}]},{"title":"Python之Scrapy初识","slug":"python-scrapy1-201-06-15","date":"2017-06-15T05:09:52.000Z","updated":"2018-01-15T09:44:51.664Z","comments":true,"path":"2017/06/15/python-scrapy1-201-06-15/","link":"","permalink":"http://arvin-he.github.io/2017/06/15/python-scrapy1-201-06-15/","excerpt":"","text":"Scrapy简介Scrapy是用Python开发的一个快速,高层次的屏幕抓取和web抓取框架，用于抓取web站点并从页面中提取结构化的数据。Scrapy用途广泛，可以用于数据挖掘、监测和自动化测试。Scrapy吸引人的地方在于它是一个框架，任何人都可以根据需求方便的修改。它也提供了多种类型爬虫的基类，如BaseSpider、sitemap爬虫等，最新版本又提供了web2.0爬虫的支持。Scratch，是抓取的意思，Scrapy大概是源于Scratch吧.Scrapy 使用了 Twisted异步网络库来处理网络通讯。整体架构大致如下: Scrapy框架及组件 引擎(Scrapy)用来处理整个系统的数据流处理, 触发事务(框架核心) 调度器(Scheduler)用来接受引擎发过来的请求, 压入队列中, 并在引擎再次请求的时候返回. 可以想像成一个URL（抓取网页的网址或者说是链接）的优先队列, 由它来决定下一个要抓取的网址是什么, 同时去除重复的网址 下载器(Downloader)用于下载网页内容, 并将网页内容返回给蜘蛛(Scrapy下载器是建立在twisted这个高效的异步模型上的) 爬虫(Spiders)爬虫是主要干活的, 用于从特定的网页中提取自己需要的信息, 即所谓的实体(Item)。用户也可以从中提取出链接,让Scrapy继续抓取下一个页面. 项目管道(Pipeline)负责处理爬虫从网页中抽取的实体，主要的功能是持久化实体、验证实体的有效性、清除不需要的信息。当页面被爬虫解析后，将被发送到项目管道，并经过几个特定的次序处理数据。 下载器中间件(Downloader Middlewares)位于Scrapy引擎和下载器之间的框架，主要是处理Scrapy引擎与下载器之间的请求及响应。 爬虫中间件(Spider Middlewares)介于Scrapy引擎和爬虫之间的框架，主要工作是处理蜘蛛的响应输入和请求输出。 调度中间件(Scheduler Middlewares)介于Scrapy引擎和调度之间的中间件，从Scrapy引擎发送到调度的请求和响应。 Scarpy运作流程: 引擎从调度器中取出一个链接(URL)用于接下来的抓取 引擎把URL封装成一个请求(Request)传给下载器 下载器把资源下载下来，并封装成应答包(Response) 爬虫解析Response 解析出实体（Item）,则交给实体管道进行进一步的处理 解析出的是链接（URL）,则把URL交给调度器等待抓取 Scrapy安装Scrapy已经支持python3,使用pip安装, 在命令行窗口输入: pip install scrapy, 回车.注意： windows平台需要依赖pywin32，请根据自己系统32/64位选择下载安装，下载地址 Scrapy基本使用创建爬虫项目运行命令: scrapy startproject project_name, 回车, 自动创建的目录如下:12345678910111213λ tree /F .C:\\USERS\\ARON\\SCRAPYTEST│ scrapy.cfg│└─scrapytest │ items.py │ middlewares.py │ pipelines.py │ settings.py │ __init__.py │ ├─spiders │ __init__.py 文件说明：scrapy.cfg 项目的配置信息,主要为Scrapy命令行工具提供一个基础的配置信息(真正爬虫相关的配置信息在settings.py文件中）items.py 设置数据存储模板，用于结构化数据，如：Django的Modelpipelines 数据处理行为，如：一般结构化的数据持久化settings.py 配置文件，如：递归的层数、并发数，延迟下载等spiders 爬虫目录，如：创建文件，编写爬虫规则注意：一般创建爬虫文件时，以网站域名命名 编写爬虫编写一个爬取校花网上的校花图片, 在spiders目录中新建 xiaohuar_spider.py 文件123456789101112#! /usr/bin/python3# -*- coding:utf-8 -*-import scrapyclass XiaoHuarSpider(scrapy.spider.Spider): name = \"xiaohuar\" allowed_domains = [\"xiaohuar.com\"] start_urls = [\"http://www.xiaohuar.com/hua/\"] def parse(self, response): current_url = response.current_url body = response.body unicode_body = response.body_as_unicode() 注意点: 爬虫文件需要定义一个类，并继承scrapy.spiders.Spider 必须定义name，即爬虫名，如果没有name，会报错. 编写函数parse，注意:该函数名不能改变，因为Scrapy源码中默认callback函数的函数名就是parse； 定义需要爬取的url，放在list中，因为可以爬取多个url，Scrapy源码是一个For循环，从上到下爬取这些url，使用生成器迭代将url发送给下载器下载url的html。 运行爬虫进入scarpytest目录, 运行命令:scrapy crawl xiaohau --nolog, 回车格式：scrapy crawl+爬虫名 –nolog即不显示日志 scrapy查询语法当爬取大量的网页，如果自己写正则匹配，会很麻烦，也很浪费时间，令人欣慰的是，scrapy内部支持更简单的查询语法，帮助我们去html中查询我们需要的标签和标签内容以及标签属性。下面逐一进行介绍： 查询子子孙孙中的某个标签(以div标签为例)：//div 查询儿子中的某个标签(以div标签为例)：/div 查询标签中带有某个class属性的标签：//div[@class=’c1′],即子子孙孙中标签是div且class=‘c1’的标签 查询标签中带有某个class=‘c1’并且自定义属性name=‘alex’的标签：//div[@class=’c1′][@name=’alex’] 查询某个标签的文本内容：//div/span/text() 即查询子子孙孙中div下面的span标签中的文本内容 查询某个属性的值（例如查询a标签的href属性）：//a/@href 示例:1234567891011121314151617181920212223242526def parse(self, response): # 分析页面 # 找到页面中符合规则的内容（校花图片），保存 # 找到所有的a标签，再访问其他a标签，一层一层的搞下去 hxs = HtmlXPathSelector(response)#创建查询对象 # 如果url是 http://www.xiaohuar.com/list-1-\\d+.html #如果url能够匹配到需要爬取的url，即本站url if re.match('http://www.xiaohuar.com/list-1-\\d+.html', response.url): #select中填写查询目标，按scrapy查询语法书写 items = hxs.select('//div[@class=\"item_list infinite_scroll\"]/div') for i in range(len(items)): #查询所有img标签的src属性，即获取校花图片地址 src = hxs.select('//div[@class=\"item_list infinite_scroll\"]/div[%d]//div[@class=\"img\"]/a/img/@src' % i).extract() #获取span的文本内容，即校花姓名 name = hxs.select('//div[@class=\"item_list infinite_scroll\"]/div[%d]//div[@class=\"img\"]/span/text()' % i).extract() #校花学校 school = hxs.select('//div[@class=\"item_list infinite_scroll\"]/div[%d]//div[@class=\"img\"]/div[@class=\"btns\"]/a/text()' % i).extract() if src: #相对路径拼接 ab_src = \"http://www.xiaohuar.com\" + src[0] #文件名，因为python27默认编码格式是unicode编码，因此我们需要编码成utf-8 file_name = \"%s_%s.jpg\" % (school[0].encode('utf-8'), name[0].encode('utf-8')) file_path = os.path.join(\"/Users/wupeiqi/PycharmProjects/beauty/pic\", file_name) urllib.urlretrieve(ab_src, file_path) 注：urllib.urlretrieve(ab_src, file_path) ，接收文件路径和需要保存的路径，会自动去文件路径下载并保存到我们指定的本地路径。 递归爬取网页上述代码仅仅实现了一个url的爬取，如果该url的爬取的内容中包含了其他url，而我们也想对其进行爬取，那么如何实现递归爬取网页呢？12345# 获取所有的url，继续访问，并在其中寻找相同的urlall_urls = hxs.select('//a/@href').extract()for url in all_urls: if url.startswith('http://www.xiaohuar.com/list-1-'): yield Request(url, callback=self.parse) 通过yield生成器向每一个url发送request请求,并执行返回函数parse,从而递归获取校花图片和校花姓名学校等信息。注：可以修改settings.py 中的配置文件，以此来指定“递归”的层数，如: DEPTH_LIMIT = 1 scrapy查询语法中的正则：123456789101112131415161718from scrapy.selector import Selectorfrom scrapy.http import HtmlResponsehtml = \"\"\"&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head lang=\"en\"&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;li class=\"item-\"&gt;&lt;a href=\"link.html\"&gt;first item&lt;/a&gt;&lt;/li&gt; &lt;li class=\"item-0\"&gt;&lt;a href=\"link1.html\"&gt;first item&lt;/a&gt;&lt;/li&gt; &lt;li class=\"item-1\"&gt;&lt;a href=\"link2.html\"&gt;second item&lt;/a&gt;&lt;/li&gt;&lt;/body&gt;&lt;/html&gt;\"\"\"response = HtmlResponse(url='http://example.com', body=html,encoding='utf-8')ret = Selector(response=response).xpath('//li[re:test(@class, \"item-\\d*\")]//@href').extract()print(ret) 语法规则：Selector(response=response查询对象).xpath(‘//li[re:test(@class, “item-d*”)]//@href’).extract()，即根据re正则匹配，test即匹配，属性名是class，匹配的正则表达式是”item-d*”，然后获取该标签的href属性。更多选择器规则 选择器规则示例:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#!/usr/bin/env python# -*- coding:utf-8 -*-import scrapyimport hashlibfrom tutorial.items import JinLuoSiItemfrom scrapy.http import Requestfrom scrapy.selector import HtmlXPathSelector class JinLuoSiSpider(scrapy.spiders.Spider): count = 0 url_set = set() name = \"jluosi\" domain = 'http://www.jluosi.com' allowed_domains = [\"jluosi.com\"] start_urls = [ \"http://www.jluosi.com:80/ec/goodsDetail.action?jls=QjRDNEIzMzAzOEZFNEE3NQ==\", ] def parse(self, response): md5_obj = hashlib.md5() md5_obj.update(response.url) md5_url = md5_obj.hexdigest() if md5_url in JinLuoSiSpider.url_set: pass else: JinLuoSiSpider.url_set.add(md5_url) hxs = HtmlXPathSelector(response) if response.url.startswith('http://www.jluosi.com:80/ec/goodsDetail.action'): item = JinLuoSiItem() item['company'] = hxs.select('//div[@class=\"ShopAddress\"]/ul/li[1]/text()').extract() item['link'] = hxs.select('//div[@class=\"ShopAddress\"]/ul/li[2]/text()').extract() item['qq'] = hxs.select('//div[@class=\"ShopAddress\"]//a/@href').re('.*uin=(?P&lt;qq&gt;\\d*)&amp;') item['address'] = hxs.select('//div[@class=\"ShopAddress\"]/ul/li[4]/text()').extract() item['title'] = hxs.select('//h1[@class=\"goodsDetail_goodsName\"]/text()').extract() item['unit'] = hxs.select('//table[@class=\"R_WebDetail_content_tab\"]//tr[1]//td[3]/text()').extract() product_list = [] product_tr = hxs.select('//table[@class=\"R_WebDetail_content_tab\"]//tr') for i in range(2,len(product_tr)): temp = &#123; 'standard':hxs.select('//table[@class=\"R_WebDetail_content_tab\"]//tr[%d]//td[2]/text()' %i).extract()[0].strip(), 'price':hxs.select('//table[@class=\"R_WebDetail_content_tab\"]//tr[%d]//td[3]/text()' %i).extract()[0].strip(), &#125; product_list.append(temp) item['product_list'] = product_list yield item current_page_urls = hxs.select('//a/@href').extract() for i in range(len(current_page_urls)): url = current_page_urls[i] if url.startswith('http://www.jluosi.com'): url_ab = url yield Request(url_ab, callback=self.parse) 获取响应cookie12345def parse(self, response): from scrapy.http.cookies import CookieJar cookieJar = CookieJar() cookieJar.extract_cookies(response, response.request) print(cookieJar._cookies) 格式化处理上述实例只是简单的图片处理，所以在parse方法中直接处理。如果对于想要获取更多的数据（获取页面的价格、商品名称、QQ等），则可以利用Scrapy的items将数据格式化，然后统一交由pipelines来处理。即不同功能用不同文件实现。 items：即用户需要爬取哪些数据，是用来格式化数据，并告诉pipelines哪些数据需要保存。 示例items.py文件：123456789101112# -*- coding: utf-8 -*-# Define here the models for your scraped items## See documentation in:# http://doc.scrapy.org/en/latest/topics/items.htmlimport scrapyclass JieYiCaiItem(scrapy.Item): company = scrapy.Field() title = scrapy.Field() qq = scrapy.Field() info = scrapy.Field() more = scrapy.Field() 即：需要爬取所有url中的公司名，title，qq，基本信息info，更多信息more。上述定义模板，以后对于从请求的源码中获取的数据同样按照此结构来获取，所以在spider中需要有一下操作：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124#!/usr/bin/env python# -*- coding:utf-8 -*- import scrapyimport hashlibfrom beauty.items import JieYiCaiItemfrom scrapy.http import Requestfrom scrapy.selector import HtmlXPathSelectorfrom scrapy.spiders import CrawlSpider, Rulefrom scrapy.linkextractors import LinkExtractor class JieYiCaiSpider(scrapy.spiders.Spider): count = 0 url_set = set() name = \"jieyicai\" domain = 'http://www.jieyicai.com' allowed_domains = [\"jieyicai.com\"] start_urls = [\"http://www.jieyicai.com\",] rules = [ #下面是符合规则的网址,但是不抓取内容,只是提取该页的链接(这里网址是虚构的,实际使用时请替换) #Rule(SgmlLinkExtractor(allow=(r'http://test_url/test?page_index=\\d+'))), #下面是符合规则的网址,提取内容,(这里网址是虚构的,实际使用时请替换) #Rule(LinkExtractor(allow=(r'http://www.jieyicai.com/Product/Detail.aspx?pid=\\d+')), callback=\"parse\"), ] def parse(self, response): md5_obj = hashlib.md5() md5_obj.update(response.url) md5_url = md5_obj.hexdigest() if md5_url in JieYiCaiSpider.url_set: pass else: JieYiCaiSpider.url_set.add(md5_url) hxs = HtmlXPathSelector(response) if response.url.startswith('http://www.jieyicai.com/Product/Detail.aspx'): item = JieYiCaiItem() item['company'] = hxs.select('//span[@class=\"username g-fs-14\"]/text()').extract() item['qq'] = hxs.select('//span[@class=\"g-left bor1qq\"]/a/@href').re('.*uin=(?P&lt;qq&gt;\\d*)&amp;') item['info'] = hxs.select('//div[@class=\"padd20 bor1 comard\"]/text()').extract() item['more'] = hxs.select('//li[@class=\"style4\"]/a/@href').extract() item['title'] = hxs.select('//div[@class=\"g-left prodetail-text\"]/h2/text()').extract() yield item current_page_urls = hxs.select('//a/@href').extract() for i in range(len(current_page_urls)): url = current_page_urls[i] if url.startswith('/'): url_ab = JieYiCaiSpider.domain + url yield Request(url_ab, callback=self.parse)``` 上述代码中：对url进行md5加密的目的是避免url过长，也方便保存在缓存或数据库中。此处代码的关键在于：* 将获取的数据封装在了Item对象中* yield Item对象 （一旦parse中执行yield Item对象，则自动将该对象交个pipelines的类来处理）```python# -*- coding: utf-8 -*-# Define your item pipelines here## Don't forget to add your pipeline to the ITEM_PIPELINES setting# See: http://doc.scrapy.org/en/latest/topics/item-pipeline.html import jsonfrom twisted.enterprise import adbapiimport MySQLdb.cursorsimport re mobile_re = re.compile(r'(13[0-9]|15[012356789]|17[678]|18[0-9]|14[57])[0-9]&#123;8&#125;')phone_re = re.compile(r'(\\d+-\\d+|\\d+)') class JsonPipeline(object): def __init__(self): self.file = open('/Users/wupeiqi/PycharmProjects/beauty/beauty/jieyicai.json', 'wb') def process_item(self, item, spider): line = \"%s %s\\n\" % (item['company'][0].encode('utf-8'), item['title'][0].encode('utf-8')) self.file.write(line) return item class DBPipeline(object): def __init__(self): self.db_pool = adbapi.ConnectionPool('MySQLdb', db='DbCenter', user='root', passwd='123', cursorclass=MySQLdb.cursors.DictCursor, use_unicode=True) def process_item(self, item, spider): query = self.db_pool.runInteraction(self._conditional_insert, item) query.addErrback(self.handle_error) return item def _conditional_insert(self, tx, item): tx.execute(\"select nid from company where company = %s\", (item['company'][0], )) result = tx.fetchone() if result: pass else: phone_obj = phone_re.search(item['info'][0].strip()) phone = phone_obj.group() if phone_obj else ' ' mobile_obj = mobile_re.search(item['info'][1].strip()) mobile = mobile_obj.group() if mobile_obj else ' ' values = ( item['company'][0], item['qq'][0], phone, mobile, item['info'][2].strip(), item['more'][0]) tx.execute(\"insert into company(company,qq,phone,mobile,address,more) values(%s,%s,%s,%s,%s,%s)\", values) def handle_error(self, e): print('error',e) 上述代码中多个类的目的是，可以同时保存在文件和数据库中，保存的优先级可以在配置文件settings中定义。 12345ITEM_PIPELINES = &#123; &apos;beauty.pipelines.DBPipeline&apos;: 300, &apos;beauty.pipelines.JsonPipeline&apos;: 100,&#125;# 每行后面的整型值，确定了他们运行的顺序，item按数字从低到高的顺序，通过pipeline，通常将这些数字定义在0-1000范围内。 设置编码自Scrapy1.2 起，增加了FEED_EXPORT_ENCODING属性，用于设置输出编码.在settings.py中添加下面的配置即可.FEED_EXPORT_ENCODING = &#39;utf-8&#39; 运行爬虫首先需要列出所有可运行的爬虫，输入: scrapy list, 回车, 这会列出所有爬虫类中指定的name属性。然后，我们可以按照name来指定运行爬虫, 如:scrapy crawl &#39;csdn_blog&#39; -o blog.json. 关于ROBOTSTXT_OBEY在settings.py文件，ROBOTSTXT_OBEY默认为True，就是要遵守robots.txt 的规则.那么 robots.txt 是什么东西呢？robots.txt 是遵循 Robot 协议的一个文件，它保存在网站的服务器中，它的作用是，告诉搜索引擎爬虫，本网站哪些目录下的网页不希望被爬取收录。在Scrapy启动后，会在第一时间访问网站的 robots.txt 文件，然后决定该网站的爬取范围。当然，我们并不是在做搜索引擎，而且在某些情况下我们想要获取的内容恰恰是被 robots.txt 所禁止访问的。所以，某些时候，我们就要将此配置项设置为 False ，拒绝遵守 Robot协议 ！所以在这里设置为False。当然可能本次爬取不一定会被它限制，但一般来说会首先选择禁止它。 参考 http://python.jobbole.com/86405/","categories":[{"name":"python","slug":"python","permalink":"http://arvin-he.github.io/categories/python/"}],"tags":[{"name":"scrapy","slug":"scrapy","permalink":"http://arvin-he.github.io/tags/scrapy/"}]},{"title":"Python之进程","slug":"python-process-2017-06-12","date":"2017-06-12T08:17:27.000Z","updated":"2017-09-08T03:51:40.127Z","comments":true,"path":"2017/06/12/python-process-2017-06-12/","link":"","permalink":"http://arvin-he.github.io/2017/06/12/python-process-2017-06-12/","excerpt":"","text":"多进程模块(multiprocessing)简介multiprocessing是多进程模块，多进程提供了任务并发性，能充分利用多核处理器, 避免了GIL（全局解释锁）对资源的影响。由于GIL（全局解释锁）的问题，多线程并不能充分利用多核处理器，如果是一个CPU计算型的任务，应该使用多进程模块 multiprocessing 。它的工作方式与线程库完全不同，但是两种库的语法却非常相似。multiprocessing给每个进程赋予单独的Python解释器，这样就规避了全局解释锁所带来的问题。 multiprocessing常用类: Process(group=None, target=None, name=None, args=(), kwargs={})派生一个进程对象，然后调用start()方法启动 Pool(processes=None, initializer=None, initargs=())返回一个进程池对象，processes进程池进程数量 Pipe(duplex=True)返回两个连接对象由管道连接 Queue(maxsize=0)返回队列对象，操作方法跟Queue.Queue一样 multiprocessing.dummy这个库是用于实现多线程 Process()类有以下些方法：run()start() :启动进程对象join([timeout]) :等待子进程终止，才返回结果。可选超时。name : 进程名字is_alive() :返回进程是否存活daemon : 进程的守护标记，一个布尔值pid: 返回进程IDexitcode :子进程退出状态码terminate() :终止进程。在unix上使用SIGTERM信号，在windows上使用TerminateProcess()。 Pool()类有以下些方法：apply(func, args=(), kwds={}) :等效内建函数apply()apply_async(func, args=(), kwds={}, callback=None) : 异步，等效内建函数apply()map(func, iterable, chunksize=None) : 等效内建函数map()map_async(func, iterable, chunksize=None, callback=None) :异步，等效内建函数map()imap(func, iterable, chunksize=1) :等效内建函数itertools.imap()imap_unordered(func, iterable, chunksize=1) :像imap()方法，但结果顺序是任意的close() :关闭进程池terminate() : 终止工作进程，垃圾收集连接池对象join() :等待工作进程退出。必须先调用close()或terminate() Pool.apply_async()和Pool.map_aysnc()又提供了以下几个方法：get([timeout]) : 获取结果对象里的结果。如果超时没有，则抛出TimeoutError异常wait([timeout]) : 等待可用的结果或超时ready() : 返回调用是否已经完成successful() multiprocessing使用一个简单的例子12345678910111213141516171819from multiprocessing import Processimport osdef worker(name): print(name) print(\"parent pid = &#123;&#125;\".format(os.getppid())) print(\"current pid = &#123;&#125;\".format(os.getpid()))if __name__ == \"__main__\": p = Process(target=worker, args=('func worker', )) p.start() p.join() print(p.name)#输出结果func workerparent pid = 5476current pid = 5992Process-1 关于join([timeout])方法说明:如果可选参数timeout为None(默认值)，该方法将阻塞，直到调用join()方法的进程终止。如果超时为正数，则阻塞最多超时timeout的设定值。请注意，如果方法终止或方法超时，该方法返回None。检查进程的exitcode以确定是否终止。 给子进程命名,方便管理12345678910111213141516171819202122232425262728293031323334353637383940from multiprocessing import Processimport osdef worker1(): print(\"this is worker1 func\") print(\"current pid = &#123;&#125;\".format(os.getpid()))def worker2(): print(\"this is worker2 func\") print(\"current pid = &#123;&#125;\".format(os.getpid()))if __name__ == \"__main__\": print(\"parent pid = &#123;&#125;\".format(os.getppid())) for n in range(3): p1 = Process(name=\"worker1\", target=worker1) p1.start() p1.join() print(\"child process name = &#123;&#125;\".format(p1.name)) p2 = Process(name=\"worker2\", target=worker2) p2.start() p2.join() print(\"child process name = &#123;&#125;\".format(p2.name))# 输出结果parent pid = 2816this is worker1 funccurrent pid = 2428child process name = worker1this is worker1 funccurrent pid = 3192child process name = worker1this is worker1 funccurrent pid = 4736child process name = worker1this is worker2 funccurrent pid = 976child process name = worker2 关于daemon这里的daemon不同于linux中守护进程的概念,这里的daemon参数是一个布尔值,如果daemon为None则创建子进程时daemon参数从父进程继承过来.如果daemon为true,则创建的子进程随着父进程退出而退出,如果daemon为false,则创建的子进程随着父进程退出而不退出,注意: 一个守护进程不允许创建子进程,否则当父进程退出后,该守护进程终止后会使由该守守护进守护进程创建的子进程变成独立进程,此外，它们不是Unix守护程序或服务，它们是正常进程，如果非守护进程已退出，则该进程将被终止（并且未加入）。 进程池有一点要强调：任务的执行周期决定于CPU核数和任务分配算法。1234567891011121314151617181920212223242526272829303132333435from multiprocessing import Pool, current_processimport os, time, sysdef worker(n): print('hello world', n) # 获取当前进程名字 print('process name:', current_process().name) # 休眠用于执行时有时间查看当前执行的进程 time.sleep(1)if __name__ == '__main__': p = Pool(processes=3) for i in range(8): r = p.apply_async(worker, args=(i,)) # 获取结果中的数据 r.get(timeout=5) p.close()# 运行结果:hello world 0process name: SpawnPoolWorker-2hello world 1process name: SpawnPoolWorker-3hello world 2process name: SpawnPoolWorker-1hello world 3process name: SpawnPoolWorker-2hello world 4process name: SpawnPoolWorker-3hello world 5process name: SpawnPoolWorker-1hello world 6process name: SpawnPoolWorker-2hello world 7process name: SpawnPoolWorker-3 进程池生成了3个子进程，通过循环执行8次worker函数，进程池会从子进程1开始去处理任务，当到达最大进程时，会继续从子进程1开始。 进程池map方法, map()方法是将序列中的元素通过函数处理返回新列表。123456789from multiprocessing import Pooldef worker(url): return 'http://%s' % urlurls = ['www.baidu.com', 'www.jd.com']pool = Pool(2)sr = pool.map(worker, urls)pool.close()print(r) 上面的hasmultiprocess函数的用法非常中规中矩且常见，但是我认为更好的写法是使用Pool，也就是对应线程池的进程池. 其中map方法用起来和内置的map函数一样，却有多进程的支持。 dummy模块当出现要从多线程改成多进程或者多进程改成多线程的时候，可以使用multiprocessing.dummy这个子模块，dummy」这个词有「模仿」的意思，如果分不清任务是CPU密集型还是IO密集型就是用这个模块. from multiprocessing.dummy import Pool, 这样在多线程/多进程之间切换非常方便。如果一个任务拿不准是CPU密集还是I/O密集型，且没有其它不能选择多进程方式的因素，都统一直接上多进程模式。 基于Pipe的parmap进程间的通信（IPC）常用的是rpc、socket、pipe（管道）和消息队列（queue）。ultiprocessing支持两种类型进程间通信：Queue和Pipe。多进程模块中涉及到了后面3种。先看一个官网给出的最基本的管道的例子：1234567891011from multiprocessing import Process, Pipedef f(conn): conn.send(['hello']) conn.close()parent_conn, child_conn = Pipe()p = Process(target=f, args=(child_conn,))p.start()print(parent_conn.recv())p.join() 其中Pipe返回的是管道2边的对象：「父连接」和「子连接」。当子连接发送一个带有hello字符串的列表，父连接就会收到，所以parent_conn.recv()就会打印出来。这样就可以简单的实现在多进程之间传输Python内置的数据结构了。但是先说明，不能被xmlrpclib序列化的对象是不能这么传输的。 队列同步机制multiprocessing的Lock、Condition、Event、RLock、Semaphore等同步原语和threading模块的机制是一样的，用法也类似. 进程间共享状态multiprocessing提供的在进程间共享状态的方式有2种： 共享内存主要通过Value或者Array来实现。常见的共享的有以下几种：12345678910111213141516In [1]: from multiprocessing.sharedctypes import typecode_to_typeIn [2]: typecode_to_typeOut[2]:&#123;'B': ctypes.c_ubyte, 'H': ctypes.c_ushort, 'I': ctypes.c_ulong, 'L': ctypes.c_ulong, 'b': ctypes.c_byte, 'c': ctypes.c_char, 'd': ctypes.c_double, 'f': ctypes.c_float, 'h': ctypes.c_short, 'i': ctypes.c_long, 'l': ctypes.c_long, 'u': ctypes.c_wchar&#125; 而且共享的时候还可以给Value或者Array传递lock参数来决定是否带锁，如果不指定默认为RLock。 进程间对象共享一个multiprocessing.Manager对象会控制一个服务器进程，其他进程可以通过代理的方式来访问这个服务器进程。常见的共享方式有以下几种： Namespace。创建一个可分享的命名空间。 Value/Array。和上面共享ctypes对象的方式一样。 dict/list。创建一个可分享的dict/list，支持对应数据结构的方法。 Condition/Event/Lock/Queue/Semaphore。创建一个可分享的对应同步原语的对象。 分布式的进程间通信用Manager和Queue就可以实现简单的分布式的不同服务器的不同进程间的通信（C/S模式）。 参考 理解Python并发编程 - 进程篇 Python多进程与多线程","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Python之线程","slug":"python-thread-2017-06-12","date":"2017-06-12T02:25:11.000Z","updated":"2017-09-08T03:51:40.168Z","comments":true,"path":"2017/06/12/python-thread-2017-06-12/","link":"","permalink":"http://arvin-he.github.io/2017/06/12/python-thread-2017-06-12/","excerpt":"","text":"关于GILPython（特指CPython）的多线程不能利用多核的优势，这是因为全局解释锁（GIL）的限制。如果是cpu密集型(计算型)的任务，使用多线程GIL就会让多线程变慢。GIL是必须的，这是Python设计的问题：Python解释器是非线程安全的。这意味着当从线程内尝试安全的访问Python对象的时候将有一个全局的强制锁。 在任何时候，仅仅一个单一的线程能够获取Python对象或者C API。每100个字节的Python指令解释器将重新获取锁，这（潜在的）阻塞了I/O操作。因为锁，CPU密集型的代码使用线程库时，不会获得性能的提高（但是当它使用之后介绍的多进程库时，性能可以获得提高）。 线程同步机制Python线程包含多种同步机制: Semaphore（信号量） Lock（锁） RLock（可重入锁） Condition（条件） Event Queue Semaphore（信号量）在多线程编程中，为了防止不同的线程同时对一个公用的资源（比如全局变量）进行修改，需要进行同时访问的数量（通常是1）。信号量同步基于内部计数器，每调用一次acquire()，计数器减1；每调用一次release()，计数器加1.当计数器为0时，acquire()调用被阻塞。123456789101112131415161718192021222324import timefrom random import randomfrom threading import Thread, Semaphoresema = Semaphore(3)def foo(tid): with sema: print('&#123;&#125; acquire sema'.format(tid)) wt = random() * 2 time.sleep(wt) print('&#123;&#125; release sema'.format(tid))threads = []for i in range(5): t = Thread(target=foo, args=(i,)) threads.append(t) t.start()for t in threads: t.join() 这个例子中，限制了同时能访问资源的数量为3。看一下运行的效果：123456789100 acquire sema1 acquire sema2 acquire sema0 release sema3 acquire sema2 release sema4 acquire sema1 release sema3 release sema4 release sema Lock（锁）Lock也可以叫做互斥锁，其实相当于信号量为1。不加锁：123456789101112131415161718192021222324252627import timefrom threading import Threadvalue = 0def foo(): global value newvalue = value + 1 time.sleep(0.001) # 使用sleep让线程有机会切换 value = newvaluethreads = []for i in range(100): t = Thread(target=foo) t.start() threads.append(t)# 创建了100个线程print(len(threads))for t in threads: t.join()print(value) 运行结果:1210010 加锁123456789101112131415161718192021222324252627import timefrom threading import Thread, Lock# 全局变量value = 0lock = Lock()def foo(): global value # 加锁,执行完会自动释放锁 with lock: new = value + 1 time.sleep(0.001) value = newthreads = []for i in range(100): t = Thread(target=foo) t.start() threads.append(t)for t in threads: t.join()print(value) 运行结果:100 RLock（可重入锁）acquire() 能够不被阻塞的被同一个线程调用多次。但是要注意的是release()需要调用与acquire()相同的次数才能释放锁。 Condition（条件）一个线程等待特定条件，而另一个线程发出特定条件满足的信号。最好说明的例子就是「生产者/消费者」模型：1234567891011121314151617181920212223242526272829303132import timeimport threadingdef consumer(cond): t = threading.currentThread() with cond: # wait()方法创建了一个名为waiter的锁， # 并且设置锁的状态为locked。这个waiter锁用于线程间的通讯 cond.wait() print('&#123;&#125;: Resource is available to consumer'.format(t.name))def producer(cond): t = threading.currentThread() with cond: print('&#123;&#125;: Making resource available'.format(t.name)) # 释放waiter锁，唤醒消费者 cond.notifyAll()condition = threading.Condition()c1 = threading.Thread(name='c1', target=consumer, args=(condition,))c2 = threading.Thread(name='c2', target=consumer, args=(condition,))p = threading.Thread(name='p', target=producer, args=(condition,))c1.start()time.sleep(1)c2.start()time.sleep(1)p.start() 运行结果:123p: Making resource availablec2: Resource is available to consumerc1: Resource is available to consumer 可以看到生产者发送通知之后，消费者都收到了。 Event一个线程发送/传递事件，另外的线程等待事件的触发.同样的用「生产者/消费者」模型的例子: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import timeimport threadingfrom random import randintTIMEOUT = 2def consumer(event, mylist): t = threading.currentThread() while 1: event_is_set = event.wait(TIMEOUT) if event_is_set: try: integer = mylist.pop() print('&#123;&#125; popped from list by &#123;&#125;'.format(integer, t.name)) # 重置事件状态 event.clear() except IndexError: # 为了让刚启动时容错 passdef producer(event, mylist): t = threading.currentThread() while 1: integer = randint(10, 100) mylist.append(integer) print('&#123;&#125; appended to list by &#123;&#125;'.format(integer, t.name)) # 设置事件 event.set() time.sleep(1)event = threading.Event()mylist = []threads = []for name in ('consumer1', 'consumer2'): t = threading.Thread(name=name, target=consumer, args=(event, mylist)) t.start() threads.append(t)p = threading.Thread(name='producer1', target=producer, args=(event, mylist))p.start()threads.append(p)for t in threads: t.join() 运行结果:123456789101112131415161718192086 appended to list by producer1 86 popped from list by consumer1 29 appended to list by producer1 29 popped from list by consumer1 36 appended to list by producer1 36 popped from list by consumer2 47 appended to list by producer1 47 popped from list by consumer2 16 appended to list by producer1 16 popped from list by consumer1 95 appended to list by producer1 95 popped from list by consumer1 51 appended to list by producer1 51 popped from list by consumer1 36 appended to list by producer1 36 popped from list by consumer1 12 appended to list by producer1 12 popped from list by consumer1 12 appended to list by producer1 12 popped from list by consumer1 可以看到事件被2个消费者比较平均的接收并处理了。如果使用了wait方法，线程就会等待我们设置事件，这也有助于保证任务的完成。 Queue队列在并发开发中最常用的。我们借助「生产者/消费者」模式来理解：生产者把生产的「消息」放入队列，消费者从这个队列中对去对应的消息执行。 大家主要关心如下4个方法就好了： put: 向队列中添加一个项。 get: 从队列中删除并返回一个项。 task_done: 当某一项任务完成时调用。 join: 阻塞直到所有的项目都被处理完。 12345678910111213141516171819202122232425262728import timeimport threadingfrom random import randomfrom queue import Queueq = Queue()def double(n): return n * 2def producer(): while 1: wt = random() time.sleep(wt) q.put((double, wt))def consumer(): while 1: task, arg = q.get() print(arg, task(arg)) q.task_done()for target in(producer, consumer): t = threading.Thread(target=target) t.start() 运行结果:123456780.5001101134617869 1.00022022692357380.2397443354990395 0.4794886709980790.018426830503480485 0.036853661006960970.9260989761246562 1.85219795224931240.808116115591099 1.6162322311821980.5868108877921562 1.17362177558431240.5195607837070528 1.03912156741410570.32311190835552184 0.6462238167110437 这就是最简化的队列架构。 Queue模块还自带了PriorityQueue（带有优先级）和LifoQueue（后进先出）2种特殊队列。下面展示线程安全的优先级队列的用法，PriorityQueue要求我们put的数据的格式是(priority_number, data)，我们看看下面的例子： 123456789101112131415161718192021222324252627282930313233343536373839import timeimport threadingfrom random import randintfrom queue import PriorityQueueq = PriorityQueue()def double(n): return n*2def producer(): count = 0 while 1: if count &gt; 5: break pri = randint(0, 100) print('put :&#123;&#125;'.format(pri)) # (priority, func, args) q.put((pri, double, pri)) count += 1def consumer(): while 1: if q.empty(): break pri, task, arg = q.get() print('[PRI:&#123;&#125;] &#123;&#125; * 2 = &#123;&#125;'.format(pri, arg, task(arg))) q.task_done() time.sleep(0.1)t = threading.Thread(target=producer)t.start()time.sleep(1)t = threading.Thread(target=consumer)t.start() 运行结果:123456789101112put :54put :70put :62put :54put :20put :75[PRI:20] 20 * 2 = 40[PRI:54] 54 * 2 = 108[PRI:54] 54 * 2 = 108[PRI:62] 62 * 2 = 124[PRI:70] 70 * 2 = 140[PRI:75] 75 * 2 = 150 可以看到put时的数字是随机的，但是get时先从优先级更高（数字小表示优先级高）开始获取的。 线程池面向对象开发中，创建和销毁对象是很费时间的，因为创建一个对象要获取内存资源或者其它更多资源。无节制的创建和销毁线程是一种极大的浪费。那我们可不可以把执行完任务的线程不销毁而重复利用呢？仿佛就是把这些线程放进一个池子，一方面我们可以控制同时工作的线程数量，一方面也避免了创建和销毁产生的开销。 线程池在标准库中其实是有体现的，只是在官方文章中基本没有被提及：123456In [1]: from multiprocessing.pool import ThreadPoolIn [2]: pool = ThreadPool(5)In [3]: pool.map(lambda x: x**2, range(5))Out[3]: [0, 1, 4, 9, 16] 自己实现:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import timeimport threadingfrom random import randomfrom queue import Queuedef double(n): return n*2class Worker(threading.Thread): def __init__(self, queue): super(Worker, self).__init__() self._q = queue self.daemon = True self.start() def run(self): while 1: f, args, kwargs = self._q.get() try: # 线程名字 print('USE: &#123;&#125;'.format(self.name)) print(f(*args, **kwargs)) except Exception as e: print(e) self._q.task_done()class ThreadPool(object): def __init__(self, num_t=5): self._q = Queue(num_t) # 创建5个工作线程 for _ in range(num_t): Worker(self._q) def add_task(self, f, *args, **kwargs): self._q.put((f, args, kwargs)) def wait_complete(self): self._q.join()pool = ThreadPool()for _ in range(8): wt = random() pool.add_task(double, wt) time.sleep(wt)pool.wait_complete() 运行结果:12345678910111213141516USE: Thread-10.4563649806005714USE: Thread-21.818831738188373USE: Thread-31.3641601633838014USE: Thread-41.4812490759517853USE: Thread-50.9838021089438205USE: Thread-10.5131452235979674USE: Thread-21.7305538822346334USE: Thread-31.8682661663096352 线程池会保证同时提供5个线程工作，但是我们有8个待完成的任务，可以看到线程按顺序被循环利用了。 参考 理解Python并发编程 - 线程篇","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Python之_magic变量和函数","slug":"python-magicVarFunc-2017-06-09","date":"2017-06-09T09:34:35.000Z","updated":"2017-09-08T03:51:40.095Z","comments":true,"path":"2017/06/09/python-magicVarFunc-2017-06-09/","link":"","permalink":"http://arvin-he.github.io/2017/06/09/python-magicVarFunc-2017-06-09/","excerpt":"","text":"关于下划线(_)的说明 单下划线开头：弱内部使用标识，无法被from M import *所引用 单下划线结尾：避免和python关键字冲突，可以加个后置下划线,如exec_() 双下划线开头：类成员变量中的私有变量， 双下划线开头，双下划线结尾：这是magic对象或属性的名字，永远不要将这样的命名方式应用于自己的变量和函数 magic变量和magic函数1. __name__ 变量 __name__属性是直接内置在.py文件中的, 这个属性经常用来当做一个使用模式的标识. * 如果.py文件是在命令行运行的文件, 即被执行的文件，则`__name__`将被设置为`__main__`。 * 如果.py文件是被import，`__name__`将被设置为.py文件的名字 2. __file__ 变量__file__可以用来获取python脚本的“路径+脚本名称”，这可能是一个相对路径也可能是一个绝对路径，取决按照什么路径来执行的脚本，一般来说__file__变量和os.path配合，可以用来获取python脚本的绝对路径：123In [5]: import osIn [7]: print(os.path.realpath(test1.__file__))C:\\Users\\aron\\Desktop\\test1.py 3. __import__ 函数python导入模块时，一般使用import，而import语句其实也是调用builtin函数,即__import__()函数实现的导入，直接使用__import__比较少见，除非导入的模块是不确定的，需要在运行时才能确定导入哪些模块，可以使用__import__，默认接收需要导入的模块名的字符串：12345In [9]: model = __import__('test')[1, 1, 2, 3, 5, 8, 13, 21, 34, 55]In [11]: model.Fib(5)Out[11]: &lt;test.Fib at 0x49ea9b0&gt; 4. __str__ 函数__str__是一个比较常用的内置函数，在定义类的时候经常使用，__str__函数返回一个字符串，这个字符串就是此对象被print时显示的内容，如果不定义这个函数，将会显示默认的格式：&lt;__main__.A object at 0x0000000001FB7C50&gt;.这个函数在django的model类中如果定义的话，print一条数据库中的数据，可以指定显示任何的值.注意：在python3.x中__str__被废弃，使用__repr__ 5. __init__ 函数__init__比较常见，是对象的初始化函数 6. __new__ 函数__new__()函数是类创建对象时调用的内置函数，必须返回一个生成的对象，__new__()函数在__init__()函数之前执行。一般来说没有必要重载这个函数，除非需要更改new对象的流程,有一种场景“单例模式”要求只能存在一个class A的对象，如果重复创建，那么返回的已经创建过的对象的引用。可以这样使用__new__函数.单例模式123456789class A(object): def __new__(cls): if not \"_instance\" in vars(cls): cls._instance=super(A,cls).__new__(cls) return cls._instancea=A()b=A()print id(a)==id(b)out&gt;&gt;True 7. __class__ 变量instance.__class__表示这个对象的类对象，但在python中，类也是一个对象,例：123456789101112131415In [12]: class A(object): ...: pass ...:In [13]: a = A()In [14]: B = a.__class__In [15]: BOut[15]: __main__.AIn [16]: b = B()In [17]: print(type(b))&lt;class '__main__.A'&gt; 可以看出，a是A类的一个对象，a.__class__就是A类，将这个类赋值给B，使用B()又可以创建出一个对象b，这个对象b也是A类的对象，这个__class__有什么用呢？请看下面的例子 8. __add__ 函数这里其实包含一系列函数，包括__sub__，__mul__，__mod__，__pow__，__xor__,这些函数是对加、减、乘、除、乘方、异或、等运算的重载，重写这些函数, 则我们自定义的对象可以具备运算功能.下面我们就自定义了一个加法操作1+2=1+2*2=51234567891011121314class A(object): def __init__(self,v): self.v=v def __add__(self,other): #创建创建一个新的对象 x=self.__class__(self.v + 2*other.v) return xa=A(1)b=A(2)c=a+bprint c.vouot&gt;&gt;5 9. __doc__ 文档字符串变量python建议在定义一个类、模块、函数的时候定义一段说明文字，以便提取这些变量字符串,方便做成说明文档,例子如下：调用别的模块、函数时如果不清楚使用方法，也可以直接查看doc文档字符串.123456789101112131415161718192021#c.py\"\"\"script c's doc\"\"\"class A(object): \"\"\" class A's doc \"\"\" passdef B(): \"\"\" function B's doc \"\"\" passprint __doc__print A.__doc__print B.__doc__out&gt;&gt;script c's docout&gt;&gt;class A's docout&gt;&gt;function B's doc 10. __iter__ 函数 和 __next__ 函数凡是可以被for...in的循环调用的对象，我们称之为可以被迭代的对象，list，str，tuple都可以被迭代，它们都实现了内部的迭代器函数，比如说list，tuple，字符串这些数据结构的迭代器如下：123456a=[1,2,3,4]b=('i',1,[1,2,3])print a.__iter__()print b.__iter__()out&gt;&gt;&lt;listiterator object at 0x0000000001CC7C50&gt;out&gt;&gt;&lt;tupleiterator object at 0x0000000001CC7B00&gt; 如果我们要实现一个我们自己的迭代器对象，那么我们必须实现两个默认的方法:__iter__和__next__。__iter__()函数将会返回一个迭代器对象，__next__()函数每次被调用都返回一个值，如果迭代完毕，则raise一个StopIteration的错误，用来终止迭代。下面的例子将实现一个可以迭代的对象，输出a~z的26个字母，该对象接收一个int参数用来表示输出字母的数量，如果该参数超过字母表的长度，则循环从‘a-z’再次进行循环输出：1234567891011121314151617181920212223242526import randomclass A(object): def __init__(self,n): self.stop=n self.value=0 #字母列表 self.alph=[chr(i) for i in range(97,123)] def __iter__(self): return self def __next__(self): #如果超过长度超过26则重置 if self.value==len(self.alph): self.value=0 self.stop=self.stop-len(self.alph) #最终，已完成n个字符的输出，则结束迭代 if self.value&gt;self.stop: raise StopIteration x=self.alph[self.value] self.value+=1 return xfor i in A(1000): print i,out&gt;&gt;a b c d e f g h i j k l m n o p q r s t u v w x y z a b c d e f g h i j k l m n o p q r s t u v w x y z a b c d e f g h i j k ..... 注意: __next__是python3中的, python2的是next() 11. __dict__ 变量, __slot__ 变量 和 __all__ 变量这三个变量有一些关系，__dict__在类和对象中都存在，它是一个包含变量名和变量的字典，见以下的例子：123456789101112131415#a.pyclass A(object): c=3 d=4 def __init__(self): self.a=1 self.b=2 def func(self): passprint A().__dict__print A.__dict__out&gt;&gt;&#123;'a': 1, 'b': 2&#125;out&gt;&gt;&#123;'__module__': '__main__', 'd': 4, 'c': 3, 'func': &lt;function func at 0x00000000021F2BA8&gt;, '__dict__': &lt;attribute '__dict__' of 'A' objects&gt;, '__weakref__': &lt;attribute '__weakref__' of 'A' objects&gt;, '__doc__': None, '__init__': &lt;function __init__ at 0x00000000021F2AC8&gt;&#125; 一个对象的__dict__只包含self定义的变量，一个类的__dict__包含了类里面的函数（func函数）、类变量，以及很多隐性的变量，包括__dict__变量本身也是隐性的。 __slot__变量的用法理解起来比较要难一点，正常的情况下，我们实例化一个对象，可以给这个对象增加任意的成员变量，即使不在类里面定义的变量都可以.12345678910111213141516#a.pyclass A(object): def __init__(self): self.a=1 self.b=2a=A()#给a增加一个x变量a.x=1#也可以给a增加一个匿名函数a.y=lambda x,y:x*yprint a.xprint a.y(3,5)out&gt;&gt;1out&gt;&gt;15 但如果我们想限制一下对象绑定的变量，我们可以在类定义的时候增加一个slots变量，这个变量是一个字符串元组，例子如下：1234567891011121314class A(object): __slots__=('a','b','x') def __init__(self): self.a=1 self.b=2 #__slots__=('a','b',) def func(self): passa=A()a.x=1#执行到a.y时会报错：AttributeError: 'A' object has no attribute 'y'a.y=lambda x,y:x*yprint a.y(3,5) __all__变量是一个字符串列表，它定义了每一个模块会被from module_name import *这样的语句可以被import的内容（变量，类，函数）123456789101112131415161718192021#a.py 不定义__all__class A(object): def __init__(self): self.a=1 self.b=2 def func(self): passdef B(): passc=10#b.pyfrom a import *print Aprint Bprint cout&gt;&gt;&lt;class 'learn_draft.A'&gt;out&gt;&gt;&lt;function B at 0x00000000021D1438&gt;out&gt;&gt;10 如果在a.py中定义__all__=[&#39;A&#39;,&#39;c&#39;],则B函数对于b.py来说是不可见的 12. __hash__ 函数哈希函数，在python中的对象有一个hashable（可哈希）的概念.对于数字、字符串、元组来说，是不可变的，也就是可哈希的，因此这些对象也可以作为字典的key值。对于列表、字典等，是可变对象，因此是不可哈希的，也就不能作为字典的key值。是否可哈希，可以调用内置函数hash()进行计算，hash()函数返回计算的到的hash值。完全相同的变量，调用哈希算法的到的hash值一定是相同的 当然一般来说，我们不会去重新定义一个对象的__hash__函数，除非我们想实现一个自定义的需求，在stackoverflow有人提出这样一个需求，需要判断有相同词频的字符串是相等的，也就是说“abb”和“bab”这样的字符串是相等的，这个时候我们可以继承字符串类，然后重写哈希函数，如下：12345678910111213141516import collectionsclass FrequencyString(str): @property def normalized(self): try: return self._normalized except AttributeError: self._normalized = normalized = ''.join(sorted(collections.Counter(self).elements())) return normalized def __eq__(self, other): return self.normalized == other.normalized def __hash__(self): return hash(self.normalized) 13. __getattr__ 函数和__setattr__ 函数，__delattr__ 函数先介绍两个内置函数，getattr()和setattr(),使用这两个函数可以获取对象的属性，或者给对象的属性赋值：1234567891011#a.pyclass A(object): def __init__(self): self.a=1 self.b=2a=A()setattr(a,'a',3)print a.aprint getattr(a,'b')out&gt;&gt;3out&gt;&gt;2 其实使用这两个函数和直接访问a.a, a.b没有任何区别，但好处是setattr和getattr接受两个字符串去确定访问对象a的哪一个属性，和__import__一样，可以在运行时在决定去访问对象变量的名字，在实际工作中经常会使用这两个函数。 __getattr__()这个函数是在访问对象不存在的成员变量是才会访问的，见下面的例子：12345678910111213141516class A(object): def __init__(self): self.a=1 self.b=2 def func(self): pass def __getattr__(self,name): print 'getattr' return self.aa=A()print a.dout&gt;&gt;getattrout&gt;&gt;1 在调用a.d时，d不是a的成员变量，则python会去查找对象是否存在__getattr__()函数，如果存在，则返回__getattr__()函数的返回值，我们这里返回的是self.a的值1。 由于__getattr__()的特性，我们可以将__getattr__()设计成一个公共的接口函数，在autotest的proxy.py中就看到了这样的用法：1234567891011121314class ServiceProxy(object):def __init__(self, serviceURL, serviceName=None, headers=None): self.__serviceURL = serviceURL self.__serviceName = serviceName self.__headers = headers or &#123;&#125;def __getattr__(self, name): if self.__serviceName is not None: name = \"%s.%s\" % (self.__serviceName, name) return ServiceProxy(self.__serviceURL, name, self.__headers)#调用的时候，op是执行的特定操作的字符串，op传入__getattr__将会把ServiceProxy对象重新的内部变量重新赋值，然后返回一个更新之后的对象function = getattr(self.proxy, op) __setattr__和__getattr__不一样，对象的所有属性赋值，都会经过__setattr__()函数，看下面的例子：1234567891011121314151617181920212223242526class A(object): def __init__(self): self.a=1 self.b=2 def func(self): pass def __getattr__(self,name): print 'getattr' return self.a def __setattr__(self, name, value): print 'setattr %s' % name if name == 'f': return object.__setattr__(self,name,value+1000) else: return object.__setattr__(self, name, value)a=A()a.f=1000print a.fout&gt;&gt;setattr aout&gt;&gt;setattr bout&gt;&gt;setattr fout&gt;&gt;2000 从输出可以看到init函数的self.a和self.b的赋值也经过了__setattr__，而且在赋值的时候我们自定义了一个if逻辑，如果name是‘f’，那么value会增加1000，最终的a.f是2000 __delattr__是删除一个对象属性用的。 14. __call__ 函数如果一个对象实现了__call__()函数，那么这个对象可以认为是一个函数对象，使用加括号的方法就可以调用，见下面例子：123456789101112131415class A(object): def __init__(self): self.li=['a','b','c','d'] def func(self): pass def __call__(self,n): #返回li列表的第n个元素 return self.li[n]a=A()#a可以当做函数一样调用print a(0),a(1),a(2)out&gt;&gt;a b c 在实际工作中__call__函数非常有用，可以把一个对象变成callable的对象. 参考 http://www.jianshu.com/p/1112320c5784","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Python之Pandas入门","slug":"python-pandas-2017-06-08","date":"2017-06-08T06:41:30.000Z","updated":"2017-09-08T03:51:40.118Z","comments":true,"path":"2017/06/08/python-pandas-2017-06-08/","link":"","permalink":"http://arvin-he.github.io/2017/06/08/python-pandas-2017-06-08/","excerpt":"","text":"这是一个简短的为新手入门的pandas教程,更高级的用法请查看ccokbook这里安装numpy, mayplotlit 和 pandas省略.首先导入如下包12345In [1]: import pandas as pdIn [2]: import numpy as npIn [3]: import matplotlib.pyplot as plt 对象创建传递一个list来创建一个 Series 对象, pandas会自动创建索引1234567891011In [4]: s = pd.Series([1,3,5,np.nan, 6, 8])In [5]: sOut[5]:0 1.01 3.02 5.03 NaN4 6.05 8.0dtype: float64 传递一个numpy的array创建一个DataFrame对象, 同时以datetime为索引和带label的列DataFrame 是有多个列的数据表，每个列拥有一个 label，当然，DataFrame 也有索引1234567891011121314151617181920# 创建datetime索引In [6]: dates = pd.date_range('20170608', periods=6)In [7]: datesOut[7]:DatetimeIndex(['2017-06-08', '2017-06-09', '2017-06-10', '2017-06-11', '2017-06-12', '2017-06-13'], dtype='datetime64[ns]', freq='D')In [8]: df = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))In [9]: dfOut[9]: A B C D2017-06-08 -0.561773 0.881191 -2.697783 -0.0346722017-06-09 -0.053409 0.814811 0.294231 -1.7537442017-06-10 -1.699722 0.971518 -2.592852 1.0884732017-06-11 -2.411028 0.312229 -1.879164 1.3884842017-06-12 -0.173929 -0.572149 2.044024 -0.1012232017-06-13 -0.906777 -0.207889 -0.776134 2.327599 传递一个dict来创建一个DataFrame, 每个 dict 的 value 会被转化成一个 Series,可以认为，DataFrame 是由多个 Series 组成的123456789101112131415In [10]: df2 = pd.DataFrame(&#123; ...: 'A': 1., ...: 'B': pd.Timestamp('20170608'), ...: 'C': pd.Series(1, index=list(range(4)), dtype='float32'), ...: 'D': np.array([3]*4, dtype='int32'), ...: 'E': pd.Categorical(['test', 'train', 'test', 'train']), ...: 'F': 'foo'&#125;)In [11]: df2Out[11]: A B C D E F0 1.0 2017-06-08 1.0 3 test foo1 1.0 2017-06-08 1.0 3 train foo2 1.0 2017-06-08 1.0 3 test foo3 1.0 2017-06-08 1.0 3 train foo 每列数据的格式用 dtypes 查看123456789In [12]: df2.dtypesOut[12]:A float64B datetime64[ns]C float32D int32E categoryF objectdtype: object 数据查看查看指定列的数据1234567In [15]: df2.AOut[15]:0 1.01 1.02 1.03 1.0Name: A, dtype: float64 用 head 和 tail 查看顶端和底端的几列, head()和tail()函数默认值都是5123456789101112131415161718192021222324252627282930In [16]: df.head() Out[16]: A B C D 2017-06-08 -0.561773 0.881191 -2.697783 -0.034672 2017-06-09 -0.053409 0.814811 0.294231 -1.753744 2017-06-10 -1.699722 0.971518 -2.592852 1.088473 2017-06-11 -2.411028 0.312229 -1.879164 1.388484 2017-06-12 -0.173929 -0.572149 2.044024 -0.101223 In [17]: df.tail(3) Out[17]: A B C D 2017-06-11 -2.411028 0.312229 -1.879164 1.388484 2017-06-12 -0.173929 -0.572149 2.044024 -0.101223 2017-06-13 -0.906777 -0.207889 -0.776134 2.327599 In [18]: df.head(2) Out[18]: A B C D 2017-06-08 -0.561773 0.881191 -2.697783 -0.034672 2017-06-09 -0.053409 0.814811 0.294231 -1.753744 In [19]: df.tail() Out[19]: A B C D 2017-06-09 -0.053409 0.814811 0.294231 -1.753744 2017-06-10 -1.699722 0.971518 -2.592852 1.088473 2017-06-11 -2.411028 0.312229 -1.879164 1.388484 2017-06-12 -0.173929 -0.572149 2.044024 -0.101223 2017-06-13 -0.906777 -0.207889 -0.776134 2.327599 单独查看 index 和 columns 和 数据, DataFrame 内部用 numpy 格式存储数据1234567891011121314151617In [20]: df.indexOut[20]:DatetimeIndex(['2017-06-08', '2017-06-09', '2017-06-10', '2017-06-11', '2017-06-12', '2017-06-13'], dtype='datetime64[ns]', freq='D')In [21]: df.columnsOut[21]: Index(['A', 'B', 'C', 'D'], dtype='object')In [22]: df.valuesOut[22]:array([[-0.56177253, 0.88119144, -2.6977834 , -0.03467225], [-0.05340873, 0.81481114, 0.29423114, -1.75374372], [-1.69972161, 0.97151768, -2.59285248, 1.08847275], [-2.41102846, 0.3122287 , -1.87916396, 1.38848363], [-0.17392908, -0.57214913, 2.04402398, -0.10122313], [-0.90677665, -0.20788934, -0.77613381, 2.32759919]]) describe() 显示数据的概要。1234567891011In [23]: df.describe()Out[23]: A B C Dcount 6.000000 6.000000 6.000000 6.000000mean -0.967773 0.366618 -0.934613 0.485819std 0.922339 0.639667 1.852466 1.428378min -2.411028 -0.572149 -2.697783 -1.75374425% -1.501485 -0.077860 -2.414430 -0.08458550% -0.734275 0.563520 -1.327649 0.52690075% -0.270890 0.864596 0.026640 1.313481max -0.053409 0.971518 2.044024 2.327599 和 numpy 一样，可以方便的得到转置,就是行列转换1234567In [24]: df.TOut[24]: 2017-06-08 2017-06-09 2017-06-10 2017-06-11 2017-06-12 2017-06-13A -0.561773 -0.053409 -1.699722 -2.411028 -0.173929 -0.906777B 0.881191 0.814811 0.971518 0.312229 -0.572149 -0.207889C -2.697783 0.294231 -2.592852 -1.879164 2.044024 -0.776134D -0.034672 -1.753744 1.088473 1.388484 -0.101223 2.327599 对 axis 按照 index 排序（axis=1 是指根据列名来排序, axis=0 是根据行名来排序）123456789In [26]: df.sort_index(axis=1, ascending=False)Out[26]: D C B A2017-06-08 -0.034672 -2.697783 0.881191 -0.5617732017-06-09 -1.753744 0.294231 0.814811 -0.0534092017-06-10 1.088473 -2.592852 0.971518 -1.6997222017-06-11 1.388484 -1.879164 0.312229 -2.4110282017-06-12 -0.101223 2.044024 -0.572149 -0.1739292017-06-13 2.327599 -0.776134 -0.207889 -0.906777 按值排序123456789In [30]: df.sort_values(by='B')Out[30]: A B C D2017-06-12 -0.173929 -0.572149 2.044024 -0.1012232017-06-13 -0.906777 -0.207889 -0.776134 2.3275992017-06-11 -2.411028 0.312229 -1.879164 1.3884842017-06-09 -0.053409 0.814811 0.294231 -1.7537442017-06-08 -0.561773 0.881191 -2.697783 -0.0346722017-06-10 -1.699722 0.971518 -2.592852 1.088473 选择注意: 以下这些对交互式环境很友好，但是作为 production code 请用优化过的 .at, .iat, .loc, .iloc, .ix等. 获取行/列从 DataFrame 选择一个列，就得到了 Series123456789In [31]: df['A']Out[31]:2017-06-08 -0.5617732017-06-09 -0.0534092017-06-10 -1.6997222017-06-11 -2.4110282017-06-12 -0.1739292017-06-13 -0.906777Freq: D, Name: A, dtype: float64 使用[] 对行切片123456In [35]: df[0:3]Out[35]: A B C D2017-06-08 -0.561773 0.881191 -2.697783 -0.0346722017-06-09 -0.053409 0.814811 0.294231 -1.7537442017-06-10 -1.699722 0.971518 -2.592852 1.088473 通过标签选择通过时间戳的下标（dates[0] = Timestamp(‘20130101’)）来访问1234567In [36]: df.loc[dates[1]]Out[36]:A -0.053409B 0.814811C 0.294231D -1.753744Name: 2017-06-09 00:00:00, dtype: float64 选择多个标签123456789In [38]: df.loc[:,['A', 'B']]Out[38]: A B2017-06-08 -0.561773 0.8811912017-06-09 -0.053409 0.8148112017-06-10 -1.699722 0.9715182017-06-11 -2.411028 0.3122292017-06-12 -0.173929 -0.5721492017-06-13 -0.906777 -0.207889 注意那个冒号，用法和 MATLAB 或 NumPy 是一样的！所以也可以这样123456In [39]: df.loc[dates[0]:dates[2], ['A', 'B']]Out[39]: A B2017-06-08 -0.561773 0.8811912017-06-09 -0.053409 0.8148112017-06-10 -1.699722 0.971518 依旧和 MATLAB 一样，当有一个维度是标量（而不是范围或序列）的时候，选择出的矩阵维度会减少12345In [40]: df.loc[dates[0], ['A', 'B']]Out[40]:A -0.561773B 0.881191Name: 2017-06-08 00:00:00, dtype: float64 如果对所有的维度都写了标量，不就是选出一个元素吗？12In [41]: df.loc[dates[0], 'A']Out[41]: -0.56177252662051747 这种情况通常用 at ，速度更快12In [42]: df.at[dates[0], 'A']Out[42]: -0.56177252662051747 通过位置选择,即整数下标选择, 和 MATLAB 完全一样这个就和数组类似啦，直接看例子。选出第4行：1234567In [43]: df.iloc[3]Out[43]:A -2.411028B 0.312229C -1.879164D 1.388484Name: 2017-06-11 00:00:00, dtype: float64 选出3~4行，0~1列：12345In [45]: df.iloc[3:5, 0:2]Out[45]: A B2017-06-11 -2.411028 0.3122292017-06-12 -0.173929 -0.572149 也能用 list 选择, 挑出指定行和列123456In [46]: df.iloc[[1, 2, 4], [0, 3]]Out[46]: A D2017-06-09 -0.053409 -1.7537442017-06-10 -1.699722 1.0884732017-06-12 -0.173929 -0.101223 也可以用slice12345In [47]: df.iloc[1:3, 1:3]Out[47]: B C2017-06-09 0.814811 0.2942312017-06-10 0.971518 -2.592852 选择单个元素12345In [48]: df.iloc[0,0]Out[48]: -0.56177252662051747In [49]: df.iat[0,0]Out[49]: -0.56177252662051747 布尔值索引根据单列的值来选择数据1234In [7]: df[df.A &gt; 0]Out[7]: A B C D2017-06-13 0.909448 -0.302722 -2.198783 -0.47542 从DataFrame中选择符合条件的值, 其中不符合条件的用NaN填充123456789In [8]: df[df &gt; 0]Out[8]: A B C D2017-06-08 NaN NaN NaN NaN2017-06-09 NaN 1.297100 NaN 0.2317422017-06-10 NaN 2.380203 NaN NaN2017-06-11 NaN 2.262221 1.135382 1.1661442017-06-12 NaN NaN NaN NaN2017-06-13 0.909448 NaN NaN NaN isin() 函数：是否在集合中, 用来过滤数据12345678910111213141516171819In [9]: df2 = df.copy()In [10]: df2['E'] = ['one', 'two', 'three', 'four', 'three', 'one']In [11]: df2Out[11]: A B C D E2017-06-08 -0.993188 -0.098497 -0.898984 -0.060261 one2017-06-09 -0.262396 1.297100 -0.161798 0.231742 two2017-06-10 -1.792578 2.380203 -0.116943 -1.486425 three2017-06-11 -2.126554 2.262221 1.135382 1.166144 four2017-06-12 -0.421283 -1.725798 -0.588929 -0.191101 three2017-06-13 0.909448 -0.302722 -2.198783 -0.475420 oneIn [12]: df2[df2['E'].isin(['two', 'four'])]Out[12]: A B C D E2017-06-09 -0.262396 1.297100 -0.161798 0.231742 two2017-06-11 -2.126554 2.262221 1.135382 1.166144 four 设置 setting为 DataFrame 增加新的列，按 index 对应1234567891011121314151617181920212223In [13]: s1 = pd.Series([1,2,3,4,5,6], index=pd.date_range('20170608', periods=6))In [14]: s1Out[14]:2017-06-08 12017-06-09 22017-06-10 32017-06-11 42017-06-12 52017-06-13 6Freq: D, dtype: int64In [15]: df['F'] = s1In [16]: dfOut[16]: A B C D F2017-06-08 -0.993188 -0.098497 -0.898984 -0.060261 12017-06-09 -0.262396 1.297100 -0.161798 0.231742 22017-06-10 -1.792578 2.380203 -0.116943 -1.486425 32017-06-11 -2.126554 2.262221 1.135382 1.166144 42017-06-12 -0.421283 -1.725798 -0.588929 -0.191101 52017-06-13 0.909448 -0.302722 -2.198783 -0.475420 6 通过label, 下标和numpy数组设置值12345678910111213141516# 通过label设置值In [17]: df.at[dates[0], 'A'] = 0# 通过下标设置值In [19]: df.iat[0,1] = 0# 用 numpy 数组设置值In [21]: df.loc[:, 'D'] = np.array([5] * len(df))In [23]: dfOut[23]: A B C D F2017-06-08 0.000000 0.000000 -0.898984 5 12017-06-09 -0.262396 1.297100 -0.161798 5 22017-06-10 -1.792578 2.380203 -0.116943 5 32017-06-11 -2.126554 2.262221 1.135382 5 42017-06-12 -0.421283 -1.725798 -0.588929 5 52017-06-13 0.909448 -0.302722 -2.198783 5 6 通过布尔值设置值1234567891011In [28]: df[df&gt;0] = -dfIn [29]: dfOut[29]: A B C D F2017-06-08 0.000000 0.000000 -0.898984 -5 -12017-06-09 -0.262396 -1.297100 -0.161798 -5 -22017-06-10 -1.792578 -2.380203 -0.116943 -5 -32017-06-11 -2.126554 -2.262221 -1.135382 -5 -42017-06-12 -0.421283 -1.725798 -0.588929 -5 -52017-06-13 -0.909448 -0.302722 -2.198783 -5 -6 缺失值pandas 用 np.nan 表示缺失值。通常它不会被计算。Reindexing 允许你改变/增加/删除 指定轴的index, 并返回数据的拷贝1234567891011In [30]: df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + ['E'])In [31]: df1.loc[dates[0]:dates[1], 'E'] = 1In [32]: df1Out[32]: A B C D F E2017-06-08 0.000000 0.000000 -0.898984 -5 -1 1.02017-06-09 -0.262396 -1.297100 -0.161798 -5 -2 1.02017-06-10 -1.792578 -2.380203 -0.116943 -5 -3 NaN2017-06-11 -2.126554 -2.262221 -1.135382 -5 -4 NaN 丢弃有NaN的行12345In [33]: df1.dropna() # 或者 df1.dropna(how='any')Out[33]: A B C D F E2017-06-08 0.000000 0.0000 -0.898984 -5 -1 1.02017-06-09 -0.262396 -1.2971 -0.161798 -5 -2 1.0 填充缺失值1234567In [35]: df1.fillna(value=5)Out[35]: A B C D F E2017-06-08 0.000000 0.000000 -0.898984 -5 -1 1.02017-06-09 -0.262396 -1.297100 -0.161798 -5 -2 1.02017-06-10 -1.792578 -2.380203 -0.116943 -5 -3 5.02017-06-11 -2.126554 -2.262221 -1.135382 -5 -4 5.0 获取布尔值的 mask：哪些值是 NaN, 则为true,否则为false123456789101112131415In [36]: pd.isnull(df1)Out[36]: A B C D F E2017-06-08 False False False False False False2017-06-09 False False False False False False2017-06-10 False False False False False True2017-06-11 False False False False False TrueIn [37]: df1Out[37]: A B C D F E2017-06-08 0.000000 0.000000 -0.898984 -5 -1 1.02017-06-09 -0.262396 -1.297100 -0.161798 -5 -2 1.02017-06-10 -1.792578 -2.380203 -0.116943 -5 -3 NaN2017-06-11 -2.126554 -2.262221 -1.135382 -5 -4 NaN 注意: 这里的df1数据其实没有改变, 返回的是运算后的数据拷贝 操作说明: 操作都会把NaN(缺失值)排除在外 统计平均值1234567891011121314151617181920# 对每一列做平均值In [38]: df.mean() # df.mean(0)Out[38]:A -0.918710B -1.328007C -0.850137D -5.000000F -3.500000dtype: float64# 对每一行做平均值In [40]: df.mean(1)Out[40]:2017-06-08 -1.3797972017-06-09 -1.7442592017-06-10 -2.4579452017-06-11 -2.9048312017-06-12 -2.5472022017-06-13 -2.882190Freq: D, dtype: float64 操作具有不同维度的对象需要对齐。pandas会沿着指定的维度自动广播12345678910111213141516171819202122232425262728293031In [42]: s = pd.Series([1, 3, 5, np.nan, 6, 8], index=dates).shift(2)In [43]: sOut[43]:2017-06-08 NaN2017-06-09 NaN2017-06-10 1.02017-06-11 3.02017-06-12 5.02017-06-13 NaNFreq: D, dtype: float64In [45]: df.sub(s, axis='index')Out[45]: A B C D F2017-06-08 NaN NaN NaN NaN NaN2017-06-09 NaN NaN NaN NaN NaN2017-06-10 -2.792578 -3.380203 -1.116943 -6.0 -4.02017-06-11 -5.126554 -5.262221 -4.135382 -8.0 -7.02017-06-12 -5.421283 -6.725798 -5.588929 -10.0 -10.02017-06-13 NaN NaN NaN NaN NaNIn [46]: dfOut[46]: A B C D F2017-06-08 0.000000 0.000000 -0.898984 -5 -12017-06-09 -0.262396 -1.297100 -0.161798 -5 -22017-06-10 -1.792578 -2.380203 -0.116943 -5 -32017-06-11 -2.126554 -2.262221 -1.135382 -5 -42017-06-12 -0.421283 -1.725798 -0.588929 -5 -52017-06-13 -0.909448 -0.302722 -2.198783 -5 -6 Apply对数据（行或列） Apply 函数123456789101112131415161718In [47]: df.apply(np.cumsum)Out[47]: A B C D F2017-06-08 0.000000 0.000000 -0.898984 -5 -12017-06-09 -0.262396 -1.297100 -1.060782 -10 -32017-06-10 -2.054974 -3.677303 -1.177726 -15 -62017-06-11 -4.181527 -5.939523 -2.313108 -20 -102017-06-12 -4.602811 -7.665321 -2.902037 -25 -152017-06-13 -5.512259 -7.968043 -5.100820 -30 -21In [48]: df.apply(lambda x: x.max() -x.min())Out[48]:A 2.126554B 2.380203C 2.081839D 0.000000F 5.000000dtype: float64 直方图12345678910111213141516171819202122232425In [49]: s = pd.Series(np.random.randint(0, 7, size=10))In [50]: sOut[50]:0 01 42 63 24 65 66 07 08 39 1dtype: int32In [52]: s.value_counts() Out[52]: 6 3 0 3 4 1 3 1 2 1 1 1 dtype: int64 字符串方法1234567891011121314In [53]: s = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca', np.nan, 'CABA', 'dog', 'cat'])In [54]: s.str.lower()Out[54]:0 a1 b2 c3 aaba4 baca5 NaN6 caba7 dog8 catdtype: object Mergeconcat简单地按行拼接123456789101112131415161718192021222324252627282930313233343536373839404142434445464748In [55]: df = pd.DataFrame(np.random.randn(10, 4))In [56]: dfOut[56]: 0 1 2 30 1.279835 0.488299 0.122145 1.0661591 -0.566047 -0.625790 -0.941786 -0.2099942 0.364785 1.185549 -0.381762 1.7528953 -0.568627 -0.235160 -1.602423 0.6039794 0.698751 -1.656823 -0.306150 2.0193425 -0.423725 1.321606 0.894416 -0.2492826 -0.125866 -2.315650 0.376551 1.0505067 -0.189071 -0.933617 -0.051930 -0.3752528 0.478909 -2.041329 1.217890 -1.0207019 -1.287622 -0.173968 0.387218 -0.004477# 拆分成pieceIn [57]: pieces = [df[:3], df[3:7], df[7:]]In [58]: piecesOut[58]:[ 0 1 2 3 0 1.279835 0.488299 0.122145 1.066159 1 -0.566047 -0.625790 -0.941786 -0.209994 2 0.364785 1.185549 -0.381762 1.752895, 0 1 2 3 3 -0.568627 -0.235160 -1.602423 0.603979 4 0.698751 -1.656823 -0.306150 2.019342 5 -0.423725 1.321606 0.894416 -0.249282 6 -0.125866 -2.315650 0.376551 1.050506, 0 1 2 3 7 -0.189071 -0.933617 -0.051930 -0.375252 8 0.478909 -2.041329 1.217890 -1.020701 9 -1.287622 -0.173968 0.387218 -0.004477]In [59]: pd.concat(pieces)Out[59]: 0 1 2 30 1.279835 0.488299 0.122145 1.0661591 -0.566047 -0.625790 -0.941786 -0.2099942 0.364785 1.185549 -0.381762 1.7528953 -0.568627 -0.235160 -1.602423 0.6039794 0.698751 -1.656823 -0.306150 2.0193425 -0.423725 1.321606 0.894416 -0.2492826 -0.125866 -2.315650 0.376551 1.0505067 -0.189071 -0.933617 -0.051930 -0.3752528 0.478909 -2.041329 1.217890 -1.0207019 -1.287622 -0.173968 0.387218 -0.004477 join和 SQL 的 join 是一个意思1234567891011121314151617181920212223In [60]: left = pd.DataFrame(&#123;'key': ['foo', 'foo'], 'lval': [1, 2]&#125;)In [61]: right = pd.DataFrame(&#123;'key': ['foo', 'foo'], 'rval': [4, 5]&#125;)In [62]: leftOut[62]: key lval0 foo 11 foo 2In [63]: rightOut[63]: key rval0 foo 41 foo 5In [64]: pd.merge(left, right, on='key')Out[64]: key lval rval0 foo 1 41 foo 1 52 foo 2 43 foo 2 5 Append向 DataFrame 增加新的数据行12345678910111213141516171819202122232425262728In [65]: df = pd.DataFrame(np.random.randn(8, 4), columns=['A','B','C','D'])In [66]: dfOut[66]: A B C D0 -0.303120 0.419378 0.111816 -0.1601041 0.924466 2.385372 -1.575671 -1.7892832 1.106048 -0.087699 1.714677 -0.0588313 0.765727 0.101523 -1.204472 0.0111804 -2.084695 -0.517287 -0.497699 0.1535165 -0.252460 0.044590 -0.481047 0.6178176 -0.121789 -1.663595 -0.464836 -0.8584577 -0.246298 0.687569 -2.081519 -1.529134In [67]: s = df.iloc[3]In [68]: df.append(s, ignore_index=True)Out[68]: A B C D0 -0.303120 0.419378 0.111816 -0.1601041 0.924466 2.385372 -1.575671 -1.7892832 1.106048 -0.087699 1.714677 -0.0588313 0.765727 0.101523 -1.204472 0.0111804 -2.084695 -0.517287 -0.497699 0.1535165 -0.252460 0.044590 -0.481047 0.6178176 -0.121789 -1.663595 -0.464836 -0.8584577 -0.246298 0.687569 -2.081519 -1.5291348 0.765727 0.101523 -1.204472 0.011180 Grouping和 SQL 中的 GROUP BY 类似，包括以下这几步： 根据某些规则，把数据分组 对每组应用一个函数 合并结果到一个数据结构中 12345678910111213141516171819202122232425262728293031323334353637In [69]: df = pd.DataFrame(&#123; ...: 'A' : ['foo', 'bar', 'foo', 'bar','foo', 'bar', 'foo', 'foo'], ...: 'B' : ['one', 'one', 'two', 'three','two', 'two', 'one', 'three'], ...: 'C' : np.random.randn(8), ...: 'D' : np.random.randn(8)&#125;)In [70]: dfOut[70]: A B C D0 foo one -1.203566 -1.1990381 bar one 2.368016 -1.0596562 foo two -0.704544 -1.0477943 bar three -0.511092 1.1218594 foo two -0.723414 -1.2255365 bar two -0.363631 0.1111776 foo one 0.271759 0.5007987 foo three -0.248960 2.035166# 做 Group 操作并对每组求和In [71]: df.groupby('A').sum()Out[71]: C DAbar 1.493293 0.173380foo -2.608725 -0.936404# 可以对两列进行 Group by 并求和In [72]: df.groupby(['A', 'B']).sum()Out[72]: C DA Bbar one 2.368016 -1.059656 three -0.511092 1.121859 two -0.363631 0.111177foo one -0.931807 -0.698240 three -0.248960 2.035166 two -1.427958 -2.273330 ReshapeStack 叠层准备数据12345678910111213141516171819202122232425262728293031323334353637In [73]: tuples = list(zip(*[['bar', 'bar', 'baz', 'baz', ...: 'foo', 'foo', 'qux', 'qux'], ...: ['one', 'two', 'one', 'two', ...: 'one', 'two', 'one', 'two']]))In [75]: index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])In [76]: df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=['A','B'])In [77]: df2 = df[:4]In [78]: df2Out[78]: A Bfirst secondbar one 0.181096 -0.610853 two -1.326709 0.269153baz one -0.455180 -0.070055 two -0.953993 -0.235160``` stack() 把 DataFrame 的所有列“压缩”到 index 里去```pythonIn [79]: stacked = df2.stack()In [80]: stackedOut[80]:first secondbar one A 0.181096 B -0.610853 two A -1.326709 B 0.269153baz one A -0.455180 B -0.070055 two A -0.953993 B -0.235160dtype: float64 反之，只要是 MultiIndex 都可以用 unstack() 恢复出列，默认把最后一个 index 解开1234567891011121314151617181920212223242526In [81]: stacked.unstack()Out[81]: A Bfirst secondbar one 0.181096 -0.610853 two -1.326709 0.269153baz one -0.455180 -0.070055 two -0.953993 -0.235160In [82]: stacked.unstack(1)Out[82]:second one twofirstbar A 0.181096 -1.326709 B -0.610853 0.269153baz A -0.455180 -0.953993 B -0.070055 -0.235160In [83]: stacked.unstack(0)Out[83]:first bar bazsecondone A 0.181096 -0.455180 B -0.610853 -0.070055two A -1.326709 -0.953993 B 0.269153 -0.235160 Pivot Table 旋转准备数据123456789101112131415161718192021In [84]: df = pd.DataFrame(&#123;'A' : ['one', 'one', 'two', 'three'] * 3, ...: 'B' : ['A', 'B', 'C'] * 4, ...: 'C' : ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'] * 2, ...: 'D' : np.random.randn(12), ...: 'E' : np.random.randn(12)&#125;)In [85]: dfOut[85]: A B C D E0 one A foo -0.379428 -0.0506811 one B foo 1.650807 0.0245302 two C foo 0.349554 1.2026923 three A bar -1.516381 -0.1633824 one B bar 0.360722 -0.2416225 one C bar -0.276398 0.5811926 two A foo 0.304563 -0.6632717 three B foo 1.328499 0.4852238 one C foo 1.665213 -0.5778439 one A bar -0.229248 -0.33532910 two B bar -0.133112 1.11935011 three C bar -0.383992 0.787800 pivot 是把原来的数据(values)作为新表的行(index)、列(columns)12345678910111213In [86]: pd.pivot_table(df, values='D', index=['A', 'B'], columns=['C'])Out[86]:C bar fooA Bone A -0.229248 -0.379428 B 0.360722 1.650807 C -0.276398 1.665213three A -1.516381 NaN B NaN 1.328499 C -0.383992 NaNtwo A NaN 0.304563 B -0.133112 NaN C NaN 0.349554 时间序列pandas 的时间序列功能在金融应用中很有用。 resample功能12345678In [88]: rng = pd.date_range('9/6/2017', periods=100, freq='S')In [89]: ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)In [90]: ts.resample('5Min').sum()Out[90]:2017-09-06 26085Freq: 5T, dtype: int32 时区表示1234567891011121314151617181920212223In [94]: rng = pd.date_range('9/6/2017 00:00', periods=5, freq='D')In [95]: ts = pd.Series(np.random.randn(len(rng)), rng)In [96]: tsOut[96]:2017-09-06 -0.7158372017-09-07 1.0214482017-09-08 1.1865082017-09-09 0.6068522017-09-10 0.566530Freq: D, dtype: float64In [97]: ts_utc = ts.tz_localize('UTC')In [98]: ts_utcOut[98]:2017-09-06 00:00:00+00:00 -0.7158372017-09-07 00:00:00+00:00 1.0214482017-09-08 00:00:00+00:00 1.1865082017-09-09 00:00:00+00:00 0.6068522017-09-10 00:00:00+00:00 0.566530Freq: D, dtype: float64 时区转换12345678In [100]: ts_utc.tz_convert('US/Eastern')Out[100]:2017-09-05 20:00:00-04:00 -0.7158372017-09-06 20:00:00-04:00 1.0214482017-09-07 20:00:00-04:00 1.1865082017-09-08 20:00:00-04:00 0.6068522017-09-09 20:00:00-04:00 0.566530Freq: D, dtype: float64 在时间跨度表示之间进行转换1234567891011121314151617181920212223242526272829303132333435363738394041424344454647In [101]: rng = pd.date_range('9/6/2017', periods=5, freq='M')In [102]: ts = pd.Series(np.random.randn(len(rng)), index=rng)In [103]: tsOut[103]:2017-09-30 -0.3378672017-10-31 0.5468832017-11-30 0.0630042017-12-31 0.4196362018-01-31 2.562404Freq: M, dtype: float64In [104]: ps = ts.to_period()In [105]: psOut[105]:2017-09 -0.3378672017-10 0.5468832017-11 0.0630042017-12 0.4196362018-01 2.562404Freq: M, dtype: float64In [106]: ps.to_timestamp()Out[106]:2017-09-01 -0.3378672017-10-01 0.5468832017-11-01 0.0630042017-12-01 0.4196362018-01-01 2.562404Freq: MS, dtype: float64In [107]: prng = pd.period_range('1990Q1', '2000Q4', freq='Q-NOV')In [108]: ts = pd.Series(np.random.randn(len(prng)), prng)In [109]: ts.index = (prng.asfreq('M', 'e') + 1).asfreq('H', 's') + 9In [110]: ts.head()Out[110]:1990-03-01 09:00 -0.3156631990-06-01 09:00 2.0925101990-09-01 09:00 0.3373021990-12-01 09:00 0.0378931991-03-01 09:00 0.463572Freq: H, dtype: float64 类别123456789101112131415161718192021222324In [111]: df = pd.DataFrame(&#123;\"id\":[1,2,3,4,5,6], \"raw_grade\":['a', 'b', 'b', 'a', 'a', 'e']&#125;)In [112]: dfOut[112]: id raw_grade0 1 a1 2 b2 3 b3 4 a4 5 a5 6 eIn [113]: df['grade'] = df['raw_grade'].astype('category')In [114]: df['grade']Out[114]:0 a1 b2 b3 a4 a5 eName: grade, dtype: categoryCategories (3, object): [a, b, e] 类别可以 inplace 地赋值：（只是改一下对应的字符串嘛，类别是用 Index 对象存储的）In [115]: df[&#39;grade&#39;].cat.categories = [&quot;very good&quot;, &quot;good&quot;, &quot;very bad&quot;]修改类别时，如果有新的类别，会自动加进去123456789101112In [117]: df['grade'] = df['grade'].cat.set_categories([\"very bad\", \"bad\", \"medium\", \"good\", \"very good\"])In [118]: df['grade']Out[118]:0 very good1 good2 good3 very good4 very good5 very badName: grade, dtype: categoryCategories (5, object): [very bad, bad, medium, good, very good] 根据类别排序123456789In [119]: df.sort_values(by='grade')Out[119]: id raw_grade grade5 6 e very bad1 2 b good2 3 b good0 1 a very good3 4 a very good4 5 a very good 做 group by 的时候，空的类别也会被呈现出来123456789In [120]: df.groupby('grade').size()Out[120]:gradevery bad 1bad 0medium 0good 2very good 3dtype: int64 绘图123456In [121]: ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000))In [122]: ts = ts.cumsum()In [123]: ts.plot()Out[123]: &lt;matplotlib.axes._subplots.AxesSubplot at 0x6a0be10&gt; 对于DtaFrame,可以直接plot123456In [124]: df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index, columns=['A', 'B', 'C', 'D'])In [125]: df = df.cumsum()In [126]: plt.figure(); df.plot(); plt.legend(loc='best')Out[126]: &lt;matplotlib.legend.Legend at 0x6c3e8f0&gt; 读写数据CSV123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566In [127]: df.to_csv('foo.csv') In [128]: pd.read_csv('foo.csv') Out[128]: Unnamed: 0 A B C D 0 2000-01-01 1.239452 1.983851 0.578987 1.155658 1 2000-01-02 0.295568 3.704782 1.962402 0.885559 2 2000-01-03 -0.139800 3.872238 2.793025 0.972079 3 2000-01-04 -0.804336 3.259410 2.159552 1.785479 4 2000-01-05 0.171984 3.027446 2.253854 0.779544 5 2000-01-06 1.781807 1.836517 4.558960 1.999731 6 2000-01-07 0.650927 0.154262 3.650160 0.685396 7 2000-01-08 0.492898 -0.198763 3.646034 -0.073848 8 2000-01-09 -0.100468 -0.623716 3.217366 0.220008 9 2000-01-10 -0.905394 0.282200 3.153474 -0.189584 10 2000-01-11 -0.962155 -1.147225 3.353251 1.283288 11 2000-01-12 -1.853063 -1.539308 5.246351 0.222400 12 2000-01-13 -3.385665 -2.982384 3.952838 0.319281 13 2000-01-14 -4.411986 -2.914887 4.775386 0.597495 14 2000-01-15 -5.938706 -3.437068 6.882886 1.105879 15 2000-01-16 -6.537699 -1.947668 8.142251 0.948407 16 2000-01-17 -6.786304 -2.735740 8.484593 1.034685 17 2000-01-18 -7.145344 -1.666703 9.420653 -0.919941 18 2000-01-19 -8.283291 0.101307 10.654933 -0.936284 19 2000-01-20 -8.330414 0.820054 11.207165 -2.622354 20 2000-01-21 -7.942291 1.559753 9.201008 -2.923220 21 2000-01-22 -4.675543 2.337827 10.364670 -3.112916 22 2000-01-23 -5.774614 0.408297 9.441821 -2.040018 23 2000-01-24 -5.993547 -0.480329 10.311053 0.852373 24 2000-01-25 -4.137167 0.099883 10.224100 0.576367 25 2000-01-26 -2.866354 -0.772702 11.812000 1.671981 26 2000-01-27 -1.764316 -2.534161 11.634361 1.638750 27 2000-01-28 -3.220852 -3.353006 11.399995 -0.562762 28 2000-01-29 -0.889241 -2.794083 10.445614 0.473105 29 2000-01-30 0.428342 -3.857681 10.930199 -0.118981 .. ... ... ... ... ... 970 2002-08-28 -2.853884 -2.041226 28.387424 17.129529 971 2002-08-29 -5.058352 0.041153 28.095666 16.654813 972 2002-08-30 -4.478272 -1.613275 26.989764 17.653338 973 2002-08-31 -2.815382 -2.764649 26.197949 16.442647 974 2002-09-01 -2.621575 -2.785604 28.007243 14.962121 975 2002-09-02 -2.476145 -3.128888 27.541079 12.853070 976 2002-09-03 -0.483923 -3.061629 27.130099 13.401077 977 2002-09-04 -0.885055 -2.059356 26.139260 12.725815 978 2002-09-05 -3.438688 -3.060238 26.267361 13.601928 979 2002-09-06 -3.646110 -2.908451 27.639157 13.749199 980 2002-09-07 -3.742097 -5.843492 27.138204 14.621900 981 2002-09-08 -4.367495 -5.523435 26.429433 14.372776 982 2002-09-09 -6.481100 -7.691100 26.325775 14.060133 983 2002-09-10 -4.406432 -5.925796 25.808105 13.717117 984 2002-09-11 -5.747746 -6.226884 26.334882 13.539911 985 2002-09-12 -5.075507 -5.976265 25.582403 13.955776 986 2002-09-13 -5.957833 -4.514403 26.154568 15.948706 987 2002-09-14 -4.822016 -3.510714 26.770429 14.903106 988 2002-09-15 -5.413908 -3.678965 29.255640 15.903795 989 2002-09-16 -7.305733 -4.970404 30.726133 17.075891 990 2002-09-17 -6.921962 -3.342561 32.499852 15.309124 991 2002-09-18 -7.650811 -3.539989 31.823857 15.100428 992 2002-09-19 -7.680999 -2.289270 31.098525 12.891011 993 2002-09-20 -7.849671 -1.712562 31.364746 13.909086 994 2002-09-21 -8.739466 -2.122690 32.004201 14.095981 995 2002-09-22 -8.740361 -0.656488 29.674406 12.590248 996 2002-09-23 -6.309331 -0.986256 30.370786 13.450941 997 2002-09-24 -6.205371 -0.419119 30.260205 12.028273 998 2002-09-25 -7.573782 -2.492400 31.063298 12.361099 999 2002-09-26 -7.317950 -2.840246 31.560766 12.502660 HDF5123In [129]: df.to_hdf('foo.h5','df')In [130]: pd.read_hdf('foo.h5','df') Excel123In [131]: df.to_excel('foo.xlsx', sheet_name='Sheet1')In [132]: pd.read_excel('foo.xlsx', 'Sheet1', index_col=None, na_values=['NA']) 坑如下，不能直接把返回值当作布尔值。123456789101112131415161718In [131]: if pd.Series([False, True, False]): ...: print('I was true') ...:---------------------------------------------------------------------------ValueError Traceback (most recent call last)&lt;ipython-input-131-ec15f6b92216&gt; in &lt;module&gt;()----&gt; 1 if pd.Series([False, True, False]): 2 print('I was true') 3c:\\python34\\lib\\site-packages\\pandas\\core\\generic.py in __nonzero__(self) 953 raise ValueError(\"The truth value of a &#123;0&#125; is ambiguous. \" 954 \"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"--&gt; 955 .format(self.__class__.__name__)) 956 957 __bool__ = __nonzero__ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). 参考 pandas十分钟入门","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Python之Numpy使用","slug":"python-numpy-2017-06-08","date":"2017-06-08T01:34:41.000Z","updated":"2017-09-08T03:51:40.108Z","comments":true,"path":"2017/06/08/python-numpy-2017-06-08/","link":"","permalink":"http://arvin-he.github.io/2017/06/08/python-numpy-2017-06-08/","excerpt":"","text":"Numpy相关介绍NumPy 是一个 Python 包。 它代表 “Numeric Python”。 它是一个由多维数组对象和用于处理数组的例程集合组成的库。使用NumPy，开发人员可以执行以下操作： 数组的算数和逻辑运算。 傅立叶变换和用于图形操作的例程。 与线性代数有关的操作, NumPy 拥有线性代数和随机数生成的内置函数。 NumPy 通常与 SciPy（Scientific Python）和 Matplotlib（绘图库）一起使用。 这种组合广泛用于替代 MatLab，是一个流行的技术计算平台, 此外NumPy 是开源的. Numpy安装在命令行窗口,输入:pip install numpy, 回车后就自动安装. NumPy 之 Ndarray 对象NumPy 中定义的最重要的对象是称为 ndarray 的 N 维数组类型。它描述相同类型的元素集合。 可以使用基于零的索引访问集合中的项目。基本的ndarray是使用 NumPy 中的数组函数创建的, ndarray 对象由计算机内存中的一维连续区域组成，带有将每个元素映射到内存块中某个位置的索引方案。 内存块以按行（C 风格）或按列（FORTRAN 或 MatLab 风格）的方式保存元素。 numpy.array(object, dtype = None, copy = True, order = None, subok = False, ndmin = 0) 123456object 任何暴露数组接口方法的对象都会返回一个数组或任何（嵌套）序列。dtype 数组的所需数据类型，可选。copy 可选，默认为true，对象是否被复制。order C（按行）、F（按列）或A（任意，默认）。subok 默认情况下，返回的数组被强制为基类数组。 如果为true，则返回子类。ndimin 指定返回数组的最小维数。 123456789# 最小维度 import numpy as np a = np.array([1, 2, 3,4,5], ndmin = 2)b = np.array([1, 2, 3], dtype = complex) print(a)print(b)[[1, 2, 3, 4, 5]][ 1.+0.j, 2.+0.j, 3.+0.j] NumPy的数据类型NumPy 支持比 Python 更多种类的数值类型12345678910111213141516171819bool_ 存储为一个字节的布尔值（真或假）int_ 默认整数，相当于 C 的long，通常为int32或int64intc 相当于 C 的int，通常为int32或int64intp 用于索引的整数，相当于 C 的size_t，通常为int32或int64int8 字节（-128 ~ 127）int16 16 位整数（-32768 ~ 32767）int32 32 位整数（-2147483648 ~ 2147483647）int64 64 位整数（-9223372036854775808 ~ 9223372036854775807）uint8 8 位无符号整数（0 ~ 255）uint16 16 位无符号整数（0 ~ 65535）uint32 32 位无符号整数（0 ~ 4294967295）uint64 64 位无符号整数（0 ~ 18446744073709551615）float_ float64的简写float16 半精度浮点：符号位，5 位指数，10 位尾数float32 单精度浮点：符号位，8 位指数，23 位尾数float64 双精度浮点：符号位，11 位指数，52 位尾数complex_ complex128的简写complex64 复数，由两个 32 位浮点表示（实部和虚部）complex128 复数，由两个 64 位浮点表示（实部和虚部） 数据类型对象 (dtype)数据类型对象描述了对应于数组的固定内存块的解释，取决于以下方面： 数据类型（整数、浮点或者 Python 对象） 数据大小 字节序（小端或大端） 在结构化类型的情况下，字段的名称，每个字段的数据类型，和每个字段占用的内存块部分。 1234numpy.dtype(object, align, copy)Object：被转换为数据类型的对象。Align：如果为true，则向字段添加间隔，使其类似 C 的结构体。Copy ? 生成dtype对象的新副本，如果为flase，结果是内建数据类型对象的引用。 1234567891011121314# 使用数组标量类型 #int8，int16，int32，int64 可替换为等价的字符串 'i1'，'i2'，'i4'，以及其他。 import numpy as np dt = np.dtype(np.int32) dt2 = np.dtype('i4') # 使用端号标记dt3 = np.dtype('&gt;i4') print(dt)print(dt2)print(dt3)int32int32&gt;i4 1234567891011121314151617181920# 首先创建结构化数据类型。 import numpy as np dt = np.dtype([('age',np.int8)])# 将其应用于 ndarray 对象 a = np.array([(10,),(20,),(30,)], dtype = dt) student = np.dtype([('name','S20'), ('age', 'i1'), ('marks', 'f4')]) stu = np.array([('abc', 21, 50),('xyz', 18, 75)], dtype = student) print(dt)print(a)# 名称可用于访问 age 列的内容 print(a['age'])print(stu)# 输出结果[('age', 'i1')][(10,) (20,) (30,)][10 20 30][('abc', 21, 50.0), ('xyz', 18, 75.0)] 每个内建类型都有一个唯一定义它的字符代码：‘b’：布尔值‘i’：符号整数‘u’：无符号整数‘f’：浮点‘c’：复数浮点‘m’：时间间隔‘M’：日期时间‘O’：Python 对象‘S’, ‘a’：字节串‘U’：Unicode‘V’：原始数据（void） NumPy - 数组属性ndarray.shape : 返回一个包含数组维度的元组，可以用于调整数组大小1234567891011121314151617181920import numpy as np a = np.array([[1,2,3],[4,5,6]]) b = np.array([[1,2,3],[4,5,6]]) # 调整数组大小 b.shape = (3,2)c = a.reshape(3,2)print(a.shape)print(b)print(c)# 输出(2, 3)[[1, 2] [3, 4] [5, 6]][[1, 2] [3, 4] [5, 6]] ndarray.ndim返回数组的维数。numpy.itemsize返回数组中每个元素的字节单位长度。 1234567891011121314151617181920212223242526In [1]: import numpy as npIn [5]: b = np.arange(24) In [6]: print(b) [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23] In [7]: c = b.reshape(2, 4, 3) In [8]: print(c) [[[ 0 1 2] [ 3 4 5] [ 6 7 8] [ 9 10 11]] [[12 13 14] [15 16 17] [18 19 20] [21 22 23]]] In [9]: print(c.ndim) 3 In [10]: x = np.array([1,2,3,4,5], dtype = np.int8)In [11]: print(x.itemsize)1 numpy.flags: 返回了它们的当前标志 C_CONTIGUOUS (C) 数组位于单一的、C 风格的连续区段内 F_CONTIGUOUS (F) 数组位于单一的、Fortran 风格的连续区段内 OWNDATA (O) 数组的内存从其它对象处借用 WRITEABLE (W) 数据区域可写入。 将它设置为flase会锁定数据，使其只读 ALIGNED (A) 数据和任何元素会为硬件适当对齐 UPDATEIFCOPY (U) 这个数组是另一数组的副本。当这个数组释放时，源数组会由这个数组中的元素更新 NumPy - 数组创建例程numpy.empty它创建指定形状和dtype的未初始化数组。 它使用以下构造函数：numpy.empty(shape, dtype = float, order = &#39;C&#39;)注意：数组元素为随机值，因为它们未初始化。numpy.zeros返回特定大小，以 0 填充的新数组。 numpy.zeros(shape, dtype = float, order = &#39;C&#39;)numpy.ones返回特定大小，以 1 填充的新数组。 numpy.ones(shape, dtype = None, order = &#39;C&#39;)12345678910111213141516171819202122232425In [1]: import numpy as npIn [2]: x = np.empty([3,2], dtype=int)In [3]: print(x)[[64618546 64654448] [64655120 64654288] [64654960 64654864]]In [4]: y = np.zeros(5)In [5]: print(y)[ 0. 0. 0. 0. 0.]# 自定义类型In [6]: a = np.zeros((2,2), dtype = [('x', 'i4'), ('y', 'i4')])In [7]: print(a)[[(0, 0) (0, 0)] [(0, 0) (0, 0)]]In [8]: b = np.ones(5)In [9]: print(b)[ 1. 1. 1. 1. 1.] NumPy来自现有数据的数组numpy.asarray将 Python 序列转换为ndarray。 numpy.asarray(a, dtype = None, order = None)其中: a 任意形式的输入参数，比如列表、列表的元组、元组、元组的元组、元组的列表numpy.frombuffer此函数将缓冲区解释为一维数组。 暴露缓冲区接口的任何对象都用作参数来返回ndarray。numpy.frombuffer(buffer, dtype = float, count = -1, offset = 0) buffer 任何暴露缓冲区接口的对象 dtype 返回数组的数据类型，默认为float count 需要读取的数据数量，默认为-1，读取所有数据 offset 需要读取的起始位置，默认为0 numpy.fromiter从任何可迭代对象构建一个ndarray对象，返回一个新的一维数组。numpy.fromiter(iterable, dtype, count = -1)1234567891011121314In [12]: s = 'Hello World'In [13]: c = np.frombuffer(s, dtype='S1')---------------------------------------------------------------------------AttributeError Traceback (most recent call last)&lt;ipython-input-13-e77d207ef97e&gt; in &lt;module&gt;()----&gt; 1 c = np.frombuffer(s, dtype='S1')AttributeError: 'str' object has no attribute '__buffer__'In [15]: c = np.fromiter(s, dtype='S1')In [16]: print(c)[b'H' b'e' b'l' b'l' b'o' b' ' b'W' b'o' b'r' b'l' b'd'] NumPy来自数值范围的数组numpy.arange返回ndarray对象，包含给定范围内的等间隔值。numpy.arange(start, stop, step, dtype)numpy.linspace指定了范围之间的均匀间隔数量，而不是步长. numpy.linspace(start, stop, num, endpoint, retstep, dtype) start 序列的起始值 stop 序列的终止值，如果endpoint为true，该值包含于序列中 num 要生成的等间隔样例数量，默认为50 endpoint 序列中是否包含stop值，默认为ture retstep 如果为true，返回样例，以及连续数字之间的步长 dtype 输出ndarray的数据类型 numpy.logspace返回一个ndarray对象，其中包含在对数刻度上均匀分布的数字。 刻度的开始和结束端点是某个底数的幂，通常为 10。numpy.logscale(start, stop, num, endpoint, base, dtype) start 起始值是base ** start stop 终止值是base ** stop num 范围内的数值数量，默认为50 endpoint 如果为true，终止值包含在输出数组当中 base 对数空间的底数，默认为10 dtype 输出数组的数据类型，如果没有提供，则取决于其它参数 1234567891011121314151617181920212223In [17]: d = np.linspace(10, 20, 5)In [18]: print(d)[ 10. 12.5 15. 17.5 20. ]In [19]: e = np.linspace(10, 20, 5, endpoint=False)In [20]: print(e)[ 10. 12. 14. 16. 18.]In [22]: f = np.linspace(10, 20, 5, retstep=True)In [23]: print(f)(array([ 10. , 12.5, 15. , 17.5, 20. ]), 2.5)# 默认底数是 10In [25]: g = np.logspace(1.0, 2.0, num=10)In [26]: print(g)[ 10. 12.91549665 16.68100537 21.5443469 27.82559402 35.93813664 46.41588834 59.94842503 77.42636827 100. ]# 将对数空间的底数设置为 2In [29]: a = np.logspace(1, 6, num=10, base=2)In [30]: print(a)[ 2. 2.93946898 4.32023896 6.34960421 9.33223232 13.71590373 20.1587368 29.62799079 43.54528001 64. ] NumPy - 切片和索引单维数组切片和list的切片一样, 下面主要介绍多维数组的切片和索引切片还可以使用省略号（…），来使选择元组的长度与数组的维度相同。 如果在行位置使用省略号，它将返回包含行中元素的ndarray。1234567891011121314151617In [31]: b = np.array([[1,2,3], [4,5,6], [7, 8, 9]])In [32]: print(b[1:])[[4 5 6] [7 8 9]]# 返回第二列元素的数组In [33]: print(b[..., 1])[2 5 8]# 返回第二行元素的数组In [34]: print(b[1, ...])[4 5 6]# 返回从第二列向后切片所有元素：In [36]: print(b[..., 1:])[[2 3] [5 6] [8 9]] Numpy高级索引参考 TutorialsPoint NumPy 教程","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Python之asyncio使用","slug":"python-asyncio-2017-06-06","date":"2017-06-06T08:00:58.000Z","updated":"2017-09-08T03:51:40.000Z","comments":true,"path":"2017/06/06/python-asyncio-2017-06-06/","link":"","permalink":"http://arvin-he.github.io/2017/06/06/python-asyncio-2017-06-06/","excerpt":"","text":"asyncio简介asyncio是Python 3.4版本引入的标准库，直接内置了对异步IO的支持。asyncio的编程模型就是一个消息循环。我们从asyncio模块中直接获取一个EventLoop的引用，然后把需要执行的协程扔到EventLoop中执行，就实现了异步IO。 到了Python 3.5添加了async和await两个关键字，分别用来替换asyncio.coroutine和yield from。自此，协程成为新的语法，而不再是一种生成器类型了。此外,事件循环与协程的引入，可以极大提高高负载下程序的I/O性能。除此之外还增加了async with(异步上下文管理)、async for(异步迭代器)语法。还有在新发布的Python 3.6里面可以用异步生成器了. 当给一个函数添加了async关键字，就会把它变成一个异步函数。async/await是Python提供的异步编程API，而asyncio只是一个利用 async/await API进行异步编程的框架.现存的一些库其实并不能原生的支持asyncio（因为会发生阻塞或者功能不可用），比如requests，如果要写爬虫，配合asyncio的应该用aiohttp，其他的如数据库驱动等各种Python对应的库也都得使用对应的aioXXX版本了。 需要进行协程切换的地方，就需要使用await关键字 同步与异步/阻塞与非阻塞概念同步与异步同步和异步关注的是消息通信机制 (synchronous communication/ asynchronous communication)所谓同步，就是在发出一个调用时，在没有得到结果之前，该调用就不返回。但是一旦调用返回，就得到返回值了。换句话说，就是由调用者主动等待这个调用的结果。而异步则是相反，调用在发出之后，这个调用就直接返回了，所以没有返回结果。换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果。而是在调用发出后，被调用者通过状态、通知来通知调用者，或通过回调函数处理这个调用。典型的异步编程模型比如Node.js，举个通俗的例子：你打电话问书店老板有没有《分布式系统》这本书，如果是同步通信机制，书店老板会说，你稍等，”我查一下”，然后开始查啊查，等查好了（可能是5秒，也可能是一天）告诉你结果（返回结果）。而异步通信机制，书店老板直接告诉你我查一下啊，查好了打电话给你，然后直接挂电话了（不返回结果）。然后查好了，他会主动打电话给你。在这里老板通过“回电”这种方式来回调。 阻塞与非阻塞阻塞和非阻塞关注的是程序在等待调用结果（消息，返回值）时的状态.阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。还是上面的例子，你打电话问书店老板有没有《分布式系统》这本书，你如果是阻塞式调用，你会一直把自己“挂起”，直到得到这本书有没有的结果，如果是非阻塞式调用，你不管老板有没有告诉你，你自己先一边去玩了， 当然你也要偶尔过几分钟check一下老板有没有返回结果。在这里阻塞与非阻塞与是否同步异步无关。跟老板通过什么方式回答你结果无关。 asyncio使用1234567891011121314import asyncio# 将heloo@asyncio.coroutinedef hello(): print(\"Hello world!\") # 异步调用asyncio.sleep(1): r = yield from asyncio.sleep(1) print(\"Hello again!\")# 获取EventLoop:loop = asyncio.get_event_loop()# 执行coroutineloop.run_until_complete(hello())loop.close() @asyncio.coroutine把一个generator标记为coroutine类型，然后，我们就把这个coroutine扔到EventLoop中执行。 hello()会首先打印出Hello world!，然后，yield from语法可以让我们方便地调用另一个generator。由于asyncio.sleep()也是一个coroutine，所以线程不会等待asyncio.sleep()，而是直接中断并执行下一个消息循环。当asyncio.sleep()返回时，线程就可以从yield from拿到返回值（此处是None），然后接着执行下一行语句。 把asyncio.sleep(1)看成是一个耗时1秒的IO操作，在此期间，主线程并未等待，而是去执行EventLoop中其他可以执行的coroutine了，因此可以实现并发执行。 我们用Task封装两个coroutine试试：1234567891011121314151617181920212223242526import threadingimport asyncio@asyncio.coroutinedef hello1(): print('Hello 1 in! (%s)' % threading.currentThread()) yield from asyncio.sleep(1) print('Hello 1 out! (%s)' % threading.currentThread()) @asyncio.coroutinedef hello2(): print('Hello 2 in! (%s)' % threading.currentThread()) yield from asyncio.sleep(1) print('Hello 2 out! (%s)' % threading.currentThread())loop = asyncio.get_event_loop()tasks = [hello1(), hello2()]loop.run_until_complete(asyncio.wait(tasks))loop.close()Hello 1 in! (&lt;_MainThread(MainThread, started 6620)&gt;)Hello 2 in! (&lt;_MainThread(MainThread, started 6620)&gt;)Hello 1 out! (&lt;_MainThread(MainThread, started 6620)&gt;)Hello 2 out! (&lt;_MainThread(MainThread, started 6620)&gt;) 由打印的当前线程名称可以看出，两个coroutine是由同一个线程并发执行的。如果把asyncio.sleep()换成真正的IO操作，则多个coroutine就可以由一个线程并发执行。 async/awaitPython 3.5开始引入了新的语法async和await，可以让coroutine的代码更简洁易读。请注意:async和await是针对coroutine的新语法,要使用新语法,只需要做两步简单的替换： 把@asyncio.coroutine替换为async； 把yield from替换为await。 12345@asyncio.coroutinedef hello(): print(\"Hello world!\") r = yield from asyncio.sleep(1) print(\"Hello again!\") async/await新语法1234async def hello(): print(\"Hello world!\") r = await asyncio.sleep(1) print(\"Hello again!\") 参考 https://juejin.im/post/5857b8a98e450a006cb060fc 廖雪峰教程","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Python之gevent使用","slug":"python-gevent-2017-06-06","date":"2017-06-06T05:08:03.000Z","updated":"2017-09-08T03:51:40.081Z","comments":true,"path":"2017/06/06/python-gevent-2017-06-06/","link":"","permalink":"http://arvin-he.github.io/2017/06/06/python-gevent-2017-06-06/","excerpt":"","text":"Greenlets在gevent中用到的主要模式是Greenlet, 它是以C扩展模块形式接入Python的轻量级协程。 Greenlet全部运行在主程序操作系统进程的内部，但它们被协作式地调度。在任何时刻，只有一个协程在运行。 在gevent里面，上下文切换是通过yielding来完成的. 当我们在受限于网络或IO的函数中使用gevent，这些函数会被协作式的调度， gevent的真正能力会得到发挥。Gevent处理了所有的细节， 来保证你的网络库会在可能的时候，隐式交出greenlet上下文的执行权。greenlet具有确定性。在相同配置相同输入的情况下，它们总是 会产生相同的输出。即使gevent通常带有确定性，当开始与如socket或文件等外部服务交互时， 不确定性也可能溜进你的程序中。因此尽管gevent线程是一种“确定的并发”形式， 使用它仍然可能会遇到像使用POSIX线程或进程时遇到的那些问题。涉及并发长期存在的问题就是竞争条件(race condition)。简单来说， 当两个并发线程/进程都依赖于某个共享资源同时都尝试去修改它的时候， 就会出现竞争条件。这会导致资源修改的结果状态依赖于时间和执行顺序。 这是个问题，我们一般会做很多努力尝试避免竞争条件， 因为它会导致整个程序行为变得不确定。最好的办法是始终避免所有全局的状态。全局状态和导入时(import-time)副作用总是会 反咬你一口！ 创建Greenletsgevent对Greenlet初始化提供了一些封装，最常用的使用模板之一有1234567891011121314151617181920212223242526272829import geventfrom gevent import Greenletdef foo(message, n): \"\"\" Each thread will be passed the message, and n arguments in its initialization. \"\"\" gevent.sleep(n) print(message)# Initialize a new Greenlet instance running the named function foothread1 = Greenlet.spawn(foo, \"Hello\", 1)# Wrapper for creating and running a new Greenlet from the named# function foo, with the passed argumentsthread2 = gevent.spawn(foo, \"I live!\", 2)# Lambda expressionsthread3 = gevent.spawn(lambda x: (x+1), 2)threads = [thread1, thread2, thread3]# Block until all threads complete.gevent.joinall(threads)HelloI live! 除使用基本的Greenlet类之外，你也可以子类化Greenlet类，重载它的_run方法。 1234567891011121314151617181920import geventfrom gevent import Greenletclass MyGreenlet(Greenlet): def __init__(self, message, n): Greenlet.__init__(self) self.message = message self.n = n def _run(self): print(self.message) gevent.sleep(self.n)g = MyGreenlet(\"Hi there!\", 3)g.start()g.join()Hi there! Greenlet状态就像任何其他成段代码，Greenlet也可能以不同的方式运行失败。 Greenlet可能未能成功抛出异常，不能停止运行，或消耗了太多的系统资源。 一个greenlet的状态通常是一个依赖于时间的参数。在greenlet中有一些标志， 让你可以监视它的线程内部状态： started – Boolean, 指示此Greenlet是否已经启动ready() – Boolean, 指示此Greenlet是否已经停止successful() – Boolean, 指示此Greenlet是否已经停止而且没抛异常value – 任意值, 此Greenlet代码返回的值exception – 异常, 此Greenlet内抛出的未捕获异常 程序停止当主程序(main program)收到一个SIGQUIT信号时，不能成功做yield操作的 Greenlet可能会令意外地挂起程序的执行。这导致了所谓的僵尸进程， 它需要在Python解释器之外被kill掉。对此，一个通用的处理模式就是在主程序中监听SIGQUIT信号，在程序退出 调用gevent.shutdown。12345678910import geventimport signaldef run_forever(): gevent.sleep(1000)if __name__ == '__main__': gevent.signal(signal.SIGQUIT, gevent.shutdown) thread = gevent.spawn(run_forever) thread.join() 超时超时是一种对一块代码或一个Greenlet的运行时间的约束。123456789101112131415import geventfrom gevent import Timeoutseconds = 10timeout = Timeout(seconds)timeout.start()def wait(): gevent.sleep(10)try: gevent.spawn(wait).join()except Timeout: print('Could not complete') 超时类也可以用在上下文管理器(context manager)中, 也就是with语句内。12345678910import geventfrom gevent import Timeouttime_to_wait = 5 # secondsclass TooLong(Exception): passwith Timeout(time_to_wait, TooLong): gevent.sleep(10) 猴子补丁(Monkey patching)我们现在来到gevent的死角了. 在此之前，我已经避免提到猴子补丁(monkey patching) 以尝试使gevent这个强大的协程模型变得生动有趣，但现在到了讨论猴子补丁的黑色艺术 的时候了。你之前可能注意到我们提到了monkey.patch_socket()这个命令，这个 纯粹副作用命令是用来改变标准socket库的。123456789101112131415161718192021import socketprint(socket.socket)print(\"After monkey patch\")from gevent import monkeymonkey.patch_socket()print(socket.socket)import selectprint(select.select)monkey.patch_select()print(\"After monkey patch\")print(select.select)class 'socket.socket'After monkey patchclass 'gevent.socket.socket'built-in function selectAfter monkey patchfunction select at 0x1924de8 Python的运行环境允许我们在运行时修改大部分的对象，包括模块，类甚至函数。 这是个一般说来令人惊奇的坏主意，因为它创造了“隐式的副作用”，如果出现问题 它很多时候是极难调试的。虽然如此，在极端情况下当一个库需要修改Python本身 的基础行为的时候，猴子补丁就派上用场了。在这种情况下，gevent能够 修改标准库里面大部分的阻塞式系统调用，包括socket、ssl、threading和 select等模块，而变为协作式运行。 例如，Redis的python绑定一般使用常规的tcp socket来与redis-server实例通信。 通过简单地调用gevent.monkey.patch_all()，可以使得redis的绑定协作式的调度 请求，与gevent栈的其它部分一起工作。 这让我们可以将一般不能与gevent共同工作的库结合起来，而不用写哪怕一行代码。 虽然猴子补丁仍然是邪恶的(evil)，但在这种情况下它是“有用的邪恶(useful evil)”。 真实世界的应用Gevent ZeroMQZeroMQ 被它的作者描述为 “一个表现得像一个并发框架的socket库”。 它是一个非常强大的，为构建并发和分布式应用的消息传递层。 ZeroMQ提供了各种各样的socket原语。最简单的是请求-应答socket对 (Request-Response socket pair)。一个socket有两个方法send和recv， 两者一般都是阻塞操作。但是Travis Cline 的一个杰出的库弥补了这一点，这个库使用gevent.socket来以非阻塞的方式 轮询ZereMQ socket。通过命令： pip install gevent-zeromq 你可以从PyPi安装gevent-zeremq。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# Note: Remember to ``pip install pyzmq gevent_zeromq``import geventfrom gevent_zeromq import zmq# Global Contextcontext = zmq.Context()def server(): server_socket = context.socket(zmq.REQ) server_socket.bind(\"tcp://127.0.0.1:5000\") for request in range(1,10): server_socket.send(\"Hello\") print('Switched to Server for %s' % request) # Implicit context switch occurs here server_socket.recv()def client(): client_socket = context.socket(zmq.REP) client_socket.connect(\"tcp://127.0.0.1:5000\") for request in range(1,10): client_socket.recv() print('Switched to Client for %s' % request) # Implicit context switch occurs here client_socket.send(\"World\")publisher = gevent.spawn(server)client = gevent.spawn(client)gevent.joinall([publisher, client])Switched to Server for 1Switched to Client for 1Switched to Server for 2Switched to Client for 2Switched to Server for 3Switched to Client for 3Switched to Server for 4Switched to Client for 4Switched to Server for 5Switched to Client for 5Switched to Server for 6Switched to Client for 6Switched to Server for 7Switched to Client for 7Switched to Server for 8Switched to Client for 8Switched to Server for 9Switched to Client for 9 参考 Gevent指南","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Node最佳实践1","slug":"node-practice-2017-06-06","date":"2017-06-06T00:36:55.000Z","updated":"2017-09-08T03:51:39.823Z","comments":true,"path":"2017/06/06/node-practice-2017-06-06/","link":"","permalink":"http://arvin-he.github.io/2017/06/06/node-practice-2017-06-06/","excerpt":"","text":"编码规范回调惯例模块应该公开一个错误优先（error-first）的回调接口。就像下面这样：12345678module.exports = function (dragonName, callback) &#123; // 这里做一些处理工作 var dragon = createDragon(dragonName); // 注意, callback第一个参数是 error // 这里传入null // 如果出错则传入错误信息 return callback(null, dragon);&#125; 确保在回调中检查错误信息, 要更好地弄明白为什么必须这样做，先想办法创建一个会挂掉的例子，然后修复它。12345678// 这个例子是会挂掉的, 我们很快会修复 :)var fs = require('fs');function readJSON(filePath, callback)&#123; fs.readFile(filePath, function(err, data) &#123; callback(JSON.parse(data)); &#125;);&#125;readJSON('./package.json', function (err, pkg) &#123; ... &#125; 首要问题是 readJSON函数，在执行过程中出现了错误，而这个函数却没有做任何错误检查。你务必要先做错误检查。改进方案：12345678910111213// 这个例子还是会挂掉 , 很快会修复!function readJSON(filePath, callback) &#123; fs.readFile(filePath, function(err, data) &#123; // 这里我们先判断是否有错误发生 if (err) &#123; // 出现错误，将错误传入回调函数 // 记住: 错误优先（error-first） 回调 callback(err); &#125; // 如果没有错误则传入null和JSON callback(null, JSON.parse(data));&#125;);&#125; 将回调函数返回上面的例子还是存在一个错误，就是如果错误发生了，if 中的表达式不会停止运行，而是继续运行下去。这会导致很多未知的错误。长话短说，务必通过回调函数返回。12345678910// 这个例子仍旧会挂掉, 马上修复!function readJSON(filePath, callback) &#123; fs.readFile(filePath, function(err, data) &#123; if (err) &#123; return callback(err); &#125; return callback(null, JSON.parse(data)); &#125;);&#125; 仅在同步代码中使用try-catch几乎完美了！但还有一件事，我们必须要小心 JSON.parse。调用JSON.parse 时，如果传入的字符串无法解析成JSON格式，会抛出异常。由于JSON.parse是同步发生的，我们可以用try-catch包装起来。请注意:你只能对同步代码块做此操作，对回调函数是不起作用的。123456789101112131415161718// 这个例子终于可以正常工作啦 :)function readJSON(filePath, callback) &#123;fs.readFile(filePath, function(err, data) &#123; var parsedJson; // 处理错误 if (err) &#123; return callback(err); &#125; // 解析JSON try &#123; parsedJson = JSON.parse(data); &#125; catch (exception)&#123; return callback(exception); &#125; // 一切工作正常 return callback(null, parsedJson);&#125;);&#125; 尽量避免 this 和 new 关键字由于Node涉及了大量的回调操作，并且重度使用高阶函数控制流程，因此在Node中绑定一个具体的上下文并不总是行之有效。使用函数式编程风格能避免不少麻烦。当然，在某些情况下原型（prototype）可能更高效，不过只要可能，还是尽量避免它们。 创建微模块用unix的方式： 开发者构建一个程序时应该将其分成很多简单的模块，各部分由定义良好的接口整合,所以问题是局部的，并且能通过替换程序部件的方式在将来的版中加入新特性。不要创建怪兽般的代码，保持简洁，一个模块就只做一件事，但是要做到极致。 使用良好的异步模式使用async异步处理模块。 错误处理错误可以分为两部分，操作错误和编程错误。 操作错误精心编写的应用程序中也一样会出现操作错误。因为这些不是 bug ，而是由于操作系统或远程服务导致的，例如：请求超时, 系统内存不足, 远程连接失败, 处理操作错误根据不同运行错误的类型，你可以采用下面的方式处理：尝试解决错误——如果文件丢失，你可以提前创建一个。当处理网络通信时，可以重试操作。把问题告诉客户，表示有些功能不能正常工作——可以用于处理用户输入。如果错误无法在当前条件下解决，终止进程，例如应用程序无法读取它的配置文件。还有，上述的所有处理方式都应该记录日志。 编程错误编程错误都算是bug。下面所列的几条你应该避免，例如：调用异步函数时没有回调。不能读取未定义（undefined）的属性 处理编程错误如果错误属于bug，立刻终止程序，你并不知道应用当前的运行状态。当错误发生时，进程控制系统应该会重启应用程序，例如：supervisord 或者 monit。 工作流技巧使用 npm init 创建新项目init 命令可以帮助你创建应用程序的 package.json 配置文件。文件设置了一些默认配置，之后可以修改。创建一个优秀的项目应该这样开始：123mkdir my-awesome-new-project cd my-awesome-new-project npm init 指定开始和测试脚本。在你的 package.son 文件中，你可以在 scripts 部分中设置脚本。npm init 默认会创建两个，start 和 test 脚本。可以通过 npm start 和 npm test 命令运行。还有，作为加分项：你可以在这里加入自定义脚本，通过 npm run-script 来运行。注意，NPM 会通过设置 $PATH 来扫描 node_modules/.bin 下的所有可执行脚本。这样可以避免安装全局的 NPM 模块。 环境变量生产部署和演示部署都应该由环境变量来实现。最主流的实现方式是同时在生产和演示中设置 NODE_ENV变量。根据你设置的环境变量，你可以使用 nconf 模块来加载配置信息。当然，你也可以在你的Node.js 应用中使用其它环境变量设置 process.env，这是一个包含了用户环境的对象。 不要重新发明轮子务必优先寻找现成的解决方案。NPM 的库超级多，涵盖了你平时需要的大部分功能。 使用风格指南所有的代码都保持统一风格有助于理解大型代码库。其中应该包含缩进、变量命名、最佳实践以及其他方面。如果想看一个实际的例子，请查看 RisingStack 编写的 Node.js 风格指南。 保持风格一致JSCS 是一个JavaScript 编码风格检查工具。将JSCS加入项目对你来说小菜一碟：npm install jscs --save-dev, 你需要做的下一步关键就是在 package.json 文件中加入下面的代码来开启它：123scripts: &#123; &quot;jscs&quot;: &quot;jscs index.js&quot;&#125; 当然，你也可以加入多个文件、目录检查。但为什么我们仅仅在 package.json 文件中创建了一个自定义的脚本呢？我们是以本地的方式安装 jscs 的，所以在一个系统中可以有多个不同版本。这样还能正常工作是因为NPM 执行时会将 node_modules/.bin 设置到 PATH上。 你可以在.jscsrc 文件中定义验证规则，或者使用预设规则。从这里可以查看可用的预设，通过 --preset=[PRESET_NAME]来应用。 执行 JSHint、JSCS 规则你的构建过程还应该包含 JSHint 和 JSCS，不过在开发者的电脑上运行 pre-commit checks 或许是个不错的主意。要实现这个很简单，你可以使用 pre-commit NPM 库：npm install --save-dev pre-commit, 然后在 package.json 文件中作如下配置：1234pre-commit&quot;: [ &quot;jshint&quot;, &quot;jscs&quot;], 注意，pre-commit 将会扫描 package.json中script里的所有脚本。开启以后，每次提交时都会自动进行检查。 用JS替换JSON做配置我们看到大量的项目都是使用JSON文件做配置的。这是目前最普遍的做法，JS配置文件则能够提供更大的灵活度。所以我们推荐你使用 config.js 文件：12345678910111213141516171819202122232425var url =require('url');var config = module.exports = &#123;&#125;;var redisToGoConfig; config.server = &#123; host: '0.0.0.0', port: process.env.PORT || 3000&#125;; // look, a comment in the config file!// would be tricky in a JSON ;)config.redis = &#123; host: 'localhost', port: 6379, options: &#123; &#125;&#125;; if (process.env.REDISTOGO_URL) &#123; redisToGoConfig = url.parse(process.env.REDISTOGO_URL); config.redis.port = redisToGoConfig.port; config.redis.host = redisToGoConfig.hostname; config.redis.options.auth_pass = redisToGoConfig.auth.split(':')[1];&#125; 使用 NODE_PATH你是否曾经碰到过下面这种情况？12345var myModule = require('../../../../lib/myModule'); myModule.doSomething(function (err) &#123;&#125;); 当你的项目结构变得错综复杂，模块依赖会非常麻烦。要解决这个问题有两个办法： 把你的模块软链接到node_modules目录下。 使用 NODE_PATH。在RisingStack我们使用 NODE_PATH 的方式，因为将所有相关文件软链接到 node_modules目录需要大量额外的工作，并且在很多操作系统下都不适用。 设置 NODE_PATH假设你的项目结构是这样的：12345--lib --model --car.js --index.js --package.json 我们可以使用 指向 lib 目录的NODE_PATH，而不是使用相对路径。在我们的package.json 的 start script部分，我们使用NODE_PATH设置并且用npm start运行项目。123456789101112131415var Car = require('model/Car'); console.log('I am a Car!'); &#123; \"name\": \"node_path\", \"version\": \"1.0.0\", \"description\": \"\", \"main\": \"index.js\", \"scripts\": &#123; \"start\": \"NODE_PATH=lib node index.js\"&#125;, \"author\": \"\", \"license\": \"ISC\"&#125; 依赖注入依赖注入是一种软件设计模式，是指将一到多个依赖（或服务）注入或通过引用的方式引入到需要依赖的对象。 依赖注入在测试中非常有用。使用这个模式你可以轻松模拟模块间的依赖关系。1234567891011121314function userModel (options) &#123;var db;if (!options.db) &#123; throw new Error('Options.db is required');&#125;db = options.db;return &#123; create: function (done) &#123; db.query('INSERT ...', done); &#125;&#125;&#125; module.exports = userModel; 12345678910var db = require('db');// do some init here, or connectdb.init(); var userModel = require('User')(&#123;db: db&#125;); userModel.create(function (err, user) &#123;&#125;); 12345678910111213141516171819var test = require('tape');var userModel = require('User'); test('it creates a user with id', function (t) &#123;var user = &#123;id: 1&#125;;var fakeDb = &#123;query: function (done) &#123;done(null, user);&#125;&#125;userModel(&#123;db: fakeDb&#125;).create(function (err, user) &#123;t.equal(user.id, 1, 'User id should match');t.end();&#125;)&#125;); 上面的例子中我们有两个不同的 db。在 index.js 文件中是“真实的” db 模块，而第二段代码中我们只是简单地创建了一个模拟的db模块。 这样我们在测试时就可以轻松地将模拟的依赖引入模块。 参考 NodeJS 最佳实践","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"NodeJS","slug":"NodeJS","permalink":"http://arvin-he.github.io/tags/NodeJS/"}]},{"title":"Node笔记3","slug":"node-notes3-2017-06-03","date":"2017-06-03T03:44:53.000Z","updated":"2017-09-08T03:51:39.816Z","comments":true,"path":"2017/06/03/node-notes3-2017-06-03/","link":"","permalink":"http://arvin-he.github.io/2017/06/03/node-notes3-2017-06-03/","excerpt":"","text":"更有用的场景服务器，请求路由以及请求处理程序都已经完成了，下面让我们按照此前的用例给网站添加交互：用户选择一个文件，上传该文件，然后在浏览器中看到上传的文件。 为了保持简单，我们假设用户只会上传图片，然后我们应用将该图片显示到浏览器中。 要实现该功能，分为如下两步：首先，让我们来看看如何处理POST请求（非文件上传），然后，使用Node.js的一个用于文件上传的外部模块。 处理POST请求下面显示一个文本区（textarea）供用户输入内容，然后通过POST请求提交给服务器。最后，服务器接受到请求，通过处理程序将输入的内容展示到浏览器中。 /start请求处理程序用于生成带文本区的表单，因此，我们将requestHandlers.js修改为如下形式：123456789101112131415161718192021222324252627282930function start(response) &#123; console.log(\"Request handler 'start' was called.\"); var body = '&lt;html&gt;'+ '&lt;head&gt;'+ '&lt;meta http-equiv=\"Content-Type\" content=\"text/html; '+ 'charset=UTF-8\" /&gt;'+ '&lt;/head&gt;'+ '&lt;body&gt;'+ '&lt;form action=\"/upload\" method=\"post\"&gt;'+ '&lt;textarea name=\"text\" rows=\"20\" cols=\"60\"&gt;&lt;/textarea&gt;'+ '&lt;input type=\"submit\" value=\"Submit text\" /&gt;'+ '&lt;/form&gt;'+ '&lt;/body&gt;'+ '&lt;/html&gt;'; response.writeHead(200, &#123;\"Content-Type\": \"text/html\"&#125;); response.write(body); response.end();&#125;function upload(response) &#123; console.log(\"Request handler 'upload' was called.\"); response.writeHead(200, &#123;\"Content-Type\": \"text/plain\"&#125;); response.write(\"Hello Upload\"); response.end();&#125;exports.start = start;exports.upload = upload; 重启服务器,就可以看到效果了.虽然直接将视觉元素放在请求处理程序中的方式太丑陋了。但是，这里不会讲述MVC之类的模式，因为这对于你了解JavaScript或者Node.js环境来说没多大关系。 接下来探讨 当用户提交表单时，触发/upload请求处理程序处理POST请求的问题。这里采用异步回调来实现非阻塞地处理POST请求的数据。因为POST请求一般都比较“重” —— 用户可能会输入大量的内容。用阻塞的方式处理大数据量的请求必然会导致用户操作的阻塞。 为了使整个过程非阻塞，Node.js会将POST数据拆分成很多小的数据块，然后通过触发特定的事件，将这些小数据块传递给回调函数。这里的特定的事件有data事件（表示新的小数据块到达了）以及end事件（表示所有的数据都已经接收完毕）。 我们需要告诉Node.js当这些事件触发的时候，回调哪些函数。怎么告诉呢？ 我们通过在request对象上注册监听器（listener） 来实现。这里的request对象是每次接收到HTTP请求时候，都会把该对象传递给onRequest回调函数。 如下所示：1234567request.addListener(\"data\", function(chunk) &#123; // called when a new chunk of data was received&#125;);request.addListener(\"end\", function() &#123; // called when all chunks of data have been received&#125;); 问题来了，这部分逻辑写在哪里呢？ 我们现在只是在服务器中获取到了request对象 —— 我们并没有像之前response对象那样，把 request 对象传递给请求路由和请求处理程序。 在我看来，获取所有来自请求的数据，然后将这些数据给应用层处理，应该是HTTP服务器要做的事情。因此，我建议，我们直接在服务器中处理POST数据，然后将最终的数据传递给请求路由和请求处理器，让他们来进行进一步的处理。 因此，实现思路就是： 将data和end事件的回调函数直接放在服务器中，在data事件回调中收集所有的POST数据，当接收到所有数据，触发end事件后，其回调函数调用请求路由，并将数据传递给它，然后，请求路由再将该数据传递给请求处理程序。 先从server.js开始：1234567891011121314151617181920212223242526272829var http = require(\"http\");var url = require(\"url\");function start(route, handle) &#123; function onRequest(request, response) &#123; var postData = \"\"; var pathname = url.parse(request.url).pathname; console.log(\"Request for \" + pathname + \" received.\"); request.setEncoding(\"utf8\"); // 注册监听器 request.addListener(\"data\", function(postDataChunk) &#123; postData += postDataChunk; console.log(\"Received POST data chunk '\"+ postDataChunk + \"'.\"); &#125;); request.addListener(\"end\", function() &#123; // 将请求路由的调用移到end事件处理程序中, 同时还把POST数据传递给请求路由 route(handle, pathname, response, postData); &#125;); &#125; http.createServer(onRequest).listen(8888); console.log(\"Server has started.\");&#125;exports.start = start; 上述代码做了三件事情：首先，我们设置了接收数据的编码格式为UTF-8，然后注册了“data”事件的监听器,用于收集每次接收到的新数据块,并将其赋值给postData变量.最后，我们将请求路由的调用移到end事件处理程序中，以确保它只会当所有数据接收完毕后才触发，并且只触发一次。我们同时还把POST数据传递给请求路由，因为这些数据，请求处理程序会用到。 上述代码在每个数据块到达的时候输出了日志，这对于最终生产环境来说，是很不好的（数据量可能会很大，还记得吧？），但是，在开发阶段是很有用的，有助于让我们看到发生了什么。 我建议可以尝试下，尝试着去输入一小段文本，以及大段内容，当大段内容的时候，就会发现data事件会触发多次。 接下来在/upload页面，展示用户输入的内容。要实现该功能，我们需要将postData传递给请求处理程序，修改router.js为如下形式：12345678910111213function route(handle, pathname, response, postData) &#123; console.log(\"About to route a request for \" + pathname); if (typeof handle[pathname] === 'function') &#123; handle[pathname](response, postData); &#125; else &#123; console.log(\"No request handler found for \" + pathname); response.writeHead(404, &#123;\"Content-Type\": \"text/plain\"&#125;); response.write(\"404 Not found\"); response.end(); &#125;&#125;exports.route = route; 然后，在requestHandlers.js中，我们将数据包含在对upload请求的响应中：123456789101112131415161718192021222324252627282930function start(response, postData) &#123; console.log(\"Request handler 'start' was called.\"); var body = '&lt;html&gt;'+ '&lt;head&gt;'+ '&lt;meta http-equiv=\"Content-Type\" content=\"text/html; '+ 'charset=UTF-8\" /&gt;'+ '&lt;/head&gt;'+ '&lt;body&gt;'+ '&lt;form action=\"/upload\" method=\"post\"&gt;'+ '&lt;textarea name=\"text\" rows=\"20\" cols=\"60\"&gt;&lt;/textarea&gt;'+ '&lt;input type=\"submit\" value=\"Submit text\" /&gt;'+ '&lt;/form&gt;'+ '&lt;/body&gt;'+ '&lt;/html&gt;'; response.writeHead(200, &#123;\"Content-Type\": \"text/html\"&#125;); response.write(body); response.end();&#125;function upload(response, postData) &#123; console.log(\"Request handler 'upload' was called.\"); response.writeHead(200, &#123;\"Content-Type\": \"text/plain\"&#125;); response.write(\"You've sent: \" + postData); response.end();&#125;exports.start = start;exports.upload = upload; 好了，我们现在可以接收POST数据并在请求处理程序中处理该数据了。 我们最后要做的是： 当前我们是把请求的整个消息体传递给了请求路由和请求处理程序。我们应该只把POST数据中，我们感兴趣的部分传递给请求路由和请求处理程序。在我们这个例子中，我们感兴趣的其实只是text字段。 我们可以使用此前介绍过的querystring模块来实现：123456789101112131415161718192021222324252627282930313233var querystring = require(\"querystring\");function start(response, postData) &#123; console.log(\"Request handler 'start' was called.\"); var body = '&lt;html&gt;'+ '&lt;head&gt;'+ '&lt;meta http-equiv=\"Content-Type\" content=\"text/html; '+ 'charset=UTF-8\" /&gt;'+ '&lt;/head&gt;'+ '&lt;body&gt;'+ '&lt;form action=\"/upload\" method=\"post\"&gt;'+ '&lt;textarea name=\"text\" rows=\"20\" cols=\"60\"&gt;&lt;/textarea&gt;'+ '&lt;input type=\"submit\" value=\"Submit text\" /&gt;'+ '&lt;/form&gt;'+ '&lt;/body&gt;'+ '&lt;/html&gt;'; response.writeHead(200, &#123;\"Content-Type\": \"text/html\"&#125;); response.write(body); response.end();&#125;function upload(response, postData) &#123; console.log(\"Request handler 'upload' was called.\"); response.writeHead(200, &#123;\"Content-Type\": \"text/plain\"&#125;); response.write(\"You've sent the text: \"+ querystring.parse(postData).text); response.end();&#125;exports.start = start;exports.upload = upload; 好了，以上就是关于处理POST数据的全部内容。 处理文件上传最终的用例：允许用户上传图片，并将该图片在浏览器中显示出来。 这里要用到的外部模块是Felix Geisendörfer开发的node-formidable模块。它对解析上传的文件数据做了很好的抽象。 其实说白了，处理文件上传“就是”处理POST数据 —— 但是，麻烦的是在具体的处理细节，所以，这里采用现成的方案更合适点。 使用该模块，首先需要安装该模块。Node.js有它自己的包管理器，叫NPM。它可以让安装Node.js的外部模块变得非常方便。通过如下一条命令就可以完成该模块的安装：npm install formidable.现在可以用formidable模块了——使用外部模块与内部模块类似，用require语句将其引入即可：var formidable = require(&quot;formidable&quot;);,这里该模块做的就是将通过HTTP POST请求提交的表单，在Node.js中可以被解析。我们要做的就是创建一个新的IncomingForm，它是对提交表单的抽象表示，之后，就可以用它解析request对象，获取表单中需要的数据字段。 node-formidable官方的例子展示了这两部分是如何融合在一起工作的：123456789101112131415161718192021222324252627var formidable = require('formidable'), http = require('http'), util = require('util');http.createServer(function(req, res) &#123; if (req.url == '/upload' &amp;&amp; req.method.toLowerCase() == 'post') &#123; // parse a file upload var form = new formidable.IncomingForm(); form.parse(req, function(err, fields, files) &#123; res.writeHead(200, &#123;'content-type': 'text/plain'&#125;); res.write('received upload:\\n\\n'); res.end(util.inspect(&#123;fields: fields, files: files&#125;)); &#125;); return; &#125; // show a file upload form res.writeHead(200, &#123;'content-type': 'text/html'&#125;); res.end( '&lt;form action=\"/upload\" enctype=\"multipart/form-data\" '+ 'method=\"post\"&gt;'+ '&lt;input type=\"text\" name=\"title\"&gt;&lt;br&gt;'+ '&lt;input type=\"file\" name=\"upload\" multiple=\"multiple\"&gt;&lt;br&gt;'+ '&lt;input type=\"submit\" value=\"Upload\"&gt;'+ '&lt;/form&gt;' );&#125;).listen(8888); 如果我们将上述代码，保存到一个文件中，并通过node来执行，就可以进行简单的表单提交了，包括文件上传。然后，可以看到通过调用form.parse传递给回调函数的files对象的内容，如下所示：1234567891011121314received upload:&#123; fields: &#123; title: &apos;Hello World&apos; &#125;, files: &#123; upload: &#123; size: 1558, path: &apos;/tmp/1c747974a27a6292743669e91f29350b&apos;, name: &apos;us-flag.png&apos;, type: &apos;image/png&apos;, lastModifiedDate: Tue, 21 Jun 2011 07:02:41 GMT, _writeStream: [Object], length: [Getter], filename: [Getter], mime: [Getter] &#125; &#125; &#125; 为了实现我们的功能，我们需要将上述代码应用到我们的应用中，另外，我们还要考虑如何将上传文件的内容（保存在/tmp目录中）显示到浏览器中。 我们先来解决后面那个问题： 对于保存在本地硬盘中的文件，如何才能在浏览器中看到呢？ 显然，我们需要将该文件读取到我们的服务器中，使用一个叫fs的模块。 我们来添加/showURL的请求处理程序，该处理程序直接硬编码将文件/tmp/test.png内容展示到浏览器中。当然了，首先需要将该图片保存到这个位置才行。 将requestHandlers.js修改为如下形式：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950var querystring = require(\"querystring\"), fs = require(\"fs\");function start(response, postData) &#123; console.log(\"Request handler 'start' was called.\"); var body = '&lt;html&gt;'+ '&lt;head&gt;'+ '&lt;meta http-equiv=\"Content-Type\" '+ 'content=\"text/html; charset=UTF-8\" /&gt;'+ '&lt;/head&gt;'+ '&lt;body&gt;'+ '&lt;form action=\"/upload\" method=\"post\"&gt;'+ '&lt;textarea name=\"text\" rows=\"20\" cols=\"60\"&gt;&lt;/textarea&gt;'+ '&lt;input type=\"submit\" value=\"Submit text\" /&gt;'+ '&lt;/form&gt;'+ '&lt;/body&gt;'+ '&lt;/html&gt;'; response.writeHead(200, &#123;\"Content-Type\": \"text/html\"&#125;); response.write(body); response.end();&#125;function upload(response, postData) &#123; console.log(\"Request handler 'upload' was called.\"); response.writeHead(200, &#123;\"Content-Type\": \"text/plain\"&#125;); response.write(\"You've sent the text: \"+ querystring.parse(postData).text); response.end();&#125;function show(response, postData) &#123; console.log(\"Request handler 'show' was called.\"); fs.readFile(\"/tmp/test.png\", \"binary\", function(error, file) &#123; if(error) &#123; response.writeHead(500, &#123;\"Content-Type\": \"text/plain\"&#125;); response.write(error + \"\\n\"); response.end(); &#125; else &#123; response.writeHead(200, &#123;\"Content-Type\": \"image/png\"&#125;); response.write(file, \"binary\"); response.end(); &#125; &#125;);&#125;exports.start = start;exports.upload = upload;exports.show = show; 我们还需要将这新的请求处理程序，添加到index.js中的路由映射表中：1234567891011var server = require(\"./server\");var router = require(\"./router\");var requestHandlers = require(\"./requestHandlers\");var handle = &#123;&#125;handle[\"/\"] = requestHandlers.start;handle[\"/start\"] = requestHandlers.start;handle[\"/upload\"] = requestHandlers.upload;handle[\"/show\"] = requestHandlers.show;server.start(router.route, handle); 重启服务器之后，通过访问http://localhost:8888/show，就可以看到保存在/tmp/test.png的图片了。 好，最后我们要的就是： 在/start表单中添加一个文件上传元素 将node-formidable整合到我们的upload请求处理程序中，用于将上传的图片保存到/tmp/test.png 将上传的图片内嵌到/uploadURL输出的HTML中 第一项很简单。只需要在HTML表单中，添加一个multipart/form-data的编码类型，移除此前的文本区，添加一个文件上传组件，并将提交按钮的文案改为“Upload file”即可。 如下requestHandler.js所示：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051var querystring = require(\"querystring\"), fs = require(\"fs\");function start(response, postData) &#123; console.log(\"Request handler 'start' was called.\"); var body = '&lt;html&gt;'+ '&lt;head&gt;'+ '&lt;meta http-equiv=\"Content-Type\" '+ 'content=\"text/html; charset=UTF-8\" /&gt;'+ '&lt;/head&gt;'+ '&lt;body&gt;'+ '&lt;form action=\"/upload\" enctype=\"multipart/form-data\" '+ 'method=\"post\"&gt;'+ '&lt;input type=\"file\" name=\"upload\"&gt;'+ '&lt;input type=\"submit\" value=\"Upload file\" /&gt;'+ '&lt;/form&gt;'+ '&lt;/body&gt;'+ '&lt;/html&gt;'; response.writeHead(200, &#123;\"Content-Type\": \"text/html\"&#125;); response.write(body); response.end();&#125;function upload(response, postData) &#123; console.log(\"Request handler 'upload' was called.\"); response.writeHead(200, &#123;\"Content-Type\": \"text/plain\"&#125;); response.write(\"You've sent the text: \"+ querystring.parse(postData).text); response.end();&#125;function show(response, postData) &#123; console.log(\"Request handler 'show' was called.\"); fs.readFile(\"/tmp/test.png\", \"binary\", function(error, file) &#123; if(error) &#123; response.writeHead(500, &#123;\"Content-Type\": \"text/plain\"&#125;); response.write(error + \"\\n\"); response.end(); &#125; else &#123; response.writeHead(200, &#123;\"Content-Type\": \"image/png\"&#125;); response.write(file, \"binary\"); response.end(); &#125; &#125;);&#125;exports.start = start;exports.upload = upload;exports.show = show; 下一步相对比较复杂。这里有这样一个问题： 我们需要在upload处理程序中对上传的文件进行处理，这样的话，我们就需要将request对象传递给node-formidable的form.parse函数。 但是，我们有的只是response对象和postData数组。看样子，我们只能不得不将request对象从服务器开始一路通过请求路由，再传递给请求处理程序。 或许还有更好的方案，但是，不管怎么说，目前这样做可以满足我们的需求。 到这里，我们可以将postData从服务器以及请求处理程序中移除了 —— 一方面，对于我们处理文件上传来说已经不需要了，另外一方面，它甚至可能会引发这样一个问题： 我们已经“消耗”了request对象中的数据，这意味着，对于form.parse来说，当它想要获取数据的时候就什么也获取不到了。（因为Node.js不会对数据做缓存） 我们从server.js开始 —— 移除对postData的处理以及request.setEncoding （这部分node-formidable自身会处理），转而采用将request对象传递给请求路由的方式：123456789101112131415var http = require(\"http\");var url = require(\"url\");function start(route, handle) &#123; function onRequest(request, response) &#123; var pathname = url.parse(request.url).pathname; console.log(\"Request for \" + pathname + \" received.\"); route(handle, pathname, response, request); &#125; http.createServer(onRequest).listen(8888); console.log(\"Server has started.\");&#125;exports.start = start; 接下来是 router.js —— 我们不再需要传递postData了，这次要传递request对象： 12345678910111213function route(handle, pathname, response, request) &#123; console.log(\"About to route a request for \" + pathname); if (typeof handle[pathname] === 'function') &#123; handle[pathname](response, request); &#125; else &#123; console.log(\"No request handler found for \" + pathname); response.writeHead(404, &#123;\"Content-Type\": \"text/html\"&#125;); response.write(\"404 Not found\"); response.end(); &#125;&#125;exports.route = route; 现在，request对象就可以在我们的upload请求处理程序中使用了。node-formidable会处理将上传的文件保存到本地/tmp目录中，而我们需要做的是确保该文件保存成/tmp/test.png。 没错，我们保持简单，并假设只允许上传PNG图片。 这里采用fs.renameSync(path1,path2)来实现。要注意的是，正如其名，该方法是同步执行的， 也就是说，如果该重命名的操作很耗时的话会阻塞。 这块我们先不考虑。 接下来，我们把处理文件上传以及重命名的操作放到一起，如下requestHandlers.js所示：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859var querystring = require(\"querystring\"), fs = require(\"fs\"), formidable = require(\"formidable\");function start(response) &#123; console.log(\"Request handler 'start' was called.\"); var body = '&lt;html&gt;'+ '&lt;head&gt;'+ '&lt;meta http-equiv=\"Content-Type\" content=\"text/html; '+ 'charset=UTF-8\" /&gt;'+ '&lt;/head&gt;'+ '&lt;body&gt;'+ '&lt;form action=\"/upload\" enctype=\"multipart/form-data\" '+ 'method=\"post\"&gt;'+ '&lt;input type=\"file\" name=\"upload\" multiple=\"multiple\"&gt;'+ '&lt;input type=\"submit\" value=\"Upload file\" /&gt;'+ '&lt;/form&gt;'+ '&lt;/body&gt;'+ '&lt;/html&gt;'; response.writeHead(200, &#123;\"Content-Type\": \"text/html\"&#125;); response.write(body); response.end();&#125;function upload(response, request) &#123; console.log(\"Request handler 'upload' was called.\"); var form = new formidable.IncomingForm(); console.log(\"about to parse\"); form.parse(request, function(error, fields, files) &#123; console.log(\"parsing done\"); fs.renameSync(files.upload.path, \"/tmp/test.png\"); response.writeHead(200, &#123;\"Content-Type\": \"text/html\"&#125;); response.write(\"received image:&lt;br/&gt;\"); response.write(\"&lt;img src='/show' /&gt;\"); response.end(); &#125;);&#125;function show(response) &#123; console.log(\"Request handler 'show' was called.\"); fs.readFile(\"/tmp/test.png\", \"binary\", function(error, file) &#123; if(error) &#123; response.writeHead(500, &#123;\"Content-Type\": \"text/plain\"&#125;); response.write(error + \"\\n\"); response.end(); &#125; else &#123; response.writeHead(200, &#123;\"Content-Type\": \"image/png\"&#125;); response.write(file, \"binary\"); response.end(); &#125; &#125;);&#125;exports.start = start;exports.upload = upload;exports.show = show; 好了，重启服务器，我们应用所有的功能就可以用了。选择一张本地图片，将其上传到服务器，然后浏览器就会显示该图片。","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"NodeJS","slug":"NodeJS","permalink":"http://arvin-he.github.io/tags/NodeJS/"}]},{"title":"Python之coroutine","slug":"python-coroutine-2017-06-02","date":"2017-06-02T05:57:23.000Z","updated":"2017-09-08T03:51:40.013Z","comments":true,"path":"2017/06/02/python-coroutine-2017-06-02/","link":"","permalink":"http://arvin-he.github.io/2017/06/02/python-coroutine-2017-06-02/","excerpt":"","text":"Coroutine概念Coroutine，又称作协程。即协同运行的例程，它是比是线程（thread）更细量级的用户态线程.特点是允许用户的主动调用和主动退出，挂起当前的例程然后返回值或去执行其他任务，接着返回原来停下的点继续执行。 一般函数都是线性执行的，不可能说执行到一半返回，等会儿又跑到原来的地方继续执行。但python（or其他动态语言）可以做到，答案是用yield语句。 其实是操作系统（OS）为我们做的工作，因为它具有getcontext和swapcontext这些特性，通过系统调用，我们可以把上下文和状态保存起来，切换到其他的上下文，这些特性为coroutine的实现提供了底层的基础。操作系统的Interrupts和Traps机制则为这种实现提供了可能性，因此它看起来可能是下面这样的: 理解生成器（generator）python有yield这个关键字，它能把一个函数变成一个generator，与return不同，yield在函数中返回值时会保存函数的状态，使下一次调用函数时会从上一次的状态继续执行，即从yield的下一条语句开始执行，节省存储空间，提高运行效率。123456def fib(max): n, a, b = 0, 0, 1 while n max: yield b a, b = b, a + b n = n + 1 注意: yield 对应的值在函数被调用时不会立刻返回，而是调用next方法时（本质上 for 循环也是调用 next 方法）才返回. 生产者-消费者协程1234567891011121314151617181920212223242526272829303132#-*- coding:utf-8def consumer(): status = True while True: n = yield status print(\"我拿到了&#123;&#125;!\".format(n)) if n == 3: status = Falsedef producer(consumer): n = 5 while n &gt; 0: # yield给主程序返回消费者的状态 yield consumer.send(n) n -= 1if __name__ == '__main__': c = consumer() c.send(None) p = producer(c) for status in p: if status == False: print(\"我只要3,4,5就行啦\") break print(\"程序结束\")我拿到了5!我拿到了4!我拿到了3!我只要3,4,5就行啦程序结束 分析:从主程序中开始看，第一句c = consumer()，因为consumer函数中存在yield语句，python会把它当成一个generator（生成器，注意：生成器和协程的概念区别很大,千万别混淆了两者），因此在运行这条语句后，python并不会像执行函数一样，而是返回了一个generator object。 第二条语句c.send(None)，这条语句的作用是将consumer（即变量c，它是一个generator）中的语句推进到第一个yield语句出现的位置，在例子中，consumer中的status = True和while True:都已经被执行了，程序停留在n = yield status的位置（注意：此时这条语句还没有被执行），上面说的send(None)语句十分重要，如果漏写这一句，那么程序直接报错。 下面第三句p = producer(c)，这里像上面一样定义了producer的生成器，注意:这里我们传入了消费者的生成器，来让producer跟consumer通信。 第四句for status in p:，这条语句会循环地运行producer和获取它yield回来的状态。 现在我们要让生产者发送1,2,3,4,5给消费者，消费者接受数字，返回状态给生产者，而我们的消费者只需要3,4,5就行了，当数字等于3时，会返回一个错误的状态。最终我们需要由主程序来监控生产者－消费者的过程状态，调度结束程序。 现在程序流进入了producer里面，我们直接看yield consumer.send(n)，生产者调用了消费者的send()方法，把n发送给consumer（即c），在consumer中的n = yield status，n拿到的是消费者发送的数字，同时，consumer用yield的方式把状态（status）返回给消费者，注意：这时producer（即消费者）的consumer.send()调用返回的就是consumer中yield的status！消费者马上将status返回给调度它的主程序，主程序获取状态，判断是否错误，若错误，则终止循环，结束程序。上面看起来有点绕，其实这里面generator.send(n)的作用是：把n发送generator(生成器)中yield的赋值语句中，同时返回generator中yield的变量（结果）。 于是程序便一直运作，直至consumer中获取的n的值变为3！此时consumer把status变为False，最后返回到主程序，主程序中断循环，程序结束。（观察输出结果，是否如你所想？） Coroutine与Generator区别最重要的区别： generator总是生成值，一般是迭代的序列 coroutine关注的是消耗值，是数据(data)的消费者 coroutine不会与迭代操作关联，而generator会 coroutine强调协同控制程序流，generator强调保存状态和产生数据 相似的是，它们都是不用return来实现重复调用的函数/对象，都用到了yield(中断/恢复)的方式来实现。 asyncio与geventasyncio是python 3.4中新增的模块，它提供了一种机制，使得你可以用协程（coroutines）、IO复用（multiplexing I/O）在单线程环境中编写并发模型。 asyncio模块主要包括了： 具有特定系统实现的事件循环（event loop）; 数据通讯和协议抽象（类似Twisted中的部分); TCP，UDP,SSL，子进程管道，延迟调用和其他; Future类; yield from的支持; 同步的支持; 提供向线程池转移作业的接口; 下面来看下asyncio的一个例子：1234567891011121314import asyncioasync def compute(x, y): print(\"Compute %s + %s ...\" % (x, y)) await asyncio.sleep(1.0) return x + yasync def print_sum(x, y): result = await compute(x, y) print(\"%s + %s = %s\" % (x, y, result))loop = asyncio.get_event_loop()loop.run_until_complete(print_sum(1, 2))loop.close() 当事件循环开始运行时，它会在Task中寻找coroutine来执行调度，因为事件循环注册了print_sum()，因此print_sum()被调用，执行result = await compute(x, y)这条语句（等同于result = yield from compute(x, y)），因为compute()自身就是一个coroutine，因此print_sum()这个协程就会暂时被挂起，compute()被加入到事件循环中，程序流执行compute()中的print语句，打印”Compute %s + %s …”，然后执行了await asyncio.sleep(1.0)，因为asyncio.sleep()也是一个coroutine，接着compute()就会被挂起，等待计时器读秒，在这1秒的过程中，事件循环会在队列中查询可以被调度的coroutine，而因为此前print_sum()与compute()都被挂起了，因此事件循环会停下来等待协程的调度，当计时器读秒结束后，程序流便会返回到compute()中执行return语句，结果会返回到print_sum()中的result中，最后打印result，事件队列中没有可以调度的任务了，此时loop.close()把事件队列关闭，程序结束。 Gevent是一个基于libv的封装了greenlet的网络库，主要用于协程以及并发的处理。 gevent的基本原理： 当一个greenlet遇到IO操作时，比如访问网络，就自动切换到其他的greenlet，等到IO操作完成，再在适当的时候切换回来继续执行。由于IO操作非常耗时，经常使程序处于等待状态，有了gevent为我们自动切换协程，就保证总有greenlet在运行，而不是等待IO。 参考 理解python coroutine","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Node笔记2","slug":"node-notes2-2017-06-01","date":"2017-06-01T09:43:53.000Z","updated":"2017-09-08T03:51:39.807Z","comments":true,"path":"2017/06/01/node-notes2-2017-06-01/","link":"","permalink":"http://arvin-he.github.io/2017/06/01/node-notes2-2017-06-01/","excerpt":"","text":"关于函数式编程将函数作为参数传递并不仅仅出于技术上的考量。对软件设计来说，这其实是个哲学问题。 想想这样的场景：在index文件中，我们可以将router对象传递进去，服务器随后可以调用这个对象的route函数。就像这样，我们传递一个东西，然后服务器利用这个东西来完成一些事。然后,那个叫路由的东西，能帮我把这个路由一下吗？但是服务器其实不需要这样的东西。它只需要把事情做完就行，其实为了把事情做完，你根本不需要东西，你需要的是动作。 也就是说，你不需要名词，你需要动词。理解了这个概念里最核心、最基本的思想转换后，我自然而然地理解了函数编程。也就是说我直接执行动作,不必给动作定一个名称,然后让那个对象根据动作名称再去执行动作,有的时候不觉得这很啰嗦么?哈哈… 路由给真正的请求处理程序路由: 是指我们要针对不同的URL有不同的处理方式。我们暂时把作为路由目标的函数称为请求处理程序。现在我们不要急着来开发路由模块，因为如果请求处理程序没有就绪的话，再怎么完善路由模块也没有多大意义。现在给应用程序增加一个新的部件。我们来创建一个叫做requestHandlers的模块，并对于每一个请求处理程序，添加一个占位用函数，随后将这些函数作为模块的方法导出： 1234567891011// requestHandlers.jsfunction start() &#123; console.log(\"Request handler 'start' was called.\");&#125;function upload() &#123; console.log(\"Request handler 'upload' was called.\");&#125;exports.start = start;exports.upload = upload; 这样就可以把请求处理程序和路由模块连接起来，让路由“有路可寻”。 在requestHandlers模块添加一点依赖,使用依赖注入可以让路由和请求处理程序之间的耦合更加松散，也因此能让路由的重用性更高。 那么什么是依赖注入?依赖注入（Dependency Injection）是用于实现控制反转（Inversion of Control）的最常见的方式之一。依赖注入不是目的，它是一系列工具和手段，最终的目的是帮助我们开发出松散耦合(loose coupled)、可维护、可测试的代码和程序。 这意味着我们得将请求处理程序(即handle)从服务器传递到路由中，但感觉上这么做更离谱了，我们得一路把这堆请求处理程序(handle)从我们的主文件(index.js)传递到服务器中(server.start函数)，再将hangle从服务器(server.start函数)传递到路由(route函数)。 那么我们要怎么传递这些请求处理程序呢？我们不想每次有一个新的URL或请求处理程序时，都要为了在路由里完成请求到处理程序的映射而反复折腾。除此之外，在路由里有一大堆if request == x then call handler y也使得系统丑陋不堪。 仔细想想，每个都要映射到一个字符串（就是请求的URL）上？似乎关联数组（associative array）能完美胜任。不过JavaScript没提供关联数组,事实上，在JavaScript中，真正能提供此类功能的是它的对象, 在python中是字典.不过javascript的对象更加强大. 在C++或C#中，当我们谈到对象，指的是类或者结构体的实例。对象根据他们实例化的模板（就是所谓的类），会拥有不同的属性和方法。但在JavaScript里对象不是这个概念。在JavaScript中，对象就是一个键/值对的集合 – 你可以把JavaScript的对象想象成一个键为字符串类型的字典。 JavaScript的对象仅仅是键/值对的集合，它又怎么会拥有方法呢？这里的值可以是字符串、数字或者函数. 现在我们已经确定将一系列请求处理程序通过一个对象(即handle)来传递，并且需要使用松耦合的方式将这个对象注入到route()函数中。我们先将这个对象引入到主文件index.js中：123456789101112// index.jsvar server = require(\"./server\");var router = require(\"./router\");var requestHandlers = require(\"./requestHandlers\");// 请求处理程序对象var handle = &#123;&#125;;handle[\"/\"] = requestHandlers.start;handle[\"/start\"] = requestHandlers.start;handle[\"/upload\"] = requestHandlers.upload;server.start(router.route, handle); 将不同的URL映射到相同的请求处理程序上是很容易的：只要在对象中添加一个键为”/“的属性，对应requestHandlers.start即可，这样就可以干净简洁地配置/start和/的请求都交由start这一处理程序处理。 在完成了对象的定义后，我们把它作为额外的参数传递给服务器，为此将server.js修改如下：123456789101112131415161718192021// server.jsvar http = require(\"http\");var url = require(\"url\");function start(route, handle) &#123; function onRequest(request, response) &#123; var pathname = url.parse(request.url).pathname; console.log(\"Request for \" + pathname + \" received.\"); route(handle, pathname); response.writeHead(200, &#123;\"Content-Type\": \"text/plain\"&#125;); response.write(\"Hello World\"); response.end(); &#125; http.createServer(onRequest).listen(8888); console.log(\"Server has started.\");&#125;exports.start = start; 在start()函数里添加了handle参数,并把handle对象作为第一个参数传递给了route()回调函数。然后我们相应地在route.js文件中修改route()函数：1234567891011// route.jsfunction route(handle, pathname) &#123; console.log(\"About to route a request for \" + pathname); if (typeof handle[pathname] === 'function') &#123; handle[pathname](); &#125; else &#123; console.log(\"No request handler found for \" + pathname); &#125;&#125;exports.route = route; 在命令行运行:node index.js, 通过以上代码，首先检查给定的路径对应的请求处理程序是否存在，如果存在直接调用相应的函数。我们可以用从关联数组中获取元素一样的方式从传递的对象中获取请求处理函数，因此就有了简洁流畅的形如handle[pathname]();的表达式，这个感觉就像在前方中提到的那样：“嗨，请帮我处理了这个路径”。 让请求处理程序作出响应其实“处理请求”说白了就是“对请求作出响应”，因此，我们需要让请求处理程序能够像onRequest函数那样可以和浏览器进行“对话”。 不好的实现方式不好的实现方式是指:让请求处理程序通过onRequest函数直接返回（return()）他们要展示给用户的信息。 我们先就这样去实现，然后再来看为什么这不是一种很好的实现方式。 让我们从让请求处理程序返回需要在浏览器中显示的信息开始。我们需要将requestHandler.js修改为如下形式：123456789101112function start() &#123; console.log(\"Request handler 'start' was called.\"); return \"Hello Start\";&#125;function upload() &#123; console.log(\"Request handler 'upload' was called.\"); return \"Hello Upload\";&#125;exports.start = start;exports.upload = upload; 同样请求路由需要将请求处理程序返回给它的信息返回给服务器。因此，我们需要将router.js修改为如下形式：1234567891011function route(handle, pathname) &#123; console.log(\"About to route a request for \" + pathname); if (typeof handle[pathname] === 'function') &#123; return handle[pathname](); &#125; else &#123; console.log(\"No request handler found for \" + pathname); return \"404 Not found\"; &#125;&#125;exports.route = route; 正如上述代码所示，当请求无法路由的时候，我们也返回了一些相关的错误信息。 最后，对server.js进行重构以使得它能够将请求处理程序通过请求路由返回的内容响应给浏览器，如下所示：12345678910111213141516171819var http = require(\"http\");var url = require(\"url\");function start(route, handle) &#123; function onRequest(request, response) &#123; var pathname = url.parse(request.url).pathname; console.log(\"Request for \" + pathname + \" received.\"); response.writeHead(200, &#123;\"Content-Type\": \"text/plain\"&#125;); var content = route(handle, pathname); response.write(content); response.end(); &#125; http.createServer(onRequest).listen(8888); console.log(\"Server has started.\");&#125;exports.start = start; 运行重构后的应用，一切都会工作的很好：请求http://localhost:8888/start,浏览器会输出“Hello Start”，请求http://localhost:8888/upload会输出“Hello Upload”,请求http://localhost:8888/foo 会输出“404 Not found”。 那么问题在哪里呢？简单的说就是： 当未来有请求处理程序需要进行非阻塞的操作的时候，我们的应用就“挂”了。为什么呢? 阻塞与非阻塞直接来看，当在请求处理程序中加入阻塞操作时会发生什么?修改下start请求处理程序，让它等待10秒以后再返回“Hello Start”。因为，JavaScript中没有类似sleep()这样的操作，所以这里只能够来点小Hack来模拟实现。将requestHandlers.js修改成如下形式：1234567891011121314151617181920function start() &#123; console.log(\"Request handler 'start' was called.\"); function sleep(milliSeconds) &#123; var startTime = new Date().getTime(); while (new Date().getTime() &lt; startTime + milliSeconds); &#125; sleep(10000); return \"Hello Start\";&#125;function upload() &#123; console.log(\"Request handler 'upload' was called.\"); return \"Hello Upload\";&#125;exports.start = start;exports.upload = upload; 上述代码中，当函数start()被调用的时候，Node.js会先等待10秒，之后才会返回“Hello Start”。当调用upload()的时候，会和此前一样立即返回。(这里只是模拟休眠10秒，实际场景中，这样的阻塞操作有很多，比如耗时的计算操作等。） 我们重启下服务器。为了看到效果，我们要进行一些相对复杂的操作：首先，打开两个浏览器窗口或者标签页。在第一个浏览器窗口的地址栏中输入http://localhost:8888/start， 但是先不要打开它！在第二个浏览器窗口的地址栏中输入http://localhost:8888/upload， 同样的，先不要打开它！接下来，做如下操作：在第一个窗口中（“/start”）按下回车，然后快速切换到第二个窗口中（“/upload”）按下回车。 注意，发生了什么： /start URL加载花了10秒，但是，/upload URL居然也花了10秒，而它在对应的请求处理程序中并没有类似于sleep()这样的操作！ 这到底是为什么呢？原因就是start()包含了阻塞操作。形象的说就是“它阻塞了所有其他的处理工作”。 这显然是个问题，因为Node一向是这样来标榜自己的：“在node中除了代码，所有一切都是并行执行的”。这句话的意思是说，Node.js可以在不新增额外线程的情况下，依然可以对任务进行并行处理 —— Node.js是单线程的。它通过事件轮询（event loop）来实现并行操作，对此，应该尽可能的避免阻塞操作，取而代之，多使用非阻塞操作。然而，要用非阻塞操作，需要使用回调，通过将函数作为参数传递给其他需要花时间做处理的函数（比方说，休眠10秒，或者查询数据库，又或者是进行大量的计算）。对于Node.js来说，它是这样处理的：“嘿，probablyExpensiveFunction()（译者注：这里指的就是需要花时间处理的函数），你继续处理你的事情，我（Node.js线程）先不等你了，我继续去处理你后面的代码，请你提供一个callbackFunction()，等你处理完之后我会去调用该回调函数的，谢谢！” 一种错误的使用非阻塞操作的方式还是从start请求处理程序开始。将其修改成如下形式：1234567891011121314151617181920var exec = require(\"child_process\").exec;function start() &#123; console.log(\"Request handler 'start' was called.\"); var content = \"empty\"; exec(\"ls -lah\", function (error, stdout, stderr) &#123; content = stdout; &#125;); return content;&#125;function upload() &#123; console.log(\"Request handler 'upload' was called.\"); return \"Hello Upload\";&#125;exports.start = start;exports.upload = upload; 上述代码中，引入了一个新的Node.js内建模块child_process。之所以用它，是为了实现一个既简单又实用的非阻塞操作：exec()。 exec()做了什么呢？它从Node.js来执行一个shell命令。在上述例子中，我们用它来获取当前目录下所有的文件（“ls -lah”）,然后，当/startURL请求的时候将文件信息输出到浏览器中。 上述代码是非常直观的： 创建了一个新的变量content（初始值为“empty”），执行“ls -lah”命令，将结果赋值给content，最后将content返回。 和往常一样，我们启动服务器，然后访问“http://localhost:8888/start” 。之后会载入一个漂亮的web页面，其内容为“empty”, 却不是”hello start”。怎么回事？原因是exec()在非阻塞这块发挥了神奇的功效。它其实是个很好的东西，有了它，我们可以执行非常耗时的shell操作而无需迫使应用停下来等待该操作。然而，针对浏览器显示的结果来看，我们并不满意我们的非阻塞操作，对吧？好，接下来，我们来修正这个问题。在这过程中，让我们先来看看为什么当前的这种方式不起作用。问题就在于:为了进行非阻塞工作，exec()使用了回调函数。在我们的例子中，该回调函数就是作为第二个参数传递给exec()的匿名函数：123exec(\"ls -lah\", function (error, stdout, stderr) &#123; content = stdout; &#125;); 现在就到了问题根源所在了：代码是同步执行的，这就意味着在调用exec()之后，Node.js会立即执行return content;, 而此时content仍然是“empty”，因为传递给exec()的回调函数还未执行到, 因为exec()的操作是异步的。这里“ls -lah”的操作其实是非常快的（除非当前目录下有上百万个文件）。这也是为什么回调函数也会很快的执行到, 不过，不管怎么说它还是异步的。为了让效果更加明显，我们使用一个更耗时的命令： “find /”，尽管在请求处理程序中，把“ls -lah”换成“find /”，当打开/start URL的时候，依然能够立即获得HTTP响应 —— 很明显，当exec()在后台执行的时候，Node.js自身会继续执行后面的代码。并且我们这里假设传递给exec()的回调函数，只会在“find /”命令执行完成之后才会被调用。 那究竟我们要如何才能实现将当前目录下的文件列表显示给用户呢？了解了这种不好的实现方式之后，我们接下来来介绍如何以正确的方式让请求处理程序对浏览器请求作出响应。 以非阻塞操作进行请求响应正确的方式是Node.js有这样一种实现方案:函数传递。目前,我们的应用已经可以通过应用各层之间传递值的方式（请求处理程序 -&gt; 请求路由 -&gt; 服务器）将请求处理程序返回的内容（请求处理程序最终要显示给用户的内容）传递给HTTP服务器。 现在采用新的实现方式：相对采用将内容传递给服务器的方式，这次采用将服务器“传递”给内容的方式。 从实践角度来说，就是将response对象（从服务器的回调函数onRequest()获取）通过请求路由传递给请求处理程序。 随后，处理程序就可以采用该对象上的函数来对请求作出响应。 原理就是如此，接下来一步步实现这种方案。先从server.js开始：123456789101112131415161718var http = require(\"http\");var url = require(\"url\");function start(route, handle) &#123; function onRequest(request, response) &#123; var pathname = url.parse(request.url).pathname; console.log(\"Request for \" + pathname + \" received.\"); // 注意route函数的第三个参数 route(handle, pathname, response); &#125; http.createServer(onRequest).listen(8888); console.log(\"Server has started.\");&#125;exports.start = start; 相对此前从route()函数获取返回值的做法，这次将response对象作为第三个参数传递给route()函数，并且，将onRequest()处理程序中所有有关response的函数调都移除，因为我们希望这部分工作让route()函数来完成。 下面就来看看我们的router.js:12345678910111213function route(handle, pathname, response) &#123; console.log(\"About to route a request for \" + pathname); if (typeof handle[pathname] === 'function') &#123; handle[pathname](response); &#125; else &#123; console.log(\"No request handler found for \" + pathname); response.writeHead(404, &#123;\"Content-Type\": \"text/plain\"&#125;); response.write(\"404 Not found\"); response.end(); &#125;&#125;exports.route = route; 同样的模式：相对此前从请求处理程序中获取返回值，这次取而代之的是直接传递response对象。如果没有对应的请求处理器处理，我们就直接返回“404”错误。最后，我们将requestHandler.js修改为如下形式：123456789101112131415161718192021var exec = require(\"child_process\").exec;function start(response) &#123; console.log(\"Request handler 'start' was called.\"); exec(\"ls -lah\", function (error, stdout, stderr) &#123; response.writeHead(200, &#123;\"Content-Type\": \"text/plain\"&#125;); response.write(stdout); response.end(); &#125;);&#125;function upload(response) &#123; console.log(\"Request handler 'upload' was called.\"); response.writeHead(200, &#123;\"Content-Type\": \"text/plain\"&#125;); response.write(\"Hello Upload\"); response.end();&#125;exports.start = start;exports.upload = upload; 我们的处理程序函数需要接收response参数，为了对请求作出直接的响应。 start处理程序在exec()的匿名回调函数中做请求响应的操作，而upload处理程序仍然是简单的回复“Hello World”，只是这次是使用response对象而已。 这时再次我们启动应用（node index.js），一切都会工作的很好。 如果想要证明/start处理程序中耗时的操作不会阻塞对/upload请求作出立即响应的话，可以将requestHandlers.js修改为如下形式：1234567891011121314151617181920212223var exec = require(\"child_process\").exec;function start(response) &#123; console.log(\"Request handler 'start' was called.\"); exec(\"find /\", &#123; timeout: 10000, maxBuffer: 20000*1024 &#125;, function (error, stdout, stderr) &#123; response.writeHead(200, &#123;\"Content-Type\": \"text/plain\"&#125;); response.write(stdout); response.end(); &#125;);&#125;function upload(response) &#123; console.log(\"Request handler 'upload' was called.\"); response.writeHead(200, &#123;\"Content-Type\": \"text/plain\"&#125;); response.write(\"Hello Upload\"); response.end();&#125;exports.start = start;exports.upload = upload; 这样一来，当请求http://localhost:8888/start的时候，会花10秒钟的时间才载入，而当请求http://localhost:8888/upload的时候，会立即响应，纵然这个时候/start响应还在处理中。 参考 Node入门","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"NodeJS","slug":"NodeJS","permalink":"http://arvin-he.github.io/tags/NodeJS/"}]},{"title":"Node笔记1","slug":"node-notes-2017-06-01","date":"2017-06-01T07:45:03.000Z","updated":"2017-09-08T03:51:39.800Z","comments":true,"path":"2017/06/01/node-notes-2017-06-01/","link":"","permalink":"http://arvin-he.github.io/2017/06/01/node-notes-2017-06-01/","excerpt":"","text":"创建一个http服务器12345678910// 第一行请求（require）Node.js自带的 http 模块，并且把它赋值给 http 变量。var http = require(\"http\");// 调用http模块提供的函数:createServer.该函数会返回一个对象// 该对象有一个listen的方法,该方法有一个数值参数,指定这个HTTP服务器监听的端口号。http.createServer(function(request, response)&#123; response.writeHead(200, &#123;\"Content-Type\":\"text/plain\"&#125;); response.write(\"Hello World\"); response.end();&#125;).listen(8888); 在命令行输入:node server.js,打开浏览器访问http://localhost:8888/，你会看到一个写着“Hello World”的网页。注意:createServer 函数的参数是一个匿名函数。即function(request, response){...}. 基于事件驱动的回调当使用 http.createServer 方法的时候，不只想要侦听某个端口，还想要它在服务器收到一个HTTP请求的时候做点什么。但问题是，这是异步的：请求任何时候都可能到达，但是服务器却跑在一个单进程中。那么Node.js程序中，当一个新的请求到达8888端口的时候，我们怎么控制流程呢？嗯，这就需要Node.js/JavaScript的事件驱动,现在看看这些概念是怎么应用在我们的服务器代码里的。我们创建了服务器，并且向创建它的方法传递了一个函数。无论何时服务器收到一个请求，这个函数就会被调用。我们不知道这件事情什么时候会发生，但是我们现在有了一个处理请求的地方：它就是我们传递过去的那个匿名函数。至于它是被预先定义的函数还是匿名函数，就无关紧要了。这个就是传说中的 回调 。我们给某个方法传递了一个函数，这个方法在有相应事件发生时调用这个函数来进行回调 。 1234567891011121314151617181920var http = require(\"http\");// http.createServer(function(request, response)// &#123;// response.writeHead(200, &#123;\"Content-Type\":\"text/plain\"&#125;);// response.write(\"Hello World\");// response.end();// &#125;).listen(8888);function onRequest(request, response)&#123; console.log(\"Request receives.\"); response.writeHead(200, &#123;\"Content-Type\":\"text/plain\"&#125;); response.write(\"Hello World\"); response.end();&#125;http.createServer(onRequest).listen(8888);console.log(\"Server has started.\"); 当运行node server.js时，它会马上在命令行上输出“Server has started.”。当我们向服务器发出请求（在浏览器访问http://localhost:8888/ ）或者强制刷新页面时，“Request received.”这条消息就会在命令行中出现。这就是事件驱动的异步服务器端JavaScript和它的回调！注意:当我们在服务器访问网页时，服务器可能会输出两次“Request received.”。那是因为大部分浏览器都会在你访问 http://localhost:8888/ 时尝试读取http://localhost:8888/favicon.ico ) 服务器是如何处理请求的当回调启动，即onRequest()函数被触发的时候,有两个参数被传入:request 和 response.它们是对象，你可以使用它们的方法来处理HTTP请求的细节，并且响应请求（比如向发出请求的浏览器发回一些东西）。所以当收到请求时，使用 response.writeHead() 函数发送一个HTTP状态200和HTTP头的内容类型（content-type），使用 response.write() 函数在HTTP相应主体中发送文本“Hello World”。最后，调用 response.end() 完成响应。目前来说，我们对请求的细节并不在意，所以我们没有使用 request 对象。 关于变量命名Node.js中自带了一个叫做“http”的模块，在代码中请求它并把返回值赋给一个本地变量http。这样本地变量http就变成了一个拥有所有 http 模块所提供的公共方法的对象。给这种本地变量起一个和模块名称一样的名字是一种惯例，但你也可以按照自己的喜好来. 创建自己的模块我们把 server.js 变成一个真正的模块，你就能搞明白了。事实上，我们不用做太多的修改。把某段代码变成模块意味着需要把我们希望提供其功能的部分 导出到请求这个模块的脚本。目前，HTTP服务器需要导出的功能非常简单，因为请求服务器模块的脚本仅仅是需要启动服务器而已。我们把服务器脚本放到一个叫做 start 的函数里，然后我们导出这个函数。12345678910111213141516// server.jsvar http = require(\"http\");function start() &#123; function onRequest(request, response) &#123; console.log(\"Request received.\"); response.writeHead(200, &#123;\"Content-Type\": \"text/plain\"&#125;); response.write(\"Hello World\"); response.end(); &#125; http.createServer(onRequest).listen(8888); console.log(\"Server has started.\");&#125;// 导出start函数exports.start = start; 这样，现在就可以创建我们的主文件 index.js 并在其中启动我们的HTTP了，虽然服务器的代码还在 server.js 中。创建 index.js 文件并写入以下内容：12var server = require(\"./server\");server.start(); 正如上面所示代码，我们可以像使用任何其他的内置模块一样使用server模块：请求这个server.js文件并把它指向一个server变量，导出的start函数就可以被我们使用了。好了。现在可以从我们的主要脚本启动我们的的应用了，在命令行输入：node index.js 路由处理不同的HTTP请求在代码中是一个不同的部分，叫做“路由选择”，接下来就创造一个叫做”路由”的模块。 我们要为路由提供请求的URL和其他需要的GET及POST参数，随后路由需要根据这些数据来执行相应的代码（这里“代码”对应整个应用的第三部分：一系列在接收到请求时真正工作的处理程序）。 因此，我们需要查看HTTP请求，从中提取出请求的URL以及GET/POST参数。这一功能应当属于路由还是服务器（甚至作为一个模块自身的功能）确实值得探讨，但这里暂定其为我们的HTTP服务器的功能。 我们需要的所有数据都会包含在request对象中，该对象作为onRequest()回调函数的第一个参数传递。但是为了解析这些数据，需要额外的Node.JS模块，它们分别是url和querystring模块。当然我们也可以用querystring模块来解析POST请求体中的参数.现在我们来给onRequest()函数加上一些逻辑，用来找出浏览器请求的URL路径： 123456789101112131415161718// server.jsvar http = require(\"http\");var url = require(\"url\");function start() &#123; function onRequest(request, response) &#123; var pathname = url.parse(request.url).pathname; console.log(\"Request for \" + pathname + \" received.\"); response.writeHead(200, &#123;\"Content-Type\": \"text/plain\"&#125;); response.write(\"Hello World\"); response.end(); &#125; http.createServer(onRequest).listen(8888); console.log(\"Server has started.\");&#125;exports.start = start; 现在可以根据请求的URL路径来区别不同请求了,然后使用路由将请求以URL路径为基准映射到处理程序上。现在以来编写路由了，建立一个名为router.js的文件，添加以下内容：12345function route(pathname) &#123; console.log(\"About to route a request for \" + pathname);&#125;exports.route = route; 如你所见，这段代码什么也没干，不过对于现在来说这是应该的。在添加更多的逻辑之前，我们需要先来看看如何把路由和服务器整合起来。使用硬编码的方式将这一依赖项绑定到服务器上是一件非常痛苦的事，因此我们采用依赖注入的方式来添加路由模块,这种方式较为松散. 首先，来扩展一下服务器的start()函数，以便将路由函数作为参数传递过去:12345678910111213141516171819202122var http = require(\"http\");var url = require(\"url\");// 注意:start函数传进一个route参数function start(route) &#123; function onRequest(request, response) &#123; var pathname = url.parse(request.url).pathname; console.log(\"Request for \" + pathname + \" received.\"); // 这个route函数就是router模块里的route函数 route(pathname); response.writeHead(200, &#123;\"Content-Type\": \"text/plain\"&#125;); response.write(\"Hello World\"); response.end(); &#125; http.createServer(onRequest).listen(8888); console.log(\"Server has started.\");&#125;exports.start = start; 同时，相应扩展index.js，使得路由函数可以被注入到服务器中：12345var server = require(\"./server\");var router = require(\"./router\");// 这里将router模块的route函数传进start函数中去server.start(router.route); 在这里，传递的route函数依旧什么也没做。如果现在启动应用随后请求一个URL，你将会看到应用输出相应的信息，这表明我们的HTTP服务器已经在使用路由模块了，并会将请求的路径传递给路由.输出结果为:123456C:\\Users\\aron\\AppData\\Roaming\\aronWorkSpace\\arvinGithub\\node&gt;node index.jsServer has started.Request for / received.About to route a request for /Request for /favicon.ico received.About to route a request for /favicon.ico 参考 Node入门","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"NodeJS","slug":"NodeJS","permalink":"http://arvin-he.github.io/tags/NodeJS/"}]},{"title":"Python之高阶函数","slug":"python-advancefunc-2016-06-01","date":"2017-06-01T03:39:39.000Z","updated":"2017-09-08T03:51:39.992Z","comments":true,"path":"2017/06/01/python-advancefunc-2016-06-01/","link":"","permalink":"http://arvin-he.github.io/2017/06/01/python-advancefunc-2016-06-01/","excerpt":"","text":"高阶函数定义高阶函数英文叫 Higher-order function, 一个函数就可以接收另一个函数作为参数，这种函数就称之为高阶函数。 变量可以指向函数123456789101112131415161718In [18]: abs(-5) Out[18]: 5 In [19]: abs Out[19]: &lt;function abs&gt; In [20]: x = abs(-10) In [21]: x Out[21]: 10 In [22]: f = abs In [23]: f Out[23]: &lt;function abs&gt; In [24]: f(-6)Out[24]: 6 由上面的示例得出：函数本身也可以赋值给变量，即：变量可以指向函数。且该变量可以来调用这个函数. 函数名也是变量函数名其实就是指向函数的变量. 对于abs()这个函数，完全可以把函数名abs看成变量，它指向一个可以计算绝对值的函数.如果把abs指向其他对象，会有什么情况发生？123456789In [25]: abs = 10 In [26]: abs(-10) ---------------------------------------------------------------------------TypeError Traceback (most recent call last)&lt;ipython-input-26-c432e3f1fd6c&gt; in &lt;module&gt;() ----&gt; 1 abs(-10) TypeError: 'int' object is not callable 把abs指向10后，就无法通过abs(-10)调用该函数了, 因为abs这个变量已经不指向求绝对值函数而是指向一个整数10！当然实际代码绝对不能这么写，这里是为了说明函数名也是变量。要恢复abs函数，请重启Python交互环境。注：由于abs函数实际上是定义在import builtins模块中的，所以要让修改abs变量的指向在其它模块也生效，要用import builtins; builtins.abs = 10。 将函数作为参数传入123456In [1]: def add(x, y, f): ...: return f(x) + f(y) ...:In [2]: add(2, -3, abs)Out[2]: 5 编写高阶函数，目的就是让函数的参数能够接收别的函数。 常用的高阶函数 map()高阶函数map()函数接收两个参数，一个是函数，一个是Iterable，map将传入的函数依次作用到序列的每个元素，并把结果作为新的Iterator返回.1234567891011In [3]: def f(x): ...: return x*x ...:In [4]: r = map(f, [1, 2, 3, 4, 5])In [5]: list(r)Out[5]: [1, 4, 9, 16, 25]In [6]: list(map(str, [1, 2, 3, 4, 5]))Out[6]: ['1', '2', '3', '4', '5'] map()传入的第一个参数是f，即函数对象本身。由于结果r是一个Iterator，Iterator是惰性序列，因此通过list()函数让它把整个序列都计算出来并返回一个list. reduce()高阶函数reduce把一个函数作用在一个序列[x1, x2, x3, …]上，这个函数必须接收两个参数，一个是函数，一个是Iterable，reduce的作用就是把结果继续和序列的下一个元素做累积计算.即对于序列内所有元素进行累计操作. 12345678910111213141516171819202122In [12]: from functools import reduceIn [13]: def add(x, y): ...: return x+y ...:In [14]: reduce(add, [1, 2, 3, 4])Out[14]: 10# 配合map()，我们就可以写出把str转换为int的函数：&gt;&gt;&gt; from functools import reduce&gt;&gt;&gt; def fn(x, y):... return x * 10 + y...&gt;&gt;&gt; def char2num(s):... return &#123;'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9&#125;[s]...&gt;&gt;&gt; reduce(fn, map(char2num, '13579'))13579# 更简洁的写法,采用lambda函数def str2int(s): return reduce(lambda x, y: x * 10 + y, map(char2num, s)) fiter()高阶函数Python内建的filter()函数用于过滤序列。filter()也接收一个函数和一个序列。和map()不同的是，filter()把传入的函数依次作用于每个元素，然后根据返回值是True还是False决定保留还是丢弃该元素。 12345def is_odd(n): return n % 2 == 1list(filter(is_odd, [1, 2, 4, 5, 6, 9, 10, 15]))# 结果: [1, 5, 9, 15] sorted()高阶函数排序也是在程序中经常用到的算法。排序的核心是比较两个元素的大小。sorted()函数也是一个高阶函数，它接受3个参数, 其中接收一个key函数来实现自定义的排序，key指定的函数将作用于list的每一个元素上，并根据key函数返回的结果进行排序, 例如按绝对值大小排序： 123456# sorted函数原型sorted(...) sorted(iterable, key=None, reverse=False) --&gt; new sorted list&gt;&gt;&gt; sorted([36, 5, -12, 9, -21], key=abs)[5, 9, -12, -21, 36] 对字符串排序，是按照ASCII的大小比较的,现在，我们提出排序应该忽略大小写，按照字母序排序。12&gt;&gt;&gt; sorted(['bob', 'about', 'Zoo', 'Credit'], key=str.lower)['about', 'bob', 'Credit', 'Zoo'] 要进行反向排序，不必改动key函数，可以传入第三个参数reverse=True：12&gt;&gt;&gt; sorted(['bob', 'about', 'Zoo', 'Credit'], key=str.lower, reverse=True)['Zoo', 'Credit', 'bob', 'about'] 参考 廖雪峰python教程","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Python之Lambda使用","slug":"python-lambda-2017-06-01","date":"2017-06-01T02:21:48.000Z","updated":"2017-09-08T03:51:40.084Z","comments":true,"path":"2017/06/01/python-lambda-2017-06-01/","link":"","permalink":"http://arvin-he.github.io/2017/06/01/python-lambda-2017-06-01/","excerpt":"","text":"Lambda 函数Python 中定义函数有两种方法，一种是用常规方式 def 定义，函数要指定名字，第二种是用 lambda 定义，不需要指定名字，称为 Lambda 函数。Lambda 函数又称匿名函数，匿名函数就是没有名字的函数。有些函数如果只是临时一用，而且它的业务逻辑也很简单时，就没必要非给它取个名字不可。 lamdba 函数使用场景 函数式编程Python提供了函数式编程的特性，如 map、reduce、filter、sorted 这些函数都支持函数作为参数.lambda 函数就可以应用在函数式编程中。下面看一个例子: 将一个整数列表，要求按照列表中元素的绝对值大小升序排列12345678910111213# 方法1In [12]: my_list = [2, 6, 5, -3, -1, 8] In [13]: sorted(my_list, key=lambda x : abs(x)) Out[13]: [-1, 2, -3, 5, 6, 8] # 方法2 In [14]: def foo(x): ...: return abs(x) ...: In [15]: sorted(my_list, key=foo) Out[15]: [-1, 2, -3, 5, 6, 8] 方法1和方法2都能达到同样的效果,只不过方法2看起来不够 Pythonic 而已。方法1更加简洁 闭包看一个用 lambda 函数作为闭包的例子123456789101112131415&gt;&gt;&gt; def my_add(n):... return lambda x:x+n...&gt;&gt;&gt; add_3 = my_add(3)&gt;&gt;&gt; add_3(7)10&gt;&gt;&gt; def my_add(n):... def wrapper(x):... return x+n... return wrapper...&gt;&gt;&gt; add_5 = my_add(5)&gt;&gt;&gt; add_5(2)7 这里的 lambda 函数就是一个闭包，在全局作用域范围中，add_3(7) 可以正常执行且返回值为10，之所以返回10是因为在my_add 局部作用域中，变量 n 的值在闭包的作用使得它在全局作用域也可以被访问到。换成常规函数也可以实现闭包，只不过是这种方式稍显啰嗦。 使用lambda局限与注意点 python中的lambda中不可以赋值 python中的lambda只能写一句表达式,不可以写多个语句 如果用 lambda 函数不能使你的代码变得更清晰时，这时就要考虑使用常规的方式来定义函数, zen of python 中有这样一句话是 Explicit is better than implicit(明了胜于晦涩)","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Python之闭包","slug":"python-closure-2017-06-01","date":"2017-06-01T00:31:07.000Z","updated":"2017-09-08T03:51:40.004Z","comments":true,"path":"2017/06/01/python-closure-2017-06-01/","link":"","permalink":"http://arvin-he.github.io/2017/06/01/python-closure-2017-06-01/","excerpt":"","text":"前言谈到闭包,先要了解两个概念:作用域和嵌套函数Python 里面有四种作用域：function, module, global和 class 作用域。由于 Python 不区分变量的声明，所以在第一次初始化变量时（必须为赋值操作）将变量加入当前环境中。如果在没对变量进行初始化的情况下使用该变量就会报运行时异常，但如果仅仅是访问（并不赋值）的情况下，查找变量的顺序会按照 LEGB 规则 (Local, Enclosing, Global, Built-in)。 作用域作用域是程序运行时变量可被访问的范围，定义在函数内的变量是局部变量，局部变量的作用范围只能是函数内部范围内，它不能在函数外引用。定义在模块最外层的变量是全局变量，它是全局范围内可见的，当然在函数里面也可以读取到全局变量的 123456s = \"hello\"def foo(): s += \"world\" return sfoo() # UnboundLocalError: local variable 's' referenced before assignment 由于在函数 foo 中在没有对 s 初始化的情况下使用了该值，所以这里会报异常，解决的办法就是使用 global 关键字：123456s = \"hello\"def foo(): global s s += \" world\" return sfoo() # return \"hello world\" 但由于 global 关键字只能限定在global作用域内查找变量，在有嵌套定义的时候就有问题了，比如：12345678def foo(): s = \"hello\" def bar(): global s # NameError: global name 's' is not defined s += \" world\" return s return barfoo()() Python 3 中引入了 nonlocal 关键字来解决这个问题，：12345678def foo(): s = \"hello\" def bar(): nonlocal s s += \" world\" return s return barfoo()() # return \"hello world\" 嵌套函数函数不仅可以定义在模块的最外层，还可以定义在另外一个函数的内部，像这种定义在函数里面的函数称之为嵌套函数（nested function）例如：12345678910def print_msg(): # print_msg 是外围函数 msg = \"zen of python\" def printer(): # printer是嵌套函数 print(msg) printer()# 输出 zen of pythonprint_msg() 对于嵌套函数，它可以访问到其外层作用域中声明的非局部（non-local）变量，比如代码示例中的变量 msg 可以被嵌套函数 printer 正常访问。那么有没有一种可能即使脱离了函数本身的作用范围，局部变量还可以被访问得到呢？答案是闭包 闭包简单的说:闭包是一个函数内部嵌套着另一个函数，而被嵌套的那个函数有权利访问嵌套它的那个函数的作用域中变量。 当符合下面几个条件时就形成了闭包： 有一个Nested function 这个Nested function访问了父函数作用域中的变量 父函数返回了这个Nested function 1234567891011def print_msg(): # print_msg 是外围函数 msg = \"zen of python\" def printer(): # printer 是嵌套函数 print(msg) return printeranother = print_msg()# 输出 zen of pythonanother() 这段代码和上面的嵌套函数的效果一样，都输出 “zen of python”。不同的地方在于内部函数 printer 直接作为返回值返回了。一般情况下，函数中的局部变量仅在函数的执行期间可用，一旦 print_msg() 执行过后，我们会认为 msg变量将不再可用。然而，在这里我们发现 print_msg 执行完之后，在调用 another 的时候 msg 变量的值正常输出了，这就是闭包的作用，闭包使得局部变量在函数外被访问成为可能。这里的 another 就是一个闭包，闭包本质上是一个函数，它有两部分组成，printer 函数和变量 msg。闭包使得这些变量的值始终保存在内存中。闭包，顾名思义，就是一个封闭的包裹，里面包裹着自由变量，就像在类里面定义的属性值一样，自由变量的可见范围随同包裹，哪里可以访问到这个包裹，哪里就可以访问到这个自由变量. 为什么要使用闭包运用闭包可以避免对全局变量的使用。对于一个只有需要实现少数方法的类我们也可以用闭包来替代，这样做可以减少资源的使用。此外，闭包允许将函数与其所操作的某些数据（环境）关连起来。这一点与面向对象编程是非常类似的，在面对象编程中，对象允许我们将某些数据（对象的属性）与一个或者多个方法相关联。一般来说，当对象中只有一个方法时，这时使用闭包是更好的选择。来看一个例子：1234567891011121314151617181920In [5]: def adder(x): ...: def wrapper(y): ...: print(\"x = &#123;&#125;\".format(x)) ...: print(\"y = &#123;&#125;\".format(y)) ...: return x+y ...: return wrapper ...: ...: In [6]: adder5 = adder(5) In [7]: adder5(10) x = 5 y = 10 Out[7]: 15 In [8]: adder5(6) x = 5 y = 6 Out[8]: 11 这比用类来实现更优雅，此外装饰器也是基于闭包的一中应用场景。所有函数都有一个 __closure__属性，如果这个函数是一个闭包的话，那么它返回的是一个由 cell 对象 组成的元组对象。cell 对象的cell_contents 属性就是闭包中的自由变量。这解释了为什么局部变量脱离函数之后，还可以在函数之外被访问的原因的，因为它存储在了闭包的 cell_contents中了。 1234567In [9]: adder.__closure__In [10]: adder5.__closure__Out[10]: (&lt;cell at 0x03F8FB30: int object at 0x1DFAD210&gt;,)In [11]: adder5.__closure__[0].cell_contentsOut[11]: 5 闭包与装饰器闭包通常用来实现一个通用的功能，Python中的装饰器就是对闭包的一种应用，只不过装饰器中父函数的参数是一个函数123456789101112131415def make_wrap(func): def wrapper(*args): print(\"before function\") func(*args) print(\"after function\") return wrapper @make_wrapdef print_msg(msg): print(msg) &gt;&gt;&gt; print_msg(\"Hello\")before functionHelloafter function 装饰器也可以进行叠加123456789101112131415161718def make_another(func): def wrapper(*args): print(\"another begin\") func(*args) print(\"another end\") return wrapper@make_another@make_wrapdef print_msg(msg): print(msg)&gt;&gt;&gt; print_msg(\"Hello\")another beginbefore functionHelloafter functionanother end 参考 http://liujiacai.net/blog/2016/05/28/scope-closure/ https://juejin.im/post/59191552128fe1005ccd015f https://juejin.im/post/59022e730ce463006156fdf3 https://kasheemlew.github.io/2017/04/05/python-closure/","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Python之functools","slug":"python-partial-2017-05-31","date":"2017-05-31T08:57:57.000Z","updated":"2017-09-08T03:51:40.124Z","comments":true,"path":"2017/05/31/python-partial-2017-05-31/","link":"","permalink":"http://arvin-he.github.io/2017/05/31/python-partial-2017-05-31/","excerpt":"","text":"functools.partialfunctools.partial 通过包装手法，允许我们 “重新定义” 函数签名, 用一些默认参数包装一个可调用对象, 返回结果是可调用对象，并且可以像原始对象一样对待冻结部分函数位置函数或关键字参数，简化函数, 更少更灵活的函数参数调用. 总之,通过设定参数的默认值，可以降低函数调用的难度.简单总结functools.partial的作用就是，把一个函数的某些参数给固定住（也就是设置默认值），返回一个新的函数，调用这个新函数会更简单。1234567891011import functoolsdef add(a, b): return a + badd(4, 2)6plus3 = functools.partial(add, 3)plus3(4)7 functool.update_wrapper默认partial对象没有__name__和__doc__, 这种情况下，对于装饰器函数非常难以debug.使用update_wrapper(),从原始对象拷贝或加入现有partial对象,它可以把被封装函数的__name__、 __module__ 、__doc__和__dict__都复制到封装函数去(模块级别常量WRAPPER_ASSIGNMENTS, WRAPPER_UPDATES)这个函数主要用在装饰器函数中，装饰器返回函数反射得到的是包装函数的函数定义而不是原始函数定义1234567891011121314151617181920212223from functools import update_wrapperdef wrap2(func): def call_it(*args, **kwargs): \"\"\"wrap func: call_it2\"\"\" print 'before call' return func(*args, **kwargs) return update_wrapper(call_it, func)@wrap2def hello2(): \"\"\"test hello\"\"\" print 'hello world2'if __name__ == '__main__': hello2() print hello2.__name__ print hello2.__doc__before callhello world2hello2test hello functool.wraps调用函数装饰器partial(update_wrapper, wrapped=wrapped, assigned=assigned, updated=updated)的简写12345678910111213141516171819from functools import wrapsdef wrap3(func): @wraps(func) def call_it(*args, **kwargs): \"\"\"wrap func: call_it2\"\"\" print 'before call' return func(*args, **kwargs) return call_it@wrap3def hello3(): \"\"\"test hello 3\"\"\" print 'hello world3'before callhello world3hello3test hello 3 functools.reduce等同于内置函数reduce(),用这个的原因是使代码更兼容(python3) functools.cmp_to_keyfunctools.cmp_to_key(func)将老式的比较函数（comparison function）转换为关键字函数（key function），与接受key function的工具一同使用（例如sorted，min，max，heapq.nlargest，itertools.groupby），该函数主要用于将程序转换成Python 3格式的，因为Python 3中不支持比较函数。123456789from functools import cmp_to_keydef compare(ele1,ele2): return ele2 - ele1a = [2,3,1]print sorted(a, key = cmp_to_key(compare))[3, 2, 1] functools.total_orderingfunctools.total_ordering(cls)这是一个类装饰器，给定一个类，这个类定义了一个或者多个比较排序方法，这个类装饰器将会补充其余的比较方法，减少了自己定义所有比较方法时的工作量；这个装饰器是在python2.7的时候加上的，它是针对某个类如果定义了__lt__、 le 、 gt 、__ge__这些方法中的至少一个，同时，被修饰的类还应该提供 __eq__()方法。使用该装饰器，则会自动的把其他几个比较函数也实现在该类中 1234567891011@total_orderingclass Student: def __eq__(self, other): return ((self.lastname.lower(), self.firstname.lower()) == (other.lastname.lower(), other.firstname.lower())) def __lt__(self, other): return ((self.lastname.lower(), self.firstname.lower()) &lt; (other.lastname.lower(), other.firstname.lower()))print dir(Student)['__doc__', '__eq__', '__ge__', '__gt__', '__le__', '__lt__', '__module__'] 参考 http://www.tuicool.com/articles/qEjEBzy","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Flask笔记","slug":"python-flasknotes-2017-05-28","date":"2017-05-28T00:43:19.000Z","updated":"2017-09-08T03:51:40.045Z","comments":true,"path":"2017/05/28/python-flasknotes-2017-05-28/","link":"","permalink":"http://arvin-he.github.io/2017/05/28/python-flasknotes-2017-05-28/","excerpt":"","text":"Flask路由中使用正则表达式1234567891011121314from werkzeug.routing import BaseConverterclass RegexConverter(BaseConverter): def __init__(self, url_map, *item): super(RegexConverter, self).__init__(url_map) self.regex = item[0]# 把转换器在初始化时设定到url_map,转换器名称为'regex'app.url_map.converters['regex'] = RegexConverter@app.route('/user/&lt;regex(\"[a-z]&#123;3&#125;\"):user_name&gt;')def user(user_name): return 'User %s' % user_name 多个url指向同一个视图1234@app.route('/projects/')@app.route('/projects2/')def projects(): return 'The project page' 注意:多个路由指向同一视图时,顺序是先从最外层的装饰器路由开始,一旦匹配到路由,就马上执行视图函数,下面的装饰器就不再执行了. 使用Manager运行flask应用程序自定义模板过滤器自定义markdown过滤器1234@app.template_fiter('md')def markdown_to_html(txt): from markdown import markdown return markdown(txt) 在模版中调用python函数12345678@app.context_processordef inject_methods(): return dict(read_md=read_md)def read_md(file_name): with open(filename) as md_file: content = reduce(lambda x,y: x+y, md_file.readlines()) return content.decode('utf-8') 过滤器和全局方法配合使得页面更加灵活 模版继承/包含与宏 画直线","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"},{"name":"Flask","slug":"Flask","permalink":"http://arvin-he.github.io/tags/Flask/"}]},{"title":"Python之Monkeypatch","slug":"python-monkeypatch-2017-05-27","date":"2017-05-27T06:21:16.000Z","updated":"2017-09-08T03:51:40.105Z","comments":true,"path":"2017/05/27/python-monkeypatch-2017-05-27/","link":"","permalink":"http://arvin-he.github.io/2017/05/27/python-monkeypatch-2017-05-27/","excerpt":"","text":"猴子补丁的由来所谓的猴子补丁的含义是指在动态语言中，不去改变源码而对功能进行追加和变更。猴子补丁的这个叫法起源于Zope框架，大家在修正Zope的Bug的时候经常在程序后面追加更新部分，这些被称作是“杂牌军补丁(guerilla patch)”，后来guerilla就渐渐的写成了gorllia(猩猩)，再后来就写了monkey(猴子)，所以猴子补丁的叫法是这么莫名其妙的得来的。 从Gevent学习猴子补丁的设计猴子补丁这种东西充分利用了动态语言的灵活性，可以对现有的语言Api进行追加，替换，修改Bug，甚至性能优化等等。比如gevent的猴子补丁就可以对ssl、socket、os、time、select、thread、subprocess、sys等模块的功能进行了增强和替换。 gevent中的猴子补丁模块gevent.monkey的设计和实现如果自己要设计实现猴子补丁，可以按照这么个模式去做，可以用ipython来阅读python模块的代码，执行import gevent.monkey之后，只需要输入??gevent.monkey就可以查看源码了。 这个模块核心的函数其实就几个，分别是get_original、patch_item、remove_item、patch_module,还有一个全局变量叫做saved，默认指向一个空的字典对象。 首先来看patch_item函数：这个函数的功能就是从指定模块中查找旧的项，并把旧的项保存到saved字典中，然后将旧项替换成新项。这里没有使用None，而是构建了一个空的object()作为默认属性.123456def patch_item(module, attr, newitem): NONE = object() olditem = getattr(module, attr, NONE) if olditem is not NONE: saved.setdefault(module.__name__, &#123;&#125;).setdefault(attr, olditem) setattr(module, attr, newitem) patch_module的实现:12345678910def patch_module(name, items=None): gevent_module = getattr(__import__('gevent.' + name), name) module_name = getattr(gevent_module, '__target__', name) module = __import__(module_name) if items is None: items = getattr(gevent_module, '__implements__', None) if items is None: raise AttributeError('%r does not have __implements__' % gevent_module) for attr in items: patch_item(module, attr, getattr(gevent_module, attr)) gevent有个约定，作为补丁的gevent模块要包含这两个属性，__target__和__implements__，__target__是被补丁的默认模块名称，可以不指定，默认为gevent子模块的名称，比如gevent.socket是socket模块的补丁，__implements__是要进行补丁的属性，这是gevent.socket模块中__implements__的定义：123456# standard functions and classes that this module re-implements in a gevent-aware way:__implements__ = ['create_connection', 'socket', 'SocketType', 'fromfd', 'socketpair'] patch_module的工作就是从gevent模块里面读取这两个属性，然后遍历调用patch_item进行替换。 如果不希望用补丁的东西，而是使用原先的模块去进行处理，该怎么办？前面提到过进行patch_item的时候会把旧的属性保存到名为saved的全局字典里面，如果要获得旧的模块属性，那么就要调用get_original函数从saved字典里面取出来。 猴子补丁使用建议猴子补丁的功能很强大，但是也带来了很多的风险，尤其是像gevent这种直接进行API替换的补丁，整个Python进程所使用的模块都会被替换，可能自己的代码能hold住，但是其它第三方库，有时候问题并不好排查，即使排查出来也是很棘手，所以，就像松本建议的那样，如果要使用猴子补丁，那么只是做功能追加，尽量避免大规模的API覆盖。 参考 http://www.tuicool.com/articles/ema22iM","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Flask之上下文机制","slug":"python-flask-context-2017-05-27","date":"2017-05-27T03:29:30.000Z","updated":"2017-09-08T03:51:40.021Z","comments":true,"path":"2017/05/27/python-flask-context-2017-05-27/","link":"","permalink":"http://arvin-he.github.io/2017/05/27/python-flask-context-2017-05-27/","excerpt":"","text":"上下文（application context 和 request context）上下文是一个难理解的概念，在知乎的一个问题下面有个很通俗易懂的回答： 每一段程序都有很多外部变量。只有像Add这种简单的函数才是没有外部变量的。一旦你的一段程序有了外部变量，这段程序就不完整，不能独立运行。你为了使他们运行，就要给所有的外部变量一个一个写一些值进去。这些值的集合就叫上下文。 – vzch flask中的上下文分两种，application context和request context，即应用上下文和请求上下文。这两者并不是全局与局部的关系，它们都处于一个请求的局部中。每个请求的g都是独立的，并且在整个请求内都是可访问修改的。 从一个 Flask App 读入配置并启动开始，就进入了 App Context，在其中我们可以访问配置文件、打开资源文件、通过路由规则反向构造 URL。当一个请求进入开始被处理时，就进入了 Request Context，在其中我们可以访问请求携带的信息，比如 HTTP Method、表单域等。 上下文对象的作用域每个传给flask对象的请求，都是在不同的线程中处理，而且同一时刻每个线程只处理一个请求。所以对于每个请求来说，它们完全不用担心自己上下文中的数据被别的请求所修改。 然后就可以解释这个特性：从flask模块中引入的g、session、request、current_app是怎么做到同一个对象能在所有请求中使用并且不会冲突。 这两个上下文，一个保存请求本身的信息，一个保存处理过程中所用到的全局变量，从逻辑上也更为清晰。 Web 应用中每个线程（或 Greenlet）同时只处理一个请求，所以 App Context 对象和 Request Context 对象也是请求间隔离的。 请求上下文Flask中所有的请求处理都在“请求上下文”中进行，在它设计之初便就有这个概念。 “请求上下文”是一个上下文对象，实现了__enter__和__exit__方法。可以使用with语句构造一个上下文环境。 进入上下文环境时，_request_ctx_stack这个栈中会推入一个_RequestContext对象。这个栈结构就是LocalStack栈。 推入栈中的_RequestContext对象有一些属性，包含了请求的的所有相关信息。例如app、request、session、g、flashes。还有一个url_adapter，这个对象可以进行URL匹配。 在with语句构造的上下文环境中可以进行请求处理。当退出上下文环境时，_request_ctx_stack这个栈会销毁刚才存储的上下文对象以上的运行逻辑使得请求的处理始终在一个上下文环境中，这保证了请求处理过程不被干扰，而且请求上下文对象保存在LocalStack栈中，也很好地实现了线程/协程的隔离。 以下是一个简单的例子： 上面的结果显示：_request_ctx_stack中为每一个线程创建了一个“键-值”对，每一“键-值”对中包含一个请求上下文对象。如果使用with语句，在离开上下文环境时栈中销毁存储的上下文对象信息。 请求上下文——0.9版本在0.9版本中，Flask引入了“应用上下文”的概念，且对“请求上下文”的实现有一定的改变。主要有一下改变: 请求上下文实现了push、pop方法，这使得对于请求上下文的操作更加的灵活； 伴随着请求上下文对象的生成并存储在栈结构中，Flask还会生成一个“应用上下文”对象，而且“应用上下文”对象也会存储在另一个栈结构中去。这是两个版本最大的不同。 我们注意到，0.9版本的“请求上下文”的pop方法中，当要将一个“请求上下文”推入_request_ctx_stack栈中的时候，会先检查另一个栈_app_ctx_stack的栈顶是否存在“应用上下文”对象或者栈顶的“应用上下文”对象的应用是否是当前应用。如果不存在或者不是当前对象，Flask会自动先生成一个“应用上下文”对象，并将其推入_app_ctx_stack中。 注意到当要离开以上“请求上下文”环境的时候，Flask会先将“请求上下文”对象从_request_ctx_stack栈中销毁，之后会根据实际的情况确定销毁“应用上下文”对象。看下面代码: 应用上下文“应用上下文”存在的一个主要功能就是确定请求所在的应用。 疑问：既然“请求上下文”中也包含app等和当前应用相关的信息，那么只要调用_request_ctx_stack.top.app或者魔法current_app就可以确定请求所在的应用了，那为什么还需要“应用上下文”对象呢？答案: 对于单应用单请求来说，使用“请求上下文”确实就可以了。然而，Flask的设计理念之一就是多应用的支持。当在一个应用的请求上下文环境中，需要嵌套处理另一个应用的相关操作时，“请求上下文”显然就不能很好地解决问题了。 如何让请求找到“正确”的应用呢？我们可能会想到，可以再增加一个请求上下文环境，并将其推入_request_ctx_stack栈中。由于两个上下文环境的运行是独立的，不会相互干扰，所以通过调用_request_ctx_stack.top.app或者魔法current_app也可以获得当前上下文环境正在处理那个应用。这种办法在一定程度上可行，但是如果对于第二个应用的处理不涉及到相关请求，那也就无从谈起“请求上下文”。 为了应对这个问题，Flask中将应用相关的信息单独拿出来，形成一个“应用上下文”对象。这个对象可以和“请求上下文”一起使用，也可以单独拿出来使用。不过有一点需要注意的是：在创建“请求上下文”时一定要创建一个“应用上下文”对象。有了“应用上下文”对象，便可以很容易地确定当前处理哪个应用，这就是魔法current_app。在0.1版本中，current_app是对_request_ctx_stack.top.app的引用，而在0.9版本中current_app是对_app_ctx_stack.top.app的引用。下面以一个多应用的例子进行说明： 123456789101112131415161718192021222324252627282930313233343536# example - Flask v0.9&gt;&gt;&gt; from flask import Flask, _request_ctx_stack, _app_ctx_stack# 创建两个Flask应用&gt;&gt;&gt; app = Flask(__name__)&gt;&gt;&gt; app2 = Flask(__name__)# 先查看两个栈中的内容&gt;&gt;&gt; _request_ctx_stack._local.__storage__&#123;&#125;&gt;&gt;&gt; _app_ctx_stack._local.__storage__&#123;&#125;# 构建一个app的请求上下文环境，在这个环境中运行app2的相关操作&gt;&gt;&gt; with app.test_request_context(): print \"Enter app's Request Context:\" print _request_ctx_stack._local.__storage__ print _app_ctx_stack._local.__storage__ print with app2.app_context(): print \"Enter app2's App Context:\" print _request_ctx_stack._local.__storage__ print _app_ctx_stack._local.__storage__ print # do something print \"Exit app2's App Context:\" print _request_ctx_stack._local.__storage__ print _app_ctx_stack._local.__storage__ print# ResultEnter app's Request Context:&#123;&lt;greenlet.greenlet object at 0x000000000727A178&gt;: &#123;'stack': [&lt;RequestContext 'http://localhost/' [GET] of __main__&gt;]&#125;&#125;&#123;&lt;greenlet.greenlet object at 0x000000000727A178&gt;: &#123;'stack': [&lt;flask.ctx.AppContext object at 0x0000000005DD0DD8&gt;]&#125;&#125;Enter app2's App Context:&#123;&lt;greenlet.greenlet object at 0x000000000727A178&gt;: &#123;'stack': [&lt;RequestContext 'http://localhost/' [GET] of __main__&gt;]&#125;&#125;&#123;&lt;greenlet.greenlet object at 0x000000000727A178&gt;: &#123;'stack': [&lt;flask.ctx.AppContext object at 0x0000000005DD0DD8&gt;, &lt;flask.ctx.AppContext object at 0x0000000007313198&gt;]&#125;&#125;Exit app2's App Context&#123;&lt;greenlet.greenlet object at 0x000000000727A178&gt;: &#123;'stack': [&lt;RequestContext 'http://localhost/' [GET] of __main__&gt;]&#125;&#125;&#123;&lt;greenlet.greenlet object at 0x000000000727A178&gt;: &#123;'stack': [&lt;flask.ctx.AppContext object at 0x0000000005DD0DD8&gt;]&#125;&#125; 在以上的例子中： 我们首先创建了两个Flask应用app和app2； 接着我们构建了一个app的请求上下文环境。当进入这个环境中时，这时查看两个栈的内容，发现两个栈中已经有了当前请求的请求上下文对象和应用上下文对象。并且栈顶的元素都是app的请求上下文和应用上下文； 之后，我们再在这个环境中嵌套app2的应用上下文。当进入app2的应用上下文环境时，两个上下文环境便隔离开来，此时再查看两个栈的内容，发现_app_ctx_stack中推入了app2的应用上下文对象，并且栈顶指向它。这时在app2的应用上下文环境中，current_app便会一直指向app2； 当离开app2的应用上下文环境，_app_ctx_stack栈便会销毁app2的应用上下文对象。这时查看两个栈的内容，发现两个栈中只有app的请求的请求上下文对象和应用上下文对象。 最后，离开app的请求上下文环境后，两个栈便会销毁app的请求的请求上下文对象和应用上下文对象，栈为空。 与上下文对象有关的“全局变量”Flask中使用的一些“全局变量”，包括current_app、request、session、g等都来自于上下文对象。其中current_app一直指向_app_ctx_stack栈顶的“应用上下文”对象，是对当前应用的引用。而request、session、g等一直指向_request_ctx_stack栈顶的“请求上下文”对象，分别引用请求上下文的request、session和g。不过，从 Flask 0.10 起，对象 g 存储在应用上下文中而不再是请求上下文中。 两种上下文分析当 app = Flask(__name__) 构造出一个 Flask App 时，App Context 并不会被自动推入 Stack 中。所以此时 Local Stack 的栈顶是空的，current_app 也是 unbound 状态。 这也是一些 Flask 用户可能被坑的地方, 比如编写一个离线脚本时，如果直接在一个 Flask-SQLAlchemy 写成的 Model 上调用 User.query.get(user_id)，就会遇到 RuntimeError。因为此时 App Context 还没被推入栈中，而 Flask-SQLAlchemy 需要数据库连接信息时就会去取 current_app.config，current_app 指向的却是 _app_ctx_stack 为空的栈顶。 解决的办法是运行脚本正文之前，先将 App 的 App Context 推入栈中，栈顶不为空后 current_app 这个 Local Proxy 对象就自然能将“取 config 属性” 的动作转发到当前 App 上了： 那么为什么在应用运行时不需要手动 app_context().push() 呢？因为 Flask App 在作为 WSGI Application 运行时，会在每个请求进入的时候将请求上下文推入 _request_ctx_stack 中，而请求上下文一定是 App 上下文之中，所以推入部分的逻辑有这样一条：如果发现 _app_ctx_stack 为空，则隐式地推入一个 App 上下文。 所以，请求中是不需要手动推上下文入栈的，但是离线脚本需要手动推入 App Context。如果没有什么特殊困难，我更建议用 Flask-Script 来写离线任务。 两个疑问 为什么 App Context 要独立出来：既然在 Web 应用运行时里，App Context 和 Request Context 都是 Thread Local 的，那么为什么还要独立二者？ 为什么要放在“栈”里：在 Web 应用运行时中，一个线程同时只处理一个请求，那么 _req_ctx_stack 和 _app_ctx_stack 肯定都是只有一个栈顶元素的。那么为什么还要用“栈”这种结构？ 答案:这两个做法给予我们多个 Flask App 共存和非 Web Runtime 中灵活控制 Context 的可能性。 我们知道对一个 Flask App 调用 app.run() 之后，进程就进入阻塞模式并开始监听请求。此时是不可能再让另一个 Flask App 在主线程运行起来的。那么还有哪些场景需要多个 Flask App 共存呢？前面提到了，一个 Flask App 实例就是一个 WSGI Application，那么 WSGI Middleware 是允许使用组合模式的.比如: 这个例子就利用 Werkzeug 内置的 Middleware 将两个 Flask App 组合成一个一个 WSGI Application。这种情况下两个 App 都同时在运行，只是根据 URL 的不同而将请求分发到不同的 App 上处理。 需要注意的是，这种用法和 Flask 的 Blueprint 是有区别的。Blueprint 虽然和这种用法很类似，但前者自己没有 App Context，只是同一个 Flask App 内部整理资源的一种方式，所以多个 Blueprint 可能共享了同一个 Flask App；后者面向的是所有 WSGI Application，而不仅仅是 Flask App，即使是把一个 Django App 和一个 Flask App 用这种用法整合起来也是可行的。 如果仅仅在 Web Runtime 中，多个 Flask App 同时工作倒不是问题。毕竟每个请求被处理的时候是身处不同的 Thread Local 中的。但是 Flask App 不一定仅仅在 Web Runtime 中被使用 —— 有两个典型的场景是在非 Web 环境需要访问上下文代码的，一个是离线脚本（前面提到过），另一个是测试。这两个场景即所谓的“Running code outside of a request”。 在非 Web 环境运行 Flask 关联的代码离线脚本或者测试这类非 Web 环境和和 Web 环境不同 —— 前者一般只在主线程运行。 设想，一个离线脚本需要操作两个 Flask App 关联的上下文，应该怎么办呢？这时候栈结构的 App Context 优势就发挥出来了。 无论有多少个 App，只要主动去 Push 它的 App Context，Context Stack 中就会累积起来。这样，栈顶永远是当前操作的 App Context。当一个 App Context 结束的时候，相应的栈顶元素也随之出栈。如果在执行过程中抛出了异常，对应的 App Context 中注册的 teardown 函数被传入带有异常信息的参数。 这么一来就解释了两个疑问, 在这种单线程运行环境中，只有栈结构才能保存多个 Context 并在其中定位出哪个才是“当前”。而离线脚本只需要 App 关联的上下文，不需要构造出请求，所以 App Context 也应该和 Request Context 分离。这也就解释了为什么需要两个上下文了. 另一个手动推入 Context 的场景是测试。测试中我们可能会需要构造一个请求，并验证相关的状态是否符合预期。例如： 这里调用 client.get 时，Request Context 就被推入了。其特点和 App Context 非常类似，这里不再赘述。 为何建议使用 App Factory 模式从官方文档来看，Flask 有 Singleton(单例) 和 App Factory 两种用法。前一种用法和其他的一些 Web 框架（如 Bottle、Sinatra）的门面广告很相似，因为代码精简，所以显得非常的“帅”： 但是这种“帅”是有代价的。一个最麻烦的问题就是编写测试的时候： 在上面的例子中，我为了测试给 App 新挂载了一个 View 函数。这是很常见的一个测试需求。但是如果 Flask App 实例是单例的，这种做法就会“弄脏”下一个测试的运行。更加麻烦的是，上述例子中如果 test_home 在 test_app 之前运行了，Flask 的开发者防御机制会认为这是一个“已经开始处理 Web 请求了，又挂载了视图”的失误，从而抛出 RuntimeError。 所以除非是应用简单到不需要 Web 层测试，否则还是尽量使用 App Factory 模式比较好。况且配合 Blueprint 的情况下，App Factory 还能帮助我们良好地组织应用结构： 这样就能彻底摆脱 app.py 和 View 模块“互相 Import”的纠结了。 参考 http://blog.csdn.net/barrysj/article/details/51519254 https://blog.tonyseek.com/post/the-context-mechanism-of-flask/ http://fanchunke.me/Flask/Flask%E4%B8%AD%E7%9A%84%E8%AF%B7%E6%B1%82%E4%B8%8A%E4%B8%8B%E6%96%87%E5%92%8C%E5%BA%94%E7%94%A8%E4%B8%8A%E4%B8%8B%E6%96%87/","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"},{"name":"Flask","slug":"Flask","permalink":"http://arvin-he.github.io/tags/Flask/"}]},{"title":"Python之WSGI","slug":"python-wsgi-2017-05-25","date":"2017-05-25T05:17:45.000Z","updated":"2017-09-08T03:51:40.170Z","comments":true,"path":"2017/05/25/python-wsgi-2017-05-25/","link":"","permalink":"http://arvin-he.github.io/2017/05/25/python-wsgi-2017-05-25/","excerpt":"","text":"WSGI概念我们先看一下面向 http 的 python 程序需要关心哪些内容： 请求 请求的方法 method 请求的地址 url 请求的内容 请求的头部 header 请求的环境信息 响应 状态码 status_code 响应的数据 响应的头部 WSGI（Web Server Gateway Interface） 的任务就是把上面的数据在 http server 和 python 应用程序之间简单友好地传递。它是一个标准，被定义在PEP 333。需要 http server 和 python 应用程序都要遵守一定的规范，实现这个标准的约定内容，才能正常工作。 应用程序端WSGI 规定每个 python 程序（Application）必须是一个可调用的对象（实现了__call__ 函数的方法或者类），接受两个参数 environ（WSGI 的环境信息） 和 start_response（开始响应请求的函数），并且返回 iterable。 几点说明： environ 和 start_response 由 http server 提供并实现 environ 变量是包含了环境信息的字典 Application 内部在返回前调用 start_response start_response也是一个 callable，接受两个必须的参数，status（HTTP状态）和 response_headers（响应消息的头） 可调用对象要返回一个值，这个值是可迭代的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445 # 1. 可调用对象是一个函数,函数都是可调用的def application(environ, start_response): response_body = 'The request method was %s' % environ['REQUEST_METHOD'] # HTTP response code and message status = '200 OK' # 应答的头部是一个列表，每对键值都必须是一个 tuple。 response_headers = [('Content-Type', 'text/plain'), ('Content-Length', str(len(response_body)))] # 调用服务器程序提供的 start_response，填入两个参数 start_response(status, response_headers) # 返回必须是 iterable return [response_body] # 2. 可调用对象是一个类class AppClass: \"\"\"这里的可调用对象就是 AppClass 这个类，调用它就能生成可以迭代的结果。 使用方法类似于： for result in AppClass(env, start_response): do_somthing(result) \"\"\" def __init__(self, environ, start_response): self.environ = environ self.start = start_response def __iter__(self): status = '200 OK' response_headers = [('Content-type', 'text/plain')] self.start(status, response_headers) yield \"Hello world!\\n\"# 3. 可调用对象是一个实例 class AppClass: \"\"\"这里的可调用对象就是 AppClass 的实例，使用方法类似于： app = AppClass() for result in app(environ, start_response): do_somthing(result) \"\"\" def __init__(self): pass def __call__(self, environ, start_response): status = '200 OK' response_headers = [('Content-type', 'text/plain')] self.start(status, response_headers) yield \"Hello world!\\n\" 服务器程序端标准要能够确切地实行，必须要求程序端和服务器端共同遵守。上面提到， envrion 和 start_response 都是服务器端提供的。 下面就看看，服务器端要履行的义务:准备 environ 参数定义 start_response 函数调用程序端的可调用对象 PEP 333 里给出了一个 wsgi server 的简单实现，我又简化了一下——去除一些异常处理和判断，添加了一点注释：1234567891011121314151617181920212223242526272829303132333435363738import os, sysdef run_with_cgi(application): # application 是程序端的可调用对象 # 准备 environ 参数，这是一个字典，里面的内容是一次 HTTP 请求的环境变量 environ = dict(os.environ.items()) environ['wsgi.input'] = sys.stdin environ['wsgi.errors'] = sys.stderr environ['wsgi.version'] = (1, 0) environ['wsgi.multithread'] = False environ['wsgi.multiprocess'] = True environ['wsgi.run_once'] = True environ['wsgi.url_scheme'] = 'http' headers_set = [] headers_sent = [] # 把应答的结果输出到终端 def write(data): sys.stdout.write(data) sys.stdout.flush() # 实现 start_response 函数，根据程序端传过来的 status 和 response_headers 参数， # 设置状态和头部 def start_response(status, response_headers, exc_info=None): headers_set[:] = [status, response_headers] return write # 调用客户端的可调用对象，把准备好的参数传递过去 result = application(environ, start_response) # 处理得到的结果，这里简单地把结果输出到标准输出。 try: for data in result: if data: # don't send headers until body appears write(data) finally: if hasattr(result, 'close'): result.close() 中间层 middleware有些程序可能处于服务器端和程序端两者之间：对于服务器程序，它就是应用程序；而对于应用程序，它就是服务器程序。这就是中间层 middleware。middleware 对服务器程序和应用是透明的，它像一个代理/管道一样，把接收到的请求进行一些处理，然后往后传递，一直传递到客户端程序，最后把程序的客户端处理的结果再返回。 middleware 做了两件事情： 被服务器程序（有可能是其他 middleware）调用，返回结果回去 调用应用程序（有可能是其他 middleware），把参数传递过去 PEP 333 上面给出了 middleware 的可能使用场景： 根据 url 把请求给到不同的客户端程序（url routing） 允许多个客户端程序/web 框架同时运行，就是把接到的同一个请求传递给多个程序。 负载均衡和远程处理：把请求在网络上传输 应答的过滤处理 那么简单地 middleware 实现是怎么样的呢？下面的代码实现的是一个简单地 url routing 的 middleware：123456789101112class Router(object): def __init__(self): self.path_info = &#123;&#125; def route(self, environ, start_response): application = self.path_info[environ['PATH_INFO']] return application(environ, start_response) def __call__(self, path): def wrapper(application): self.path_info[path] = application return wrapperrouter = Router() 怎么在程序里面使用呢？1234567891011121314151617181920212223#here is the application@router('/hello') #调用 route 实例，把函数注册到 paht_info 字典def hello(environ, start_response): status = '200 OK' output = 'Hello' response_headers = [('Content-type', 'text/plain'), ('Content-Length', str(len(output)))] write = start_response(status, response_headers) return [output]@router('/world')def world(environ, start_response): status = '200 OK' output = 'World!' response_headers = [('Content-type', 'text/plain'), ('Content-Length', str(len(output)))] write = start_response(status, response_headers) return [output]#here run the applicationresult = router.route(environ, start_response)for value in result: write(value) 想要更多的话，就去看 PEP333，文档里还有下面更多的知识： 错误处理 environ 变量包含哪些值，都是什么意思。 输入和输出的细节 start_response 的更多规范 content-length 等头部规范 缓存和文本流 unicode 和多语言处理 …… 参考 官方文档 PEP333 Getting Started with WSGI http://cizixs.com/2014/11/08/understand-wsgi http://blog.csdn.net/yangz_xx/article/details/37508909 wsgiref：官方的 wsgi 实现，包括客户端和服务器端","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"},{"name":"Flask","slug":"Flask","permalink":"http://arvin-he.github.io/tags/Flask/"}]},{"title":"vscode插件和配置","slug":"vscode-config-plugins-2017-05-25","date":"2017-05-25T02:14:46.000Z","updated":"2017-09-08T03:51:40.191Z","comments":true,"path":"2017/05/25/vscode-config-plugins-2017-05-25/","link":"","permalink":"http://arvin-he.github.io/2017/05/25/vscode-config-plugins-2017-05-25/","excerpt":"","text":"插件AlignBeautifyC/C++Emoji CodeHTML SnippetsJavaScript(ES6) code snippetsjsxOne Dark ThemePath IntellisensePythonReactjs code snippetsRunnervscode-icons 配置{ “[cpp]”: { “editor.quickSuggestions”: false }, “[c]”: { “editor.quickSuggestions”: false }, // “editor.wordWrap”: “bounded”, // “editor.wordWrapColumn”: 80, // 控制字体系列 “editor.fontFamily”: “Consolas, ‘Courier New’, monospace, ‘宋体’”, // 以像素为单位控制字号。 “editor.fontSize”: 16, // 控制选取范围是否有圆角 “editor.roundedSelection”: false, // 建议小组件的字号 “editor.suggestFontSize”: 14, // 在“打开的编辑器”窗格中显示的编辑器数量。将其设置为 0 可隐藏窗格。 “explorer.openEditors.visible”: 0, // 是否已启用自动刷新 “git.autorefresh”: false, // 是否启用了自动提取。 “git.autofetch”: false, // 以像素为单位控制终端的字号，这是 editor.fontSize 的默认值。 “terminal.integrated.fontSize”: 16, // 控制终端游标是否闪烁。 “terminal.integrated.cursorBlinking”: true, // 一个制表符等于的空格数。该设置在 editor.detectIndentation 启用时根据文件内容进行重写。 “editor.tabSize”: 4, “editor.minimap.enabled”: false, // Tab Size “beautify.tabSize”: 4, &quot;python.linting.pylintEnabled&quot;: false, &quot;python.linting.pep8Enabled&quot;: true, &quot;files.autoSave&quot;: &quot;afterDelay&quot;, &quot;files.autoSaveDelay&quot;: 1000, &quot;workbench.iconTheme&quot;: &quot;vscode-icons&quot;, &quot;window.zoomLevel&quot;: 1, &quot;workbench.colorTheme&quot;: &quot;Monokai&quot; }","categories":[{"name":"工具","slug":"工具","permalink":"http://arvin-he.github.io/categories/工具/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://arvin-he.github.io/tags/Tools/"}]},{"title":"NodeJS/Vue安装","slug":"node-vue-setup-2017-05-25","date":"2017-05-25T01:26:58.000Z","updated":"2017-09-08T03:51:39.826Z","comments":true,"path":"2017/05/25/node-vue-setup-2017-05-25/","link":"","permalink":"http://arvin-he.github.io/2017/05/25/node-vue-setup-2017-05-25/","excerpt":"","text":"node简介简单的说 Node.js 就是运行在服务端的 JavaScript。Node.js 是一个基于 Chrome V8 引擎的 JavaScript 运行环境。Node.js 使用了一个事件驱动、非阻塞式 I/O 的模型，使其轻量又高效。Node.js 的包管理器 npm，是全球最大的开源库生态系统。 node安装windows下的NodeJS安装是比较方便的（v0.6.0版本之后，支持windows native），只需要登陆官网 node官网，便可以看到首页的“INSTALL”按钮，直接点击就会自动下载安装了。 安装完成后可以使用cmd（win+r然后输入cmd进入）测试下是否安装成功。方法：在cmd下输入node -v，出现版本提示就是完成了NodeJS的安装。 npm的安装。由于新版的NodeJS已经集成了npm，所以之前npm也一并安装好了。同样可以使用cmd命令行输入”npm -v”来测试是否成功安装。出现版本提示便是已经安装好了。 vue简介Vue.js是一套构建用户界面的渐进式框架。与其他重量级框架不同的是，Vue 采用自底向上增量开发的设计。Vue 的核心库只关注视图层，并且非常容易学习，非常容易与其它库或已有项目整合。另一方面，Vue 完全有能力驱动采用单文件组件和Vue生态系统支持的库开发的复杂单页应用。Vue.js 的目标是通过尽可能简单的 API 实现响应的数据绑定和组合的视图组件。Vue.js是一个MVVM模式的框架. 安装cnpm由于有些npm有些资源被屏蔽或者是国外资源的原因，经常会导致用npm安装依赖包的时候失败或者速度非常慢，所有需要npm的国内镜像-cnpm.在命令行中输入:npm install -g cnpm --registry=http://registry.npm.taobao.org,回车然后等待安装,完成之后，就可以用cnpm代替npm来安装依赖包了。如果想进一步了解cnpm的，查看淘宝npm镜像官网。 vue安装在命令行输入:cnpm install -g vue-cli,回车,等待安装 用vue-cli构建项目要创建项目，首先我们要选定目录，然后再命令行中把目录转到选定的目录.下面创建一个vueflask项目,在命令行输入命令:vue init webpack vueflask,回车.这个命令是初始化一个项目，其中webpack是构建工具，也就是整个项目是基于webpack的。其中vueflask是整个项目文件夹的名称，这个文件夹会自动生成在你指定的目录中.运行初始化命令的时候回让用户输入几个基本的选项，如项目名称，描述，作者等信息，如果不想填直接回车默认就好.整个项目的目录结构，我们主要在src目录中做修改。这个项目现在还只是一个结构框架，整个项目需要的依赖资源都还没有安装 安装项目所需的依赖要安装依赖包，首先cd到项目文件夹(vueflask文件夹)，然后运行命令cnpm install ，等待安装。安装完成之后，会在我们的项目目录vueflask文件夹中多出一个node_modules文件夹，这里边就是我们项目需要的依赖包资源。安装完依赖包之后，就可以运行整个项目了。 运行vue项目在项目目录中，运行命令npm run dev或cnpm run dev ，会用热加载的方式运行我们的应用，热加载可以在修改完代码后不用手动刷新浏览器就能实时看到修改后的效果。关于npm run dev命令，其中的“run”对应的是package.json文件中，scripts字段中的dev，也就是node build/dev-server.js命令的一个快捷方式。 项目运行成功后，浏览器会自动打开localhost:8080（如果浏览器没有自动打开，可以手动输入）。运行成功后，会看到如下所示的界面。 参考 http://www.cnblogs.com/qdrw/articles/6380091.html","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Vue","slug":"Vue","permalink":"http://arvin-he.github.io/tags/Vue/"},{"name":"NodeJS","slug":"NodeJS","permalink":"http://arvin-he.github.io/tags/NodeJS/"}]},{"title":"Python之生成器","slug":"python-generator-2017-05-24","date":"2017-05-24T07:15:24.000Z","updated":"2017-09-08T03:51:40.075Z","comments":true,"path":"2017/05/24/python-generator-2017-05-24/","link":"","permalink":"http://arvin-he.github.io/2017/05/24/python-generator-2017-05-24/","excerpt":"","text":"容器(container)容器是一种把多个元素组织在一起的数据结构，容器中的元素可以逐个地迭代获取，可以用 in, not in关键字判断元素是否包含在容器中。在Python中，常见的容器对象有：list, deque, ….set, frozensets, ….dict, defaultdict, OrderedDict, Counter, ….tuple, namedtuple, …str 尽管绝大多数容器都提供了某种方式来获取其中的每一个元素，但这并不是容器本身提供的能力，而是可迭代对象赋予了容器这种能力，当然并不是所有的容器都是可迭代的，比如：Bloom filter，虽然Bloom filter可以用来检测某个元素是否包含在容器中，但是并不能从容器中获取其中的每一个值，因为Bloom filter压根就没把元素存储在容器中，而是通过一个散列函数映射成一个值保存在数组中。 可迭代对象(iterable)很多容器都是可迭代对象，此外还有更多的对象同样也是可迭代对象，比如处于打开状态的files，sockets等等。但凡是可以返回一个迭代器的对象都可称之为可迭代对象.12345678910111213&gt;&gt;&gt; x = [1, 2, 3]&gt;&gt;&gt; y = iter(x)&gt;&gt;&gt; z = iter(x)&gt;&gt;&gt; next(y)1&gt;&gt;&gt; next(y)2&gt;&gt;&gt; next(z)1&gt;&gt;&gt; type(x)&lt;class 'list'&gt;&gt;&gt;&gt; type(y)&lt;class 'list_iterator'&gt; 这里 x 是一个可迭代对象，可迭代对象和容器一样是一种通俗的叫法，并不是指某种具体的数据类型，list是可迭代对象，dict是可迭代对象，set也是可迭代对象。y 和 z 是两个独立的迭代器，迭代器内部持有一个状态，该状态用于记录当前迭代所在的位置，以方便下次迭代的时候获取正确的元素。迭代器有一种具体的迭代器类型，比如 list_iterator， set_iterator。可迭代对象实现了 __iter__和 __next__方法（python2中是 next方法，python3是 next方法），这两个方法对应内置函数 iter()和 next()。__iter__方法返回可迭代对象本身，这使得他既是一个可迭代对象同时也是一个迭代器。当运行下面代码:123x = [1, 2, 3]for elem in x: ... 实际执行情况是: 迭代器(iterator)迭代器就是用于迭代操作（for 循环）的对象，它像列表一样可以迭代获取其中的每一个元素，它是一个带状态的对象，它能在你调用 next()方法的时候返回容器中的下一个值，任何实现了 __next__ 方法（python2 是 next）方法的对象都是迭代器以斐波那契数列为例来实现一个迭代器：12345678910111213141516171819202122232425class Fib(object): def __init__(self, n): self.prev = 0 self.cur = 1 self.n = n def __iter__(self): return self def __next__(self): if self.n &gt; 0: value = self.cur self.cur = self.cur + self.prev self.prev = value self.n -= 1 return value else: raise StopIteration() # 兼容python2 def __next__(self): return self.next()f = Fib(10)print([i for i in f])#[1, 1, 2, 3, 5, 8, 13, 21, 34, 55] Fib既是一个可迭代对象（因为它实现了 __iter__方法），又是一个迭代器（因为实现了 __next__方法）。实例变量 prev和 cur维护迭代器内部的状态。每次调用 next()方法的时候做两件事： 为下一次调用 next()方法修改状态 为当前这次调用生成返回结果迭代器就像一个懒加载的工厂，等到有人需要的时候才给它生成值返回，没调用的时候就处于休眠状态等待下一次调用。 生成器普通函数用 return 返回一个值，然而在 Python 中还有一种函数，用关键字 yield 来返回值，这种函数叫生成器函数，函数被调用时会返回一个生成器对象，生成器本质上还是一个迭代器，也是用在迭代操作中，因此它有和迭代器一样的特性，唯一的区别在于实现方式上不一样.生成器其实是一种特殊的迭代器，不过这种迭代器更加优雅。它不需要再像上面的类一样写 __iter__()和 __next__()方法了，只需要一个 yiled关键字。生成器一定是迭代器（反之不成立），因此任何生成器也是以一种懒加载的模式生成值。最简单的生成器函数：12345678&gt;&gt;&gt; def func(n): yield n*2&gt;&gt;&gt; func&lt;function func at 0x02397B70&gt;&gt;&gt;&gt; g = func(5)&gt;&gt;&gt; g&lt;generator object func at 0x023961E8&gt; func 就是一个生成器函数，调用该函数时返回对象就是生成器 g ，这个生成器对象的行为和迭代器是非常相似的，可以用在 for 循环等场景中。注意 yield 对应的值在函数被调用时不会立刻返回，而是调用next方法时（本质上 for 循环也是调用 next 方法）才返回.123456789&gt;&gt;&gt; g = func(5)&gt;&gt;&gt; next(g)10&gt;&gt;&gt; g = func(5)&gt;&gt;&gt; for i in g:... print(i)...10 用生成器实现斐波那契数列:123456789def fib(n): prev, curr = 0, 1 while n &gt; 0: n -= 1 yield curr prev, curr = curr, curr + prevprint([i for i in fib(10)])#[1, 1, 2, 3, 5, 8, 13, 21, 34, 55] fib就是一个普通的python函数，它特殊的地方在于函数体中没有return关键字，函数的返回值是一个生成器对象。当执行 f=fib()返回的是一个生成器对象，此时函数体中的代码并不会执行，只有显示或隐示地调用next的时候才会真正执行里面的代码。 生成器在Python中是一个非常强大的编程结构，可以用更少地中间变量写流式代码，此外，相比其它容器对象它更能节省内存和CPU，当然它可以用更少的代码来实现相似的功能。现在就可以动手重构你的代码了，但凡看到类似：123456789def something(): result = [] for ... in ...: result.append(x) return resultdef iter_something(): for ... in ...: yield x 生成器表达式(generator expression)生成器表达式是列表推倒式的生成器版本，看起来像列表推导式，但是它返回的是一个生成器对象而不是列表对象。12345&gt;&gt;&gt; a = (x*x for x in range(10))&gt;&gt;&gt; a&lt;generator object &lt;genexpr&gt; at 0x401f08&gt;&gt;&gt;&gt; sum(a)285 生成器的执行顺序在调用__next__()或者进入for循环之后，函数执行到yield就返回一个值，然后函数暂停。在下次调用__next__()之后，生成器开始执行yield之后的语句。 生成器对象的成员函数生成器对象有几个比较重要的成员函数：__next__()和__iter__()：有这两个函数，生成器就具有了可迭代性send()：这个函数很有用，可以用来给生成器函数传递一个新的值close()：关闭这个生成器，关闭之后生成器就不可再调用throw（）：给生成器传入一个异常 send函数的用法12345678910111213141516171819202122232425262728293031323334#send函数的用法from random import randintdef Gen(n): i=0 while (i&lt;n): i=i+1 #yeild语句，在重新开始执行的时候可以获得一个值，这个值就是由send函数输入的 res = yield randint(0, 100) if res=='stop': print ('forced stop') breakif __name__=='__main__': #初始化一个生成器对象 c=Gen(10) print (c.__next__()) print (c.__next__()) #传入‘start’字符串， print (c.send('start')) #传入‘stop’字符串，生成器跳出while循环 print (c.send('stop')) #继续迭代生成器将报错 print (c.__next__())执行结果：957749forced stopTraceback (most recent call last): File \"sample3.py\", line 17, in &lt;module&gt; print (c.send('stop'))StopIteration 从执行结果来看，调用前两个next和第三个send函数，生成器都会yield出结果。第四次调用send函数之后，也开始了迭代，不过由于退出了while循环，没有再一次回到yield，所以最终的结果里面只有三个数字最后一次调用next函数，出现报错，因为生成器已经关闭。 close函数的用法123456789101112131415161718192021222324#close函数的用法from random import randintdef Gen(n): i=0 while (i&lt;n): i=i+1 yield randint(0,100)if __name__=='__main__': c=Gen(10) print (c.__next__()) print (c.__next__()) #close生成器之后，再调用next将报错 c.close() print (c.__next__())执行结果：8165Traceback (most recent call last): File \"sample4.py\", line 15, in &lt;module&gt; print (c.__next__())StopIteration close函数的用法就是关闭生成器对象，其实调用send或者next函数都会‘open’这个生成器，期间生成器都会记录执行的中间结果，直到生成器被关闭为止 throw函数的用法1234567891011121314151617from random import randintdef Gen(n): i=0 while (i&lt;n): i=i+1 try: res = yield randint(0,100) except IOError: print ('get the IO Error')if __name__=='__main__': c=Gen(10) print (c.__next__()) #给生成器扔进去一个异常 c.throw(IOError) print (c.__next__()) 执行结果：39get the IO Error19 可以看到生成器内部成功的捕获并处理了这个异常，并且没有阻断生成器后面的执行流程 参考 https://mp.weixin.qq.com/s/baavCsOtKH0uuUGI-GPecw http://www.jianshu.com/p/1c7c6ee38392","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Python之装饰器","slug":"python-decorator-2017-05-24","date":"2017-05-24T05:31:32.000Z","updated":"2017-09-08T03:51:40.018Z","comments":true,"path":"2017/05/24/python-decorator-2017-05-24/","link":"","permalink":"http://arvin-he.github.io/2017/05/24/python-decorator-2017-05-24/","excerpt":"","text":"装饰器概念谈装饰器前，还要先要明白一件事，Python 中的函数和 Java、C++不太一样，Python 中的函数可以像普通变量一样当做参数传递给另外一个函数.装饰器本质上是一个 Python 函数或类，其返回值也是一个函数或类对象, 作用是让其他函数或类在不需要做任何代码修改的前提下增加额外功能。123456789#!/usr/bin/env# -*-coding:utf-8-*-__author__ = 'arvin'def decorator(func): print(\"%s was called\" % func.__name__) func()def hello(name=\"arvin\"): print(\"Hello %s!\" % name)decorator(hello) 装饰器应用场景装饰器经常用于有切面需求的场景，比如：插入日志、性能测试、事务处理、缓存、权限校验等场景，装饰器是解决这类问题的绝佳设计。有了装饰器，就可以抽离出大量与函数功能本身无关的雷同代码到装饰器中并继续重用。概括的讲，装饰器的作用就是为已经存在的对象添加额外的功能。 @ 语法糖@ 符号其实就是装饰器的语法糖，它放在函数开始定义的地方，这样就可以省略最后一步再次赋值的操作。1234567891011def log(func): def wrapper(): logging.warn(\"%s is running\" % func.__name__) return func() return wrapper@logdef foo(): print(\"this is foo function\")foo() 有了 @ ，就可以省去foo = log(foo)这一句了，直接调用 foo() 即可得到想要的结果。foo() 函数不需要做任何修改，只需在定义的地方加上装饰器，调用的时候还是和以前一样，如果有其他的类似函数，可以继续调用装饰器来修饰函数，而不用重复修改函数或者增加新的封装。这样，就提高了程序的可重复利用性，并增加了程序的可读性。 装饰器在 Python 使用如此方便都要归因于 Python 的函数能像普通的对象一样能作为参数传递给其他函数，可以被赋值给其他变量，可以作为返回值，可以被定义在另外一个函数内。 不带参数的装饰器在代码运行期间动态增加功能的方式，称之为“装饰器”（Decorator）,本质上，decorator就是一个返回函数的高阶函数. 定义装饰器12345def log(func): def wrapper(*args, **kw): print('call %s():' % func.__name__) return func(*args, **kw) return wrapper 其中,wrapper名字是自定义的,上面的log是一个decorator,接受一个函数作为参数，并返回一个函数。 使用装饰器123@logdef now(): print('2017-4-25') 调用now()函数，不仅会运行now()函数本身，还会在运行now()函数前打印一行日志. 带参数的装饰器装饰器的语法允许我们在调用时，提供其它参数，比如@decorator(a)。这样，就为装饰器的编写和使用提供了更大的灵活性。比如，我们可以在装饰器中指定日志的等级.1234567891011121314def use_logging(level): def decorator(func): def wrapper(*args, **kwargs): if level == \"warn\": logging.warn(\"%s is running\" % func.__name__) elif level == \"info\": logging.info(\"%s is running\" % func.__name__) return func(*args) return wrapper return decorator@use_logging(level=\"warn\")def foo(name='foo'): print(\"this is %s\" % name) 上面的 use_logging 是允许带参数的装饰器。它实际上是对原有装饰器的一个函数封装，并返回一个装饰器。我们可以将它理解为一个含有参数的闭包。当我们使用@use_logging(level=”warn”)调用的时候，Python 能够发现这一层的封装，并把参数传递到装饰器的环境中。@use_logging(level=”warn”)等价于@decorator 类装饰器相比函数装饰器，类装饰器具有灵活度大、高内聚、封装性等优点。使用类装饰器主要依靠类的__call__方法，当使用 @ 形式将装饰器附加到函数上时，就会调用此方法。1234567891011121314class Foo(object): def __init__(self, func): self._func = func def __call__(self): print ('class decorator runing') self._func() print ('class decorator ending')@Foodef bar(): print ('bar')bar() 使用functools.wraps使用装饰器极大地复用了代码，但有一个缺点就是原函数的元信息不见了，比如函数的docstring、__name__、参数列表，先看例子：123456789101112131415# 装饰器def logged(func): def with_logging(*args, **kwargs): print func.__name__ # 输出 'with_logging' print func.__doc__ # 输出 None return func(*args, **kwargs) return with_logging# 函数@loggeddef f(x): \"\"\"does some math\"\"\" return x + x * xlogged(f) 不难发现，函数 f 被with_logging取代了，当然它的docstring，__name__就是变成了with_logging函数的信息了。好在有functools.wraps，wraps本身也是一个装饰器，它能把原函数的元信息拷贝到装饰器里面的 func 函数中，这使得装饰器里面的 func 函数也有和原函数 foo 一样的元信息了。12345678910111213from functools import wrapsdef logged(func): @wraps(func) def with_logging(*args, **kwargs): print func.__name__ # 输出 'f' print func.__doc__ # 输出 'does some math' return func(*args, **kwargs) return with_logging@loggeddef f(x): \"\"\"does some math\"\"\" return x + x * x 装饰器顺序一个函数还可以同时定义多个装饰器，比如:12345@a@b@cdef f (): pass 它的执行顺序是从里到外，最先调用最里层的装饰器，最后调用最外层的装饰器，它等效于f = a(b(c(f))) 在函数执行之后进行装饰12345678910111213141516171819202122#!/usr/bin/env# -*-coding:utf-8-*-__author__ = 'arvin'def decorator(func): def wrapper(): print(\"%s was called\" % func.__name__) func() print(\"bye~\") return wrapper@decoratordef hello(name=\"arvin\"): print(\"Hello %s!\" % name)hello()# 执行outputs:hello was calledHello arvin!bye~ 可以这样理解hello()==decorator(hello)()==wrapper()，最后其实就是执行wrapper()函数而已 12345678910111213141516#!/usr/bin/env# -*-coding:utf-8-*-__author__ = 'arvin'from functools import wrapsdef decorator(func): @wraps(func) def wrapper(*args, **kwargs): print(\"%s was called\" % func.__name__) func(*args, **kwargs) print(\"bye~\") return wrapper@decoratordef hello(name=\"arvin\"): print(\"Hello %s!\" % name)hello('world') 参考 https://juejin.im/post/587c565f128fe1006b00c973 http://www.jianshu.com/p/ada1ceecd079","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"python之Sip使用","slug":"python-sip-2017-05-13","date":"2017-05-13T00:54:15.000Z","updated":"2017-09-08T03:51:40.148Z","comments":true,"path":"2017/05/13/python-sip-2017-05-13/","link":"","permalink":"http://arvin-he.github.io/2017/05/13/python-sip-2017-05-13/","excerpt":"","text":"Sip使用步骤第一步: 编写个C文件，功能是将两个数字相加并输出，命名为add.c，这个将成为在Python中的模块名，如下：1234567/* File : add.c */ int add(int x, int y) &#123; int g; g = x + y; return g; &#125; 第二步: 手工编写SIP文件，在使用SIP的过程中，一个C/C++的源码文件尽量对应一个同名的sip文件,这里命名为add.sip，如下：123/* Define the SIP wrapper to the add library. */ %Module(name=add, language=&quot;C&quot;) int add(int x, int y); 如果是源程序是用C++写的，那么这里的（name=add, language=”C”）就可以省去。这里的C源码文件没有头文件，所以对应的sip文件很简单。如果C/C++的源码是实现部分，在实现部分还包括接口部分，即头文件。那么在相应的sip文件中需要用下面的代码来包含相应的头文件.123%TypeHeaderCode #include &lt;word.h&gt; %End sip文件与正式的C/C++头文件相似，但与之不同的是：sip文件不包含相应的头文件的私有成员变量（private或protected）。更详细的sip文件编写规范，请参考riverbank官方网站上的说明文档SIP Reference Guide。 第三步:编译C文件。按照官网的说法，是编写configure.py，但先做一些必不可少的工作。在命令行将add.c编译成add.o文件：输入gcc -c add.c, 将这一步生成的add.o文件生产库文件：ar -r libadd.a add.o,这两步在这里是为一个单独的C模块测试的，如果是大量的C模块，可以用一个makefile一并批量完成。记住，需要将libadd.a文件复制到Python文件夹下的libs文件夹中。也可以将源代码直接编译成dll 第四步:手工编写configure.py文件，同样，这个configure文件的编写也不难，看下规范就会了。这里，我们模仿官网的模版写一个自己的configure.py。123456789101112131415161718192021import os import sipconfig # The name of the SIP build file generated by SIP and used by the build system. build_file = \"add.sbf\" # Get the SIP configuration information. config = sipconfig.Configuration() # Run SIP to generate the code. os.system(\" \".join([config.sip_bin, \"-c\", \".\", \"-b\", build_file, \"add.sip\"])) # Create the Makefile. makefile = sipconfig.SIPModuleMakefile(config, build_file) # Add the library we are wrapping. The name doesn't include any platform # specific prefixes or extensions (e.g. the \"lib\" prefix on UNIX, or the # \".dll\" extension on Windows). makefile.extra_libs = [\"add\"] # Generate the Makefile itself. makefile.generate() 第五步:运行configure.py，会生成一个makefile文件（直接用IDLE打开configure.py，按F5运行；或者命令行用python configure.py运行都可以）。这里有个诡异的地方，有的人会在这一步会报错，说找不到add.sbf文件，而add.sbf文件应该是configure.py运行时调用相关函数自动产生的。若出现这个问题，请重新编译SIP。如果是Windows下，最好是在另一台机器上拷贝一个完整的包含能正常的SIP的Python文件夹，到有问题的机器上，将问题Python文件夹覆盖掉。 第六步: 在命令行输入make（这里会生成一个关于函数的警告，不用管它，若有问题请检查前面的步骤），生成add.pyd文件。然后再输入make install（将add.pyd文件装入到Python的Lib文件夹下的sit-packages文件夹中）。 第七步: 打开Python 的命令行，进行测试：1234&gt;&gt;&gt;import add &gt;&gt;&gt;add.add(4, 7) 11 &gt;&gt;&gt; 提示：（1）这些文件可以放到Python的文件夹下新建的文件夹中（所有的操作在这个目录下的命令行窗口中使用）。注意，Python的父文件夹名不能有空格，否则会无法读取库文件。（2）使用MinGW，需要把~\\MinGW\\bin添加的环境变量中（Linux下则不必），这样才能使用gcc、make和ar等工具。 C++中的sip写法具体的实现办法和上面介绍的相似，所不同的就是根据相应的C++头文件来写对应的sip文件。详细过程如下。 首先，写好C++类的实现和接口部分（以Geometry类中的方法，输入半径，显示周长或面积为例）：12345678910111213//Geometry.hclass Geometry&#123; public: Geometry(double r); //构造函数 double calPerimeter(double radius); //参数半径，返回圆周长 double calArea(double radius); //参数半径，返回原面积 private: double perimeter; double radius; double area;&#125;; 接着，是C++的实现部分：1234567891011121314151617181920//Geometry.cpp#include &lt;iostream&gt;#include \"Geometry.h\"#define PI 3.141592 Geometry::Geometry(double r) //构造函数&#123; radius = r;&#125; double Geometry::calPerimeter(double radius) //参数半径，返回圆周长&#123; perimeter = radius * 2* PI; return perimeter;&#125;double Geometry::calArea(double radius) //参数半径，返回原面积&#123; area = radius * radius * PI; return perimeter;&#125; 第三步：如同上文中介绍的，在命令行中用g++ -c Geometry.cpp和ar -r libGeometry.a Geometry.o来编译出库文件，并把库文件添加到Python文件夹下的libs文件夹中。 第四步：编写C++文件对应的sip文件，再次提示，sip文件是基于C++的头文件的。本例中的sip文件内容为：12345678910111213//Geometry.sip%Module Geometry class Geometry &#123;%TypeHeaderCode#include &lt;Geometry.h&gt;%End public: Geometry(double r); double calPerimeter(double radius); double calArea(double radius);&#125;; 第五步：在命令行中使用Python configure.py命令，注意，configure.py文件是自己写的，configure的模板在上文中有，只需将上文中的模板中的add改为对应的Geometry，也就是类名就可以了。 第六步：在命令行中依次使用mingw32-make和ming32-make install将编译出的Geometry.pyd复制到Python文件夹下的Libs/site-packages文件夹中。 若不出意外，上述步骤可以执行成功。注：这里所有的命令都是在Geometry类的文件所在目录下完成的。 参考 http://blog.csdn.net/sunny2038/article/details/7237630","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"NSIS打包发布Windows可执行文件","slug":"nsis-2017-05-13","date":"2017-05-13T00:49:17.000Z","updated":"2017-09-08T03:51:39.831Z","comments":true,"path":"2017/05/13/nsis-2017-05-13/","link":"","permalink":"http://arvin-he.github.io/2017/05/13/nsis-2017-05-13/","excerpt":"","text":"NSIS简介NSIS(Nullsoft Scriptable Install System)是一种为Windows创建安装程序的工具,开源免费。NSIS创建能够安装，卸载，设置系统设置，提取文件等的安装程序。可完全控制安装程序的每个部分, 使用默认选项，开销只有34 KB。 NSIS特性NSIS将所有文件和安装脚本打包压缩成一个可执行文件，有三种集成压缩方法(ZLib，BZip2，LZMA), 其中LZMA压缩方法效果更好。可以轻松添加自定义逻辑并处理不同的升级，版本检查和更多。脚本语言提供可以在目标系统上使用的命令, 支持变量，函数和字符串操作,从文件夹创建和注册表编辑到文本/二进制文件修改，修改环境变量和系统重新引导等.甚至可以直接调用Windows API。可以创建自定义向导页面以获取用户输入或集成配置选项。NSIS包括一个经典和现代的向导界面，甚至可以创建自己的自定义界面（对话框，字体，背景，图标，文本，复选标记，图像等）NSIS编译器具有强大的预处理器。允许将多个项目集成到单个安装程序中或自动生成安装程序构建。还可生成不同的版本，如精简版和完整版本。完全多语言，在一个安装程序中支持多种语言。有60多个翻译可用，也可以创建自己的翻译。 Unicode支持允许更多的语言。Installer 使用CRC32校验和进行自检,能够从注册表检测目标目录.易于使用的插件系统（包括用于创建自定义对话框，互联网连接，HTTP下载，文件修补，Win32 API调用等的插件）.Installer 可以大到2GB .自动安装的可选静音模式 一个预处理器，支持定义的符号，宏，条件编译，标准预定义. NSIS版本选择NSIS有unicode版本和GBK版本,选择NSIS时需要注意,如果你想以utf-8打开nsi文件,那么请选择NSIS的unicode版本的.否则选择GBK版本的.否则在编译nsi文件时会报错. 模板结构预设参数（包括外部压缩器选择、编译选项、宏定义以及文件包含等）普通安装设置自定义函数安装程序区域内容安装程序回调函数及其相关函数定义卸载程序区域内容卸载程序回调函数及其相关函数定义 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169;定义一些参数!define PRODUCT_NAME &quot;valueReader&quot;!define PRODUCT_VERSION &quot;1.0.0.0&quot;!define PRODUCT_PUBLISHER &quot;Arvin&quot;!define PRODUCT_FULL_NAME &quot;$&#123;PRODUCT_NAME&#125; $&#123;PRODUCT_VERSION&#125;&quot;!define OUT_DIR &quot;.&quot;!define OUT_FILE_NAME &quot;$&#123;PRODUCT_NAME&#125;.exe&quot;RequestExecutionLevel user!define UNINST_KEY &quot;SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Uninstall&quot;!define SHORTCUT_NAME &quot;$&#123;PRODUCT_NAME&#125;&quot;!define PRODUCT_UNINST_KEY &quot;$&#123;UNINST_KEY&#125;\\$&#123;PRODUCT_NAME&#125;&quot;; MUI 设置!define MUI_WELCOMEPAGE_TITLE &quot; $&#123;PRODUCT_NAME&#125; $&#123;PRODUCT_VERSION&#125;安装向导&quot;!define MUI_WELCOMEFINISHPAGE_BITMAP &quot;$&#123;NSISDIR&#125;\\Contrib\\Graphics\\Wizard\\orange.bmp&quot;!define MUI_HEADERIMAGE!define MUI_HEADERIMAGE_BITMAP &quot;$&#123;NSISDIR&#125;\\Contrib\\Graphics\\Header\\orange.bmp&quot;!define MUI_HEADERIMAGE_UNBITMAP &quot;$&#123;NSISDIR&#125;\\Contrib\\Graphics\\Header\\orange-uninstall.bmp&quot;!include MUI2.nsh!include FileFunc.nshName &quot;$&#123;PRODUCT_NAME&#125;&quot;BrandingText &quot;http://www.microbit.com/&quot;; 输出文件OutFile &quot;$&#123;OUT_DIR&#125;\\$&#123;OUT_FILE_NAME&#125;&quot;; 安装路径InstallDir &quot;C:\\$&#123;PRODUCT_NAME&#125;&quot;;安装显示图标及图片;!define MUI_ICON &quot;favor.ico&quot;;卸载图标;!define MUI_UNICON &quot;uninst.ico&quot;;Icon &quot;favor.ico&quot;;UninstallIcon &quot;uninst.ico&quot;Page custom nsDialogsPage nsDialogsPageLeave; 安装页面!insertmacro MUI_PAGE_WELCOME!insertmacro MUI_PAGE_DIRECTORY!insertmacro MUI_PAGE_INSTFILES; 卸载页面!insertmacro MUI_UNPAGE_CONFIRM!insertmacro MUI_UNPAGE_INSTFILES; 语言支持!insertmacro MUI_LANGUAGE SimpChineseSection &quot;Installer Section&quot; Delete &quot;$DESKTOP\\$&#123;PRODUCT_NAME&#125;*.lnk&quot; Delete &quot;$SMSTARTUP\\$&#123;PRODUCT_NAME&#125;*.lnk&quot; RMDir /r &quot;$SMPROGRAMS\\$&#123;PRODUCT_NAME&#125;&quot; SetOutPath $INSTDIR ; 拷贝文件和文件夹, 过滤不需要拷贝文件 File /r /x &quot;*.nsi&quot; /x &quot;*.bat&quot; /x &quot;*.pyc&quot; /x &quot;make/*&quot; &quot;.\\dist\\*&quot; File /r &quot;log&quot; File /r &quot;make\\platforms&quot; File &quot;config.ini&quot; File &quot;favor.ico&quot; File &quot;uninst.ico&quot; WriteUninstaller &quot;uninstall.exe&quot; ; 开机自动启动 ;CreateShortCut &quot;$SMSTARTUP\\$&#123;PRODUCT_NAME&#125;.lnk&quot; &quot;$INSTDIR\\$&#123;PRODUCT_NAME&#125;.exe&quot; CreateDirectory &quot;$SMPROGRAMS\\$&#123;PRODUCT_NAME&#125;&quot; ; 创建卸载快捷方式到[开始]菜单 CreateShortCut &quot;$SMPROGRAMS\\$&#123;PRODUCT_NAME&#125;\\卸载 $&#123;PRODUCT_NAME&#125;.lnk&quot; &quot;$INSTDIR\\Uninstall.exe&quot; ; 创建快捷方式到[开始]菜单 CreateShortCut &quot;$SMPROGRAMS\\$&#123;PRODUCT_NAME&#125;\\$&#123;PRODUCT_NAME&#125;.lnk&quot; &quot;$INSTDIR\\$&#123;PRODUCT_NAME&#125;.exe&quot; &quot;&quot; &quot;$INSTDIR\\favor.ico&quot; ; 创建快捷方式到桌面 CreateShortCut &quot;$DESKTOP\\$&#123;PRODUCT_NAME&#125;.lnk&quot; &quot;$INSTDIR\\$&#123;PRODUCT_NAME&#125;.exe&quot; &quot;&quot; &quot;$INSTDIR\\favor.ico&quot; WriteRegStr HKLM &quot;$&#123;PRODUCT_UNINST_KEY&#125;&quot; &quot;DisplayName&quot; &quot;$&#123;PRODUCT_NAME&#125;&quot; WriteRegStr HKLM &quot;$&#123;PRODUCT_UNINST_KEY&#125;&quot; &quot;DisplayIcon&quot; &quot;$INSTDIR\\$&#123;PRODUCT_NAME&#125;.exe&quot; WriteRegStr HKLM &quot;$&#123;PRODUCT_UNINST_KEY&#125;&quot; &quot;UninstallString&quot; &quot;$INSTDIR\\uninstall.exe&quot; WriteRegStr HKLM &quot;$&#123;PRODUCT_UNINST_KEY&#125;&quot; &quot;Publisher&quot; &quot;Arvin&quot;SectionEndSection &quot;un.Uninstaller Section&quot; Delete &quot;$DESKTOP\\$&#123;PRODUCT_NAME&#125;*.lnk&quot; Delete &quot;$DESKTOP\\$&#123;SHORTCUT_NAME&#125;*.lnk&quot; Delete &quot;$SMSTARTUP\\$&#123;PRODUCT_NAME&#125;*.lnk&quot; RMDir /r &quot;$SMPROGRAMS\\$&#123;PRODUCT_NAME&#125;&quot; RMDir /r &quot;$INSTDIR&quot; DeleteRegKey HKLM &quot;$&#123;PRODUCT_UNINST_KEY&#125;&quot;SectionEndVIProductVersion &quot;$&#123;PRODUCT_VERSION&#125;&quot;VIAddVersionKey /LANG=$&#123;LANG_SIMPCHINESE&#125; &quot;CompanyName&quot; &quot;MicroBit Auto&quot;VIAddVersionKey /LANG=$&#123;LANG_SIMPCHINESE&#125; &quot;FileDescription&quot; &quot;$&#123;PRODUCT_NAME&#125; 安装程序&quot;VIAddVersionKey /LANG=$&#123;LANG_SIMPCHINESE&#125; &quot;FileVersion&quot; &quot;$&#123;PRODUCT_VERSION&#125;&quot;VIAddVersionKey /LANG=$&#123;LANG_SIMPCHINESE&#125; &quot;InternalName&quot; &quot;$&#123;OUT_FILE_NAME&#125;&quot;VIAddVersionKey /LANG=$&#123;LANG_SIMPCHINESE&#125; &quot;LegalCopyright&quot; &quot;Copyright (C) 2017 Arvin&quot;VIAddVersionKey /LANG=$&#123;LANG_SIMPCHINESE&#125; &quot;OriginalFilename&quot; &quot;$&#123;OUT_FILE_NAME&#125;&quot;VIAddVersionKey /LANG=$&#123;LANG_SIMPCHINESE&#125; &quot;ProductName&quot; &quot;$&#123;PRODUCT_NAME&#125;&quot;VIAddVersionKey /LANG=$&#123;LANG_SIMPCHINESE&#125; &quot;ProductVersion&quot; &quot;$&#123;PRODUCT_VERSION&#125;&quot;Var UninstallFileNameFunction .onInit Call CreateMutex ReadRegStr $UninstallFileName HKLM &quot;$&#123;PRODUCT_UNINST_KEY&#125;&quot; &quot;UninstallString&quot;FunctionEndFunction CreateMutex Retry: System::Call &quot;kernel32::CreateMutexW(i 0, i 0, w &apos;MicroBitauto.com/valReader/1.0&apos; ) i .R1 ?e&quot; Pop $R0 System::Call &quot;kernel32::CloseHandle(i R1) i.s&quot; $&#123;If&#125; $R0 != 0 MessageBox MB_RetryCancel|MB_ICONEXCLAMATION &quot;$&#123;PRODUCT_NAME&#125; 正在运行. 请关闭 $&#123;PRODUCT_NAME&#125; 后重试&quot; IdRetry Retry Quit $&#123;EndIf&#125;FunctionEndVar RADIO_REPAIRVar RADIO_REMOVEVar Checkbox_State_REPAIRVar Checkbox_State_REMOVEVar Checkbox_StateFunction nsDialogsPage $&#123;if&#125; $UninstallFileName == &quot;&quot; Abort $&#123;EndIf&#125; !insertmacro MUI_HEADER_TEXT &quot;$&#123;PRODUCT_NAME&#125; 维护模式&quot; &quot;重新安装或卸载“$&#123;PRODUCT_NAME&#125;”&quot; nsDialogs::Create /NOUNLOAD 1018 $&#123;NSD_CreateLabel&#125; 0u 0u 300u 30u &quot;请选择您要执行的操作，然后单击 [下一步(N)] 继续&quot; $&#123;NSD_CreateRadioButton&#125; 30u 30u 120u 30u &quot;重新安装&quot; Pop $RADIO_REPAIR $&#123;If&#125; $Checkbox_State_REPAIR == $&#123;BST_CHECKED&#125; $&#123;NSD_Check&#125; $RADIO_REPAIR $&#123;NSD_GetState&#125; $RADIO_REPAIR $Checkbox_State $&#123;EndIf&#125; $&#123;NSD_CreateRadioButton&#125; 30u 60u 120u 30u &quot;卸载&quot; Pop $RADIO_REMOVE $&#123;If&#125; $Checkbox_State_REMOVE == $&#123;BST_CHECKED&#125; $&#123;NSD_Check&#125; $RADIO_REMOVE $&#123;NSD_GetState&#125; $RADIO_REMOVE $Checkbox_State $&#123;EndIf&#125; $&#123;If&#125; $Checkbox_State &lt;&gt; $&#123;BST_CHECKED&#125; $&#123;NSD_Check&#125; $RADIO_REPAIR $&#123;EndIf&#125; nsDialogs::ShowFunctionEndFunction nsDialogsPageLeave $&#123;NSD_GetState&#125; $RADIO_REPAIR $Checkbox_State_REPAIR $&#123;NSD_GetState&#125; $RADIO_REMOVE $Checkbox_State_REMOVE $&#123;If&#125; $Checkbox_State_REMOVE == $&#123;BST_CHECKED&#125; Exec $UninstallFileName Quit $&#123;EndIf&#125;FunctionEnd 参考 http://nsis.sourceforge.net/Docs/Chapter1.html#intro-about http://www.cnblogs.com/myall/p/3637759.html","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"NSIS","slug":"NSIS","permalink":"http://arvin-he.github.io/tags/NSIS/"}]},{"title":"Python之pyenv与virtualenv使用","slug":"python-pyenv-2017-05-09","date":"2017-05-09T01:45:02.000Z","updated":"2017-09-08T03:51:40.130Z","comments":true,"path":"2017/05/09/python-pyenv-2017-05-09/","link":"","permalink":"http://arvin-he.github.io/2017/05/09/python-pyenv-2017-05-09/","excerpt":"","text":"pyenv 与 virtualenv多个python版本共存有2种方式:python版本切换的工具—pyenv, pyenv目前还不支持windows,只支持Linux.另外一个工具virtualenv则提供了一种功能,就是将一个目录建立为一个虚拟的python环境,用户可以建立多个虚拟环境,每个环境里面的python版本可以是不同的,也可以是相同的,而且环境之间相互独立。 pyenv 与 virtualenv区别pyenv 是针对 python 版本的管理，通过修改环境变量的方式实现；virtualenv 是针对python的包的多版本管理，通过将python包安装到一个模块来作为python的包虚拟环境，通过切换目录来实现不同包环境间的切换。 pyenv安装与使用自动安装: pyenv 提供了自动安装的工具，执行命令安装即可：1curl -L https://raw.githubusercontent.com/yyuu/pyenv-installer/master/bin/pyenv-installer | bash 手动安装:将 pyenv 检出到你想安装的目录。建议路径为：$HOME/.pyenv12$ cd$ git clone git://github.com/yyuu/pyenv.git .pyenv 添加环境变量。PYENV_ROOT 指向 pyenv 检出的根目录，并向 $PATH 添加 $PYENV_ROOT/bin 以提供访问 pyenv 这条命令的路径1234$ echo &apos;export PYENV_ROOT=&quot;$HOME/.pyenv&quot;&apos; &gt;&gt; ~/.bash_profile$ echo &apos;export PATH=&quot;$PYENV_ROOT/bin:$PATH&quot;&apos; &gt;&gt; ~/.bash_profile# 向 shell 添加 pyenv init 以启用 shims 和命令补完功能$ echo &apos;eval &quot;$(pyenv init -)&quot;&apos; &gt;&gt; ~/.bash_profile 这里的 shell 配置文件（~/.bash_profile）依不同 Linux作修改——Zsh：~/.zshenv；Ubuntu：~/.bashrc重启 shell（因为修改了 $PATH）,$ exec $SHELL pyenv常用命令12345678$ pyenv install --list # 该命令会列出可以用 pyenv 安装的 Python 版本。列表很长，仅列举其中几个:$ pyenv versions # 查看系统当前安装的python列表$ pyenv install -v 3.5.1 # 安装python$ pyenv uninstall 2.7.3 # 卸载python$ pyenv update # 更新 pyenv 及其插件$ pyenv rehash # 创建垫片路径为所有已安装的可执行文件 （如：~/.pyenv/versions//bin/） 创建 shims，因此，每当你增删了 Python 版本或带有可执行文件的包（如 pip）以后，都应该执行一次本命令） python切换12345$ pyenv global 3.4.0 – 设置全局的 Python 版本，通过将版本号写入 ~/.pyenv/version 文件的方式。$ pyenv local 2.7.3 – 设置面向程序的本地版本，通过将版本号写入当前目录下的 .python-version 文件的方式。通过这种方式设置的 Python 版本优先级较 global 高。pyenv 会从当前目录开始向上逐级查找 .python-version 文件，直到根目录为止。若找不到，就用 global 版本。$ pyenv shell pypy-2.2.1 – 设置面向 shell 的 Python 版本，通过设置当前 shell 的 PYENV_VERSION 环境变量的方式。这个版本的优先级比 local 和 global 都要高。–unset 参数可以用于取消当前 shell 设定的版本。$ pyenv shell --unset python优先级shell &gt; local &gt; global virtualenv安装与使用注意:创建的虚拟环境是和你当前安装的python版本是一致的,它不能用作不同python版本的切换, 如果你要在windows下安装不同的python版本,就只能再安装一个python版本.virtualenv主要用来管理包不同版本来设定独立的python环境,与不同版本包做区分.在命令行窗口输入:pip install virtualenv,回车 创建虚拟环境如果你已经安装好virtualenv, 则进入到工程目录中,接着使用如下的命令创建一个虚拟环境1$ python -m venv flask 如果你的python版本低于3.4,则需要安装 virtualenv.py,123456# windowspip install virtualenvvirtualenv flask# linuxsudo apt-get install python-virtualenvvirtualenv flask 这样就创建了一个完整的 Python 环境.虚拟环境是能够激活以及停用的，如果需要的话，一个激活的环境可以把它的 bin 文件夹加入到系统路径。我个人是不喜欢这种特色，所以我从来不激活任何环境,相反我会直接输入我想要调用的解释器的路径。如下:调用虚拟环境的pip安装python的包1234# windowsflask\\Scripts\\pip install flask# linuxflask/bin/pip install flask 参考 http://www.pylixm.cc/posts/2016-06-19-Virtualenv-install.html","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Python之应用程序打包发布","slug":"python-packprograms-2017-05-08","date":"2017-05-08T03:20:24.000Z","updated":"2017-09-08T03:51:40.112Z","comments":true,"path":"2017/05/08/python-packprograms-2017-05-08/","link":"","permalink":"http://arvin-he.github.io/2017/05/08/python-packprograms-2017-05-08/","excerpt":"","text":"Windows上Python程序打包发布方式 .py文件：直接提供源码，使用者自行安装Python并且安装依赖的各种库。(Python官方的各种安装包就是这样做的) .pyc文件：不愿意公开源码,可使用pyc文件发布，pyc文件是Python解释器可以识别的二进制码，故发布后也是跨平台的，需要使用者安装相应版本的Python和依赖库。 可执行文件：包含了Python和依赖库,用户只要点击快捷方式即可. 比较麻烦的是需要针对不同平台需要打包不同的可执行文件. 各种打包工具的对比如下： Solution Windows Linux OS X Python 3 License One-file mode Zipfile import Eggs pkg_resources support bbFreeze yes yes yes no MIT no yes yes yes py2exe yes no no yes MIT yes yes no no pyInstaller yes yes yes yes GPL yes no yes no cx_Freeze yes yes yes yes PSF no yes yes no py2app no no yes yes MIT no yes yes yes PS.其中pyInstaller和cx_Freeze都是不错的，stackoverflow上也有人建议用cx_Freeze，说是更便捷些。pkg_resources新版的pyInstaller貌似是支持的。 使用py2exe打包发布程序py2exe打包发布注意: 目前py2exe只支持到3.4版本,3.6版本不支持,主要是语法上不支持. 安装py2exe: pip install py2exe 准备好你要打包的程序,如hello.py 12# hello.pyprint(\"hello\") 创建安装脚本程序（setup.py）使用py2exe工具里需要一个setup.py的脚本，在你需要打包的应用程序目录下创建一个setup.py脚本文件,具体内容如下： 12345#python 3.4from distutils.core import setupimport py2exesetup(console=['hello.py']) 在这个脚本里调用setup函数，创建控制台应用程序，它的入口主文件是hello.py文件。 运行脚本（setup.py）文件在控制台窗口中进入到需要打包的应用程序目录下,在控制台窗口里输入命令：python setup.py py2exe,回车,然后就开始自动打包.运行这个命令成功之后，会在当前的目录下面创建一个发布的目录dist，所有需要发布的文件就会拷贝到此目录下面。 执行生成的exe程序经过上面的步骤，就可以进入目录dist下面进行运行exe程序了,双击就可运行.运行成功之后，与前面使用python hello.py是一样的结果，不过这个目录内容就可以发布到不同的电脑上进行运行，且不需要安装python。 py2exe使用出现的问题 py2exe 在打包简单的文件时能够正常工作,但打包稍微复杂的应用程序时会出现递归溢出的问题,打包失败,不知原因,且网上没有好的解决方法. 如果是PyQt的GUI应用程序,py2exe则不会将平台相关的东西(即PyQt下的platform文件夹)打包进来. 使用Pyinstaller打包发布程序Pyinstaller安装控制台窗口输入:pip install pyinstaller,回车,然后开始自动安装pyinstaller Pyinstaller使用目录切换到你要打包程序的目录下, 在控制台窗口输入:pyinstaller yourprogram.py,回车,然后在你的程序目录下创建一个dist文件夹,里面包含你要打包的所有相关的东西.注意:配置文件不会被打包加进去 一些选项python pyinstaller.py [opts] yourprogram.py主要选项-F, -onefile 打包成一个exe文件-D, -onedir 创建一个目录，包含exe文件，但会依赖很多文件（默认选项）-c, -console, -nowindowed 使用控制台，无界面（默认）-w, -windowed, -noconsole 使用窗口，无控制台 缺点打包了很多东西,比较大 使用cx_Freeze打包发布程序安装cx_Freeze在控制台窗口输入:pip install cx_Freeze,回车,然后就自动安装cx_Freeze了. cx_Freeze使用与py2exe一样,需要在要打包的程序目录下创建一个setup.py, 当然也可以是其他名字然后在命令行窗口输入:python setup.py build,回车,然后就会在程序目录下创建一个build文件夹,里面打包了所有需要用到的依赖123456789101112131415# setup.pyimport sysfrom cx_Freeze import setup, Executable# 依赖关系被自动检测，但可能需要微调build_exe_options = &#123;\"packages\": [\"os\"], \"excludes\": [\"tkinter\"]&#125;# GUI应用程序在Windows上需要不同的基础（默认值为控制台应用程序)base = Noneif sys.platform == \"win32\": base = \"Win32GUI\"setup( name = \"guifoo\", version = \"0.1\", description = \"My GUI application!\", options = &#123;\"build_exe\": build_exe_options&#125;, executables = [Executable(\"guifoo.py\", base=base)]) 打包成*.msi格式在命令行窗口输入:python setup.py bdist_msi,回车,就会在build目录下生成一个*.msi格式的软件安装包 将Python程序打包成.zip文件并发布在部署Python程序的时候。一般是把所有的源代码复制到目标机器上。我发现一个更好的办法是把源代码打包成.zip文件，然后直接运行这个.zip文件。比如：python besteam.zip它的秘密是在.zip文件中包含一个__main__.py，当python运行这个zip时，会自动找到它并运行。__main__.py的内容一般是调用主脚本。一行即可，比如:import besteam,如果不想让源代码发布出去，这更是一个好办法。不需要手动地找出编译后的python字节码文件。python提供了一个zipfile. PyZipFile的类自动地将源代码编译成字节码并打包在一起。下面是一个简单的示例脚本：12345678910# -*- coding:utf-8 -*- import zipfile, os besteamzip = zipfile.PyZipFile(\"besteam.zip\" ,\"w\", zipfile.ZIP_DEFLATED) for filename in (\"__main__.py\", \"besteam.py\"): besteamzip.writepy(filename)for dirname in os.listdir(\".\"): initfile=os.path.join(dirname, \"__init__.py\") if os.path.isdir(dirname) and os.path.exists(initfile): besteamzip.writepy(dirname)besteamzip.close() 需要注意的是,Python各个版本的字节码是不兼容的。所以，如果运行环境中有多个版本的Python就不能这么搞了，要么制作多个包，要么发布源代码。 参考 Python依赖打包发布详细 Freezing Your Code http://www.tuicool.com/articles/Ivuaaq http://cx-freeze.readthedocs.io/en/latest/distutils.html","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Python之logging模块探究","slug":"python-logging-2017-05-07","date":"2017-05-07T07:46:55.000Z","updated":"2017-11-27T01:06:11.174Z","comments":true,"path":"2017/05/07/python-logging-2017-05-07/","link":"","permalink":"http://arvin-he.github.io/2017/05/07/python-logging-2017-05-07/","excerpt":"","text":"python日志等级 FATAL - 导致程序退出的严重系统级错误，不可恢复，当错误发生时，系统管理员需要立即介入，谨慎使用。 ERROR - 运行时异常以及预期之外的错误，也需要立即处理，但紧急程度低于FATAL,当错误发生时，影响了程序的正确执行。需要注意的是这两种级别属于服务自己的错误，需要管理员介入，用户输入出错不属于此分类。 WARN - 预期之外的运行时状况，表示系统可能出现问题。对于那些目前还不是错误，然而不及时处理也会变成错误的情况，也可以记为WARN，如磁盘过低。 INFO - 有意义的事件信息，记录程序正常的运行状态，比如收到请求，成功执行。通过查看INFO,可以快速定位WARN，ERROR, FATAL。INFO不宜过多，通常情况下不超过TRACE的10%。 DEBUG - 与程序运行时的流程相关的详细信息以及当前变量状态。 TRACE - 更详细的跟踪信息。DEBUG和TRACE这两种规范由项目组自己定义,通过该种日志，可以查看某一个操作每一步的执行过程，可以准确定位是何种操作，何种参数，何种顺序导致了某种错误的发生 日志存放日志最好放到单独的日志目录，例如 /var/logs/ 下，按照应用分成不同的目录，或者是文件。日志不要放在应用目录下，那样不利于自动化部署和应用升级，备份等。 日志切分日志可以按照每天，每周或者是文件的大小，切分之后压缩。一方面容易按时间回溯，另一方面可以减少磁盘空间，对于很久之前的日志，可以传输到远程服务器，或者是删除。 一些好的习惯 root级别的设置: 日志格式, 有利于标准化 class 中设置logger self.logger = logging.getLogger(type(self).name), 以类名作为日志实例的名字 模块，文件中设置 logger logger = logging.getLogger(name), 以模块的名字作为日志实例的名字 使用JSON YAML等格式来配置logging，感觉比使用代码或者 ini格式看起来更方面 错误日志是比较特殊的日志，因为它需要更多的信息，例如错误产生的上下文，还有错误堆栈等信息。可以通过 python logging context pypi 关键词google一些信息，或者自己设计一个 logging handler 来实现。 不要用file作为日志实例的名字, 否则日志会直接file文件的最后面添加日志. 记录 Exception 的trace 信息123456try: open('/path/to/does/not/exist', 'rb')except (SystemExit, KeyboardInterrupt): raiseexcept Exception, e: logger.error('Failed to open file', exc_info=True) 日志设定在软件开发过程中,需要将日志信息输出到控制台,写入到日志文件中.但是如何做呢?在你的应用程序创建一个模块,如logger.py 123456789101112131415161718192021# logger.pyimport logging # 创建一个logger logger = logging.getLogger(__file__) logger.setLevel(logging.DEBUG) # 创建一个handler，用于写入日志文件 fh = logging.FileHandler('mylog.log') fh.setLevel(logging.DEBUG) # 再创建一个handler，用于输出到控制台 ch = logging.StreamHandler() ch.setLevel(logging.DEBUG) # 定义handler的输出格式 formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s') fh.setFormatter(formatter) ch.setFormatter(formatter) # 给logger添加handler logger.addHandler(fh) logger.addHandler(ch) # 记录一条日志 logger.info('this is first log.') 在模块级别获取日志实例的隐患加入你的日志配置是写在一个配置文件件,如ini,json或者yaml文件中,当你在模块中以模块名字实例了一个日志实例,此时日志的配置还没有加载的话,你的日志实例是没有配置的,你会发现没有日志被记录到日志文件中,控制台打印的日志没有格式.好的做法是在需要打印日志的时候创建日志实例.123456789101112import loggingdef foo(): logger = logging.getLogger(__name__) logger.info('Hi, foo')class Bar(object): def __init__(self, logger=None): self.logger = logger or logging.getLogger(__name__) def bar(self): self.logger.info('Hi, bar') python2.7出来了一个新参数disable_existing_loggers,解决了上面的问题,1234567891011121314151617181920212223242526272829303132import loggingimport logging.configlogger = logging.getLogger(__name__)# load config from file# logging.config.fileConfig('logging.ini', disable_existing_loggers=False)# or, for dictConfiglogging.config.dictConfig(&#123; 'version': 1, 'disable_existing_loggers': False, # this fixes the problem 'formatters': &#123; 'standard': &#123; 'format': '%(asctime)s [%(levelname)s] %(name)s: %(message)s' &#125;, &#125;, 'handlers': &#123; 'default': &#123; 'level':'INFO', 'class':'logging.StreamHandler', &#125;, &#125;, 'loggers': &#123; '': &#123; 'handlers': ['default'], 'level': 'INFO', 'propagate': True &#125; &#125;&#125;)logger.info('It works!') 使用json或yaml配置日志你可以从一个字典里加载日志配置,这也意味着你可以从json或yaml加载日志配置,尽管你可以从ini文件加载日志配置,但毕竟读写不方便,下面演示用json和yaml写日志配置logging.json123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&#123; \"version\": 1, \"disable_existing_loggers\": false, \"formatters\": &#123; \"simple\": &#123; \"format\": \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\" &#125; &#125;, \"handlers\": &#123; \"console\": &#123; \"class\": \"logging.StreamHandler\", \"level\": \"DEBUG\", \"formatter\": \"simple\", \"stream\": \"ext://sys.stdout\" &#125;, \"info_file_handler\": &#123; \"class\": \"logging.handlers.RotatingFileHandler\", \"level\": \"INFO\", \"formatter\": \"simple\", \"filename\": \"info.log\", \"maxBytes\": 10485760, \"backupCount\": 20, \"encoding\": \"utf8\" &#125;, \"error_file_handler\": &#123; \"class\": \"logging.handlers.RotatingFileHandler\", \"level\": \"ERROR\", \"formatter\": \"simple\", \"filename\": \"errors.log\", \"maxBytes\": 10485760, \"backupCount\": 20, \"encoding\": \"utf8\" &#125; &#125;, \"loggers\": &#123; \"my_module\": &#123; \"level\": \"ERROR\", \"handlers\": [\"console\"], \"propagate\": \"no\" &#125; &#125;, \"root\": &#123; \"level\": \"INFO\", \"handlers\": [\"console\", \"info_file_handler\", \"error_file_handler\"] &#125;&#125; logging.yaml123456789101112131415161718192021222324252627282930313233343536373839404142---version: 1disable_existing_loggers: Falseformatters: simple: format: \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"handlers: console: class: logging.StreamHandler level: DEBUG formatter: simple stream: ext://sys.stdout info_file_handler: class: logging.handlers.RotatingFileHandler level: INFO formatter: simple filename: info.log maxBytes: 10485760 # 10MB backupCount: 20 encoding: utf8 error_file_handler: class: logging.handlers.RotatingFileHandler level: ERROR formatter: simple filename: errors.log maxBytes: 10485760 # 10MB backupCount: 20 encoding: utf8loggers: my_module: level: ERROR handlers: [console] propagate: noroot: level: INFO handlers: [console, info_file_handler, error_file_handler]... 如何读取json和yaml配置12345678910111213141516171819202122import osimport jsonimport logging.configdef setup_logging( default_path='logging.json', default_level=logging.INFO, env_key='LOG_CFG'): \"\"\"Setup logging configuration \"\"\" path = default_path value = os.getenv(env_key, None) if value: path = value if os.path.exists(path): with open(path, 'rt') as f: config = json.load(f) logging.config.dictConfig(config) else: logging.basicConfig(level=default_level) json是一个标准库,不需要安装,yaml需要安装,但yaml文件更易读 1234567891011121314151617181920212223import osimport logging.configimport yamldef setup_logging( default_path='logging.yaml', default_level=logging.INFO, env_key='LOG_CFG'): \"\"\"Setup logging configuration \"\"\" path = default_path value = os.getenv(env_key, None) if value: path = value if os.path.exists(path): with open(path, 'rt') as f: config = yaml.safe_load(f.read()) logging.config.dictConfig(config) else: logging.basicConfig(level=default_level) logging模块的APIlogging.getLogger([name])返回一个logger实例，如果没有指定name，返回root logger。只要name相同，返回的logger实例都是同一个而且只有一个，即name和logger实例是一一对应的。这意味着，无需把logger实例在各个模块中传递。只要知道name，就能得到同一个logger实例. Logger.setLevel(lvl)设置logger的level， level有以下几个级别：NOTSET &lt; DEBUG &lt; INFO &lt; WARNING &lt; ERROR &lt; CRITICAL Logger.addHandler(hdlr)logger可以雇佣handler来帮它处理日志， handler主要有以下几种：StreamHandler: 输出到控制台;FileHandler:输出到文件handler还可以设置自己的level以及输出格式。 logging.basicConfig([**kwargs])这个函数用来配置root logger,为root logger创建一个StreamHandler,设置默认的格式。这些函数:logging.debug()、logging.info()、logging.warning()、logging.error()、logging.critical() 如果调用的时候发现root logger没有任何handler，会自动调用basicConfig添加一个handler,如果root logger已有handler,这个函数不做任何事情,使用basicConfig来配置root logger的输出格式和level： 关于root logger以及logger的父子关系关于root logger, 实际上logger实例之间还有父子关系, root logger就是处于最顶层的logger, 它是所有logger的祖先。如下图: root logger是默认的logger如果不创建logger实例, 直接调用logging.debug()、logging.info()logging.warning()、logging.error()、logging.critical()这些函数，那么使用的logger就是 root logger,它可以自动创建，也是单实例的。 如何得到root logger通过logging.getLogger()或者logging.getLogger(“”)来得到root logger实例。 默认的levelrootlogger默认的level是logging.WARNING 如何表示父子关系logger的name的命名方式可以表示logger之间的父子关系. 比如：12parent_logger = logging.getLogger('foo')child_logger = logging.getLogger('foo.bar') 什么是effective levellogger有一个概念，叫effective level。 如果一个logger没有显示地设置level，那么它就用父亲的level。如果父亲也没有显示地设置level， 就用父亲的父亲的level，以此推,直到到达root logger，root logger一定设置过level。默认为logging.WARNINGchild loggers得到消息后，会把消息分发给它的handler处理，也会传递给所有祖先logger处理， 123456789101112131415161718192021import logging # 设置root logger r = logging.getLogger() ch = logging.StreamHandler() ch.setLevel(logging.DEBUG) formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s') ch.setFormatter(formatter) r.addHandler(ch) # 创建一个logger作为父亲 p = logging.getLogger('foo') p.setLevel(logging.DEBUG) ch = logging.StreamHandler() ch.setLevel(logging.DEBUG) formatter = logging.Formatter('%(asctime)s - %(message)s') ch.setFormatter(formatter) p.addHandler(ch) # 创建一个孩子logger c = logging.getLogger('foo.bar') c.debug('foo') 122017-05-07 16:04:29,893 - foo 2011-05-07 16:04:29,893 - DEBUG - foo 可见， 子logger没有任何handler，所以对消息不做处理。但是它把消息转发给了它的父亲以及root logger。最后输出两条日志。 一些问题当你的应用程序用到了日志模块,并同时输出日志到控制台和文件中,打包发布并安装你的应用程序后,运行你的程序后有日志输出,当关闭应用程序会弹出一个弹框,让你去日志文件检查错误信息,并且会自动生成一个和应用程序同名的日志文件.这个弹框及和应用程序同名日志文件是怎么产生的呢?原因是:控制台窗口的句柄导致的,不要将日志文件输出到控制台窗口即可. logging模块的一些局限logging模块是单进程的,当在多进程中涉及到日志切分就会出现日志错乱的现象和日志重复的现象.在tornado中就有所体现.像tornado这种推荐进行多进程部署的框架，在类似的日志切分上会发生错误，原因是: 单个的日志文件作为进程间的共享资源，当其中一个进程进行日志切分的时候，实际上是将原来的日志文件改名，然后新建一个日志文件，文件操作描述符fd发生了改变，其它的进程不知道这个操作，再次写入日志的时候因为找不到新的文件描述符发生异常。 每次TimedRotatingHandler做切分操作时，所做的步骤如下： 如现在的文件为mownfish.log, 切分后的文件名设定为mownfish.log.2013-11-24 判断是否存在和切分后重命名的文件mownfish.log.2013-11-24一样名称的文件，如果存在就删除 将当前的日志文件mownfish.log重命名为mownfish.log.2013-11-24 以“w”模式打开一个新文件mownfish.log,并写入新的日志。 当一个进程做好日志切分后,名称为mownfish.log文件的描述符已经变了,而其他进程在写入日志的是否发现日志的文件描述符不一致从而发生异常. 多个模块使用logging每个 logger 都有个名字，以 ‘.’ 来划分继承关系。名字为空的就是 root_logger.首先在主模块定义了logger’mainModule’，并对它进行了配置，就可以在解释器进程里面的其他地方通过getLogger(‘mainModule’)得到的对象都是一样的，不需要重新配置，可以直接使用。定义的该logger的子logger，都可以共享父logger的定义和配置，所谓的父子logger是通过命名来识别，任意以’mainModule’开头的logger都是它的子logger，例如’mainModule.sub’。 实际开发一个application，首先可以通过logging配置文件编写好这个application所对应的配置，可以生成一个根logger，如’PythonAPP’，然后在主函数中通过fileConfig加载logging配置，接着在application的其他地方、不同的模块中，可以使用根logger的子logger，如’PythonAPP.Core’，’PythonAPP.Web’来进行log，而不需要反复的定义和配置各个模块的logger。 logging 是线程安全的么？logging是线程安全的, handler 内部使用了 threading.RLock() 来保证同一时间只有一个线程能够输出。但是，在使用 logging.FileHandler 时，多进程同时写一个日志文件是不支持的。 Tornado的日志以及日志重复问题多进程日志使用的TimedRotatingFileHandler并不是进程安全的，日志的准确性无法保证，所以改用线程安全的ConcurrentLogHandler。 ConcurrentLogHandler需要安装, pip install ConcurrentLogHandler ConcurrentLogHandler不能将日志根据时间分片 filename: 日志文件地址，相对地址或绝对地址均可mode: 默认为”a”maxBytes: 文件长度，超过最大长度自动分片，最初日志都会写入filename里面，到达设置的最大长度之后进行分片，分片后文件名为filename.1 filename.2，以此类推backupCount: 最大日志文件保留数量，默认为0即不会删除日志文件encoding: 日志文件编码格式，默认为gbk def init_log(): logfile = \"/data1/restful_log/restful_api_thread.log\" filesize = 800*1024*1024 log = getLogger() rotate_handler = ConcurrentRotatingFileHandler(logfile, \"a\", filesize, encoding=\"utf-8\") datefmt_str = '%Y-%m-%d %H:%M:%S' format_str = '%(asctime)s\\t%(levelname)s\\t%(message)s ' formatter = Formatter(format_str, datefmt_str) rotate_handler.setFormatter(formatter) log.addHandler(rotate_handler) log.setLevel(WARN) return log 参考 使用python的logging模块","categories":[{"name":"python","slug":"python","permalink":"http://arvin-he.github.io/categories/python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"C++之指针初识","slug":"cpp-pointer1-2017-05-05","date":"2017-05-05T06:36:18.000Z","updated":"2017-09-08T03:51:39.346Z","comments":true,"path":"2017/05/05/cpp-pointer1-2017-05-05/","link":"","permalink":"http://arvin-he.github.io/2017/05/05/cpp-pointer1-2017-05-05/","excerpt":"","text":"指针基本知识和定义硬盘保存数据是基于物理的磁性，访问靠机械运动，所以速度比较慢.内存保存数据是基于电信号，速度比较快，但是所有数据不能长久保存，掉电即失.指针的介绍都是以内存和地址开始的,内存的基本单位是字节（byte），每一个字节都有一个独一无二的地址.为了保存内存中的一个地址值，C 语言需要一种特殊的变量类型，这种变量类型就是指针变量类型。整型变量保存一个整数，字符变量保存一个字符，指针变量保存一个地址. 指针声明指针的定义通常有两种风格,建议采用风格1,char是一个基本类型,*p说明是一个指针, char*连在一起就显得比较怪异.当连续定义两个指针,容易出错,如下面的第三行代码1234char *p; // 风格 1char* p; // 风格 2char* p1, p2; // 错误char *p1, *p2; // 正确 1234*p = ＆a; /* p = ＆a is right */i**p; /*- what is this?*/*p**p; /*- and then? */*p/*p; /*-My God!*/","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"C/C++","slug":"C-C","permalink":"http://arvin-he.github.io/tags/C-C/"}]},{"title":"C++之类型转换(Type Casting)","slug":"cpp-typecasting-2017-05-05","date":"2017-05-05T01:21:54.000Z","updated":"2017-09-08T03:51:39.355Z","comments":true,"path":"2017/05/05/cpp-typecasting-2017-05-05/","link":"","permalink":"http://arvin-he.github.io/2017/05/05/cpp-typecasting-2017-05-05/","excerpt":"","text":"类型转换分类类型转换是将给定类型的表达式转换为另一种类型。C++中的转型可分为两种：隐式类型转换和显式类型转换。下面将详细介绍这两种转型操作，以及各自的适用场景，潜在问题，最终将总结使用类型转换操作应牢记的原则。 C风格的强制类型转换(Type Cast)很简单，不管什么类型的转换统统是：TYPE b = (TYPE)aC++风格的类型转换提供了4种类型转换操作符来应对不同场合的应用。1234const_cast，字面上理解就是去const属性。static_cast，命名上理解是静态类型转换。如int转换成char。dynamic_cast，命名上理解是动态类型转换。如子类和父类之间的多态类型转换。reinterpret_cast，仅仅重新解释类型，但没有进行二进制的转换。 4种类型转换的格式，如：TYPE B = static_cast(TYPE)(a)。 隐式类型转换隐式类型转换是C中的遗留物，在C++中并不推荐使用（C++有专门的转型操作符，见下文的显式转型）。将某种类型的对象拷贝到另一种不同类型的对象中时就会发生隐式转型。比如异型赋值，返回值（函数声明的返回值与代码块实际返回值不同的情况下），按值传递异型参数等情况均会发生隐式类型转换。123short a = 128;int b;b = a; 如上所示，short 类型的对象被赋值给 int 型的对象，这是C++语言内建支持的标准转换。情形一：标准转换支持数值类型，bool以及某些指针之间相互转换。注意：某些转换可能会导致精度丢失，比如从 long 转换到 int。情形二：可被单参调用（只有一个参数或多个参数但至少从第二个参数起均带有缺省值）的构造函数或隐式类型转换操作符也会引起隐式类型转换。比如：1234567891011121314class A &#123;&#125;; class B&#123; public: B (A a) &#123;&#125; public: B (int c, int d = 0); public: operator double() const; &#125;;A a;B b1 = a;B b2 = 10;B b3;double d;d = 10 + b3; 上面的代码里就存在只带有一个参数的构造函数，多个参数但至少从第二个参数起均带有缺省值以及用户自定义类型转换操作符这三种情况。隐式类型转换是件麻烦事，它们很可能导致错误或非预期的函数被调用；此外 C++ 也不能在一个转换过程中连续进行多于一次的用户自定义转换操作（即情形二中的转换），如下所示：接上面的代码，A （类型的对象，后略）可被隐式转换为 B，B 可被隐式转换为 C，但 A 却非常不合逻辑地不可被隐式转换为 C。12345678class C&#123; public: C(B b) &#123;&#125;;&#125;A a;C c;c = a; // 错误！ 因此应该尽量避免隐式类型转换，为此 C++ 提供了关键字 explicit 来规避可被单参调用的构造函数引起的隐式类型转换。但标准转换以及隐式类型转换操作符引起的转换只能由程序员来小心处理了。当然 C++ 语言还是提供了必要的工具，这些工具就是下面要讲的显式类型转换关键字：static_cast, const_cast, dynamic_cast 以及 reinterpret_cast。 显示类型转换C++ 是一门强类型转换，因此不同自定义类型之间的转换必须进行显式转换，基础数据类型也可以进行显式转换。1234short a = 10;int b;b = (int) a; // c-like cast notationb = int (a); // functional notation 以上是基础数据类型之间进行传统的强制类型转换。这种强制类型转换可以在两种指向不同类型对象的指针之间进行，这很可能是相当危险的事情。所以 C++ 提供四种转换操作符来细分显式类型转换：1234static_cast &lt;new_type&gt; (expression)const_cast &lt;new_type&gt; (expression)dynamic_cast &lt;new_type&gt; (expression)reinterpret_cast &lt;new_type&gt; (expression) static_caststatic_cast 很像 C 语言中的旧式类型转换。它能进行基础类型之间的转换，也能将带有可被单参调用的构造函数或用户自定义类型转换操作符的类型转换，还能在存有继承关系的类之间进行转换（即可将基类转换为子类，也可将子类转换为基类），还能将 non-const对象转换为 const对象（注意：反之则不行，那是const_cast的职责） 基类和子类之间转换：其中子类指针转换成父类指针是安全的；但父类指针转换成子类指针是不安全的。(基类和子类之间的动态类型转换建议用dynamic_cast) 基本数据类型转换。enum, struct, int, char, float等。static_cast不能进行无关类型（如非基类和子类）指针之间的转换。 把空指针转换成目标类型的空指针。 把任何类型的表达式转换成void类型。 static_cast不能去掉类型的const、volitale属性(用const_cast)。123456789101112131415double d = 3.14159265;int i = static_cast&lt;int&gt;(d);class A &#123;&#125;;class B&#123;public: B (A a) &#123;&#125;;&#125;; A a;B b = static_cast&lt;B&gt;(a); class CBase &#123;&#125;;class CDerived: public CBase &#123;&#125;;CBase * a = new CBase;CDerived * b = static_cast&lt;CDerived *&gt;(a); 注意：static_cast 转换时并不进行运行时安全检查，所以是非安全的，很容易出问题。因此 C++ 引入 dynamic_cast 来处理安全转型。 dynamic_castdynamic_cast 主要用来在继承体系中的安全向下转型。它能安全地将指向基类的指针转型为指向子类的指针或引用，并获知转型动作成功是否。如果转型失败会返回null（转型对象为指针时）或抛出异常（转型对象为引用时）。dynamic_cast 会动用运行时信息（RTTI）来进行类型安全检查，因此 dynamic_cast 存在一定的效率损失。（曾见过属于优化代码80/20法则中的20那一部分的一段游戏代码，起初使用的是 dynamic_cast，后来被换成 static_cast 以提升效率，当然这仅是权宜之策，并非好的设计。）有条件转换，动态类型转换，运行时类型安全检查(转换失败返回NULL)： 安全的基类和子类之间转换。 必须要有虚函数。 相同基类不同子类之间的交叉转换。但结果是NULL。123456789101112131415161718192021class BaseClass &#123;public: int m_iNum; virtualvoid foo()&#123;&#125;; //基类必须有虚函数。保持多台特性才能使用dynamic_cast&#125;; class DerivedClass: public BaseClass &#123;public: char*m_szName[100]; void bar()&#123;&#125;;&#125;; BaseClass* pb =new DerivedClass();DerivedClass *pd1 = static_cast&lt;DerivedClass *&gt;(pb); //子类-&gt;父类，静态类型转换，正确但不推荐DerivedClass *pd2 = dynamic_cast&lt;DerivedClass *&gt;(pb); //子类-&gt;父类，动态类型转换，正确 BaseClass* pb2 =new BaseClass();DerivedClass *pd21 = static_cast&lt;DerivedClass *&gt;(pb2); //父类-&gt;子类，静态类型转换，危险！访问子类m_szName成员越界DerivedClass *pd22 = dynamic_cast&lt;DerivedClass *&gt;(pb2); //父类-&gt;子类，动态类型转换，安全的。结果是NULL 12345678class CBase &#123; &#125;;class CDerived: public CBase &#123; &#125;;CBase b;CBase* pb;CDerived d;CDerived* pd;pb = dynamic_cast&lt;CBase*&gt;(&amp;d); // ok: derived-to-basepd = dynamic_cast&lt;CDerived*&gt;(&amp;b); // error: base-to-derived 上面的代码中最后一行 VS2010 会报如下错误：error C2683: ‘dynamic_cast’ : ‘CBase’ is not a polymorphic type IntelliSense: the operand of a runtime dynamic_cast must have a polymorphic class type.这是因为 dynamic_cast 只有在基类带有虚函数的情况下才允许将基类转换为子类。123456789101112131415161718class CBase &#123; virtual void dummy() &#123;&#125; &#125;; class CDerived: public CBase &#123; int a; &#125;; int main () &#123; CBase * pba = new CDerived; CBase * pbb = new CBase; CDerived * pd1, * pd2; pd1 = dynamic_cast&lt;CDerived*&gt;(pba); pd2 = dynamic_cast&lt;CDerived*&gt;(pbb); return 0; &#125; 结果是：上面代码中的 pd1 不为 null,而 pd2 为 null。dynamic_cast 也可在 null 指针和指向其他类型的指针之间进行转换，也可以将指向类型的指针转换为 void 指针（基于此，我们可以获取一个对象的内存起始地址 const void rawAddress = dynamic_cast&lt;const void &gt; (this);）。 const_castconst_cast 可去除对象的常量性（const），它还可以去除对象的易变性（volatile）。const_cast 的唯一职责就在于此，若将 const_cast 用于其他转型将会报错。12345678910void print (char * str)&#123; cout &lt;&lt; str &lt;&lt; endl;&#125;int main ()&#123; const char * c = \"hello, world\"; print ( const_cast&lt;char *&gt; (c) ); return 0;&#125; reinterpret_castreinterpret_cast 用来执行低级转型，如将一个 int 指针强转为 int。其转换结果与编译平台息息相关，不具有可移植性，因此在一般的代码中不常见到它。reinterpret_cast 常用的一个用途是转换函数指针类型，即可以将一种类型的函数指针转换为另一种类型的函数指针，但这种转换可能会导致不正确的结果。总之，reinterpret_cast 只用于底层代码，一般我们都用不到它，如果你的代码中使用到这种转型，务必明白自己在干什么。 转换的类型必须是一个指针、引用、算术类型、函数指针或者成员指针。 在比特位级别上进行转换。它可以把一个指针转换成一个整数，也可以把一个整数转换成一个指针（先把一个指针转换成一个整数，在把该整数转换成原类型的指针，还可以得到原先的指针值）。但不能将非32bit的实例转成指针。 最普通的用途就是在函数指针类型之间进行转换。 很难保证移植性。 typeid：获取表达式的类型typeid 定义在标准头文件&lt;typeinfo&gt;中，用于获取表达式的类型，它返回一个数据类型或类名字的字符串。当 typeid 用于自定义类型时，它使用 RTTI 信息来获取对象的动态类型。基于 typeid，我们可以构建出比较对象（动态）类型的操作。 使用原则：尽量避免类型转换操作；优先使用 C++ 风格的转型 鉴于类型转换的隐蔽，不安全，易引起非预期的函数调用，对象切割等诸多问题，应该尽量避免类型转换操作。如使用 explicit 声明可被单参调用的构造函数，按引用传递参数或返回值，使用虚函数机制等等可避免类型转换； 若类型转换不可避免，优先使用 C++ 风格的新式类型转换。C++ 风格的类型转换一则易于辨识，二则有着其特有惯用手法，遵循这些惯用手法好处多多。 总结去const属性用const_cast;基本类型转换用static_cast;多态类之间的类型转换用daynamic_cast;不同类型的指针类型转换用reinterpret_cast; 参考 参考文章 参考文章","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"C/C++","slug":"C-C","permalink":"http://arvin-he.github.io/tags/C-C/"}]},{"title":"C++之overload,override,hide","slug":"cpp-oov-2017-05-04","date":"2017-05-04T08:30:08.000Z","updated":"2017-09-08T03:51:39.343Z","comments":true,"path":"2017/05/04/cpp-oov-2017-05-04/","link":"","permalink":"http://arvin-he.github.io/2017/05/04/cpp-oov-2017-05-04/","excerpt":"","text":"重载(overload)、覆盖(override)、隐藏(hide)的区别 这三个概念都是与OO中的多态有关系的。如果单是区别重载与覆盖这两个概念是比较容易的，但是隐藏这一概念却使问题变得有点复杂了，下面说说它们的区别吧。重载:是指不同的函数使用相同的函数名，但是函数的参数个数或类型不同。调用的时候根据函数的参数来区别不同的函数。覆盖:(也叫重写)是指在派生类中重新对基类中的虚函数（注意是虚函数）重新实现。即函数名和参数都一样，只是函数的实现体不一样。隐藏:是指派生类中的函数把基类中相同名字的函数屏蔽掉了。隐藏与另外两个概念表面上看来很像，很难区分，其实他们的关键区别就是在多态的实现上。什么叫多态？简单地说就是一个接口，多种实现吧。 12345678910111213141516#include &lt;iostream.h&gt; class Base &#123; public: virtual void f(float x)&#123; cout &lt;&lt; \"Base::f(float) \" &lt;&lt; x &lt;&lt; endl; &#125; void g(float x)&#123; cout &lt;&lt; \"Base::g(float) \" &lt;&lt; x &lt;&lt; endl; &#125; void h(float x)&#123; cout &lt;&lt; \"Base::h(float) \" &lt;&lt; x &lt;&lt; endl; &#125; &#125;; class Derived : public Base &#123; public: virtual void f(float x)&#123; cout &lt;&lt; \"Derived::f(float) \" &lt;&lt; x &lt;&lt; endl; &#125; void g(int x)&#123; cout &lt;&lt; \"Derived::g(int) \" &lt;&lt; x &lt;&lt; endl; &#125; void h(float x)&#123; cout &lt;&lt; \"Derived::h(float) \" &lt;&lt; x &lt;&lt; endl; &#125; &#125;; 下面说明一下：（1）函数Derived::f(float)覆盖(重写)了Base::f(float)。（2）函数Derived::g(int)隐藏了Base::g(float)，而不是重载。（3）函数Derived::h(float)隐藏了Base::h(float)，而不是覆盖。 实际应用在实际的编程中，我们会因此遇到什么问题呢？再看下面的代码：123456789101112131415161718void main(void) &#123; Derived d; Base *pb = &amp;d; Derived *pd = &amp;d; // Good : behavior depends solely on type of the object pb-&gt;f(3.14f); // Derived::f(float) 3.14 pd-&gt;f(3.14f); // Derived::f(float) 3.14 // Bad : behavior depends on type of the pointer pb-&gt;g(3.14f); // Base::g(float) 3.14 pd-&gt;g(3.14f); // Derived::g(int) 3 (surprise!) // Bad : behavior depends on type of the pointer pb-&gt;h(3.14f); // Base::h(float) 3.14 (surprise!) pd-&gt;h(3.14f); // Derived::h(float) 3.14 &#125; 在第一种调用中，函数的行为取决于指针所指向的对象。在第二第三种调用中，函数的行为取决于指针的类型。所以说，隐藏破坏了面向对象编程中多态这一特性，会使得OOP人员产生混乱。不过隐藏也并不是一无是处，它可以帮助编程人员在编译时期找出一些错误的调用。但我觉得还是应该尽量使用隐藏这一些特性，该加virtual时就加吧。 C++ 重载 覆盖 隐藏的区别和执行方式成员函数被重载的特征（1）相同的范围（在同一个类中）；（2）函数名字相同；（3）参数不同；（4）virtual 关键字可有可无。覆盖是指派生类函数覆盖基类函数，特征是（1）不同的范围（分别位于派生类与基类）；（2）函数名字相同；（3）参数相同；（4）基类函数必须有virtual 关键字。“隐藏”是指派生类的函数屏蔽了与其同名的基类函数，规则如下（1）如果派生类的函数与基类的函数同名,但是参数不同。此时,不论有无virtual关键字,基类的函数将被隐藏(注意别与重载混淆).（2）如果派生类的函数与基类的函数同名，并且参数也相同，但是基类函数没有virtual 关键字。此时，基类的函数被隐藏（注意别与覆盖混淆）3种情况怎么执行： 重载：看参数 隐藏：用什么就调用什么 覆盖：调用派生类 ###实例一:1234567891011121314151617181920#include \"stdafx.h\"#include &lt;iostream.h&gt;class CB&#123;public: void f(int) &#123; cout &lt;&lt; \"CB::f(int)\" &lt;&lt; endl; &#125;&#125;;class CD : public CB&#123;public: void f(int, int) &#123; cout &lt;&lt; \"CD::f(int,int)\" &lt;&lt; endl; &#125; void test() &#123; f(1); &#125;&#125;;int main(int argc, char* argv[])&#123; return 0;&#125; 编译了一下error C2660: &#39;f&#39; : function does not take 1 parameters结论：在类CD这个域中，没有f(int)这样的函数，基类中的void f(int)被隐藏 如果把派生CD中成员函数void f(int,int)的声明改成和基类中一样，即f(int)，基类中的void f(int)还是一样被覆盖，此时编译不会出错，在函数中test调用的是CD中的f(int) 所以，在基类中的某些函数，如果没有virtral关键字，函数名是f(参数是什么我们不管)，那么如果在派生类CD中也声明了某个f成员函数，那么在类CD域中，基类中所有的那些f都被隐藏。 刚才说的是没有virtual的情况，如果有virtual的情况呢？？实例二：12345678910111213141516171819#include \"stdafx.h\"#include &lt;iostream.h&gt;class CB&#123;public: virtual void f(int) &#123; cout &lt;&lt; \"CB::f(int)\" &lt;&lt; endl; &#125;&#125;;class CD : public CB&#123;public: void f(int) &#123; cout &lt;&lt; \"CD::f(int)\" &lt;&lt; endl; &#125;&#125;;int main(int argc, char* argv[])&#123; return 0;&#125; 这种情况我们叫覆盖(override)！覆盖指的是派生类的虚拟函数覆盖了基类的同名且参数相同的函数！在这里，要强调的是，这种覆盖，要满足两个条件:(a)有virtual关键字，在基类中函数声明的时候加上就可以了(b)基类CB中的函数和派生类CD中的函数要一模一样，什么叫一模一样，函数名，参数，返回类型三个条件。有人可能会对(b)中的说法质疑，说返回类型也要一样？？是，覆盖的话必须一样，我试了试，如果在基类中,把f的声明改成virtual int f(int)，编译出错了:error C2555: ‘CD::f’ : overriding virtual function differs from ‘CB::f’ only by return type or calling convention所以，覆盖的话，必须要满足上述的(a)(b)条件. 那么如果基类CB中的函数f有关键字virtual，但是参数和派生类CD中的函数f参数不一样呢，实例三:1234567891011121314151617181920#include \"stdafx.h\"#include &lt;iostream.h&gt;class CB&#123; public: virtual void f(int) &#123; cout &lt;&lt; \"CB::f(int)\" &lt;&lt; endl; &#125;&#125;;class CD : public CB&#123;public: void f(int，int) &#123; cout &lt;&lt; \"CD::f(int，int)\" &lt;&lt; endl; &#125; void test() &#123; f(1); &#125;&#125;;int main(int argc, char* argv[])&#123; return 0;&#125; 编译出错了，error C2660: ‘f’ : function does not take 1 parameters和实例一中的情况一样哦，结论也是基类中的函数被隐藏了。 通过上面三个例子，得出一个简单的结论如果基类中的函数和派生类中的两个名字一样的函数f满足下面的两个条件(a)在基类中函数声明的时候有virtual关键字(b)基类CB中的函数和派生类CD中的函数一模一样，函数名，参数，返回类型都一样。那么这就是叫做覆盖(override)，这也就是虚函数，多态的性质 那么其他的情况呢？？只要名字一样，不满足上面覆盖的条件，就是隐藏了。 下面我要讲最关键的地方了，好多人认为，基类CB中的f(int)会继承下来和CD中的f(int,int)在派生类CD中构成重载，就像实例一中想像的那样。对吗？我们先看重载的定义重载(overload):必须在一个域中,函数名称相同但是函数参数不同,重载的作用就是同一个函数有不同的行为,因此不是在一个域中的函数是无法构成重载的,这个是重载的重要特征必须在一个域中，而继承明显是在两个类中了，所以上面的想法是不成立的，派生类中的f(int,int)把基类中的f(int)隐藏了所以，相同的函数名的函数，在基类和派生类中的关系只能是覆盖或者隐藏。 关于隐藏可以简单的理解成，在派生类域中，看不到基类中的那个同名函数了，或者说，是并没有继承下来给你用，如实例一那样。 隐藏(hide):指的是派生类的成员函数隐藏了基类函数的成员函数.隐藏一词可以这么理解:在调用一个类的成员函数的时候,编译器会沿着类的继承链逐级的向上查找函数的定义,如果找到了那么就停止查找了,所以如果一个派生类和一个基类都有同一个同名(暂且不论参数是否相同)的函数,而编译器最终选择了在派生类中的函数,那么我们就说这个派生类的成员函数”隐藏”了基类的成员函数,也就是说它阻止了编译器继续向上查找函数的定义. 参考 参考文章","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"C/C++","slug":"C-C","permalink":"http://arvin-he.github.io/tags/C-C/"}]},{"title":"C++之using关键字","slug":"cpp-using-2017-05-04","date":"2017-05-04T08:05:57.000Z","updated":"2017-09-08T03:51:39.376Z","comments":true,"path":"2017/05/04/cpp-using-2017-05-04/","link":"","permalink":"http://arvin-he.github.io/2017/05/04/cpp-using-2017-05-04/","excerpt":"","text":"有两种基本用法：using声明和using指示（using namespace …）。前者是声明，引入命名空间或基类作用域内已经被声明的名称。后者引入命名空间内所有的名称。C++11新增了一类用法，可以代替typename，同时可以配合template使用（typedef基于语法考虑未被允许加入这种用法）。 在当前文件中引入命名空间最熟悉的用法，例如：using namespace std; 在子类中使用 using 声明引入基类成员名称（参见C++ primer）在private或者protected继承时，基类成员的访问级别在派生类中更受限：12345678class Base &#123;public: std::size_t size() const &#123; return n; &#125;protected: std::size_t n;&#125;;class Derived : private Base &#123; . . . &#125;; 在这一继承层次中，成员函数 size 在 Base 中为 public，但在 Derived 中为 private。为了使 size 在 Derived 中成为 public，可以在 Derived 的 public 部分增加一个 using 声明。如下这样改变 Derived 的定义，可以使 size 成员能够被用户访问，并使 n 能够被 Derived的派生类访问：12345678class Derived : private Base &#123;public: using Base::size;protected: using Base::n;// ...&#125;; 另外，当子类中的成员函数和基类同名时，子类中重定义的成员函数将隐藏基类中的版本，即使函数原型不同也是如此（隐藏条件见下面）。 如果基类中成员函数有多个重载版本，派生类可以重定义所继承的 0 个或多个版本，但是通过派生类型只能访问派生类中重定义的那些版本，所以如果派生类想通过自身类型使用所有的重载版本，则派生类必须要么重定义所有重载版本，要么一个也不重定义。有时类需要仅仅重定义一个重载集中某些版本的行为，并且想要继承其他版本的含义，在这种情况下，为了重定义需要特化的某个版本而不得不重定义每一个基类版本，可能会令人厌烦。可以在派生类中为重载成员名称提供 using 声明（为基类成员函数名称而作的 using 声明将该函数的所有重载实例加到派生类的作用域），使派生类不用重定义所继承的每一个基类版本。一个 using 声明只能指定一个名字，不能指定形参表，使用using声明将名字加入作用域之后，派生类只需要重定义本类型确实必须定义的那些函数，对其他版本可以使用继承的定义。 “隐藏”是指派生类的函数屏蔽了与其同名的基类函数，规则如下：1、如果派生类的函数与基类的函数同名，但是参数不同。此时，不论有无virtual关键字，基类的函数将被隐藏（注意别与重载混淆）2、如果派生类的函数与基类的函数同名，并且参数也相同，但是基类函数没有virtual关键字。此时，基类的函数被隐藏（注意别与覆盖混淆） 12345678910111213141516171819202122232425262728#include \"StdAfx.h\"#include &lt;iostream&gt;using namespace std;class Base&#123;public: void menfcn() &#123; cout&lt;&lt;\"Base function\"&lt;&lt;endl; &#125; void menfcn(int n) &#123; cout&lt;&lt; cout&lt;&lt;\"Base function with int\"&lt;&lt;endl; &#125;&#125;;class Derived : Base&#123;public: using Base::menfcn; //using声明只能指定一个名字，不能带形参表 int menfcn(int)&#123; cout&lt;&lt; cout&lt;&lt;\"Derived function with int\"&lt;&lt;endl; &#125;&#125;;int main()&#123; Base b; Derived d; b.menfcn(); //若去掉Derived类中的using声明,会出现错误:error C2660:'Derived::menfcn':function does not take 0 arguments d.menfcn(); std::cin.ignore(std::cin.gcount()+1); //清空缓冲区 std::cin.get();//暂停程序执行 &#125;","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"C/C++","slug":"C-C","permalink":"http://arvin-he.github.io/tags/C-C/"}]},{"title":"C++之volatile关键字","slug":"cpp-volatile-2017-05-03","date":"2017-05-03T07:22:22.000Z","updated":"2017-09-08T03:51:39.423Z","comments":true,"path":"2017/05/03/cpp-volatile-2017-05-03/","link":"","permalink":"http://arvin-he.github.io/2017/05/03/cpp-volatile-2017-05-03/","excerpt":"","text":"volatile的本意是“易变的”,volatile关键字是一种类型修饰符，用它声明的类型变量表示可以被某些编译器未知的因素更改，比如操作系统、硬件或者其它线程等。遇到这个关键字声明的变量，编译器对访问该变量的代码就不再进行优化，从而可以提供对特殊地址的稳定访问。 当要求使用volatile 声明的变量的值的时候，系统总是重新从它所在的内存读取数据，即使它前面的指令刚刚从该处读取过数据。而且读取的数据立刻被寄存。例如：1234volatile int i=10;int a = i;...... //其他代码，并未明确告诉编译器，对i进行过操作int b = i; volatile 指出 i是随时可能发生变化的，每次使用它的时候必须从i的地址中读取，因而编译器生成的汇编代码会重新从i的地址读取数据放在b中。而优化做法是，由于编译器发现两次从i读数据的代码之间的代码没有对i进行过操作，它会自动把上次读的数据放在b中。而不是重新从i里面读。这样以来，如果i是一个寄存器变量或者表示一个端口数据就容易出错，所以说volatile可以保证对特殊地址的稳定访问。 volatile的易变性所谓的易变性，在汇编层面反映出来，就是两条语句，下一条语句不会直接使用上一条语句对应的volatile变量的寄存器内容，而是重新从内存中读取。 volatile的不可优化性“不可优化”特性。volatile告诉编译器，不要对我这个变量进行各种激进的优化，甚至将变量直接消除，保证程序员写在代码中的指令，一定会被执行。 volatile的顺序性C/C++ Volatile关键词前面提到的易变性和不可优化性，让Volatile经常被解读为一个为多线程而生的关键词：一个全局变量，会被多线程同时访问/修改，那么线程内部，就不能假设此变量的不变性，并且基于此假设，来做一些程序设计。当然，这样的假设，本身并没有什么问题，多线程编程，并发访问/修改的全局变量，通常都会建议加上Volatile关键词修饰，来防止C/C++编译器进行不必要的优化。但是，很多时候，C/C++ Volatile关键词，在多线程环境下，会被赋予更多的功能，从而导致问题的出现。 ”顺序性”，能够保证Volatile变量间的顺序性，编译器不会进行乱序优化。Volatile变量与非Volatile变量的顺序，编译器不保证顺序，可能会进行乱序优化。同时，C/C++ Volatile关键词，并不能用于构建happens-before语义，因此在进行多线程程序设计时，要小心使用volatile，不要掉入volatile变量的使用陷阱之中。 关于volatile的补充：一个定义为volatile的变量是说这变量可能会被意想不到地改变，这样，编译器就不会去假设这个变量的值了。精确地说就是，优化器在用到这个变量时必须每次都小心地重新读取这个变量的值，而不是使用保存在寄存器里的备份。下面是volatile变量的几个例子： 并行设备的硬件寄存器（如：状态寄存器） 一个中断服务子程序中会访问到的非自动变量(Non-automatic variables) 多线程应用中被几个任务共享的变量 关于volatile的一些问题：1). 一个参数既可以是const还可以是volatile吗？解释为什么。2). 一个指针可以是volatile 吗？解释为什么。3). 下面的函数有什么错误：1234int square(volatile int *ptr)&#123; return *ptr * *ptr;&#125; 下面是答案：1). 是的。一个例子是只读的状态寄存器。它是volatile因为它可能被意想不到地改变。它是const因为程序不应该试图去修改它。2). 是的。尽管这并不很常见。一个例子是当一个中服务子程序修改一个指向一个buffer的指针时。3). 这段代码的有个恶作剧。这段代码的目的是用来返指针*ptr指向值的平方，但是，由于*ptr指向一个volatile型参数，编译器将产生类似下面的代码：1234567int square(volatile int *ptr)&#123; int a,b; a = *ptr; b = *ptr; return a * b;&#125; 由于*ptr的值可能被意想不到地该变，因此a和b可能是不同的。结果，这段代码可能返不是你所期望的平方值！正确的代码如下：123456long square(volatile int *ptr)&#123; int a; a = *ptr; return a * a;&#125; 参考 参考文章 参考文章","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"C/C++","slug":"C-C","permalink":"http://arvin-he.github.io/tags/C-C/"}]},{"title":"C++之explicit关键字","slug":"cpp-explicit-2017-05-03","date":"2017-05-03T06:49:41.000Z","updated":"2017-09-08T03:51:39.299Z","comments":true,"path":"2017/05/03/cpp-explicit-2017-05-03/","link":"","permalink":"http://arvin-he.github.io/2017/05/03/cpp-explicit-2017-05-03/","excerpt":"","text":"explicit关键字C++中，explicit关键字用来修饰类的构造函数，被修饰的构造函数的类，不能发生相应的隐式类型转换，只能以显示的方式进行类型转换。 在C++中，如果一个类只有一个参数的构造函数，C++允许一种特殊的声明类变量的方式。即可以直接将一个对应于构造函数参数类型的数据直接赋值给类变量，编译器在编译时会自动进行类型转换，将对应于构造函数参数类型的数据转换为类的对象。如果在构造函数前加上explicit修饰词，则会禁止这种自动转换，此时，即使将对应于构造函数参数类型的数据直接赋值给类变量，编译器也会报错。 explicit使用注意事项explicit 关键字只能用于类内部的构造函数声明上，且作用于单个参数的构造函数。 示例12345678910111213class Student&#123;public:int age;Student (int a) &#123;age=a;&#125;&#125;; void foo ( void )&#123; Student s1(10); //方式一 Student* p_s2=new Student(10); //方式二 Student s3=10; //方式三&#125; 第三种方式比较特殊,因为C++是一种强类型语言，不同的数据类型是不能随意转换的，必须进行显式或隐式的类型转换，这里，没有进行任何显式转换，直接将一个整型数据赋值给了类变量s3.这里是进行了一次隐式类型转换，编译器自动将对应于构造函数参数类型的数据转换为了该类的对象，最终方式三经编译器自动转换后和方式一的实现方式是相同的。","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"C/C++","slug":"C-C","permalink":"http://arvin-he.github.io/tags/C-C/"}]},{"title":"C/C++之extern关键字","slug":"cpp-extern-2017-04-27","date":"2017-04-27T01:39:42.000Z","updated":"2017-09-08T03:51:39.301Z","comments":true,"path":"2017/04/27/cpp-extern-2017-04-27/","link":"","permalink":"http://arvin-he.github.io/2017/04/27/cpp-extern-2017-04-27/","excerpt":"","text":"extern作用extern可以置于变量或者函数前，表示变量或者函数的定义在别的文件中，提示编译器遇到此变量和函数时在其他模块中寻找其定义。此外extern也可用来进行链接指定。 extern有两个作用:第一个,当它与”C”一起连用时，如: extern &quot;C&quot; void fun(int a, int b);则告诉编译器在编译fun这个函数名时按着C的规则去翻译相应的函数名而不是C++的，C++的规则在翻译这个函数名时会把fun这个名字变得面目全非，可能是fun@aBc_int_int#%$也可能是别的，不同的编译器采用的方法不一样，为什么这么做呢，因为C++支持函数的重载.第二，当extern不与”C”在一起修饰变量或函数时，它的作用就是声明函数或全局变量的作用范围的关键字,如在头文件中: extern int g_Int; ，其声明的函数和变量可以在本模块和其他模块中使用.记住它是一个声明不是定义!也就是说B模块(编译单元)要是引用模块(编译单元)A中定义的全局变量或函数时，它只要包含A模块的头文件即可,在编译阶段，模块B虽然找不到该函数或变量，但它不会报错，它会在链接时从模块A生成的目标代码中找到此函数。 extern一些使用实例 问题:在一个源文件里定义了一个数组:char a[6];,在另外一个文件里用下列语句进行了声明：extern char \\*a, 请问这样可以吗？答案:不可以，程序运行时会告诉你非法访问。原因:指向类型T的指针并不等价于类型T的数组。extern char a声明的是一个指针变量而不是字符数组，因此与实际的定义不同，从而造成运行时非法访问。应该将声明改为extern char a[]。分析:例子分析如下，如果a[] = “abcd”,则外部变量a=0x61626364 (abcd的ASCII码值)，a显然没有意义,显然a指向的空间（0x61626364）没有意义，易出现非法内存访问。这提示我们，在使用extern时候要严格对应声明时的格式，在实际编程中，这样的错误屡见不鲜。extern用在变量声明中常常有这样一个作用，你在*.c文件中声明了一个全局的变量，这个全局的变量如果要被引用，就放在*.h中并用extern来声明。 问题：单方面修改extern 函数原型当函数提供方单方面修改函数原型时，如果使用方不知情继续沿用原来的extern声明，这样编译时编译器不会报错。但是在运行过程中，因为少了或者多了输入参数，往往会照成系统错误，这种情况应该如何解决？答案与分析：目前业界针对这种情况的处理没有一个很完美的方案，通常的做法是提供方在自己的xxx_pub.h中提供对外部接口的声明，然后调用方include该头文件，从而省去extern这一步。以避免这种错误。宝剑有双锋，对extern的应用，不同的场合应该选择不同的做法。 extern “C”, 在C++环境下使用C函数的时候，常常会出现编译器无法找到obj模块中的C函数定义，从而导致链接失败的情况，应该如何解决这种情况呢？答案与分析：C++语言在编译的时候为了解决函数的多态问题，会将函数名和参数联合起来生成一个中间的函数名称，而C语言则不会，因此会造成链接时找不到对应函数的情况，此时C函数就需要用extern “C”进行链接指定，这告诉编译器，请保持我的名称，不要给我生成用于链接的中间函数名。下面是一个标准的写法： 1234567891011121314//在.h文件的头上#ifdef __cplusplus#if __cplusplusextern \"C\"&#123; #endif #endif /* __cplusplus */ … … //.h文件结束的地方 #ifdef __cplusplus #if __cplusplus&#125;#endif#endif /* __cplusplus */ 常见extern放在函数的前面成为函数声明的一部分，那么，C语言的关键字extern在函数的声明中起什么作用？答案与分析：如果函数的声明中带有关键字extern，仅仅是暗示这个函数可能在别的源文件里定义，没有其它作用。即下述两个函数声明没有明显的区别：extern int f();和int f();当然，这样的用处还是有的，就是在程序中取代include “*.h”来声明函数，在一些复杂的项目中，我比较习惯在所有的函数声明前添加extern修饰。关于这样做的原因和利弊可见下面的这个例子：用extern修饰的全局变量(1) 在test1.h中有下列声明:12345#ifndef TEST1H#define TEST1Hextern char g_str[]; // 声明全局变量g_strvoid fun1();#endif (2) 在test1.cpp中123#include \"test1.h\"char g_str[] = \"123456\"; // 定义全局变量g_strvoid fun1() &#123; cout &lt;&lt; g_str &lt;&lt; endl; &#125; (3) 以上是test1模块， 它的编译和连接都可以通过,如果我们还有test2模块也想使用g_str,只需要在原文件中引用就可以了12#include \"test1.h\"void fun2() &#123; cout &lt;&lt; g_str &lt;&lt; endl; &#125; 以上test1和test2可以同时编译连接通过，如果你感兴趣的话可以用ultraEdit打开test1.obj,你可以在里面找到”123456”这个字符串,但是你却不能在test2.obj里面找到，这是因为g_str是整个工程的全局变量，在内存中只存在一份,test2.obj这个编译单元不需要再有一份了，不然会在连接时报告重复定义这个错误! 有些人喜欢把全局变量的声明和定义放在一起，这样可以防止忘记了定义.如把上面test1.h改为:extern char g_str[] = &quot;123456&quot;; // 这个时候相当于没有extern,然后把test1.cpp中的g_str的定义去掉,这个时候再编译连接test1和test2两个模块时，会报链接错误，这是因为你把全局变量g_str的定义放在了头文件之后，test1.cpp这个模块包含了test1.h所以定义了一次g_str,而test2.cpp也包含了test1.h,所以再一次定义了g_str,这个时候链接器在链接test1和test2时发现两个g_str。如果你非要把g_str的定义放在test1.h中的话，那么就把test2的代码中#include “test1.h”去掉 换成:extern char g_str[];123//在test2先声明下,再使用extern char g_str[];void fun2() &#123; cout &lt;&lt; g_str &lt;&lt; endl; &#125; 这个时候编译器就知道g_str是引自于外部的一个编译模块了，不会在本模块中再重复定义一个出来，但是我想说这样做非常糟糕，因为你由于无法在test2.cpp中使用#include &quot;test1.h&quot;,那么test1.h中声明的其他函数你也无法使用了，除非也用都用extern修饰，这样的话你光声明的函数就要一大串，而且头文件的作用就是要给外部提供接口使用的，所以 请记住， 只在头文件中做声明，真理总是这么简单。 extern 和 static(1) extern 表明该变量在别的地方已经定义过了,在这里要使用那个变量.(2) static 表示静态的变量，分配内存的时候, 存储在静态区,不存储在栈上面. static 作用范围是内部连接的关系, 和extern有点相反.它和对象本身是分开存储的,extern也是分开存储的,但是extern可以被其他的对象用extern引用,而static 不可以,只允许对象本身用它.具体差别:首先，static与extern是一对“水火不容”的家伙，也就是说extern和static不能同时修饰一个变量；其次，static修饰的全局变量声明与定义同时进行，也就是说当你在头文件中使用static声明了全局变量后，它也同时被定义了；最后，static修饰全局变量的作用域只能是本身的编译单元，也就是说它的“全局”只对本编译单元有效，其他编译单元则看不到它,如:(1) test1.h:12345#ifndef TEST1H#define TEST1Hstatic char g_str[] = \"123456\"; void fun1();#endif (2) test1.cpp:12#include \"test1.h\"void fun1() &#123; cout &lt;&lt; g_str &lt;&lt; endl; &#125; (3) test2.cpp12#include \"test1.h\"void fun2() &#123; cout &lt;&lt; g_str &lt;&lt; endl; &#125; 以上两个编译单元可以连接成功, 当你打开test1.obj时，你可以在它里面找到字符串”123456”,同时你也可以在test2.obj中找到它们，它们之所以可以连接成功而没有报重复定义的错误是因为虽然它们有相同的内容，但是存储的物理地址并不一样，就像是两个不同变量赋了相同的值一样，而这两个变量分别作用于它们各自的编译单元。 也许你比较较真，自己偷偷的跟踪调试上面的代码,结果你发现两个编译单元（test1,test2）的g_str的内存地址相同，于是你下结论static修饰的变量也可以作用于其他模块，但是我要告诉你，那是你的编译器在欺骗你，大多数编译器都对代码都有优化功能，以达到生成的目标程序更节省内存，执行效率更高，当编译器在连接各个编译单元的时候，它会把相同内容的内存只拷贝一份，比如上面的”123456”, 位于两个编译单元中的变量都是同样的内容，那么在连接的时候它在内存中就只会存在一份了，如果你把上面的代码改成下面的样子，你马上就可以拆穿编译器的谎言:(1) test1.cpp:123456#include \"test1.h\"void fun1()&#123; g_str[0] = \"a\"; cout &lt;&lt; g_str &lt;&lt; endl;&#125; (2) test2.cpp12#include \"test1.h\"void fun2() &#123; cout &lt;&lt; g_str &lt;&lt; endl; &#125; (3)1234void main()&#123; fun1(); // a23456 fun2(); // 123456 &#125; 这个时候你在跟踪代码时，就会发现两个编译单元中的g_str地址并不相同，因为你在一处修改了它，所以编译器被强行的恢复内存的原貌，在内存中存在了两份拷贝给两个模块中的变量使用。正是因为static有以上的特性，所以一般定义static全局变量时，都把它放在源文件中而不是头文件，这样就不会给其他模块造成不必要的信息污染，同样记住这个原则吧！ extern 和const C++中const修饰的全局常量具有跟static相同的特性，即它们只能作用于本编译模块中，但是const可以与extern连用来声明该常量可以作用于其他编译模块中, 如extern const char g_str[];,然后在原文件中别忘了定义:const char g_str[] = &quot;123456&quot;;. 所以当const单独使用时它就与static相同，而当与extern一起合作的时候，它的特性就跟extern的一样了！我只是想提醒你，const char* g_str = &quot;123456&quot; 与 const char g_str[] =&quot;123465&quot;是不同的， 前面那个const 修饰的是char *而不是g_str,它的g_str并不是常量，它被看做是一个定义了的全局变量（可以被其他编译单元使用）， 所以如果你像让char* g_str遵守const的全局常量的规则，最好这么定义const char* const g_str=”123456”. 假如a.h中有 int a=10; t1.cpp和t2.cpp同时include “a.h”则编译不成功，因为a重复定义；如果 a.h中是 static int a=10;则可以，因为t1和t2中的a只是名字相同，地址空间不同；如果a.h中是 extern int a; 并且在a.cpp中 int a=10; 则t1和t2中的a指向同一个地址空间。 在头文件中定义全局变量，如果该头文件不被任何.c或者.cpp中包含的话，该变量的定义是没有意义的，即使加了extern 关键字。因为在变量定义中，extern关键字是不起作用的，extern只用作声明。编译器在编译时，是不管头文件的，只有在预处理时会include头文件中的内容，也就是把头文件中的内容全盘粘贴过来。因此，如果你只是在头文件中定义变量，而不include头文件，这时，编译器无论是在预处理阶段，还是在链接阶段，直接无视头文件的存在(链接器只会在.c/.cpp生成的目标文件(.o)中查找变量名）。这样一来，头文件中定义的变量也就形同虚设，完全没有意义可言。因此虽然在头文件定义,但不include该头文件时,VS链接时也就会在.c/.cpp生成的目标文件(.o)中查找变量名出现无法解析的外部命令了。 参考 C/C++中extern关键字详解","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"C/C++","slug":"C-C","permalink":"http://arvin-he.github.io/tags/C-C/"}]},{"title":"C/C++之inline关键字","slug":"cpp-inline-2017-04-26","date":"2017-04-26T07:57:56.000Z","updated":"2017-09-08T03:51:39.304Z","comments":true,"path":"2017/04/26/cpp-inline-2017-04-26/","link":"","permalink":"http://arvin-he.github.io/2017/04/26/cpp-inline-2017-04-26/","excerpt":"","text":"内联函数 —— C 中关键字 inline 用法解析内联函数:在C语言中，如果一些函数被频繁调用，不断地有函数入栈，即函数栈，会造成栈空间或栈内存的大量消耗。为了解决这个问题，特别的引入了inline修饰符，表示为内联函数。栈空间就是指放置程式的局部数据也就是函数内数据的内存空间，在系统下，栈空间是有限的，假如频繁大量的使用就会造成因栈空间不足所造成的程式出错的问题，函数的死循环递归调用的最终结果就是导致栈内存空间耗尽。 123456789101112131415#include &lt;stdio.h&gt;//函数定义为inline即:内联函数inline char* dbtest(int a)&#123; return (i % 2 &gt; 0) ? \"奇\" : \"偶\";&#125;int main()&#123; int i = 0; for (i=1; i &lt; 100; i++) &#123; printf(\"i:%d 奇偶性:%s /n\", i, dbtest(i)); &#125;&#125; 上面的例子就是标准的内联函数的用法，使用inline修饰带来的好处我们表面看不出来，其实在内部的工作就是在每个for循环的内部任何调用dbtest(i)的地方都换成了(i%2&gt;0)?”奇”:”偶”这样就避免了频繁调用函数对栈内存重复开辟所带来的消耗。其实这种有点类似动态库和静态库的问题，将dbtest函数中的代码直接被放到main函数中，执行for循环时，会不断调用这段代码，而不是不断地开辟一个函数栈。 内联函数的注意事项:关键字inline 必须与函数定义体放在一起才能使函数成为内联，仅将inline 放在函数声明前面不起任何作用。所以说，inline 是一种“用于实现的关键字”，而不是一种“用于声明的关键字”。一般地，用户可以阅读函数的声明，但是看不到函数的定义。尽管在大多数教科书中内联函数的声明、定义体前面都加了inline 关键字，但我认为inline 不应该出现在函数的声明中。这个细节虽然不会影响函数的功能，但是体现了高质量C++/C 程序设计风格的一个基本原则：声明与定义不可混为一谈，用户没有必要、也不应该知道函数是否需要内联。 inline的使用是有所限制的inline只适合函数体内代码简单的函数使用，不能包含复杂的结构控制语句例如while、switch，并且内联函数本身不能是直接递归函数(自己内部还调用自己的函数). 慎用内联内联能提高函数的执行效率，为什么不把所有的函数都定义成内联函数？如果所有的函数都是内联函数，还用得着“内联”这个关键字吗？内联是以代码膨胀（复制）为代价，仅仅省去了函数调用的开销，从而提高函数的执行效率。如果执行函数体内代码的时间，相比于函数调用的开销较大，那么效率的收获会很少。另一方面，每一处内联函数的调用都要复制代码，将使程序的总代码量增大，消耗更多的内存空间。以下情况不宜使用内联：（1）如果函数体内的代码比较长，使用内联将导致内存消耗代价较高。（2）如果函数体内出现循环，那么执行函数体内代码的时间要比函数调用的开销大。一个好的编译器将会根据函数的定义体，自动地取消不值得的内联（这进一步说明了inline 不应该出现在函数的声明中）。 总结：因此,将内联函数放在头文件里实现是合适的,省却你为每个文件实现一次的麻烦.而声明跟定义要一致,其实是指,如果在每个文件里都实现一次该内联函数的话,那么,最好保证每个定义都是一样的,否则,将会引起未定义的行为,即是说,如果不是每个文件里的定义都一样,那么,编译器展开的是哪一个,那要看具体的编译器而定.所以,最好将内联函数定义放在头文件中. 参考 参考文章","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"C/C++","slug":"C-C","permalink":"http://arvin-he.github.io/tags/C-C/"}]},{"title":"C++之线程与进程","slug":"cpp-thread-process-2017-04-26","date":"2017-04-26T02:47:37.000Z","updated":"2017-09-08T03:51:39.351Z","comments":true,"path":"2017/04/26/cpp-thread-process-2017-04-26/","link":"","permalink":"http://arvin-he.github.io/2017/04/26/cpp-thread-process-2017-04-26/","excerpt":"","text":"进程与线程的概念 任务调度大部分操作系统(如Windows、Linux)的任务调度是采用时间片轮转的抢占式调度方式，即一个任务执行一小段时间后强制暂停去执行下一个任务，每个任务轮流执行。任务执行的一小段时间叫做时间片，任务正在执行时的状态叫运行状态，任务执行一段时间后强制暂停去执行下一个任务，被暂停的任务就处于就绪状态等待下一个属于它的时间片的到来,这样每个任务都能得到执行. 进程操作系统是计算机的管理者，它负责任务的调度、资源的分配和管理，统领整个计算机硬件；应用程序则是具有某种功能的程序，程序是运行于操作系统之上的.在早期的操作系统中并没有线程的概念，进程是能拥有资源和独立运行的最小单位，也是程序执行的最小单位。任务调度采用的是时间片轮转的抢占式调度方式，而进程是任务调度的最小单位，每个进程有各自独立的一块内存，使得各个进程之间内存地址相互隔离。 进程是一个具有一定独立功能的程序在一个数据集上的一次动态执行的过程，是操作系统进行资源分配和调度的一个独立单位，是应用程序运行的载体。 进程是一种抽象的概念，从来没有统一的标准定义。进程一般由程序、数据集合和进程控制块三部分组成。程序用于描述进程要完成的功能，是控制进程执行的指令集；数据集合是程序在执行时所需要的数据和工作区；程序控制块(Program Control Block，简称PCB)，包含进程的描述信息和控制信息，是进程存在的唯一标志。 进程具有的特征：动态性：进程是程序的一次执行过程，是临时的，有生命期的，是动态产生，动态消亡的；并发性：任何进程都可以同其他进程一起并发执行；独立性：进程是系统进行资源分配和调度的一个独立单位；结构性：进程由程序、数据和进程控制块三部分组成。 线程线程是程序执行中一个单一的顺序控制流程，是程序执行流的最小单元，是处理器调度和分派的基本单位。一个进程可以有一个或多个线程，各个线程之间共享程序的内存空间(也就是所在进程的内存空间)。一个标准的线程由线程ID、当前指令指针(PC)、寄存器和堆栈组成,而进程由内存空间(代码、数据、进程空间、打开的文件)和一个或多个线程组成。 进程与线程的区别 线程是程序执行的最小单位，而进程是操作系统分配资源的最小单位； 一个进程由一个或多个线程组成，线程是一个进程中代码的不同执行路线； 进程之间相互独立，但同一进程下的各个线程之间共享程序的内存空间(包括代码段、数据集、堆等)及一些进程级的资源(如打开文件和信号)，某进程内的线程在其它进程不可见； 调度和切换：线程上下文切换比进程上下文切换要快得多。总之，线程和进程都是一种抽象的概念，线程是一种比进程更小的抽象，线程和进程都可用于实现并发。在早期的操作系统中并没有线程的概念，进程是能拥有资源和独立运行的最小单位，也是程序执行的最小单位。它相当于一个进程里只有一个线程，进程本身就是线程。所以线程有时被称为轻量级进程(Lightweight Process，LWP）。后来，随着计算机的发展，对多个任务之间上下文切换的效率要求越来越高，就抽象出一个更小的概念——线程，一般一个进程会有多个(也可是一个)线程。 多线程与多核很多操作系统的书都说“同一时间点只有一个任务在执行”,其实“同一时间点只有一个任务在执行”这句话是不准确的，至少它是不全面的。那多核处理器的情况下，线程是怎样执行呢？这就需要了解内核线程。多核(心)处理器是指在一个处理器上集成多个运算核心从而提高计算能力，也就是有多个真正并行计算的处理核心，每一个处理核心对应一个内核线程。内核线程（Kernel Thread， KLT）就是直接由操作系统内核支持的线程，这种线程由内核来完成线程切换，内核通过操作调度器对线程进行调度，并负责将线程的任务映射到各个处理器上。一般一个处理核心对应一个内核线程，比如单核处理器对应一个内核线程，双核处理器对应两个内核线程，四核处理器对应四个内核线程。 现在的电脑一般是双核四线程、四核八线程，是采用超线程技术将一个物理处理核心模拟成两个逻辑处理核心，对应两个内核线程，所以在操作系统中看到的CPU数量是实际物理CPU数量的两倍，如你的电脑是双核四线程，打开“任务管理器\\性能”可以看到4个CPU的监视器，四核八线程可以看到8个CPU的监视器。 超线程技术就是利用特殊的硬件指令，把一个物理芯片模拟成两个逻辑处理核心，让单个处理器都能使用线程级并行计算，进而兼容多线程操作系统和软件，减少了CPU的闲置时间，提高的CPU的运行效率。这种超线程技术(如双核四线程)由处理器硬件的决定，同时也需要操作系统的支持才能在计算机中表现出来。 程序一般不会直接去使用内核线程，而是去使用内核线程的一种高级接口——轻量级进程（Light Weight Process，LWP），轻量级进程就是我们通常意义上所讲的线程(我们在这称它为用户线程)，由于每个轻量级进程都由一个内核线程支持，因此只有先支持内核线程，才能有轻量级进程。用户线程与内核线程的对应关系有三种模型：一对一模型、多对一模型、多对多模型. 一对一模型一个用户线程就唯一地对应一个内核线程(反过来不一定成立，一个内核线程不一定有对应的用户线程)。这样，如果CPU没有采用超线程技术(如四核四线程的计算机)，一个用户线程就唯一地映射到一个物理CPU的线程，线程之间的并发是真正的并发。一对一模型使用户线程具有与内核线程一样的优点，一个线程因某种原因阻塞时其他线程的执行不受影响；此处，一对一模型也可以让多线程程序在多处理器的系统上有更好的表现。但一对一模型也有两个缺点：1.许多操作系统限制了内核线程的数量，因此一对一模型会使用户线程的数量受到限制；2.许多操作系统内核线程调度时，上下文切换的开销较大，导致用户线程的执行效率下降。 多对一模型多对一模型将多个用户线程映射到一个内核线程上，线程之间的切换由用户态的代码来进行，因此相对一对一模型，多对一模型的线程切换速度要快许多；此外，多对一模型对用户线程的数量几乎无限制。但多对一模型也有两个缺点：1.如果其中一个用户线程阻塞，那么其它所有线程都将无法执行，因为此时内核线程也随之阻塞了；2.在多处理器系统上，处理器数量的增加对多对一模型的线程性能不会有明显的增加，因为所有的用户线程都映射到一个处理器上了。 多对多模型多对多模型结合了一对一模型和多对一模型的优点，将多个用户线程映射到多个内核线程上。多对多模型的优点有：1.一个用户线程的阻塞不会导致所有线程的阻塞，因为此时还有别的内核线程被调度来执行；2.多对多模型对用户线程的数量没有限制；3.在多处理器的操作系统中，多对多模型的线程也能得到一定的性能提升，但提升的幅度不如一对一模型的高。在现在流行的操作系统中，大都采用多对多的模型。 进程和线程的状态当线程的数量小于处理器的数量时，线程的并发是真正的并发，不同的线程运行在不同的处理器上。但当线程的数量大于处理器的数量时，线程的并发会受到一些阻碍，此时并不是真正的并发，因为此时至少有一个处理器会运行多个线程。在单个处理器运行多个线程时，并发是一种模拟出来的状态。操作系统采用时间片轮转的方式轮流执行每一个线程。现在，几乎所有的现代操作系统采用的都是时间片轮转的抢占式调度方式，如我们熟悉的Unix、Linux、Windows及Mac OS X等流行的操作系统。线程是程序执行的最小单位，也是任务执行的最小单位。在早期只有进程的操作系统中，进程有五种状态，创建、就绪、运行、阻塞(等待)、退出。早期的进程相当于现在的只有单个线程的进程，那么现在的多线程也有五种状态，现在的多线程的生命周期与早期进程的生命周期类似。 进程的状态进程在运行过程有三种状态：就绪、运行、阻塞，创建和退出状态描述的是进程的创建过程和退出过程。创建：进程正在创建，还不能运行。操作系统在创建进程时要进行的工作包括分配和建立进程控制块表项、建立资源表格并分配资源、加载程序并建立地址空间；就绪：时间片已用完，此线程被强制暂停，等待下一个属于他的时间片到来；运行：此线程正在执行，正在占用时间片；阻塞：也叫等待状态，等待某一事件(如IO或另一个线程)执行完；退出：进程已结束，所以也称结束状态，释放操作系统分配的资源。 线程的状态创建：一个新的线程被创建，等待该线程被调用执行；就绪：时间片已用完，此线程被强制暂停，等待下一个属于他的时间片到来；运行：此线程正在执行，正在占用时间片；阻塞：也叫等待状态，等待某一事件(如IO或另一个线程)执行完；退出：一个线程完成任务或者其他终止条件发生，该线程终止进入退出状态，退出状态释放该线程所分配的资源。 线程优先级优先级调度(Priority Schedule)决定了线程按照什么顺序轮流执行.线程拥有各自的线程优先级(Thread Priority),线程的优先级可以由用户手动设置，此外系统也会根据不同情形调整优先级。频繁等待的线程称之为IO密集型线程(IO Bound Thread)，而把很少等待的线程称之为CPU密集型线程(CPU Bound Thread)。IO密集型线程总是比CPU密集型线程更容易得到优先级的提升。 线程饿死:优先级较低的线程，在它执行之前总是有比它优先级更高的线程等待执行，因此这个低优先级的线程始终得不到执行。 在优先级调度环境下，线程优先级的改变有三种方式： 用户指定优先级； 根据进入等待状态的频繁程度提升或降低优先级(由操作系统完成)； 长时间得不到执行而被提升优先级。 线程安全与锁多个线程对同一数据的进行访问时需要同步，以确保线程安全。同步(synchronization)就是指一个线程访问数据时，其它线程不得对同一个数据进行访问，即同一时刻只能有一个线程访问该数据，当这一线程访问结束时其它线程才能对这它进行访问。同步最常见的方式就是使用锁(Lock)，也称为线程锁。锁是一种非强制机制，每一个线程在访问数据或资源之前，首先试图获取(Acquire)锁，并在访问结束之后释放(Release)锁。在锁被占用时试图获取锁，线程会进入等待状态，直到锁被释放再次变为可用。 二元信号量二元信号量(Binary Semaphore)是一种最简单的锁，它有两种状态：占用和非占用。它适合只能被唯一一个线程独占访问的资源。当二元信号量处于非占用状态时，第一个试图获取该二元信号量锁的线程会获得该锁，并将二元信号量锁置为占用状态，之后其它试图获取该二元信号量的线程会进入等待状态，直到该锁被释放。 信号量多元信号量允许多个线程访问同一个资源，多元信号量简称信号量(Semaphore)，对于允许多个线程并发访问的资源，这是一个很好的选择。一个初始值为N的信号量允许N个线程并发访问。线程访问资源时首先获取信号量锁，进行如下操作：1). 将信号量的值减1；2). 如果信号量的值小于0，则进入等待状态，否则继续执行；访问资源结束之后，线程释放信号量锁，进行如下操作：1). 将信号量的值加1；2). 如果信号量的值小于1(等于0)，唤醒一个等待中的线程； 互斥量互斥量(Mutex)和二元信号量类似，资源仅允许一个线程访问。与二元信号量不同的是，信号量在整个系统中可以被任意线程获取和释放，也就是说，同一个信号量可以由一个线程获取而由另一线程释放。而互斥量则要求哪个线程获取了该互斥量锁就由哪个线程释放，其它线程越俎代庖释放互斥量是无效的。 临界区临界区(Critical Section)是一种比互斥量更加严格的同步手段。互斥量和信号量在系统的任何进程都是可见的，也就是说一个进程创建了一个互斥量或信号量，另一进程试图获取该锁是合法的。而临界区的作用范围仅限于本进程，其它的进程无法获取该锁。除此之处，临界区与互斥量的性质相同。 读写锁读写锁(Read-Write Lock)允许多个线程同时对同一个数据进行读操作，而只允许一个线程进行写操作。这是因为读操作不会改变数据的内容，是安全的；而写操作会改变数据的内容，是不安全的。对同一个读写锁，有两种获取方式：共享的(Shared)和独占的(Exclusive)。当锁处于自由状态时，试图以任何一种方式获取锁都能成功，并将锁置为对应的状态；如果锁处于共享状态，其它线程以共享方式获取该锁，仍然能成功，此时该锁分配给了多个线程；如果其它线程试图如独占的方式获取处于共享状态的锁，它必须等待所有线程释放该锁；处于独占状态的锁阻止任何线程获取该锁，不论它们以何种方式。获取读写锁的方式总结如下：|读写锁的状态 |以共享方式获取 |以独占方式获取||————|—————|————-||自由 |成功 |成功||共享 |成功 |等待||独占 |等待 |等待| 单线程任何程序至少有一个线程，即使你没有主动地创建线程，程序从一开始执行就有一个默认的线程，被称为主线程(main thread)，只有一个线程的程序称为单线程程序。 线程使用 创建线程在Windows平台，Windows API提供了对多线程的支持。Windows中线程相关的操作和方法：CreateThread与CloseHandle.CreateThread用于创建一个线程，其函数原型如下： 12345678HANDLE WINAPI CreateThread( LPSECURITY_ATTRIBUTES lpThreadAttributes, //线程安全相关的属性，常置为NULL SIZE_T dwStackSize, //新线程的初始化栈在大小，可设置为0 LPTHREAD_START_ROUTINE lpStartAddress, //被线程执行的回调函数，也称为线程函数 LPVOID lpParameter, //传入线程函数的参数，不需传递参数时为NULL DWORD dwCreationFlags, //控制线程创建的标志 LPDWORD lpThreadId //传出参数，用于获得线程ID，如果为NULL则不返回线程ID); 说明：lpThreadAttributes：指向SECURITY_ATTRIBUTES结构的指针，决定返回的句柄是否可被子进程继承，如果为NULL则表示返回的句柄不能被子进程继承。dwStackSize ：线程栈的初始化大小，字节单位。系统分配这个值对lpStartAddress：指向一个函数指针，该函数将被线程调用执行。因此该函数也被称为线程函数(ThreadProc)，是线程执行的起始地址，线程函数是一个回调函数，由操作系统在线程中调用。 线程函数的原型如下：DWORD WINAPI ThreadProc(LPVOID lpParameter); //lpParameter是传入的参数，是一个空指针lpParameter：传入线程函数(ThreadProc)的参数，不需传递参数时为NULLdwCreationFlags：控制线程创建的标志，有三个类型，0：线程创建后立即执行线程；CREATE_SUSPENDED：线程创建后进入就绪状态，直到线程被唤醒时才调用；STACK_SIZE_PARAM_IS_A_RESERVATION：dwStackSize 参数指定线程初始化栈的大小，如果STACK_SIZE_PARAM_IS_A_RESERVATION标志未指定，dwStackSize将会设为系统预留的值。返回值：如果线程创建成功，则返回这个新线程的句柄，否则返回NULL。如果线程创建失败，可通过GetLastError函数获得错误信息。BOOL WINAPI CloseHandle(HANDLE hObject); //关闭一个被打开的对象句柄可用这个函数关闭创建的线程句柄，如果函数执行成功则返回true(非0),如果失败则返回false(0)，如果执行失败可调用GetLastError.函数获得错误信息。 创建一个简单的线程:1234567891011121314151617181920212223242526272829#include \"stdafx.h\"#include &lt;windows.h&gt;#include &lt;iostream&gt;using namespace std;//线程函数DWORD WINAPI ThreadProc(LPVOID lpParameter)&#123; for (int i = 0; i &lt; 5; ++ i) &#123; cout &lt;&lt; \"子线程:i = \" &lt;&lt; i &lt;&lt; endl; Sleep(100); &#125; return 0L;&#125;int main()&#123; //创建一个线程 HANDLE thread = CreateThread(NULL, 0, ThreadProc, NULL, 0, NULL); //关闭线程 CloseHandle(thread); //主线程的执行路径 for (int i = 0; i &lt; 5; ++ i) &#123; cout &lt;&lt; \"主线程:i = \" &lt;&lt; i &lt;&lt; endl; Sleep(100); &#125; return 0;&#125; 在线程函数中传入参数12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include \"stdafx.h\"#include &lt;windows.h&gt;#include &lt;iostream&gt;using namespace std;#define NAME_LINE 40//定义线程函数传入参数的结构体typedef struct __THREAD_DATA&#123; int nMaxNum; char strThreadName[NAME_LINE]; __THREAD_DATA() : nMaxNum(0) &#123; memset(strThreadName, 0, NAME_LINE * sizeof(char)); &#125;&#125;THREAD_DATA;//线程函数DWORD WINAPI ThreadProc(LPVOID lpParameter)&#123; THREAD_DATA* pThreadData = (THREAD_DATA*)lpParameter; for (int i = 0; i &lt; pThreadData-&gt;nMaxNum; ++ i) &#123; cout &lt;&lt; pThreadData-&gt;strThreadName &lt;&lt; \" --- \" &lt;&lt; i &lt;&lt; endl; Sleep(100); &#125; return 0L;&#125;int main()&#123; //初始化线程数据 THREAD_DATA threadData1, threadData2; threadData1.nMaxNum = 5; strcpy(threadData1.strThreadName, \"线程1\"); threadData2.nMaxNum = 10; strcpy(threadData2.strThreadName, \"线程2\"); //创建第一个子线程 HANDLE hThread1 = CreateThread(NULL, 0, ThreadProc, &amp;threadData1, 0, NULL); //创建第二个子线程 HANDLE hThread2 = CreateThread(NULL, 0, ThreadProc, &amp;threadData2, 0, NULL); //关闭线程 CloseHandle(hThread1); CloseHandle(hThread2); //主线程的执行路径 for (int i = 0; i &lt; 5; ++ i) &#123; cout &lt;&lt; \"主线程 === \" &lt;&lt; i &lt;&lt; endl; Sleep(100); &#125; system(\"pause\"); return 0;&#125; 线程同步 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#include \"stdafx.h\"#include &lt;windows.h&gt;#include &lt;iostream&gt;#define NAME_LINE 40//定义线程函数传入参数的结构体typedef struct __THREAD_DATA&#123; int nMaxNum; char strThreadName[NAME_LINE]; __THREAD_DATA() : nMaxNum(0) &#123; memset(strThreadName, 0, NAME_LINE * sizeof(char)); &#125;&#125;THREAD_DATA;HANDLE g_hMutex = NULL; //互斥量//线程函数DWORD WINAPI ThreadProc(LPVOID lpParameter)&#123; THREAD_DATA* pThreadData = (THREAD_DATA*)lpParameter; for (int i = 0; i &lt; pThreadData-&gt;nMaxNum; ++ i) &#123; //请求获得一个互斥量锁 WaitForSingleObject(g_hMutex, INFINITE); cout &lt;&lt; pThreadData-&gt;strThreadName &lt;&lt; \" --- \" &lt;&lt; i &lt;&lt; endl; Sleep(100); //释放互斥量锁 ReleaseMutex(g_hMutex); &#125; return 0L;&#125;int main()&#123; //创建一个互斥量 g_hMutex = CreateMutex(NULL, FALSE, NULL); //初始化线程数据 THREAD_DATA threadData1, threadData2; threadData1.nMaxNum = 5; strcpy(threadData1.strThreadName, \"线程1\"); threadData2.nMaxNum = 10; strcpy(threadData2.strThreadName, \"线程2\"); //创建第一个子线程 HANDLE hThread1 = CreateThread(NULL, 0, ThreadProc, &amp;threadData1, 0, NULL); //创建第二个子线程 HANDLE hThread2 = CreateThread(NULL, 0, ThreadProc, &amp;threadData2, 0, NULL); //关闭线程 CloseHandle(hThread1); CloseHandle(hThread2); //主线程的执行路径 for (int i = 0; i &lt; 5; ++ i) &#123; //请求获得一个互斥量锁 WaitForSingleObject(g_hMutex, INFINITE); cout &lt;&lt; \"主线程 === \" &lt;&lt; i &lt;&lt; endl; Sleep(100); //释放互斥量锁 ReleaseMutex(g_hMutex); &#125; system(\"pause\"); return 0;&#125; 模拟火车售票系统SaleTickets.h : 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include \"stdafx.h\"#include &lt;windows.h&gt;#include &lt;iostream&gt;#include &lt;strstream&gt; #include &lt;string&gt;using namespace std;#define NAME_LINE 40//定义线程函数传入参数的结构体typedef struct __TICKET&#123; int nCount; char strTicketName[NAME_LINE]; __TICKET() : nCount(0) &#123; memset(strTicketName, 0, NAME_LINE * sizeof(char)); &#125;&#125;TICKET;typedef struct __THD_DATA&#123; TICKET* pTicket; char strThreadName[NAME_LINE]; __THD_DATA() : pTicket(NULL) &#123; memset(strThreadName, 0, NAME_LINE * sizeof(char)); &#125;&#125;THD_DATA; //基本类型数据转换成字符串template&lt;class T&gt;string convertToString(const T val)&#123; string s; std::strstream ss; ss &lt;&lt; val; ss &gt;&gt; s; return s;&#125;//售票程序DWORD WINAPI SaleTicket(LPVOID lpParameter); SaleTickets.cpp ： 1234567891011121314151617181920212223242526272829303132333435#include \"stdafx.h\"#include &lt;windows.h&gt;#include &lt;iostream&gt;#include \"SaleTickets.h\"using namespace std;extern HANDLE g_hMutex;//售票程序DWORD WINAPI SaleTicket(LPVOID lpParameter)&#123; THD_DATA* pThreadData = (THD_DATA*)lpParameter; TICKET* pSaleData = pThreadData-&gt;pTicket; while(pSaleData-&gt;nCount &gt; 0) &#123; //请求获得一个互斥量锁 WaitForSingleObject(g_hMutex, INFINITE); if (pSaleData-&gt;nCount &gt; 0) &#123; cout &lt;&lt; pThreadData-&gt;strThreadName &lt;&lt; \"出售第\" &lt;&lt; pSaleData-&gt;nCount -- &lt;&lt; \"的票,\"; if (pSaleData-&gt;nCount &gt;= 0) &#123; cout &lt;&lt; \"出票成功!剩余\" &lt;&lt; pSaleData-&gt;nCount &lt;&lt; \"张票.\" &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; \"出票失败！该票已售完。\" &lt;&lt; endl; &#125; &#125; Sleep(10); //释放互斥量锁 ReleaseMutex(g_hMutex); &#125; return 0L;&#125; 测试程序： 1234567891011121314151617181920212223242526272829303132333435363738//售票系统void Test2()&#123; //创建一个互斥量 g_hMutex = CreateMutex(NULL, FALSE, NULL); //初始化火车票 TICKET ticket; ticket.nCount = 100; strcpy(ticket.strTicketName, \"北京--&gt;赣州\"); const int THREAD_NUMM = 8; THD_DATA threadSale[THREAD_NUMM]; HANDLE hThread[THREAD_NUMM]; for(int i = 0; i &lt; THREAD_NUMM; ++ i) &#123; threadSale[i].pTicket = &amp;ticket; string strThreadName = convertToString(i); strThreadName = \"窗口\" + strThreadName; strcpy(threadSale[i].strThreadName, strThreadName.c_str()); //创建线程 hThread[i] = CreateThread(NULL, NULL, SaleTicket, &amp;threadSale[i], 0, NULL); //请求获得一个互斥量锁 WaitForSingleObject(g_hMutex, INFINITE); cout &lt;&lt; threadSale[i].strThreadName &lt;&lt; \"开始出售 \" &lt;&lt; threadSale[i].pTicket-&gt;strTicketName &lt;&lt; \" 的票...\" &lt;&lt; endl; //释放互斥量锁 ReleaseMutex(g_hMutex); //关闭线程 CloseHandle(hThread[i]); &#125; system(\"pause\");&#125; 进程的创建进程间同步方式 Mutex（互斥）可以跨进城使用 Semphore（信号量）可以跨进城使用等 进程间的通信方式进程间通信又称IPC(Inter-Process Communication),指多个进程之间相互通信，交换信息的方法。进程间通讯(IPC)方法主要有以下几种: 管道/FIFO/共享内存/消息队列/信号根据进程通信时信息量大小的不同,可以将进程通信划分为两大类型:1、低级通信,控制信息的通信(主要用于进程之间的同步,互斥,终止和挂起等等控制信息的传递)2、高级通信,大批数据信息的通信(主要用于进程间数据块数据的交换和共享,常见的高级通信有管道,消息队列,共享内存等). 1.管道有命名管道和非命名管道(即匿名管道)之分，非命名管道(即匿名管道)只能用于父子进程通讯，命名管道可用于非父子进程，命名管道就是FIFO，管道是先进先出的通讯方式.管道( pipe )：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。命名管道 (named pipe) ： 命名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。 2.消息队列是用于两个进程之间的通讯，首先在一个进程中创建一个消息队列，然后再往消息队列中写数据，而另一个进程则从那个消息队列中取数据。需要注意的是，消息队列是用创建文件的方式建立的，如果一个进程向某个消息队列中写入了数据之后，另一个进程并没有取出数据，即使向消息队列中写数据的进程已经结束，保存在消息队列中的数据并没有消失，也就是说下次再从这个消息队列读数据的时候，就是上次的数据！!消息队列( message queue ) ： 消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。 3.信号量，它与WINDOWS下的信号量是一样的.信号量( semophore ) ： 信号量是一个计数器，可以用来控制多个进程对共享资源的访问。不是用于交换大批数据,而用于多线程之间的同步.常作为一种锁机制,防止某进程在访问资源时其它进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。 4.共享内存，类似于WINDOWS下的DLL中的共享变量，但LINUX下的共享内存区不需要像DLL这样的东西，只要首先创建一个共享内存区，其它进程按照一定的步骤就能访问到这个共享内存区中的数据，当然可读可写.共享内存( shared memory )：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。信号 ( signal ) ： 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。 套接字( socket ) ：套接字也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同机器间的进程通信 参考 编程思想之多线程与多进程 知乎","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"C/C++","slug":"C-C","permalink":"http://arvin-he.github.io/tags/C-C/"}]},{"title":"OOP基本特征和基本原则","slug":"cpp-oop-2017-04-24","date":"2017-04-24T08:00:15.000Z","updated":"2017-09-08T03:51:39.319Z","comments":true,"path":"2017/04/24/cpp-oop-2017-04-24/","link":"","permalink":"http://arvin-he.github.io/2017/04/24/cpp-oop-2017-04-24/","excerpt":"","text":"面向对象三个基本特征面向对象的三个基本特征是：封装、继承、多态 封装 封装是面向对象的特征之一，是对象和类概念的主要特性。封装，也就是把客观事物封装成抽象的类，并且类可以把自己的数据和方法只让可信的类或者对象操作，对不可信的进行信息隐藏。 继承 继承是指这样一种能力：它可以使用现有类的所有功能，并在无需重新编写原来的类的情况下对这些功能进行扩展。通过继承创建的新类称为“子类”或“派生类”，被继承的类称为“基类”、“父类”或“超类”。 要实现继承，可以通过“继承”（Inheritance）和“组合”（Composition）来实现。 多态性 多态性（polymorphisn）是允许将父对象设置成为和一个或更多的他的子对象相等的技术，赋值之后，父对象就可以根据当前赋值给它的子对象的特性以不同的方式运作。简单的说：允许将子类类型的指针赋值给父类类型的指针。 实现多态，有两种方式，覆盖和重载。覆盖和重载的区别在于，覆盖在运行时决定，即运行时多态,重载是在编译时决定,即编译时多态。并且覆盖和重载的机制不同，例如在 Java 中，重载方法的签名必须不同于原先方法的，但对于覆盖签名必须相同。 面向对象类关系类与类之间主要有6种关系模式，这六种模板写法导致了平时书写代码的不同耦合度。具体如下所列（耦合度依次增强排列）： 依赖关系一般而言，依赖关系在Java语言中体现为局域变量、方法的形参，或者对静态方法的调用。 关联关系使一个类知道另一个类的属性和方法。关联可以是双向的，也可以是单向的。在Java语言中，关联关系一般使用成员变量来实现。 聚合关系聚合是关联关系的一种，是强的关联关系，聚合是整体和个体之间的关系。与关联关系一样，聚合关系也是通过实例变量实现的，但是关联关系所涉及的两个类是处在同一层次上的，而在聚合关系中，两个类是处在不平等层次上的，一个代表整体，另一个代表部分。 组合关系组合是关联关系的一种，是比聚合关系强的关系。它要求普通的聚合关系中代表整体的对象负责代表部分对象的生命周期，组合关系是不能共享的。代表整体的对象需要负责保持部分对象和存活，在一些情况下将负责代表部分的对象湮灭掉。代表整体的对象可以将代表部分的对象传递给另一个对象，由后者负责此对象的生命周期。换言之，代表部分的对象在每一个时刻只能与一个对象发生组合关系，由后者排他地负责生命周期。部分和整体的生命周期一样。 继承关系继承表示类与类（或者接口与接口）之间的父子关系。 实现关系接口定义好操作的集合，由实现类去完成接口的具体操作。 面向对象的基本原则1. 单一职责原则单一职责原则的英文名称是 Single Responsibility Principle，简称是 SPR，简单地说就是一个类只做一件事，这个设计原则备受争议却又极其重要。很多时候都是需要个人经验来界定。当然，最大的问题就是对职责的定义，什么是类的职责，以及怎么划分类的职责。 单一职责原则是实现高内聚、低耦合的指导方针，它是最简单但又最难运用的原则。每一个职责都是变化的一个轴线，如果一个类有一个以上的职责，这些职责就耦合在了一起。这会导致脆弱的设计。当一个职责发生变化时，可能会影响其它的职责。另外，多个职责耦合在一起，会影响复用性。 单一职责所表达出的用意就是“单一”二字.如何划分一个类、一个函数的职责，每个人都有自己的看法，这需要根据个人经验、具体的业务逻辑而定。但是，它也有一些基本的指导原则，例如，两个完全不一样的功能就不应该放在一个类中。一个类中应该是一组相关性很高的函数、数据的封装。工程师可以不断地审视自己的代码，根据具体的业务、功能对类进行相应的拆分，我想这会是你优化代码迈出的第一步。 2. 开闭原则开闭原则的英文全称是Open Close Principle，简称OCP.一个软件实体应当对扩展开放，对修改关闭。即软件实体应尽量在不修改原有代码的情况下进行扩展。当软件需要变化时，我们应该尽量通过扩展的方式来实现变化，而不是通过修改已有的代码来实现。 为了满足开闭原则，需要对系统进行抽象化设计，抽象化是开闭原则的关键。在Java、C#等编程语言中，可以为系统定义一个相对稳定的抽象层，而将不同的实现行为移至具体的实现层中完成。在很多面向对象编程语言中都提供了接口、抽象类等机制，可以通过它们定义系统的抽象层，再通过具体类来进行扩展。如果需要修改系统的行为，无须对抽象层进行任何改动，只需要增加新的具体类来实现新的业务功能即可，实现在不修改已有代码的基础上扩展系统的功能，达到开闭原则的要求。 开闭原则指导我们，当软件需要变化时，应该尽量通过扩展的方式来实现变化，而不是通过修改已有的代码来实现。这里的“应该尽量”4个字说明OCP原则并不是说绝对不可以修改原始类的，当我们嗅到原来的代码“腐化气味”时，应该尽早地重构，以使得代码恢复到正常的“进化”轨道，而不是通过继承等方式添加新的实现，这会导致类型的膨胀以及历史遗留代码的冗余。我们的开发过程中也没有那么理想化的状况，完全地不用修改原来的代码，因此，在开发过程中需要自己结合具体情况进行考量，是通过修改旧代码还是通过继承使得软件系统更稳定、更灵活，在保证去除“代码腐化”的同时，也保证原有模块的正确性。 3. 里氏代换原则里氏替换原则英文全称是Liskov Substitution Principle，简称LSP.面向对象的语言的三大特点是继承、封装、多态，里氏替换原则就是依赖于继承、多态这两大特性。里氏替换原则简单来说就是所有引用基类、接口的地方必须能透明地使用其子类的对象。通俗点讲，只要父类能出现的地方子类就可以出现，而且替换为子类也不会产生任何报错或者异常，使用者可能根本就不需要知道是子类还是父类。但是，反过来就不行了，有子类出现的地方，父类未必就能使用。 在使用里氏代换原则时需要注意如下几个问题： 子类的所有方法必须在父类中声明，或子类必须实现父类中声明的所有方法。根据里氏代换原则，为了保证系统的扩展性，在程序中通常使用父类来进行定义，如果一个方法只存在子类中，在父类中不提供相应的声明，则无法在以父类定义的对象中使用该方法。 我们在运用里氏代换原则时，尽量把父类设计为抽象类或者接口，让子类继承父类或实现父接口，并实现在父类中声明的方法，运行时，子类实例替换父类实例，我们可以很方便地扩展系统的功能，同时无须修改原有子类的代码，增加新的功能可以通过增加一个新的子类来实现。里氏代换原则是开闭原则的具体实现手段之一。 Java语言中，在编译阶段，Java编译器会检查一个程序是否符合里氏代换原则，这是一个与实现无关的、纯语法意义上的检查，但Java编译器的检查是有局限的。 里氏替换原则的核心原理是抽象，抽象又依赖于继承这个特性，在OOP当中，继承的优缺点都相当明显。 继承的优点如下：（1）代码重用，减少创建类的成本，每个子类都拥有父类的方法和属性；（2）子类与父类基本相似，但又与父类有所区别；（3）提高代码的可扩展性。 继承的缺点如下：（1）继承是侵入性的，只要继承就必须拥有父类的所有属性和方法；（2）可能造成子类代码冗余、灵活性降低，因为子类必须拥有父类的属性和方法。 4. 接口隔离原则接口隔离原则英文全称是InterfaceSegregation Principles，简称ISP.使用多个专门的接口，而不使用单一的总接口，即客户端不应该依赖那些它不需要的接口。另一种定义是：类间的依赖关系应该建立在最小的接口上。接口隔离原则将非常庞大、臃肿的接口拆分成为更小的和更具体的接口，这样客户将会只需要知道他们感兴趣的方法。接口隔离原则的目的是系统解开耦合，从而容易重构、更改和重新部署。 这里的“接口”往往有两种不同的含义：一种是指一个类型所具有的方法特征的集合，仅仅是一种逻辑上的抽象；另外一种是指某种语言具体的“接口”定义，有严格的定义和结构，比如Java语言中的interface。对于这两种不同的含义，ISP的表达方式以及含义都有所不同： 当把“接口”理解成一个类型所提供的所有方法特征的集合的时候，这就是一种逻辑上的概念，接口的划分将直接带来类型的划分。可以把接口理解成角色，一个接口只能代表一个角色，每个角色都有它特定的一个接口，此时，这个原则可以叫做“角色隔离原则”。 如果把“接口”理解成狭义的特定语言的接口，那么ISP表达的意思是指接口仅仅提供客户端需要的行为，客户端不需要的行为则隐藏起来，应当为客户端提供尽可能小的单独的接口，而不要提供大的总接口。在面向对象编程语言中，实现一个接口就需要实现该接口中定义的所有方法，因此大的总接口使用起来不一定很方便，为了使接口的职责单一，需要将大接口中的方法根据其职责不同分别放在不同的小接口中，以确保每个接口使用起来都较为方便，并都承担某一单一角色。接口应该尽量细化，同时接口中的方法应该尽量少，每个接口中只包含一个客户端（如子模块或业务逻辑类）所需的方法即可，这种机制也称为“定制服务”，即为不同的客户端提供宽窄不同的接口。 5. 迪米特法则迪米特原则英文全称为Law of Demeter，简称LOD，也称为最少知识原则（Least Knowledge Principle）.一个软件实体应当尽可能少地与其他实体发生相互作用.通俗地讲，一个类应该对自己需要耦合或调用的类知道得最少，类的内部如何实现、如何复杂都与调用者或者依赖者没关系，调用者或者依赖者只需要知道他需要的方法即可，其他的我一概不关心。类与类之间的关系越密切，耦合度越大，当一个类发生改变时，对另一个类的影响也越大。 迪米特原则还有一个英文解释是：Only talk to your immedate friends（只与直接的朋友通信）。什么叫做直接的朋友呢？每个对象都必然会与其他对象有耦合关系，两个对象之间的耦合就成为朋友关系，这种关系的类型有很多例如组合、聚合、依赖等。 如果一个系统符合迪米特法则，那么当其中某一个模块发生修改时，就会尽量少地影响其他模块，扩展会相对容易，这是对软件实体之间通信的限制，迪米特法则要求限制软件实体之间通信的宽度和深度。迪米特法则可降低系统的耦合度，使类与类之间保持松散的耦合关系。迪米特法则还有几种定义形式，包括：不要和“陌生人”说话、只与你的直接朋友通信等，在迪米特法则中，对于一个对象，其朋友包括以下几类：(1) 当前对象本身(this)；(2) 以参数形式传入到当前对象方法中的对象；(3) 当前对象的成员对象；(4) 如果当前对象的成员对象是一个集合，那么集合中的元素也都是朋友；(5) 当前对象所创建的对象。任何一个对象，如果满足上面的条件之一，就是当前对象的“朋友”，否则就是“陌生人”。在应用迪米特法则时，一个对象只能与直接朋友发生交互，不要与“陌生人”发生直接交互，这样做可以降低系统的耦合度，一个对象的改变不会给太多其他对象带来影响。 迪米特法则要求我们在设计系统时，应该尽量减少对象之间的交互，如果两个对象之间不必彼此直接通信，那么这两个对象就不应当发生任何直接的相互作用，如果其中的一个对象需要调用另一个对象的某一个方法的话，可以通过第三者转发这个调用。简言之，就是通过引入一个合理的第三者来降低现有对象之间的耦合度。 在将迪米特法则运用到系统设计中时，要注意下面的几点：在类的划分上，应当尽量创建松耦合的类，类之间的耦合度越低，就越有利于复用，一个处在松耦合中的类一旦被修改，不会对关联的类造成太大波及；在类的结构设计上，每一个类都应当尽量降低其成员变量和成员函数的访问权限；在类的设计上，只要有可能，一个类型应当设计成不变类；在对其他类的引用上，一个对象对其他对象的引用应当降到最低。 依赖倒置原则具体依赖抽象，上层依赖下层。假设B是较A低的模块，但B需要使用到A的功能，这个时候，B不应当直接使用A中的具体类；而应当由B定义一抽象接口，并由A来实现这个抽象接口，B只使用这个抽象接口；这样就达到了依赖倒置的目的，B也解除了对A的依赖，反过来是A依赖于B定义的抽象接口。通过上层模块难以避免依赖下层模块，假如B也直接依赖A的实现，那么就可能造成循环依赖。 赖倒置原则的几个关键点如下。 高层模块不应该依赖底层模块，两者都应该依赖其抽象。 抽象不应该依赖细节。 细节应该依赖抽象。 采用依赖倒置原则可以减少类之间的耦合性，提高系统的稳定性，降低并行开发引起的风险，提高代码的可读性和可维护性。 7. 合成复用原则尽量使用对象组合，而不是继承来达到复用的目的。 合成复用原则就是在一个新的对象里通过关联关系（包括组合关系和聚合关系）来使用一些已有的对象，使之成为新对象的一部分；新对象通过委派调用已有对象的方法达到复用功能的目的。简言之：复用时要尽量使用组合/聚合关系（关联关系），少用继承。 在面向对象设计中，可以通过两种方法在不同的环境中复用已有的设计和实现，即通过组合/聚合关系或通过继承，但首先应该考虑使用组合/聚合，组合/聚合可以使系统更加灵活，降低类与类之间的耦合度，一个类的变化对其他类造成的影响相对较少；其次才考虑继承，在使用继承时，需要严格遵循里氏代换原则，有效使用继承会有助于对问题的理解，降低复杂度，而滥用继承反而会增加系统构建和维护的难度以及系统的复杂度，因此需要慎重使用继承复用。 通过继承来进行复用的主要问题在于继承复用会破坏系统的封装性，因为继承会将基类的实现细节暴露给子类，由于基类的内部细节通常对子类来说是可见的，所以这种复用又称“白箱”复用，如果基类发生改变，那么子类的实现也不得不发生改变；从基类继承而来的实现是静态的，不可能在运行时发生改变，没有足够的灵活性；而且继承只能在有限的环境中使用（如类没有声明为不能被继承） 由于组合或聚合关系可以将已有的对象（也可称为成员对象）纳入到新对象中，使之成为新对象的一部分，因此新对象可以调用已有对象的功能，这样做可以使得成员对象的内部实现细节对于新对象不可见，所以这种复用又称为“黑箱”复用，相对继承关系而言，其耦合度相对较低，成员对象的变化对新对象的影响不大，可以在新对象中根据实际需要有选择性地调用成员对象的操作；合成复用可以在运行时动态进行，新对象可以动态地引用与成员对象类型相同的其他对象。 一般而言，如果两个类之间是“Has-A”的关系应使用组合或聚合，如果是“Is-A”关系可使用继承。”Is-A”是严格的分类学意义上的定义，意思是一个类是另一个类的”一种”；而”Has-A”则不同，它表示某一个角色具有某一项责任。 写在最后的话设计模式的四大要素中就明确指出，模式的运用应该根据软件系统所面临的问题来决定是否需要使用现有的设计。也就是说，再出现问题或者你预计会出现那样的问题时，才推荐使用特定的设计模式，而不是将各种设计模式套进你的软件中。 不管在设计、实现、测试之间有多少时间都应该避免过度设计，它会打破你的反馈回路，使你的设计得不到反馈，从而慢慢陷入危险中。所以你只需要保持简单的设计，这样就有时间来测试该设计是否真的可行，然后作出最后的决策。 参考 面向对象设计的基本原则 面向对象六大原则和设计模式 设计模式之面向对象七大基本原则 设计模式之面向对象与类基础特征概念","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"OOP","slug":"OOP","permalink":"http://arvin-he.github.io/tags/OOP/"}]},{"title":"Http读书笔记第六章","slug":"http-note6-2017-04-23","date":"2017-04-23T12:31:18.000Z","updated":"2017-09-08T03:51:39.628Z","comments":true,"path":"2017/04/23/http-note6-2017-04-23/","link":"","permalink":"http://arvin-he.github.io/2017/04/23/http-note6-2017-04-23/","excerpt":"","text":"http首部http首部内容为客户端和服务器分别处理请求和响应提供所需要的信息 HTTP 请求报文在请求中，HTTP 报文由方法、URI、HTTP 版本、HTTP 首部字段等部分构成。 HTTP 响应报文在响应中，HTTP 报文由 HTTP 版本、状态码（数字和原因短语）、HTTP 首部字段 3 部分构成. HTTP 首部字段HTTP 首部字段是由首部字段名和字段值构成的，中间用冒号“:” 分隔。 HTTP 首部字段根据实际用途被分为以下 4 种类型。通用首部字段（General Header Fields）请求报文和响应报文两方都会使用的首部。 请求首部字段（Request Header Fields）从客户端向服务器端发送请求报文时使用的首部。补充了请求的附加内容、客户端信息、响应内容相关优先级等信息。 响应首部字段（Response Header Fields）从服务器端向客户端返回响应报文时使用的首部。补充了响应的附加内容，也会要求客户端附加额外的内容信息。 实体首部字段（Entity Header Fields）针对请求报文和响应报文的实体部分使用的首部。补充了资源内容更新时间等与实体有关的信息。 HTTP/1.1 首部字段一览通用首部字段首部字段名 说明Cache-Control 控制缓存的行为指令的参数是可选的，多个指令之间通过“,”分隔 Connection 逐跳首部、连接的管理Date 创建报文的日期时间Pragma 报文指令Trailer 报文末端的首部一览Transfer-Encoding 指定报文主体的传输编码方式Upgrade 升级为其他协议Via 代理服务器的相关信息Warning 错误通知 请求首部字段首部字段名 说明Accept 用户代理可处理的媒体类型Accept-Charset 优先的字符集Accept-Encoding 优先的内容编码Accept-Language 优先的语言（自然语言）Authorization Web认证信息Expect 期待服务器的特定行为From 用户的电子邮箱地址Host 请求资源所在服务器If-Match 比较实体标记（ETag）If-Modified-Since 比较资源的更新时间If-None-Match 比较实体标记（与 If-Match 相反）If-Range 资源未更新时发送实体 Byte 的范围请求If-Unmodified-Since 比较资源的更新时间（与If-Modified-Since相反）Max-Forwards 最大传输逐跳数Proxy-Authorization 代理服务器要求客户端的认证信息Range 实体的字节范围请求Referer 对请求中 URI 的原始获取方TE 传输编码的优先级User-Agent HTTP 客户端程序的信息 响应首部字段首部字段名 说明Accept-Ranges 是否接受字节范围请求Age 推算资源创建经过时间ETag 资源的匹配信息Location 令客户端重定向至指定URIProxy-Authenticate 代理服务器对客户端的认证信息Retry-After 对再次发起请求的时机要求Server HTTP服务器的安装信息Vary 代理服务器缓存的管理信息WWW-Authenticate 服务器对客户端的认证信息 实体首部字段首部字段名 说明Allow 资源可支持的HTTP方法Content-Encoding 实体主体适用的编码方式Content-Language 实体主体的自然语言Content-Length 实体主体的大小（单位：字节）Content-Location 替代对应资源的URIContent-MD5 实体主体的报文摘要Content-Range 实体主体的位置范围Content-Type 实体主体的媒体类型Expires 实体主体过期的日期时间Last-Modified 资源的最后修改日期时间 End-to-end 首部和 Hop-by-hop 首部HTTP 首部字段将定义成缓存代理和非缓存代理的行为，分成 2 种类型。端到端首部（End-to-end Header）分在此类别中的首部会转发给请求 / 响应对应的最终接收目标，且必须保存在由缓存生成的响应中，另外规定它必须被转发。 逐跳首部（Hop-by-hop Header）分在此类别中的首部只对单次转发有效，会因通过缓存或代理而不再转发。HTTP/1.1 和之后版本中，如果要使用 hop-by-hop 首部，需提供 Connection 首部字段。 其他所有字段都属于端到端首部。ConnectionKeep-AliveProxy-AuthenticateProxy-AuthorizationTrailerTETransfer-EncodingUpgrade","categories":[{"name":"Web","slug":"Web","permalink":"http://arvin-he.github.io/categories/Web/"}],"tags":[{"name":"http","slug":"http","permalink":"http://arvin-he.github.io/tags/http/"}]},{"title":"Python之subprocess模块","slug":"python-subprocess-2017-04-22","date":"2017-04-22T02:44:12.000Z","updated":"2017-09-08T03:51:40.159Z","comments":true,"path":"2017/04/22/python-subprocess-2017-04-22/","link":"","permalink":"http://arvin-he.github.io/2017/04/22/python-subprocess-2017-04-22/","excerpt":"","text":"subprocess模块subprocess模块,即子进程模块,允许您生成新进程，并连接到输入/输出/错误管道，并获取其返回代码。subprocess包主要功能是执行外部的命令和程序。 subprocess模块使用subprocess包中定义有数个创建子进程的函数，这些函数分别以不同的方式创建子进程，可以根据需要来从中选取一个使用。另外subprocess还提供了一些管理标准流(standard stream)和管道(pipe)的工具，从而在进程间使用文本通信。 使用subprocess包中的函数创建子进程的时候，要注意: 在创建子进程之后，父进程是否暂停，并等待子进程运行 函数返回什么 当returncode不为0时，父进程如何处理 subprocess.call()父进程等待子进程完成返回退出信息(returncode，相当于exit code，见Linux进程基础) subprocess.check_call()父进程等待子进程完成返回0检查退出信息，如果returncode不为0，则举出错误subprocess.CalledProcessError，该对象包含有returncode属性，可用try…except…来检查(见Python错误处理)。 subprocess.check_output()父进程等待子进程完成返回子进程向标准输出的输出结果检查退出信息，如果returncode不为0，则举出错误subprocess.CalledProcessError，该对象包含有returncode属性和output属性，output属性为标准输出的输出结果，可用try…except…来检查。 这三个函数的使用方法相类似，以subprocess.call()来说明:我们将程序名(ls)和所带的参数(-l)一起放在一个表中传递给subprocess.call()1234567import subprocessrc = subprocess.call([\"ls\",\"-l\"])subprocess.check_call( [\"svn\", \"export\", \"--force\", \"--revision\", revision, src, dst], stdout=subprocess.DEVNULL)output = subprocess.check_output( [\"svn\", \"log\", svn_path, \"-v\", \"--limit\", \"1\"]).decode(\"gbk\").strip() 也可以通过一个shell来解释一整个字符串:123import subprocessout = subprocess.call(\"ls -l\", shell=True)out = subprocess.call(\"cd ..\", shell=True) 上面使用了shell=True这个参数。这个时候，我们使用一整个字符串，而不是一个列表来运行子进程。Python将先运行一个shell，再用这个shell来解释这整个字符串。 关于Popen()实际上，上面的三个函数都是基于Popen()的封装(wrapper)。这些封装的目的在于让我们容易使用子进程。当我们想要更个性化的需求的时候，就要转向Popen类，该类生成的对象用来代表子进程。与上面的封装不同，Popen对象创建后，主程序不会自动等待子进程完成。我们必须调用对象的wait()方法，父进程才会等待 (也就是阻塞block)：123import subprocesschild = subprocess.Popen([\"ping\",\"-c\",\"5\",\"www.google.com\"])print(\"parent process\") 从运行结果中看到，父进程在开启子进程之后并没有等待child的完成，而是直接运行print。对比等待的情况:1234import subprocesschild = subprocess.Popen([\"ping\",\"-c\",\"5\",\"www.google.com\"])child.wait()print(\"parent process\") 此外，你还可以在父进程中对子进程进行其它操作，比如我们上面例子中的child对象:1234child.poll() # 检查子进程状态child.kill() # 终止子进程child.send_signal() # 向子进程发送信号child.terminate() # 终止子进程 子进程的PID存储在child.pid 子进程的文本流控制沿用child子进程) 子进程的标准输入，标准输出和标准错误也可以通过如下属性表示: child.stdin child.stdout child.stderr 我们可以在Popen()建立子进程的时候改变标准输入、标准输出和标准错误，并可以利用subprocess.PIPE将多个子进程的输入和输出连接在一起，构成管道(pipe):12345import subprocesschild1 = subprocess.Popen([\"ls\",\"-l\"], stdout=subprocess.PIPE)child2 = subprocess.Popen([\"wc\"], stdin=child1.stdout,stdout=subprocess.PIPE)out = child2.communicate()print(out) subprocess.PIPE实际上为文本流提供一个缓存区。child1的stdout将文本输出到缓存区，随后child2的stdin从该PIPE中将文本读取走。child2的输出文本也被存放在PIPE中，直到communicate()方法从PIPE中读取出PIPE中的文本。要注意的是，communicate()是Popen对象的一个方法，该方法会阻塞父进程，直到子进程完成。 我们还可以利用communicate()方法来使用PIPE给子进程输入:123import subprocesschild = subprocess.Popen([\"cat\"], stdin=subprocess.PIPE)child.communicate(\"vamei\".encode()) 我们启动子进程之后，cat会等待输入，直到我们用communicate()输入”vamei”。 调用subprocess模块的推荐方法是:推荐使用run()函数来处理几乎所有用例或情景。对于更高级的用例，可以直接使用基础的Popen接口。1subprocess.run(args, *, stdin=None, input=None, stdout=None, stderr=None, shell=False, timeout=None, check=False, encoding=None, errors=None) 运行由args描述的命令。等待命令完成，然后返回一个CompletedProcess实例。完整的run函数签名与Popen构造函数大致相同(除了超时，输入和检查外)，该函数的所有参数都传递给该接口。默认情况下，这不捕获stdout或stderr。要做到这一点，通过PIPE的stdout和/或stderr参数。超时参数传递给Popen.communicate（）。如果超时过期，则子进程将被杀死并等待。在子进程终止后，将重新提出TimeoutExpired异常。输入的参数传递给Popen.communicate（），从而传递给子进程的stdin。如果使用，它必须是一个字节序列，如果指定了编码或错误，或者是universal_newlines为真，则为字符串。使用时，内部Popen对象将自动使用stdin = PIPE创建，并且stdin参数也可能不被使用。如果检查为真，并且进程以非零退出代码退出，则将引发CalledProcessError异常。该异常的属性保存参数，退出代码以及stdout和stderr（如果被捕获）。如果指定了编码或错误，或者universal_newlines为true，则使用指定的编码和错误或io.TextIOWrapper默认文件在文本模式下打开stdin，stdout和stderr的文件对象。否则，文件对象将以二进制模式打开。 args是所有调用所必需的，应该是一个字符串或一系列程序参数。通常优选提供参数序列，因为它允许模块处理任何所需的转义和引用参数（例如，允许文件名中的空格）。如果传递单个字符串，则shell必须为True（见下文），否则字符串必须简单地命名要执行的程序，而不指定任何参数。 Popen构造函数1class subprocess.Popen(args, bufsize=-1, executable=None, stdin=None, stdout=None, stderr=None, preexec_fn=None, close_fds=True, shell=False, cwd=None, env=None, universal_newlines=False, startupinfo=None, creationflags=0, restore_signals=True, start_new_session=False, pass_fds=(), *, encoding=None, errors=None) 在新进程中执行子程序。在POSIX上，该类使用os.execvp（）类似的行为来执行子程序。在Windows上，该类使用Windows CreateProcess（）函数.args应该是程序参数的序列，或者是一个单个的字符串。默认情况下，如果args是序列，则要执行的程序是args中的第一个项目。如果args是字符串，则解释是平台依赖的，并在下面描述。请参阅shell和可执行参数，以获得与默认行为的更多差异。除非另有说明，否则建议将args作为序列。 在Windows上，如果args是一个序列，它将以转换参数序列到Windows上的字符串中所述的方式转换为字符串。这是因为底层的CreateProcess（）对字符串运行.shell参数（默认为False）指定是否使用shell作为程序执行。如果shell为True，则建议将args作为字符串而不是序列传递。 Popen Objects(Popen对象)Popen类的实例有以下几种方法：Popen.poll():检查子进程是否终止。设置并返回returncode属性。Popen.wait(timeout=None):等待子进程终止。设置并返回returncode属性.如果进程在超时秒后没有终止，请引发超时突发异常。捕获这个异常是安全的，并重试等待。当使用stdout = PIPE或stderr = PIPE时，这将会死锁，并且子进程向管道生成足够的输出，从而阻止等待OS管道缓冲区接受更多数据。使用Popen.communicate（）使用管道避免这种情况。Popen.communicate(input=None, timeout=None):与进程交互：将数据发送到stdin。从stdout和stderr读取数据，直到文件到达。等待进程终止。可选的输入参数应该是要发送到子进程的数据，否则，如果没有数据发送给子进程，则为None。如果流以文本模式打开，则输入必须是字符串。否则，它必须是字节。communication（）返回一个元组（stdout_data，stderr_data）。如果流以文本模式打开，数据将为字符串;否则，字节。请注意，如果要将数据发送到进程的stdin，则需要使用stdin = PIPE创建Popen对象。类似地，要在结果元组中获得除None之外的任何内容，您还需要给出stdout = PIPE和/或stderr = PIPE.如果进程在超时秒后没有终止，则会引发一个TimeoutExpired异常。捕捉此异常并重试通信不会丢失任何输出。如果超时过期，子进程不会被终止，所以为了正确清理，运行良好的应用程序应该杀死子进程并完成通信：123456proc = subprocess.Popen(...)try: outs, errs = proc.communicate(timeout=15)except TimeoutExpired: proc.kill() outs, errs = proc.communicate() 读取的数据被缓冲在内存中，因此如果数据很大或无限制，则不要使用此方法。 Popen.terminate(): 旧的高级API在Python 3.5之前，这subprocess中函数中的check_output, check_call, call这三个函数包含了高级API到子进程。现在可以在很多情况下使用run（），但很多现有的代码调用这些函数。","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Python之一些杂记","slug":"python-reviewcode1-2017-04-22","date":"2017-04-22T01:45:05.000Z","updated":"2017-09-08T03:51:40.133Z","comments":true,"path":"2017/04/22/python-reviewcode1-2017-04-22/","link":"","permalink":"http://arvin-he.github.io/2017/04/22/python-reviewcode1-2017-04-22/","excerpt":"","text":"1. 取指定文件所在目录的父目录12方式1: os.path.dirname(os.path.dirname(__file__))方式2: os.path.dirname(os.path.dirname(os.path.abspath(__file__))) dirname是获取输入路径的目录.尽量用方式2,方式1有风险,当你将目录切到当前的脚本所在的目录时并运行该脚本,输出的目录是空.方式2就不会存在这种问题.看下面的例子12345678910111213print(&quot;file1 = &#123;&#125;&quot;.format(__file__))print(&quot;file2 = &#123;&#125;&quot;.format(os.path.abspath(__file__)))print(&quot;dir1 = &#123;&#125;&quot;.format(os.path.dirname(__file__)))print(&quot;dir2 = &#123;&#125;&quot;.format(os.path.dirname(os.path.dirname(__file__))))print(&quot;dir3 = &#123;&#125;&quot;.format(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))输出结果:F:\\2.2&gt;python _build/translate.pyfile1 = _build/translate.pyfile2 = F:\\2.2\\_build\\translate.pydir1 = _builddir2 =dir3 = F:\\2.2 2. pwd,$pwd与cwd都指某个进程运行时所在的目录.pwd 是linux 自带的命令.全称:pathname of the current working directory.$PWD 是个系统变量cwd: 不是系统自带的命令, 但是属于系统的属性.全称: current working directory . 不但在 /proc/{id} 这个目录下可以看到cwd, 在很多其他的编程语言中也可以看到( 例如grunt ).有时候 pwd 与 $PWD 给出的结果不同. 3. decode与encode","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Http读书笔记第五章","slug":"http-note5-2017-04-18","date":"2017-04-18T14:56:17.000Z","updated":"2017-09-08T03:51:39.625Z","comments":true,"path":"2017/04/18/http-note5-2017-04-18/","link":"","permalink":"http://arvin-he.github.io/2017/04/18/http-note5-2017-04-18/","excerpt":"","text":"与 HTTP 协作的 Web 服务器一台 Web 服务器可搭建多个独立域名的 Web 网站，也可作为通信路径上的中转服务器提升传输效率。 用单台虚拟主机实现多个域名HTTP/1.1 规范允许一台 HTTP 服务器搭建多个 Web 站点提供 Web 托管服务（Web Hosting Service）的供应商，可以用一台服务器为多位客户服务，也可以以每位客户持有的域名运行各自不同的网站。这是因为利用了虚拟主机（Virtual Host，又称虚拟服务器）的功能。即使物理层面只有一台服务器，但只要使用虚拟主机的功能，则可以假想已具有多台服务器。 如果一台服务器内托管了 www.tricorder.jp 和 www.hackr.jp 这两个域名，当收到请求时就需要弄清楚究竟要访问哪个域名。在相同的 IP 地址下，由于虚拟主机可以寄存多个不同主机名和域名的 Web 网站，因此在发送 HTTP 请求时，必须在 Host 首部内完整指定主机名或域名的 URI。 通信数据转发程序 ：代理、网关、隧道HTTP 通信时，除客户端和服务器以外，还有一些用于通信数据转发的应用程序，例如代理、网关和隧道。它们可以配合服务器工作.这些应用程序和服务器可以将请求转发给通信线路上的下一站服务器，并且能接收从那台服务器发送的响应再转发给客户端。 代理代理是一种有转发功能的应用程序，它扮演了位于服务器和客户端“中间人”的角色，接收由客户端发送的请求并转发给服务器，同时也接收服务器返回的响应并转发给客户端。代理服务器的基本行为就是接收客户端发送的请求后转发给其他服务器。代理不改变请求 URI，会直接发送给前方持有资源的目标服务器。持有资源实体的服务器被称为源服务器。从源服务器返回的响应经过代理服务器后再传给客户端。在 HTTP 通信过程中，可级联多台代理服务器。请求和响应的转发会经过数台类似锁链一样连接起来的代理服务器。转发时，需要附加Via 首部字段以标记出经过的主机信息。使用代理服务器的理由有：利用缓存技术减少网络带宽的流量，组织内部针对特定网站的访问控制，以获取访问日志为主要目的，等等。代理有多种使用方法，按两种基准分类。一种是是否使用缓存，另一种是是否会修改报文。 缓存代理代理转发响应时，缓存代理（Caching Proxy）会预先将资源的副本（缓存）保存在代理服务器上。当代理再次接收到对相同资源的请求时，就可以不从源服务器那里获取资源，而是将之前缓存的资源作为响应返回。 透明代理转发请求或响应时，不对报文做任何加工的代理类型被称为透明代理（Transparent Proxy）。反之，对报文内容进行加工的代理被称为非透明代理。 网关网关是转发其他服务器通信数据的服务器，接收从客户端发送来的请求时，它就像自己拥有资源的源服务器一样对请求进行处理。有时客户端可能都不会察觉，自己的通信目标是一个网关。网关的工作机制和代理十分相似。而网关能使通信线路上的服务器提供非 HTTP 协议服务。利用网关能提高通信的安全性，因为可以在客户端与网关之间的通信线路上加密以确保连接的安全。比如，网关可以连接数据库，使用SQL 语句查询数据。另外，在 Web 购物网站上进行信用卡结算时，网关可以和信用卡结算系统联动。 隧道隧道是在相隔甚远的客户端和服务器两者之间进行中转，并保持双方通信连接的应用程序。隧道可按要求建立起一条与其他服务器的通信线路，届时使用 SSL 等加密手段进行通信。隧道的目的是确保客户端能与服务器进行安全的通信。隧道本身不会去解析 HTTP 请求。也就是说，请求保持原样中转给之后的服务器。隧道会在通信双方断开连接时结束。隧道本身是透明的，客户端不用在意隧道的存在. 保存资源的缓存缓存是指代理服务器或客户端本地磁盘内保存的资源副本。利用缓存可减少对源服务器的访问，因此也就节省了通信流量和通信时间。缓存服务器是代理服务器的一种，并归类在缓存代理类型中。换句话说，当代理转发从服务器返回的响应时，代理服务器将会保存一份资源的副本。缓存服务器的优势在于利用缓存可避免多次从源服务器转发资源。因此客户端可就近从缓存服务器上获取资源，而源服务器也不必多次处理相同的请求了。 缓存的有效期限当遇上源服务器上的资源更新时，如果还是使用不变的缓存，那就会演变成返回更新前的“旧”资源了。即使存在缓存，也会因为客户端的要求、缓存的有效期等因素，向源服务器确认资源的有效性。若判断缓存失效，缓存服务器将会再次从源服务器上获取“新”资源。 客户端的缓存缓存不仅可以存在于缓存服务器内，还可以存在客户端浏览器中。以Internet Explorer 程序为例，把客户端缓存称为临时网络文件（Temporary Internet File）。浏览器缓存如果有效，就不必再向服务器请求相同的资源了，可以直接从本地磁盘内读取。另外，和缓存服务器相同的一点是，当判定缓存过期后，会向源服务器确认资源的有效性。若判断浏览器缓存失效，浏览器会再次请求新资源。 在 HTTP 出现之前的协议 FTP（File Transfer Protocol）传输文件时使用的协议。该协议历史久远，可追溯到 1973 年前后，比 TCP/IP 协议族的出现还要早。虽然它在 1995 年被 HTTP 的流量（Traffic）超越，但时至今日，仍被广泛沿用。 NNTP（Network News Transfer Protocol）用于 NetNews 电子会议室内传送消息的协议。在 1986 年前后出现，属于比较古老的一类协议。现在，利用 Web 交换信息已成主流，所以该协议已经不怎么使用了。 Archie搜索 anonymous FTP 公开的文件信息的协议。1990 年前后出现，现在已经不常使用。 WAIS（Wide Area Information Servers）以关键词检索多个数据库使用的协议。1991 年前后出现。由于现在已经被 HTTP 协议替代，也已经不怎么使用了。 Gopher查找与互联网连接的计算机内信息的协议。1991 年前后出现，由于现在已经被 HTTP 协议替代，也已经不怎么使用了。","categories":[{"name":"Web","slug":"Web","permalink":"http://arvin-he.github.io/categories/Web/"}],"tags":[{"name":"http","slug":"http","permalink":"http://arvin-he.github.io/tags/http/"}]},{"title":"Http读书笔记第四章","slug":"http-note4-2017-04-17","date":"2017-04-17T12:01:13.000Z","updated":"2017-09-08T03:51:39.622Z","comments":true,"path":"2017/04/17/http-note4-2017-04-17/","link":"","permalink":"http://arvin-he.github.io/2017/04/17/http-note4-2017-04-17/","excerpt":"","text":"返回结果的 HTTP 状态码HTTP 状态码负责表示客户端 HTTP 请求的返回结果、标记服务器端的处理是否正常、通知出现的错误等工作。 状态码的类别 类别 原因短语 1XX Informational（信息性状态码） 接收的请求正在处理 2XX Success（成功状态码） 请求正常处理完毕 3XX Redirection（重定向状态码） 需要进行附加操作以完成请求 4XX Client Error（客户端错误状态码） 服务器无法处理请求 5XX Server Error（服务器错误状态码） 服务器处理请求出错 仅记录在 RFC2616 上的 HTTP 状态码就达 40 种，若再加上WebDAV（Web-based Distributed Authoring and Versioning，基于万维网的分布式创作和版本控制）（RFC4918、5842） 和附加 HTTP 状态码(RFC6585)等扩展，数量就达 60 余种,实际上经常使用的大概只有 14 种. 2XX 成功2XX 的响应结果表明请求被正常处理了。 204 No Content该状态码代表服务器接收的请求已成功处理，但在返回的响应报文中不含实体的主体部分。另外，也不允许返回任何实体的主体。比如，当从浏览器发出请求处理后，返回 204 响应，那么浏览器显示的页面不发生更新。一般在只需要从客户端往服务器发送信息，而对客户端不需要发送新信息内容的情况下使用。 206 Partial Content该状态码表示客户端进行了范围请求，而服务器成功执行了这部分的GET 请求。响应报文中包含由 Content-Range 指定范围的实体内容。 3XX 重定向3XX 响应结果表明浏览器需要执行某些特殊的处理以正确处理请求。 301 Moved Permanently永久性重定向。该状态码表示请求的资源已被分配了新的 URI，以后应使用资源现在所指的 URI。也就是说，如果已经把资源对应的 URI保存为书签了，这时应该按 Location 首部字段提示的 URI 重新保存。 302 Found临时性重定向。该状态码表示请求的资源已被分配了新的 URI，希望用户（本次）能使用新的 URI 访问。302 状态码代表的资源不是被永久移动，只是临时性质的。换句话说，已移动的资源对应的URI 将来还有可能发生改变。比如，用户把 URI 保存成书签，但不会像 301 状态码出现时那样去更新书签，而是仍旧保留返回 302 状态码的页面对应的 URI。 303 See Other该状态码表示由于请求对应的资源存在着另一个 URI，应使用 GET方法定向获取请求的资源。303 状态码和 302 Found 状态码有着相同的功能，但 303 状态码明确表示客户端应当采用 GET 方法获取资源，这点与 302 状态码有区别。 304 Not Modified该状态码表示客户端发送附带条件的请求时，服务器端允许请求访问资源，但未满足条件的情况。304 状态码返回时，不包含任何响应的主体部分。304 虽然被划分在 3XX 类别中，但是和重定向没有关系。附带条件的请求是指采用 GET 方法的请求报文中包含 If-Match，If-Modified-Since，If-None-Match，If-Range,If-Unmodified-Since 中任一首部。 307 Temporary Redirect临时重定向。该状态码与 302 Found 有着相同的含义。尽管 302 标准禁止 POST 变换成 GET，但实际使用时大家并不遵守。307 会遵照浏览器标准，不会从 POST 变成 GET。但是，对于处理响应时的行为，每种浏览器有可能出现不同的情况。 4XX 客户端错误4XX 的响应结果表明客户端是发生错误的原因所在。 400 Bad Request该状态码表示请求报文中存在语法错误。当错误发生时，需修改请求的内容后再次发送请求。另外，浏览器会像 200 OK 一样对待该状态码。 401 Unauthorized该状态码表示发送的请求需要有通过 HTTP 认证（BASIC 认证、DIGEST 认证）的认证信息。另外若之前已进行过 1 次请求，则表示用户认证失败。返回含有 401 的响应必须包含一个适用于被请求资源的 WWW-Authenticate 首部用以质询（challenge）用户信息。当浏览器初次接收到 401 响应，会弹出认证用的对话窗口。 403 Forbidden该状态码表明对请求资源的访问被服务器拒绝了。服务器端没有必要给出拒绝的详细理由，但如果想作说明的话，可以在实体的主体部分对原因进行描述，这样就能让用户看到了.未获得文件系统的访问授权，访问权限出现某些问题（从未授权的发送源 IP 地址试图访问）等列举的情况都可能是发生 403 的原因。 404 Not Found该状态码表明服务器上无法找到请求的资源。除此之外，也可以在服务器端拒绝请求且不想说明理由时使用。 5XX 服务器错误5XX 的响应结果表明服务器本身发生错误。 500 Internal Server Error该状态码表明服务器端在执行请求时发生了错误。也有可能是 Web应用存在的 bug 或某些临时的故障。 503 Service Unavailable该状态码表明服务器暂时处于超负载或正在进行停机维护，现在无法处理请求。如果事先得知解除以上状况需要的时间，最好写入RetryAfter 首部字段再返回给客户端。 状态码和状况的不一致不少返回的状态码响应都是错误的，但是用户可能察觉不到这点。比如 Web 应用程序内部发生错误，状态码依然返回 200 OK，这种情况也经常遇到。","categories":[{"name":"Web","slug":"Web","permalink":"http://arvin-he.github.io/categories/Web/"}],"tags":[{"name":"http","slug":"http","permalink":"http://arvin-he.github.io/tags/http/"}]},{"title":"Http读书笔记第三章","slug":"http-note3-2017-04-16","date":"2017-04-16T12:47:54.000Z","updated":"2017-09-08T03:51:39.592Z","comments":true,"path":"2017/04/16/http-note3-2017-04-16/","link":"","permalink":"http://arvin-he.github.io/2017/04/16/http-note3-2017-04-16/","excerpt":"","text":"术语:MIME:（Multipurpose Internet Mail Extensions，多用途因特网邮件扩展） HTTP 报文用于 HTTP 协议交互的信息被称为 HTTP 报文.请求端（客户端）的HTTP 报文叫做请求报文，响应端（服务器端）的叫做响应报文。HTTP 报文本身是由多行（用 CR+LF 作换行符）数据构成的字符串文本。HTTP 报文大致可分为报文首部和报文主体两块。两者由最初出现的空行（CR+LF）来划分,通常，并不一定要有报文主体。 请求报文及响应报文的结构 请求行:包含用于请求的方法，请求 URI 和 HTTP 版本。状态行:包含表明响应结果的状态码，原因短语和 HTTP 版本。首部字段:包含表示请求和响应的各种条件和属性的各类首部。一般有 4 种首部，分别是：通用首部、请求首部、响应首部和实体首部。其他:可能包含 HTTP 的 RFC 里未定义的首部（Cookie 等） 编码提升传输速率HTTP 在传输数据时可以按照数据原貌直接传输，但也可以在传输过程中通过编码提升传输速率。通过在传输时编码，能有效地处理大量的访问请求。但是，编码的操作需要计算机来完成，因此会消耗更多的 CPU 等资源 报文主体和实体主体的差异报文（message）是 HTTP 通信中的基本单位，由 8 位组字节流（octet sequence，其中 octet 为 8 个比特）组成，通过 HTTP 通信传输。实体（entity）作为请求或响应的有效载荷数据（补充项）被传输，其内容由实体首部和实体主体组成。 HTTP 报文的主体用于传输请求或响应的实体主体。通常，报文主体等于实体主体。只有当传输中进行编码操作时，实体主体的内容发生变化，才导致它和报文主体产生差异。 压缩传输的内容编码内容编码指明应用在实体内容上的编码格式，并保持实体信息原样压缩。内容编码后的实体由客户端接收并负责解码。 常用的内容编码有以下几种。 gzip（GNU zip） compress（UNIX 系统的标准压缩） deflate（zlib） identity（不进行编码） 分割发送的分块传输编码在 HTTP 通信过程中，请求的编码实体资源尚未全部传输完成之前，浏览器无法显示请求页面。在传输大容量数据时，通过把数据分割成多块，能够让浏览器逐步显示页面。这种把实体主体分块的功能称为分块传输编码（Chunked Transfer Coding）。分块传输编码会将实体主体分成多个部分（块）。每一块都会用十六进制来标记块的大小，而实体主体的最后一块会使用“0(CR+LF)”来标记。使用分块传输编码的实体主体会由接收的客户端负责解码，恢复到编码前的实体主体。HTTP/1.1 中存在一种称为传输编码（Transfer Coding）的机制，它可以在通信时按某种编码方式传输，但只定义作用于分块传输编码中。 在 HTTP 报文中使用多部分对象集合时，需要在首部字段里加上Content-type.使用 boundary 字符串来划分多部分对象集合指明的各类实体.boundary 字符串指定的各个实体的起始行之前插入“–”标记. 多部分对象集合的每个部分类型中，都可以含有首部字段。另外，可以在某个部分中嵌套使用多部分对象集合。 获取部分内容的范围请求可恢复的机制:所谓恢复是指能从之前下载中断处恢复下载.要实现可恢复功能需要指定下载的实体范围。执行范围请求时，会用到首部字段 Range 来指定资源的 byte 范围。响应会返回状态码为 206 Partial Content 的响应报文.对于多重范围的范围请求，响应会在首部字段 Content-Type 标明 multipart/byteranges 后返回响应报文.如果服务器端无法响应范围请求，则会返回状态码 200 OK 和完整的实体内容。 内容协商返回最合适的内容当浏览器的默认语言为英语或中文，访问相同 URI 的 Web 页面时，则会显示对应的英语版或中文版的 Web 页面。这样的机制称为内容协商（Content Negotiation）。内容协商机制是指客户端和服务器端就响应的资源内容进行交涉，然后提供给客户端最为适合的资源。内容协商会以响应资源的语言、字符集、编码方式等作为判断的基准。 包含在请求报文中的某些首部字段（如下）就是判断的基准: Accept Accept-Charset Accept-Encoding Accept-Language Content-Language 内容协商技术有以下 3 种类型: 服务器驱动协商（Server-driven Negotiation）由服务器端进行内容协商。以请求的首部字段为参考，在服务器端自动处理。但对用户来说，以浏览器发送的信息作为判定的依据，并不一定能筛选出最优内容。 客户端驱动协商（Agent-driven Negotiation）由客户端进行内容协商的方式。用户从浏览器显示的可选项列表中手动选择。还可以利用 JavaScript 脚本在 Web 页面上自动进行上述选择。比如按 OS 的类型或浏览器类型，自行切换成 PC 版页面或手机版页面。 透明协商（Transparent Negotiation）是服务器驱动和客户端驱动的结合体，是由服务器端和客户端各自进行内容协商的一种方法。","categories":[{"name":"Web","slug":"Web","permalink":"http://arvin-he.github.io/categories/Web/"}],"tags":[{"name":"http","slug":"http","permalink":"http://arvin-he.github.io/tags/http/"}]},{"title":"Flask用户登录","slug":"flask-userlogin-2017-16","date":"2017-04-16T09:19:00.000Z","updated":"2017-09-08T03:51:39.481Z","comments":true,"path":"2017/04/16/flask-userlogin-2017-16/","link":"","permalink":"http://arvin-he.github.io/2017/04/16/flask-userlogin-2017-16/","excerpt":"","text":"Flask用户登录是建立 web 表单和数据库的联系，并且编写登录系统。 配置对于登录系统，会使用到两个扩展，Flask-Login 和 Flask-OpenID,Flask-OpenID 扩展需要一个存储文件的临时文件夹的路径。对此，我们提供了一个 tmp 文件夹的路径。 重构用户模型Flask-Login 扩展需要在我们的 User 类中实现一些特定的方法。但是类如何去实现这些方法却没有什么要求。 user_loader回调必须编写一个函数用于从数据库加载用户。这个函数将会被 Flask-Login 使用 登录视图函数oid.loginhandle 告诉 Flask-OpenID 这是登录视图函数。在函数开始的时候，用检查 g.user 是否被设置成一个认证用户，如果是的话将会被重定向到首页。这里的想法是如果是一个已经登录的用户的话，就不需要二次登录了。Flask 中的 g 全局变量是一个在请求生命周期中用来存储和共享数据。将登录的用户存储在这里(g)。在 redirect 调用中使用的 url_for 函数是定义在 Flask 中，以一种干净的方式为一个给定的视图函数获取 URL。 让 Flask 为你构建 URLs是一个很好的选择。OpenID 认证异步发生。如果认证成功的话，Flask-OpenID 将会调用一个注册了 oid.after_login 装饰器的函数。如果失败的话，用户将会回到登陆页面。 Flask-OpenID 登录回调这里是 after_login 函数 全局变量g.user在登录视图函数中我们检查 g.user 为了决定用户是否已经登录.为了实现这个我们用 Flask 的 before_request 装饰器。任何使用了 before_request 装饰器的函数在接收请求之前都会运行 登出只需要检查有效的用户是否被设置到 g.user 以及是否我们已经添加了登出链接。","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"},{"name":"Flask","slug":"Flask","permalink":"http://arvin-he.github.io/tags/Flask/"}]},{"title":"PyQt5的翻译机制分析","slug":"pyqt-translate-2017-04-14","date":"2017-04-14T06:17:42.000Z","updated":"2017-09-08T03:51:39.989Z","comments":true,"path":"2017/04/14/pyqt-translate-2017-04-14/","link":"","permalink":"http://arvin-he.github.io/2017/04/14/pyqt-translate-2017-04-14/","excerpt":"","text":"1. PyQt中的翻译流程 遍历要翻译的文件,如*.py和*.ui,以及其他需要翻译的文件等,并创建*.pro文件,(如translations.pro),将扫描到的要翻译的文件按照指定格式写入到*.pro文件中,其格式如下所示: 12345678910111213141516// 如translations.pro中的内容格式// SOURCES指定要翻译的文本文件的路径,最好用相对路径// FORMS指定要翻译的ui文件的路径// TRANSLATIONS指定翻译文件的路径 SOURCES += \\ E:/working/srd/plugins/tool/tool1.py \\ E:/working/srd/plugins/tool/tooldialog1.py \\ E:/working/srd/tool/tooldialog2.pyFORMS += \\ E:/working/srd/plugins/tool/res/tool.ui \\ E:/working/srd/plugins/tool/res/tooldialog1.ui \\ E:/working/srd/plugins/tool/res/tooldialog2.uiTRANSLATIONS += \\ E:/working/srd/plugins/tool/res/translations/zh_CN.ts 在.py或者其他文本文件中创建翻译对象,并标记要翻译的文本源,这是用来提取要翻译的文本源,也是标明哪些文件需要被翻译,对于\\ui文件一般都是默认可翻译的.同时在应用程序运行时,根据翻译对象去查找翻译后的文本,注意:创建的翻译对象要统一,不要不同的文件创建不同的翻译对象,这样很容易错乱掉,且不要和系统函数或者内建函数或变量重名. 123_translate = QtCore.QCoreApplication.translatepushButton = QtWidgets.QPushButton(_translate(&quot;centering&quot;, &quot;Record &#123;&#125;&quot;).format(item))_logger.error(_translate(&quot;centering&quot;, &quot;y2 is equal to y1, please pick fit coordination&quot;)) 使用Linguist翻译工具中的lupdate工具运行加载translations.pro文件,lupdate工具就会扫描SOURCES和FORMS中的文件(如*.py和*.ui文件),并创建ts文件,并将扫描到的要翻译的源文本提取出来按照指定的格式写入到ts文件中去,然后在Linguist中打开ts文件并开始翻译.ts的格式如下: 123456789101112131415161718192021&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;TS version=&quot;2.0&quot; language=&quot;zh_CN&quot;&gt; &lt;context&gt; &lt;name&gt;MACRO&lt;/name&gt; &lt;message&gt; &lt;location filename=&quot;../user/PROBE_SUB/9336&quot; line=&quot;231&quot;&gt;&lt;/location&gt; &lt;source&gt;74&lt;/source&gt; &lt;translation type=&quot;unfinished&quot;&gt;&lt;/translation&gt; &lt;/message&gt; &lt;message&gt; &lt;location filename=&quot;../user/ARRAYRECT_PATH_CYCLE&quot; line=&quot;34&quot;&gt;&lt;/location&gt; &lt;source&gt;Please select 2 plane in 2 plane machining&lt;/source&gt; &lt;translation&gt;两板加工时请选择两板&lt;/translation&gt; &lt;/message&gt; &lt;message&gt; &lt;location filename=&quot;../../centering.py&quot; line=&quot;180&quot;/&gt; &lt;source&gt;Y1 and Y2 centering has done??&lt;/source&gt; &lt;translation type=&quot;obsolete&quot;&gt;Y1与Y2分中完成!&lt;/translation&gt; &lt;/message&gt; &lt;/context&gt;&lt;/TS&gt; 翻译好并保存ts文件后,使用lrelease工具生成qm文件,lrelease工具会加载ts文件,并做一些去重的工作,以节省qm文件的大小. 最后在应用程序中加载qm翻译文件,qm文件也是一种资源文件,在应用程序中需要注意加载的时机,比如应当在界面显示前或者日志打印前加载好.12345678910translator = QtCore.QTranslator()translator.load(QtCore.QLocale(), &quot;&quot;, &quot;&quot;, &quot;:/&#123;&#125;/translations&quot;.format(__name__.replace(&quot;.&quot;, &quot;/&quot;)))QtWidgets.qApp.installTranslator(translator)# 指定名称的翻译文件 if os.path.exists(os.path.join(basic.sysDir, &apos;macro/translations/common_zh_CN.qm&apos;)): _common_macro_translator = QtCore.QTranslator() _common_macro_translator.load(QtCore.QLocale(), &quot;common&quot;, &quot;_&quot;, os.path.join( basic.sysDir, &quot;macro/translations&quot;)) QtWidgets.qApp.installTranslator(_common_macro_translator) 2. 关于PyQt的Linguist在PyQt5的安装包有一个Linguist翻译工具,为应用程序的国际化提供很好的支持.Linguist提供了两款工具lupdate和lrelease.它们可以处理qmake项目文件(*.pro)，可直接在文件系统上运行. lupdate会逐个扫描应用程序中的.ui和.py文件,然后产生翻译源文件(*.ts),里面包含所有用户可见的文本,但未经过翻译(unfinished).生成的.ts文件通过Linguist翻译工具打开即可看到所扫描到的要被翻译的源文本.当*.py或*.ui的源文本被修改了,再次运行lupdate,就可以从应用程序中同步可见的文本,且不会破坏已经翻译好的文本.lupdate工具从应用程序中提取的用户界面字符串。它读取应用程序的.pro文件，以确定哪些源文件包含的文本需要被翻译。这意味着源文件都必须被列在.pro中。如果文件没有列出，其中的文本则不会被发现。 运行lrelease会读取对应的.ts文件,并生成用于应用程序运行是用的.qm文件.运行lrelese时生成.qm文件时会删除相同的源文本,只保留一个,这样.qm文件会比较小,且生成的.qm文件是二进制的. 3. 使用lupdate和lrelease12345# Qtlupdate myproject.pro # PyQtpylupdate translations.pro lrelease myproject.pro 4. ts文件规格分析ts文件是可读的XML文件,包含源短语及其翻译，ts文件通常由lupdate创建与更新. &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;ts文件的开头说明,其实是xml文件的开头说明.指明xml版本和编码 &lt;!DOCTYPE TS&gt;指明文档类型是一个ts文件,可有可无 TS标签TS标签格式如下,指定Linguist版本和翻译后的语言,TS标签里的内容是由context标签组成 123456789101112&lt;TS version=&quot;2.1&quot; language=&quot;zh_CN&quot;&gt; &lt;context&gt; ... &lt;/context&gt; &lt;context&gt; ... &lt;/context&gt; &lt;context&gt; ... &lt;/context&gt; ...&lt;/TS&gt; context标签context标签是一个上下文标签,不同的context是根据子标签的来区分,指明这个context的对象名.通常一个文件就是一个context,如果是以ui文件,那么name就是这个ui的对象名,注意不是ui文件名,如果是一个py文件,那么name就是py文件名.如果想把多个文件合并到一个context中去,那么需要指定一个name,那么这多个文件的翻译都会放在这一个context中.这个name最终传给翻译对象的第一个参数. 1234567891011121314&lt;context&gt; &lt;name&gt;...&lt;/name&gt; &lt;message&gt; &lt;location filename=&quot;...&quot; line=&quot;...&quot;/&gt; &lt;source&gt;...&lt;/source&gt; &lt;translation&gt;...&lt;/translation&gt; &lt;/message&gt; &lt;message&gt; &lt;location filename=&quot;...&quot; line=&quot;...&quot;/&gt; &lt;source&gt;...&lt;/source&gt; &lt;translation&gt;...&lt;/translation&gt; &lt;/message&gt; ...&lt;/context&gt; 注意:这里的name其实是对应这翻译对象里的name的参数.如:12macro_text = \\_translate(&quot;MACRO&quot;, dst\\_text)pushButton = QPushButton(_translate(&quot;centering&quot;, &quot;Record &#123;&#125;&quot;).format(item)) message标签message标签由location,source和translation标签组成,其中:location:指定被翻译文件的路径和行号,注意:被翻译文件路径是相对与这个ts文件的相对路径source:翻译的源文本translation:翻译文本translation的翻译状态有type指定,type有三种情况:unfinished(未翻译),空(已翻译),obsolete(废弃的)12345&lt;message&gt; &lt;location filename=&quot;...&quot; line=&quot;...&quot;/&gt; &lt;source&gt;...&lt;/source&gt; &lt;translation&gt;...&lt;/translation&gt;&lt;/message&gt; 5. qm文件qm(Qt message)文件和ts文件的文件名称一样,一一对应,qm文件由lrelease创建. 6. 创建ts文件ts文件其实就是xml文件,创建ts文件可以应用python的第三方包:xmltodict,可将字典数据结构直接转化成xml了.12345678910111213141516171819202122232425TS_XML = OrderedDict()TS = OrderedDict()context = OrderedDict()TS[\"@version\"] = \"2.1\"TS[\"@language\"] = \"zh_CN\"context[\"name\"] = \"MACRO\"message = OrderedDict()location = OrderedDict()translation = OrderedDict()# message/location 标签location[\"@filename\"] = os.path.relpath(file_path, trans_path).replace(\"\\\\\", \"/\")location[\"@line\"] = line_index + 1message[\"location\"] = locationif line_content.strip()[0:3] == 'ASK': source = ((match.group()[4:-1]).split(','))[2]# message/source 标签message[\"source\"] = source# message/translation 标签translation[\"@type\"] = \"unfinished\"message[\"translation\"] = translationTS[\"context\"] = contextTS_XML[\"TS\"] = TS# 创建ts文件with open(os.path.join(ts_path, trans_file_name), \"w\", encoding=\"utf-8\") as f: xmltodict.unparse(TS_XML, f, pretty=True, newl=new_line, indent=indent) 有了ts文件,就可以应用lupdate和lrelease工具生成qm文件当翻译源文本有了修改,就需要重新生成ts文件了,这里需要注意一个问题,没有修改的翻译会被丢失.这就需要先解析修改前的ts文件,然后对比修改后的ts文件的源文本,只更新修改了的.12345678910111213141516171819def parseTS(ts_path): if 'base' in ts_path and 'macro' in ts_path: trans_file_name = \"common_zh_CN.ts\" elif 'sys' in ts_path and 'macro' in ts_path: trans_file_name = \"user_zh_CN.ts\" ts_file = os.path.join(ts_path, trans_file_name) with open(ts_file, \"r\", -1, \"utf-8\") as f: document = f.read() ts_xml = xmltodict.parse(document) macro_context_list = ts_xml['TS']['context']['message'] return macro_context_listdef updateTS(ts_path, new_message_list): old_message_list = parseTS(ts_path) for new_message in new_message_list: for old_message in old_message_list: if new_message[\"source\"] == old_message[\"source\"]: new_message[\"translation\"] = old_message[\"translation\"] return new_message_list","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"PyQt5","slug":"PyQt5","permalink":"http://arvin-he.github.io/tags/PyQt5/"}]},{"title":"Http读书笔记第二章","slug":"http-note2-2017-04-13","date":"2017-04-13T14:28:20.000Z","updated":"2017-09-08T03:51:39.589Z","comments":true,"path":"2017/04/13/http-note2-2017-04-13/","link":"","permalink":"http://arvin-he.github.io/2017/04/13/http-note2-2017-04-13/","excerpt":"","text":"客户端与服务端客户端:请求访问文本或图像等资源的一端,服务器端:提供资源响应的一端.两台计算机之间使用 HTTP 协议通信时，在一条通信线路上必定有一端是客户端，另一端则是服务器端.实际情况，两台计算机作为客户端和服务器端的角色有可能会互换。但就仅从一条通信路线来说，服务器端和客户端的角色是确定的，而用 HTTP 协议能够明确区分哪端是客户端，哪端是服务器端。 HTTP 协议HTTP 协议规定，请求从客户端发出，最后服务器端响应该请求并返回。换句话说，肯定是先从客户端开始建立通信的，服务器端在没有接收到请求之前不会发送响应。 请求报文组成:是由请求方法、请求 URI、协议版本、可选的请求首部字段和内容实体构成的。 响应报文组成:1234567HTTP/1.1 200 OKDate: Tue, 10 Jul 2012 06:50:15 GMTContent-Length: 362Content-Type: text/html&lt;html&gt;... 在起始行开头的 HTTP/1.1 表示服务器对应的 HTTP 版本。紧挨着的 200 OK 表示请求的处理结果的状态码（status code）和原因短语（reason-phrase）。下一行显示了创建响应的日期时间，是首部字段（header field）内的一个属性。接着以一空行分隔，之后的内容称为资源实体的主体（entitybody）。 响应报文基本上由协议版本、状态码（表示请求成功或失败的数字代码）、用以解释状态码的原因短语、可选的响应首部字段以及实体主体构成。 HTTP 是不保存状态的协议HTTP 是一种不保存状态，即无状态（stateless）协议.HTTP 协议自身不对请求和响应之间的通信状态进行保存。也就是说在 HTTP 这个级别，协议对于发送过的请求或响应都不做持久化处理。使用 HTTP 协议，每当有新的请求发送时，就会有对应的新响应产生。协议本身并不保留之前一切的请求或响应报文的信息。 HTTP/1.1 虽然是无状态协议，但为了实现期望的保持状态功能，于是引入了 Cookie 技术。有了 Cookie 再用 HTTP 协议通信，就可以管理状态了。 请求 URI 定位资源HTTP 协议使用 URI 定位互联网上的资源。正是因为 URI 的特定功能，在互联网上任意位置的资源都能访问到。 告知服务器意图的 HTTP 方法GET ：获取资源GET 方法用来请求访问已被 URI 识别的资源。指定的资源经服务器端解析后返回响应内容。也就是说，如果请求的资源是文本，那就保持原样返回；如果是像 CGI（Common Gateway Interface，通用网关接口）那样的程序，则返回经过执行后的输出结果。 POST：传输实体主体虽然用 GET 方法也可以传输实体的主体，但一般不用 GET 方法进行传输，而是用 POST 方法。虽说 POST 的功能与 GET 很相似，但POST 的主要目的并不是获取响应的主体内容。 PUT：传输文件PUT 方法用来传输文件。就像 FTP 协议的文件上传一样，要求在请求报文的主体中包含文件内容，然后保存到请求 URI 指定的位置。但是，鉴于 HTTP/1.1 的 PUT 方法自身不带验证机制，任何人都可以上传文件 , 存在安全性问题，因此一般的 Web 网站不使用该方法。若配合 Web 应用程序的验证机制，或架构设计采用REST（REpresentational State Transfer，表征状态转移）标准的同类Web 网站，就可能会开放使用 PUT 方法。 HEAD：获得报文首部HEAD 方法和 GET 方法一样，只是不返回报文主体部分。用于确认URI 的有效性及资源更新的日期时间等。 DELETE：删除文件DELETE 方法用来删除文件，是与 PUT 相反的方法。DELETE 方法按请求 URI 删除指定的资源。HTTP/1.1 的 DELETE 方法本身和 PUT 方法一样不带验证机制，所以一般的 Web 网站也不使用 DELETE 方法。当配合 Web 应用程序的验证机制，或遵守 REST 标准时还是有可能会开放使用的。 OPTIONS：询问支持的方法OPTIONS 方法用来查询针对请求 URI 指定的资源支持的方法。 TRACE：追踪路径TRACE 方法是让 Web 服务器端将之前的请求通信环回给客户端的方法。发送请求时，在 Max-Forwards 首部字段中填入数值，每经过一个服务器端就将该数字减 1，当数值刚好减到 0 时，就停止继续传输，最后接收到请求的服务器端则返回状态码 200 OK 的响应。客户端通过 TRACE 方法可以查询发送出去的请求是怎样被加工修改/ 篡改的。这是因为，请求想要连接到源目标服务器可能会通过代理中转，TRACE 方法就是用来确认连接过程中发生的一系列操作。但是，TRACE 方法本来就不怎么常用，再加上它容易引发XST（Cross-Site Tracing，跨站追踪）攻击，通常就更不会用到了。 CONNECT：要求用隧道协议连接代理CONNECT 方法要求在与代理服务器通信时建立隧道，实现用隧道协议进行 TCP 通信。主要使用 SSL（Secure Sockets Layer，安全套接层）和 TLS（Transport Layer Security，传输层安全）协议把通信内容加 密后经网络隧道传输。CONNECT 方法的格式:CONNECT 代理服务器名:端口号 HTTP版本 持久连接节省通信量HTTP 协议的初始版本中，每进行一次 HTTP 通信就要断开一次 TCP连接。为解决上述 TCP 连接的问题，HTTP/1.1 和一部分的 HTTP/1.0 想出了持久连接（HTTP Persistent Connections，也称为 HTTP keep-alive 或HTTP connection reuse）的方法。持久连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。持久连接的好处在于减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载。另外，减少开销的那部分时间，使HTTP 请求和响应能够更早地结束，这样 Web 页面的显示速度也就相应提高了。在 HTTP/1.1 中，所有的连接默认都是持久连接，但在 HTTP/1.0 内并未标准化。虽然有一部分服务器通过非标准的手段实现了持久连接，但服务器端不一定能够支持持久连接。毫无疑问，除了服务器端，客户端也需要支持持久连接。 管线化持久连接使得多数请求以管线化（pipelining）方式发送成为可能。从前发送请求后需等待并收到响应，才能发送下一个请求。管线化技术出现后，不用等待响应亦可直接发送下一个请求。这样就能够做到同时并行发送多个请求，而不需要一个接一个地等待响应了。 使用 Cookie 的状态管理HTTP 是无状态协议，它不对之前发生过的请求和响应的状态进行管理。也就是说，无法根据之前的状态进行本次的请求处理。无状态协议当然也有它的优点。由于不必保存状态，自然可减少服务器的 CPU 及内存资源的消耗。 Cookie 技术通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。Cookie 会根据从服务器端发送的响应报文内的一个叫做 Set-Cookie 的首部字段信息，通知客户端保存 Cookie。当下次客户端再往该服务器发送请求时，客户端会自动在请求报文中加入 Cookie 值后发送出去。服务器端发现客户端发送过来的 Cookie 后，会去检查究竟是从哪一个客户端发来的连接请求，然后对比服务器上的记录，最后得到之前的状态信息。","categories":[{"name":"Web","slug":"Web","permalink":"http://arvin-he.github.io/categories/Web/"}],"tags":[{"name":"http","slug":"http","permalink":"http://arvin-he.github.io/tags/http/"}]},{"title":"Flask之数据库使用","slug":"flask-DB-2017-04-12","date":"2017-04-12T12:29:07.000Z","updated":"2017-09-08T03:51:39.443Z","comments":true,"path":"2017/04/12/flask-DB-2017-04-12/","link":"","permalink":"http://arvin-he.github.io/2017/04/12/flask-DB-2017-04-12/","excerpt":"","text":"1. Flask 中的数据库使用 Flask-SQLAlchemy 扩展来管理应用程序的数据。这个扩展封装了SQLAlchemy项目，这是一个 对象关系映射器或者ORM。 2. 数据库迁移使用 SQLAlchemy-migrate 来跟踪数据库的更新。它只是在开始建立数据库的时候多花费些工作.SQLAlchemy-migrate 包自带命令行和 APIs，这些 APIs 以一种将来允许容易升级的方式来创建数据库。一个空的 sqlite 数据库，创建一开始就支持迁移。同样你还将有一个 db_repository 文件夹，里面还有一些文件，这是 SQLAlchemy-migrate 存储它的数据文件的地方。请注意，我们不会再生的存储库，如果它已经存在。这将使我们重新创建数据库，同时保留现有的存储库，如果我们需要。SQLAlchemy-migrate 迁移的方式就是比较数据库(在本例中从 app.db 中获取)与我们模型的结构(从文件 app/models.py 获取)。两者间的不同将会被记录成一个迁移脚本存放在迁移仓库中。迁移脚本知道如何去迁移或撤销它，所以它始终是可能用于升级或降级一个数据库。 在使用脚本自动地完成迁移的时候也不是没有问题的，有时候它很难识别新老格式的变化。为了让 SQLAlchemy-migrate 容易地识别出变化，绝不要重命名存在的字段，仅限于增加或者删除模型或者字段，或者改变已存在字段的类型。当然我一直会检查生成的迁移脚本，确保它是正确。不应该在没有备份下去尝试迁移数据库。当然也不能在生产环境下直接运行迁移脚本，必须在开发环境下确保迁移运转正常。 3. 数据库配置小型的应用，采用 sqlite 数据库。sqlite 数据库是小型应用的最方便的选择，每一个数据库都是存储在单个文件里。大型的可以采用MySql.12345import osbasedir = os.path.abspath(os.path.dirname(__file__))SQLALCHEMY_DATABASE_URI = &apos;sqlite:///&apos; + os.path.join(basedir, &apos;app.db&apos;)SQLALCHEMY_MIGRATE_REPO = os.path.join(basedir, &apos;db_repository&apos;) SQLALCHEMY_DATABASE_URI 是 Flask-SQLAlchemy 扩展需要的。这是数据库文件的路径。SQLALCHEMY_MIGRATE_REPO 是文件夹，把 SQLAlchemy-migrate 数据文件存储在这里。 4. 数据库模型存储在数据库中数据将会以类的集合来表示，称之为数据库模型。ORM 层需要做的翻译就是将从这些类创建的对象映射到适合的数据库表的行. 5. 数据库升级和回退假设有一个应用程序在开发机器上，同时有一个拷贝部署在到线上的生产机器上。在下一个版本中，你的数据模型有一个变化，比如新增了一个表。如果没有迁移脚本，可能必须要琢磨着如何修改数据库格式在开发和生产机器上，这会花费很大的工作。 如果有数据库迁移的支持，当准备发布新版的时候，只需要录制一个新的迁移，拷贝迁移脚本到生产服务器上接着运行脚本，所有事情就完成了。数据库升级也只需要一点 Python 脚本(文件 db_upgrade.py):当你运行上述脚本的时候，数据库将会升级到最新版本。通常情况下，没有必要把数据库降低到旧版本，但是，SQLAlchemy-migrate 支持这么做(文件 db_downgrade.py)这个脚本会回退数据库一个版本。你可以运行多次来回退多个版本。","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"},{"name":"Flask","slug":"Flask","permalink":"http://arvin-he.github.io/tags/Flask/"}]},{"title":"Flask表单","slug":"flask-wtf-2017-04-10","date":"2017-04-10T14:27:56.000Z","updated":"2017-09-08T03:51:39.484Z","comments":true,"path":"2017/04/10/flask-wtf-2017-04-10/","link":"","permalink":"http://arvin-he.github.io/2017/04/10/flask-wtf-2017-04-10/","excerpt":"","text":"处理 web 表单，我们将使用 Flask-WTF扩展.在 Flask-WTF 中，表单是表示成对象，Form 类的子类。一个表单子类简单地把表单的域定义成类的变量。 1. 配置Flask-WTFFlaks-WTF 扩展只需要两个配置。12CSRF_ENABLED = TrueSECRET_KEY = &apos;you-will-never-guess&apos; CSRF_ENABLED 配置是为了激活跨站点请求伪造保护。在大多数情况下，你需要激活该配置使得你的应用程序更安全些。SECRET_KEY 配置仅仅当 CSRF 激活的时候才需要，它是用来建立一个加密的令牌，用于验证一个表单。当你编写自己的应用程序的时候，请务必设置很难被猜测到密钥。 2. 用户登录表单创建一个登录表单，用户用于认证系统,我们导入 Form 类，接着导入两个我们需要的字段类，TextField 和 BooleanField。DataRequired 验证器只是简单地检查相应域提交的数据是否是空。在 Flask-WTF 中有许多的验证器. 3. 登录表单模板重用base.html 模板通过 extends 模板继承声明语句,好处是以确保所有网页的布局一致性。模板与常规的 HTML 表单之间存在一些不同处。模板期望一个实例化自我们刚才创建地表单类的表单对象储存成一个模板参数，称为 form。当我们编写渲染这个模板的视图函数的时候，我们将会特别注意传送这个模板参数到模板中。form.hidden_tag() 模板参数将被替换为一个隐藏字段，用来是实现在配置中激活的 CSRF 保护.如果你已经激活了 CSRF，这个字段需要出现在你所有的表单中。 4. 表单视图导入 LoginForm 类，从这个类实例化一个对象，接着把它传入到模板中。这就是我们渲染表单所有要做的。注意:路由装饰器的 methods 参数。参数告诉 Flask 这个视图函数接受 GET 和 POST 请求。如果不带参数的话，视图只接受 GET 请求。 5. 接收表单数据Flask-WTF 使得工作变得简单的另外一点就是处理提交的数据.form表单对象中validate_on_submit 方法做了所有表单处理工作 当表单正在展示给用户的时候调用它，它会返回 False. 如果 validate_on_submit 在表单提交请求中被调用，它将会收集所有的数据，对字段进行验证，如果所有的事情都通过的话，它将会返回 True，表示数据都是合法的。这就是说明数据是安全的，并且被应用程序给接受了。 如果至少一个字段验证失败的话，它将会返回 False，接着表单会重新呈现给用户，这也将给用户一次机会去修改错误。 6. 加强字段验证加强字段验证是为了提示用户表单哪里出错了.当字段验证失败的时候， Flask-WTF 会向表单对象中添加描述性的错误信息。这些信息是可以在模板中使用的，因此我们只需要增加一些逻辑来获取它。通常情况下，任何需要验证的字段都会把错误信息放入 form.field_name.errors 下。在我们的例子中，我们使用 form.openid.errors 。我们以红色的字体颜色显示这些错误信息以引起用户的注意。 7. 处理 OpenIDs一些大的互联网服务提供商支持 OpenID 认证自己的会员。比如，如果你有一个 Google 的账号，你也就有了一个它们的 OpenID","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"},{"name":"Flask","slug":"Flask","permalink":"http://arvin-he.github.io/tags/Flask/"}]},{"title":"MySQL基本命令","slug":"mysql-cmds-2017-04-09","date":"2017-04-09T08:45:44.000Z","updated":"2017-09-08T03:51:39.791Z","comments":true,"path":"2017/04/09/mysql-cmds-2017-04-09/","link":"","permalink":"http://arvin-he.github.io/2017/04/09/mysql-cmds-2017-04-09/","excerpt":"","text":"MySQL基本命令 创建一个数据库:create database gogs; 显示所有数据库:show databases; 使用指定数据库:use gogs; 创建表:123CREATE TABLE pages (id BIGINT(7) NOT NULL AUTO_INCREMENT, title VARCHAR(200),content VARCHAR(10000), created TIMESTAMP DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY(id)); 注意:mysql数据表必须至少有一列,否则不能创建.每个字段定义由三部分组成： 名称（ id 、 title 、 created 等） 数据类型（ BIGINT(7) 、 VARCHAR 、 TIMESTAMP ） 其他可选属性（ NOT NULL AUTO_INCREMENT ）在字段定义列表的最后，还要定义一个“主键”（key）. 查看数据表的结构:describe pages; 插入数据:12insert into pages (title, content) VALUES (&quot;Test page title&quot;, &quot;This is some test page content. It can be up to 10,000 characters long.&quot;); 注意: pages 表里有四个字段（ id 、 title 、 content 、 created ），但实际上你只需要插入两个字段（ title 和 content ）的数据即可。因为 id 字段是自动递增的（每次新插入数据行时 MySQL 自动增加 1），通常不用处理。另外， created 字段的类型是timestamp ，默认就是数据加入时的时间戳。 查询数据: 123456# 精确查询select * from pages where id = 2;# 模糊查询select * from pages where title like &quot;%test%&quot;;# 返回部分字段查询select id, title from pages where content like &quot;%page content%&quot;; 删除数据:delete from pages where id = 1; 更新数据:update pages set title=&quot;a new title&quot;, content=&quot;some new content&quot; where id=2;","categories":[{"name":"数据库","slug":"数据库","permalink":"http://arvin-he.github.io/categories/数据库/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://arvin-he.github.io/tags/MySQL/"}]},{"title":"MySQL免安装配置","slug":"mysqlsetup-2017-04-07","date":"2017-04-07T07:56:03.000Z","updated":"2017-09-08T03:51:39.793Z","comments":true,"path":"2017/04/07/mysqlsetup-2017-04-07/","link":"","permalink":"http://arvin-he.github.io/2017/04/07/mysqlsetup-2017-04-07/","excerpt":"","text":"1. MySQL下载下载mysql-5.7.17-winx64.zip,32位机器下载mysql-5.7.17-wix32.zip,不要下载mysql-installer-community-5.7.17.0.msi.mysql下载链接 2. 解压mysql12#解压目录D:\\Program Files\\mysql-5.7.17-winx64 3. 配置mysql 在mysql解压目录下复制my-default.ini,放到mysql的解压目录,并重命名为my.ini. my.ini里修改为1234567891011121314[client]# port=3306default-character-set = utf8[mysql]default-character-set = utf8[mysqld]# basedir 为安装文件解压后的目录 ｜ basedir和datadir 可以使用相对路径basedir = D:/Program Files/mysql-5.7.17-winx64# datadir 为用来存放数据的目录datadir = D:/Program Files/mysql-5.7.17-winx64/datacharacter_set_server = utf8sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES 4. 添加mysql的环境变量将D:\\Program Files\\mysql-5.7.17-winx64\\bin添加到环境变量. 5. 将mysql注册为windows系统服务 从控制台中进入到mysql解压目录下的bin目录 输入命令:mysqld -install 6. 初始化mysql数据目录注意:mysql5.7解压后没有数据目录,即在解压目录中没有data文件夹.这会导致启动mysql服务失败.1mysqld --defaults-file=&quot;D:\\Program Files\\mysql-5.7.17-winx64\\my.ini&quot; --initialize-insecure 它会初始化 data 目录，在执行此命令前请先把data目录下的所有文件先删除，否则会失败. 可以选择用 –initialize-insecure 或者 –initialize 来初始化，–initialize-insecure 初始化root密码为空，如果用 –initialize来初始化，会产生一个随机密码. 执行成功后，在data目录下会生成mysql，perofrmance_schema，sys等目录文件. 7. 启动mysql服务在控制台输入:net start mysql 8. mysql一些命令1234567891011121314#安装服务mysqld -install#启动服务net start mysql#进入mysqlmysql -u root -p#移除mysql服务mysqld -remove#停止服务net stop mysql 9. 修改root帐号密码刚安装完成时root账号默认密码为空，此时可以将密码修改为指定的密码。如：123456123456&gt;mysql –u root mysql&gt;show databases; # 注意:分号不能丢 mysql&gt;use mysql; # 使用sql数据库,这个是初始化data目录自动生成的 mysql&gt;set password=password(&apos;123456&apos;); # 修改密码 mysql&gt;FLUSH PRIVILEGES; mysql&gt;QUIT 10. 一些其他命令1mysql -u root -p #-u表示用户, -p表示需要输入密码 11. 一些问题 MYSQL服务无法启动MYSQL服务无法启动的原因是:没有初始化mysql数据目录,mysql5.7解压后,在解压目录中没有data文件夹. 解决方法:在bin目录下输入命令:mysqld --initialize-insecure --user=mysql,然后在mysql根目录下会自动生成一个data文件夹. Error 1045: Access denied for user ‘root’@’localhost’ (using password: YES)解决方法: net stop mysql (停用MySQL服务,没启动的可以省略) 找到安装路径 MySQL Server 5.7下的my.ini打开 my.ini,找到 [mysqld] 然后在下面加上这句： skip_grant_tables （意思好像是 启动MySQL服务的时候跳过权限表认证 ） 启动数据库修改密码了 net start mysql (启动MySQL服务)—&gt; mysql 回车 (如果成功，将出现MySQL提示符) 输入use mysql; （连接权限数据库）。 改密码：update user set authentication_string=password(“123”) where user=”root”;（别忘了最后加分号) 刷新权限（必须步骤）：flush privileges; 退出 quit 将第3 步的 my.ini里的 skip_grant_tables 去掉（启动MySQL服务的时候不能让他跳过权限表认证 ） 重启MySQL ，再进入，使用用户名root和刚才设置的新密码123就可以登录了。 MySQL5.7更改密码时出现ERROR 1054 (42S22): Unknown column ‘password’ in ‘field list’.新安装的MySQL5.7，登录时提示密码错误，安装的时候并没有更改密码，后来通过免密码登录的方式更改密码，输入update mysql.user set password=password(‘123’) where user=’root’时提示ERROR 1054 (42S22): Unknown column ‘password’ in ‘field list’，原因:原来是mysql数据库下已经没有password这个字段了，password字段改成了authentication_string.解决方法:update user set authentication_string=password(“123”) where user=”root”;（别忘了最后加分号)","categories":[{"name":"数据库","slug":"数据库","permalink":"http://arvin-he.github.io/categories/数据库/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"http://arvin-he.github.io/tags/MySQL/"}]},{"title":"Http读书笔记第一章","slug":"http-note1-2017-04-06","date":"2017-04-06T14:35:06.000Z","updated":"2017-09-08T03:51:39.514Z","comments":true,"path":"2017/04/06/http-note1-2017-04-06/","link":"","permalink":"http://arvin-he.github.io/2017/04/06/http-note1-2017-04-06/","excerpt":"","text":"1. 一些名词概念 HTTP（HyperText Transfer Protocol，超文本传输协议 URL（Uniform Resource Locator，统一资源定位符） URI 是 Uniform Resource Identifier 的缩写,统一资源标识符 TCP/IP 是互联网相关的各类协议族的总称 RFC（Request for Comments，征求修正意见书）RFC 是互联网的设计文档，要是不按照 RFC 标准执行，就有可能导致无法通信的状况。 2. TCP/IP分层TCP/IP 协议族按层次分别分为以下 4 层：应用层、传输层、网络层和数据链路层 应用层:决定了向用户提供应用服务时通信的活动.TCP/IP 协议族内预存了各类通用的应用服务。比如，FTP（File Transfer Protocol，文件传输协议）和 DNS（Domain Name System，域名系统）服务就是其中两类。HTTP 协议也处于该层。 传输层:传输层对上层应用层，提供处于网络连接中的两台计算机之间的数据传输。传输层有两个性质不同的协议：TCP（Transmission Control Protocol，传输控制协议）和 UDP（User Data Protocol，用户数据报协议）。 网络层:网络层用来处理在网络上流动的数据包。数据包是网络传输的最小数据单位。该层规定了通过怎样的路径（所谓的传输路线）到达对方计算机，并把数据包传送给对方。 链路层(网络接口层):用来处理连接网络的硬件部分。包括控制操作系统、硬件的设备驱动、NIC（Network Interface Card，网络适配器，即网卡），及光纤等物理可见部分（还包括连接器等一切传输媒介）。硬件上的范畴均在链路层的作用范围之内。 3. 与 HTTP 关系密切的协议 : IP、TCP 和DNS IP协议IP 协议的作用是把各种数据包传送给对方。而要保证确实传送到对方那里，则需要满足各类条件。其中两个重要的条件是 IP 地址和 MAC地址（Media Access Control Address）。IP 地址指明了节点被分配到的地址，MAC 地址是指网卡所属的固定地址。IP 地址可以和 MAC 地址进行配对。IP 地址可变换，但 MAC地址基本上不会更改。使用 ARP 协议凭借 MAC 地址进行通信,IP 间的通信依赖 MAC 地址。在网络上，通信的双方在同一局域网（LAN）内的情况是很少的，通常是经过多台计算机和网络设备中转才能连接到对方。而在进行中转时，会利用下一站中转设备的 MAC地址来搜索下一个中转目标。这时，会采用 ARP 协议（Address Resolution Protocol）。ARP 是一种用以解析地址的协议，根据通信方的 IP 地址就可以反查出对应的 MAC 地址。在到达通信目标前的中转过程中，那些计算机和路由器等网络设备只能获悉很粗略的传输路线。这种机制称为路由选择（routing）. TCP协议TCP 位于传输层，提供可靠的字节流服务,所谓的字节流服务（Byte Stream Service）是指，为了方便传输，将大块数据分割成以报文段（segment）为单位的数据包进行管理。而可靠的传输服务是指，能够把数据准确可靠地传给对方。为了准确无误地将数据送达目标处，TCP 协议采用了三次握手（three-way handshaking）策略。用 TCP 协议把数据包送出去后，TCP不会对传送后的情况置之不理，它一定会向对方确认是否成功送达。握手过程中使用了 TCP 的标志（flag） —— SYN（synchronize） 和ACK（acknowledgement）。发送端首先发送一个带 SYN 标志的数据包给对方。接收端收到后，回传一个带有 SYN/ACK 标志的数据包以示传达确认信息。最后，发送端再回传一个带 ACK 标志的数据包，代表“握手”结束。若在握手过程中某个阶段莫名中断，TCP 协议会再次以相同的顺序发送相同的数据包。除了上述三次握手，TCP 协议还有其他各种手段来保证通信的可靠性。 DNC服务协议DNS（Domain Name System）服务是和 HTTP 协议一样位于应用层的协议。它提供域名到 IP 地址之间的解析服务。DNS 协议提供通过域名查找 IP 地址，或逆向从 IP 地址反查域名的服务。 4. URI(统一资源标识符)URI 就是由某个协议方案表示的资源的定位标识符。协议方案是指访问资源所使用的协议类型名称。URI 用字符串标识某一互联网资源，而 URL 表示资源的地点（互联网上所处的位置）。可见 URL 是 URI 的子集。 使用 http: 或 https: 等协议方案名获取访问资源时要指定协议类型。不区分字母大小写，最后附一个冒号（:）。也可使用 data: 或 javascript: 这类指定数据或脚本程序的方案名。 登录信息（认证）指定用户名和密码作为从服务器端获取资源时必要的登录信息（身份认证）。此项是可选项。 服务器地址使用绝对 URI 必须指定待访问的服务器地址。地址可以是类似hackr.jp 这种 DNS 可解析的名称，或是 192.168.1.1 这类 IPv4 地址名，还可以是 [0:0:0:0:0:0:0:1] 这样用方括号括起来的 IPv6 地址名。 服务器端口号指定服务器连接的网络端口号。此项也是可选项，若用户省略则自动使用默认端口号。 带层次的文件路径指定服务器上的文件路径来定位特指的资源。这与 UNIX 系统的文件目录结构相似。 查询字符串针对已指定的文件路径内的资源，可以使用查询字符串传入任意参数。此项可选。 片段标识符使用片段标识符通常可标记出已获取资源中的子资源（文档内的某个位置）。但在 RFC 中并没有明确规定其使用方法。该项也为可选项。 5.其他 1997 年 1 月公布的 HTTP/1.1 是目前主流的 HTTP 协议版本","categories":[{"name":"Web","slug":"Web","permalink":"http://arvin-he.github.io/categories/Web/"}],"tags":[{"name":"http","slug":"http","permalink":"http://arvin-he.github.io/tags/http/"}]},{"title":"Flask模板","slug":"flask-module-2017-04-05","date":"2017-04-05T03:07:17.000Z","updated":"2017-09-08T03:51:39.472Z","comments":true,"path":"2017/04/05/flask-module-2017-04-05/","link":"","permalink":"http://arvin-he.github.io/2017/04/05/flask-module-2017-04-05/","excerpt":"","text":"1. jinjia2模版分隔符jinjia2模版有两种分隔符 {% … %} # 用于执行类似 for 循环或者赋值的声明， {{ … }} # 用于输出表达的结果到模板中 2. 如何组织模版模板/目录结构反映应用程序的 URL 结构123456789101112templates/ layout.html index.html about.html profile/ layout.html index.html photos.html admin/ layout.html index.html analytics.html 3. 模版继承通常有一个顶层的 layout.html，它定义了应用程序的通用布局以及网站的每一部分。如果看看上面的目录的话，会看到一个顶层的 myapp/templates/layout.html，同样还有 myapp/templates/profile/layout.html 和myapp/templates/admin/layout.html。最后两个文件继承和修改第一个文件。继承是用 {% extends %} 和 {% block %} 标签实现的。 在父模板中，我们能定义由子模板来填充的块。123456789101112&#123;# _myapp/templates/layout.html_ #&#125;&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;title&gt;&#123;% block title %&#125;&#123;% endblock %&#125;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &#123;% block body %&#125; &lt;h1&gt;This heading is defined in the parent.&lt;/h1&gt; &#123;% endblock %&#125; &lt;/body&gt;&lt;/html&gt; 子模版1234567&#123;# _myapp/templates/index.html_ #&#125;&#123;% extends &quot;layout.html&quot; %&#125;&#123;% block title %&#125;Hello world!&#123;% endblock %&#125;&#123;% block body %&#125; &#123;&#123; super() &#125;&#125; &lt;h2&gt;This heading is defined in the child.&lt;/h2&gt;&#123;% endblock %&#125; super() 函数让我们渲染父级块的内容。 4. 创建宏宏就像由模板代码构成的函数。抽象出重复出现的代码片段到宏,以减少大量的重复代码.在应用程序导航的HTML上，需要给一个 “活跃的”链接一个 class(class=”active”)。没有宏的话，要编写一大段 if … else 语句检查每一个链接来找到正处于活跃的一个。宏提供了一种模块化代码的方式；像函数一样工作. 如何使用宏标记一个活跃的链接12345678910111213141516171819&#123;# myapp/templates/layout.html #&#125;&#123;% from &quot;macros.html&quot; import nav_link with context %&#125;&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &#123;% block head %&#125; &lt;title&gt;My application&lt;/title&gt; &#123;% endblock %&#125; &lt;/head&gt; &lt;body&gt; &lt;ul class=&quot;nav-list&quot;&gt; &#123;&#123; nav_link(&apos;home&apos;, &apos;Home&apos;) &#125;&#125; &#123;&#123; nav_link(&apos;about&apos;, &apos;About&apos;) &#125;&#125; &#123;&#123; nav_link(&apos;contact&apos;, &apos;Get in touch&apos;) &#125;&#125; &lt;/ul&gt; &#123;% block body %&#125; &#123;% endblock %&#125; &lt;/body&gt;&lt;/html&gt; 在模板中就是调用一个未定义的宏 - nav_link,并向其传递两个参数：目标端点（例如，目标视图的函数名）以及要显示的文本。 如何定义宏定义在模板中使用的 nav_link 宏123456789&#123;# myapp/templates/macros.html #&#125;&#123;% macro nav_link(endpoint, text) %&#125;&#123;% if request.endpoint.endswith(endpoint) %&#125; &lt;li class=&quot;active&quot;&gt;&lt;a href=&quot;&#123;&#123; url_for(endpoint) &#125;&#125;&quot;&gt;&#123;&#123;text&#125;&#125;&lt;/a&gt;&lt;/li&gt;&#123;% else %&#125; &lt;li&gt;&lt;a href=&quot;&#123;&#123; url_for(endpoint) &#125;&#125;&quot;&gt;&#123;&#123;text&#125;&#125;&lt;/a&gt;&lt;/li&gt;&#123;% endif %&#125;&#123;% endmacro %&#125; 注意:导入语句中指定了 with context。Jinja 的 context 是由传递到 render_template() 函数的参数以及来自Python代码的Jinja环境上下文组成。对于模板来说，这些变量在模板被渲染的时候是可用的。一些变量是明显地由我们传入，例如，render_template(“index.html”, color=”red”)，但是还有一些变量和函数是由 Flask 自动地包含在上下文中，例如，request, g 和 session。当我们说{% from ... import ... with context %}的时候，就是告诉 Jinja 这些变量对宏也可用。 5. 自定义过滤器过滤器就是由Python代码组成的函数并且能在模板中使用Jinja 过滤器是一个函数，它能够在{{ ... }}中用于处理一个表达式的结果。在表达式结果输出到模板之前它就被调用。1&lt;h2&gt;&#123;&#123; article.title|title &#125;&#125;&lt;/h2&gt; 在这段代码中，title 过滤器接收 article.title 作为参数并且返回一个过滤后的标题，接着过滤后的标题将会输出到模板中。这就像 UNIX 的“管道化”一个程序到另一个程序的输出。 现在要在myapp/util/filters.py 中定义我们的过滤器。这里给出一个 util 包，它里面有各种各样的模块。12345678# myapp/util/filters.pyfrom .. import app@app.template_filter()def caps(text): &quot;&quot;&quot;Convert a string to all caps.&quot;&quot;&quot; return text.uppercase() 在这段代码中我们使用 @app.template_filter() 装饰器注册我们的函数成一个 Jinja 过滤器。 默认的过滤器名称就是函数的名称，但是你可以传入一个参数到装饰器中来改变它。1234@app.template_filter(&apos;make_caps&apos;)def caps(text): &quot;&quot;&quot;Convert a string to all caps.&quot;&quot;&quot; return text.uppercase() 现在我们可以在模板中调用 make_caps 而不是caps：{{ &quot;hello world!&quot;|make_caps }}。为了要让我们的过滤器在模板中可用的话，我们只需要在我们的顶层 __init.py__ 的中导入它。1234# myapp/__init__.py# Make sure app has been initialized first to prevent circular imports.from .util import filters","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"},{"name":"Flask","slug":"Flask","permalink":"http://arvin-he.github.io/tags/Flask/"}]},{"title":"Flask环境设置","slug":"flask-setup-2017-04-04","date":"2017-04-04T06:46:19.000Z","updated":"2017-09-08T03:51:39.479Z","comments":true,"path":"2017/04/04/flask-setup-2017-04-04/","link":"","permalink":"http://arvin-he.github.io/2017/04/04/flask-setup-2017-04-04/","excerpt":"","text":"1. flask环境搭建 创建一个文件夹microblog: mkdir microblog 进入microblog目录中:cd microblog 在microblog创建虚拟环境: python -m venv flask, 该命令是在 flask 文件夹中创建一个完整的 Python 环境。如果你的python版本低于3.4(包括2.7),需要手动下载安装virtualenv,然后通过命令安装:virtualenv flask 虚拟环境是能够激活和关闭的,一个激活的环境可以将它的bin文件夹加到系统路径.但我不喜欢这个特色,所以我从来不激活任何环境,通过输入我想调用的解释器的路径.如想要使用pip工具,则我会输入:flask/scripit/pip install [packagename] 安装flask及扩展 123456789101112$ flask\\Scripts\\pip install flask$ flask\\Scripts\\pip install flask-login$ flask\\Scripts\\pip install flask-openid$ flask\\Scripts\\pip install flask-mail$ flask\\Scripts\\pip install flask-sqlalchemy$ flask\\Scripts\\pip install sqlalchemy-migrate$ flask\\Scripts\\pip install flask-whooshalchemy$ flask\\Scripts\\pip install flask-wtf$ flask\\Scripts\\pip install flask-babel$ flask\\Scripts\\pip install guess_language$ flask\\Scripts\\pip install flipflop$ flask\\Scripts\\pip install coverage 现在你的microblog文件夹下有一个flask子文件夹,这个flask子文件夹中有python解释器以及flask框架和扩展,环境搭建好后就可以使用flask去创建web应用程序了.","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"},{"name":"Flask","slug":"Flask","permalink":"http://arvin-he.github.io/tags/Flask/"}]},{"title":"Python Coroutine(协程)浅析","slug":"python-coroutine-2017-04-03","date":"2017-04-03T02:28:07.000Z","updated":"2017-09-08T03:51:40.007Z","comments":true,"path":"2017/04/03/python-coroutine-2017-04-03/","link":"","permalink":"http://arvin-he.github.io/2017/04/03/python-coroutine-2017-04-03/","excerpt":"","text":"1. 协程简介协程，即协作式程序，又称微线程、纤程，英文名Coroutine。思想是，一系列互相依赖的协程间依次使用CPU，每次只有一个协程工作，而其他协程处于休眠状态。协程可以在运行期间的某个点上暂停执行，并在恢复运行时从暂停的点上继续执行。协程已经被证明是一种非常有用的程序组件，不仅被python、lua、ruby等脚本语言广泛采用，而且被新一代面向多核的编程语言如golang rust-lang等采用作为并发的基本单位。协程可以被认为是一种用户空间线程，与传统的线程相比，有2个主要的优点： 与线程不同，协程是自己主动让出CPU，并交付他期望的下一个协程运行，而不是在任何时候都有可能被系统调度打断。因此协程的使用更加清晰易懂，并且多数情况下不需要锁机制。 与线程相比，协程的切换由程序控制，发生在用户空间而非内核空间，因此切换的代价非常小。总结起来是一句话：协程可以认为是一种用户态线程，与系统提供的线程不同点是，它需要主动让出CPU时间，而不是由系统进行调度，即控制权在程序员手上。 2. Python协程史 Python 2.2 中的生成器让代码执行过程可以暂停 (yield) Python 2.5 中可以将值返回给暂停的生成器，这使得 Python 中协程的概念成为可能 (send) Python 3.3 中的 yield from，使得重构生成器与将它们串联起来都很简单 (yield from) Python 3.4 以后通过标准库 asyncio 获得了事件循环的特性 (asyncio) Python 3.5 使用async/await语法引入对协程的显式支持 (async/await) Python 3.6 增强asyncio，支持异步生成器、异步解析式 3. yield关键字为了理解什么是 yield, 你必须理解什么是生成器(generator)。关于生成器我的理解是是：生成器保存的是算法，需要时再计算(惰性计算)创建生成器有两种方式：第一种方法：把一个列表生成式的[]改成()，就创建了一个generator：12l = [x * x for x in range(10)] # l [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]g = (x * x for x in range(10)) # g &lt;generator object &lt;genexpr&gt; at 0x1022ef630&gt; 第二种方式：在函数中使用yield关键字，函数就变成了一个generator。函数里有了yield后，执行到yield就会停住，当需要再往下算时才会再往下算。所以生成器函数即使是有无限循环也没关系，它需要算到多少就会算多少，不需要就不往下算。例如你想要自己实现一个 range() 函数，你可以用立即计算的方式创建一个整数列表：12345678910def eager_range(up_to): \"\"\"Create a list of integers, from 0 to up_to, exclusive.\"\"\" sequence = [] index = 0 while index &lt; up_to: sequence.append(index) index += 1 return sequencel = eager_range(1000000) 然而这里存在的问题是，如果你想创建从0到1,000,000这样一个很大的序列，你不得不创建能容纳1,000,000个整数的列表。但是当加入了生成器之后，你可以不用创建完整的序列，你只需要能够每次保存一个整数的内存即可。 12345678910111213141516def lazy_range(up_to): \"\"\"Generator to return the sequence of integers from 0 to up_to, exclusive.\"\"\" index = 0 while index &lt; up_to: yield index index += 1g = lazy_range(1000000) # &lt;generator object lazy_range at 0x040A25D0&gt;next(g).........next(g)Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;StopIteration 让函数遇到 yield 表达式时暂停执行 – 虽然在 Python 2.5 以前它只是一条语句 – 并且能够在后面重新执行，这对于减少内存使用、生成无限序列非常有用。你有可能已经发现，生成器完全就是关于迭代器的。有一种更好的方式生成迭代器当然很好（尤其是当你可以给一个生成器对象添加 iter() 方法时），但是人们知道，如果可以利用生成器“暂停”的部分，添加“将东西发送回生成器”的功能，那么 Python 突然就有了协程的概念（当然这里的协程仅限于 Python 中的概念；Python 中真实的协程在后面才会讨论）。将东西发送回暂停了的生成器这一特性通过 PEP 342添加到了 Python 2.5。与其它特性一起，PEP 342 为生成器引入了 send() 方法。这让我们不仅可以暂停生成器，而且能够传递值到生成器暂停的地方。还是以我们的 range() 为例，你可以让序列向前或向后跳过几个值： 123456789101112131415161718def jumping_range(up_to): \"\"\"Generator for the sequence of integers from 0 to up_to, exclusive. Sending a value into the generator will shift the sequence by that amount. \"\"\" index = 0 while index &lt; up_to: jump = yield index if jump is None: jump = 1 index += jumpiterator = jumping_range(5)print(next(iterator)) # 0print(iterator.send(2)) # 2print(next(iterator)) # 3print(iterator.send(-1)) # 2for x in iterator: print(x) # 3, 4 其实next()和send()在一定意义上作用是相似的，区别是send()可以传递yield表达式的值进去，而next()不能传递特定的值，只能传递None进去。 因此，我们可以看做next(g) == g.send(None) 需要注意的是，第一次调用时，请使用next()语句或是send(None)，不能使用send发送一个非None的值，否则会出错，因为没有yield语句来接收这个值。 4. yield from在PEP 380 为 Python 3.3 添加了 yield from之前，生成器都没有变动。严格来说，这一特性让你能够从迭代器（生成器刚好也是迭代器）中返回任何值，从而可以干净利索的方式重构生成器。 1234yield from iterator# (本质上)相当于：for x in iterator: yield x 12345678def lazy_range(up_to): \"\"\"Generator to return the sequence of integers from 0 to up_to, exclusive.\"\"\" index = 0 def gratuitous_refactor(): while index &lt; up_to: yield index index += 1 yield from gratuitous_refactor() yield from 通过让重构变得简单，也让你能够将生成器串联起来，使返回值可以在调用栈中上下浮动，而不需对编码进行过多改动。 12345678910111213141516171819def bottom(): \"\"\"Returning the yield lets the value that goes up the call stack to come right back down\"\"\" return (yield 42)def middle(): return (yield from bottom())def top(): return (yield from middle())# Get the generator.gen = top()value = next(gen)print(value) # Prints '42'.try: value = gen.send(value * 2)except StopIteration as exc: value = exc.valueprint(value) # Prints '84'. 5. asyncioasyncio是一个基于事件循环的异步I/O库，Python3.4将其引入标准库，Python3.3可通过pip安装asyncio包括的内容很多很复杂，这里只会做基本的两点：协同程序和事件循环。 协程的基本概念前面已经讲过，这里先来说一下事件循环通俗来说，事件循环 “是一种等待程序分配事件或消息的编程架构”，其提供一种循环机制，让你可以“在A发生时，执行B”。基本上来说事件循环就是监听当有什么发生时，同时事件循环也关心这件事并执行相应的代码，本质上是以队列的方式来重新分配时间片。在asyncio中事件循环扮演的是个调度器的角色，被用来安排协同程序的执行。PEP 342中通过asyncio.coroutine装饰的函数为协程，这里的协程是和asyncio及其事件循环一起使用的。这赋予了 Python 第一个对于协程的明确定义，也就是基于生成器的协程这意味着突然之间所有实现了协程接口的生成器，即便它们并不是要以协程方式应用，都符合这一定义。为了修正这一点，asyncio 要求所有要用作协程的生成器必须由asyncio.coroutine修饰。 使用以下语法声明生成器协程： 123456@asyncio.coroutinedef generator_coroutine(): passa = generator_coroutine()print(a) # &lt;generator object coro at 0x040F0B48&gt; yield from在asyncio模块中得以发扬光大。通过yield from，我们可以用asyncio.sleep将协程控制权交给事件循环，然后挂起当前协程；之后，由事件循环决定何时唤醒asyncio.sleep,接着向后执行代码。先看示例代码： 123456789101112131415import asyncio@asyncio.coroutinedef countdown(number, n): while n &gt; 0: print('T-minus', n, '(&#123;&#125;)'.format(number)) yield from asyncio.sleep(1) n -= 1loop = asyncio.get_event_loop()tasks = [ asyncio.ensure_future(countdown(\"A\", 2)), asyncio.ensure_future(countdown(\"B\", 3))]loop.run_until_complete(asyncio.wait(tasks))loop.close() 在解释上面例子之前，需要先简单了解一下asyncio.Future Future可以理解为延迟结果的抽象，在其他语言中也称作Promise.你可以对任何asyncio.Future对象使用 yield from，从而将其传递给事件循环，暂停协程的执行来等待某些事情的发生（ future 对象并不重要，只是asyncio细节的实现）。一旦 future 对象获取了事件循环，它会一直在那里监听，直到完成它需要做的一切。当 future 完成自己的任务之后，事件循环会察觉到，暂停并等待在那里的协程会通过send()方法获取future对象的返回值并开始继续执行。 以上面的代码为例, 事件循环启动每一个 countdown() 协程，一直执行到遇见其中一个协程的 yield from 和 asyncio.sleep() 。这样会返回一个 asyncio.Future对象并将其传递给事件循环，同时暂停这一协程的执行。事件循环会监控这一future对象，直到倒计时1秒钟之后（同时也会检查其它正在监控的对象，比如像其它协程）。1秒钟的时间一到，事件循环会选择刚刚传递了future对象并暂停了的 countdown() 协程，将future对象的结果返回给协程，然后协程可以继续执行。这一过程会一直持续到所有的 countdown() 协程执行完毕，事件循环也被清空。稍后我会给你展示一个完整的例子，用来说明协程/事件循环之类的这些东西究竟是如何运作的，但是首先我想要解释一下async和await。 关于asyncio这里只做了简单的介绍，它其实包括以下内容，大家可以去查看官方文档： 事件循环 任务和协程 传输和协议 基于协程的流 子进程 同步原语 队列 6. async与awaitPEP 492引入async/await语法，中明确了协程类型(原生协程)，用于区别于基于生成器的协程在以前，我们可以用生成器实现协程（PEP 342），后来又对其进行了改进，引入了yield from语法（PEP 380）。但仍有一些缺点： 协程和普通生成器使用相同的语法，所以很容易把它们搞混，初学者更是如此。 一个函数是否是一个协程，取决于它里面是否出现了yield或yield from语句。这并不明显，容易在重构函数的时候搞乱，导致出错。 异步调用被yield语法限制了，我们不能获得、使用更多的语法特性，比如with和for。这个PEP把协程从生成器独立出来，成为Python的一个原生事物。这会消除协程和生成器之间的混淆，方便编写不依赖特定库的协程代码。使用以下语法声明原生协程： 12345async def native_coroutine(): passa = native_coroutine()print(a) # &lt;coroutine object a at 0x000000000567EFC0&gt; 原生协程语法的关键点： async def函数必定是协程，即使里面不含有await语句。 如果在async函数里面使用yield或yield from语句，会引发SyntaxError异常。 协程在调用时会返回一个coroutine对象 协程不再抛出StopIteration异常，而是替代为RuntimeError 当协程进行垃圾回收时，一个从未被await的协程会抛出RuntimeWarning异常 await表达式下面新的await表达式用于获取协程执行结果：123async def read_data(db): data = await db.fetch('SELECT ...') pass await与yield from相似，挂起read_data协程的执行直到db.fetch这个awaitable对象完成并返回结果数据。原生协程与生成器协程的区别与联系 原生协程对象不实现__iter__和__next__方法。因此，他们不能够通过iter()，list()，tuple()和其他一些内置函数进行迭代。他们也不能用于for…in循环。在原生协程中尝试使用__iter__或者__next会触发TypeError异常。 未被装饰的生成器不能够yield from一个原生协程：这样会引发TypeError。 基于生成器的协程(asyncio代码必须使用@asyncio.coroutine)可以yield from一个原生协程。 对原生协程对象和原生协程函数调用inspect.isgenerator()和inspect.isgeneratorfunction()会返回False。 协程内部基于生成器，原生协程与生成器协程共享实现过程。类似于生成器对象，原生协程包含throw()，send()和close()方法。 7. 异步生成器与异步解析式PEP 492 引入支持原生协程和async /await的语法到Python 3.5。 在Python 3.5实现里的一个值得注意的局限性就在于它不可能使用await和yield在同一个函数体中。而在Python 3.6中，这个限制已解除，这使得定义异步生成器成为可能：12345async def ticker(delay, to): \"\"\"Yield numbers from 0 to *to* every *delay* seconds.\"\"\" for i in range(to): yield i await asyncio.sleep(delay) PEP 530 添加了对async for在list、set、dict解析式以及generator表达式中的使用支持： result = [i async for i in aiter() if i % 2]此外，所有解析式都支持“await”表达式： result = [await fun() for fun in funcs if await condition()] 8. gevent使用gevent是一个基于协同的Python网络库，它使用greenlet在libev事件循环之上提供高级同步API。主要特性： 基于libev的快速事件循环 基于greenlet的轻量级执行单元 重用python标准api(event,queue) 协同的socket和ssl模块 使用标准库和第三方模块写标准阻塞socket(gevent.monkey) 通过线程池或c-ares执行的DNS查询。 内置TCP/UDP/HTTP服务器 支持子进程(gevent.subprocess) 支持线程池 下面简单介绍gevent的使用gevent.spawn(function, args, **kwargs)创建一个新的Greenlet对象并安排它运行function(args，**kwargs)注意：这时function还没有启动，它的运行依赖于gevent的事件循环，只有启动事件循环，它才会被调度gevent.sleep(seconds=0)将当前的greenlet睡眠seconds秒使用gevent.sleep相当于切换上下文，让出执行权gevent.joinall等待多个greenlet执行结束有时需要知道greenlet运行的状态，在greenlet中有一些标志， 让你可以监视它的线程内部状态: started – Boolean, 指示此Greenlet是否已经启动 ready() – Boolean, 指示此Greenlet是否已经停止 successful() – Boolean, 指示此Greenlet是否已经停止而且没抛异常 value – 任意值, 此Greenlet代码返回的值 exception – 异常, 此Greenlet内抛出的未捕获异常 更多gevent api介绍 参考文档 Python官方文档 PEP 255 – Simple Generators PEP 342 – Coroutines via Enhanced Generators PEP 380 – Syntax for Delegating to a Subgenerator PEP 3156 – Asynchronous IO Support Rebooted: the “asyncio” Module PEP 492 – Coroutines with async and await syntax 廖雪峰Python教程 PEP 525 PEP 530 Python 3.5协程原理 gevent官方文档 gevent教程","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Python之列表解析式","slug":"python-listgeneration-2017-04-02","date":"2017-04-02T12:06:51.000Z","updated":"2017-09-08T03:51:40.088Z","comments":true,"path":"2017/04/02/python-listgeneration-2017-04-02/","link":"","permalink":"http://arvin-he.github.io/2017/04/02/python-listgeneration-2017-04-02/","excerpt":"","text":"列表解析式概念列表解析式是将一个列表（实际上适用于任何可迭代对象（iterable））转换成另一个列表的工具。在转换过程中，可以指定元素必须符合一定的条件，才能添加至新的列表中，这样每个元素都可以按需要进行转换。如果熟悉函数式编程（functional programming），可以把列表解析式看作为结合了filter函数与map函数功能的语法糖： 列表解析式应用列表解析式可用来过滤列表中的元素,而不必使用循环加判断的方式 循环与解析式每个列表解析式都可以重写为for循环，但不是每个for循环都能重写为列表解析式。 无条件子句的列表解析式12&gt;&gt;&gt; list(range(1, 11))[1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 嵌套循环示例如下:123# 使用两层循环，生成全排列&gt;&gt;&gt; [m + n for m in 'ABC' for n in 'XYZ']['AX', 'AY', 'AZ', 'BX', 'BY', 'BZ', 'CX', 'CY', 'CZ'] 下面是一个拉平（flatten）矩阵（以列表为元素的列表）的for循环：1234flattened = []for row in matrix: for n in row: flattened.append(n) 下面这个列表解析式实现了相同的功能：flattened = [n for row in matrix for n in row] 如果要在列表解析式中处理嵌套循环，请记住for循环子句的顺序与我们原来for循环的顺序是一致的。若写成flattened = [n for n in row for row in matrix]则是错误的.同样地原则也适用集合解析式（set comprehension）和字典解析式（dictionary comprehension）。 带条件子句的列表解析式列表生成式可用来过滤列表中的元素123# for循环后面还可以加上if判断&gt;&gt;&gt; [x * x for x in range(1, 11) if x % 2 == 0][4, 16, 36, 64, 100] 字典解析式1flipped = &#123;value: key for key, value in original.items()&#125; 注意可读性Python支持在括号和花括号之间断行123456789101112131415doubled_odds = [ n * 2 for n in numbers if n % 2 == 1]flattened = [ n for row in matrix for n in row]flipped = &#123; value: key for key, value in original.items()&#125; 参考文档 Python官方文档 廖雪峰Python教程 http://codingpy.com/article/python-list-comprehensions-explained-visually/","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Python使用","slug":"python-skills-2017-04-01","date":"2017-04-01T07:41:13.000Z","updated":"2017-09-08T03:51:40.152Z","comments":true,"path":"2017/04/01/python-skills-2017-04-01/","link":"","permalink":"http://arvin-he.github.io/2017/04/01/python-skills-2017-04-01/","excerpt":"","text":"1. windows下Python2与Python3共存的使用方法windows下同时安装了Python2.7.13与Python3.6后,默认的使用python2. 命令行分别使用python2和python3 调用python2,使用 py -2 调用python3,使用 py -3 使用pip安装库 安装到Python2时，就使用 pip2 install [name] 安装到Python3时，就使用pip3 install [name] 2. pip工具使用pip 命令使用: pip [options]12345678910111213Commands: install Install packages. download Download packages. uninstall Uninstall packages. freeze Output installed packages in requirements format. list List installed packages. show Show information about installed packages. check Verify installed packages have compatible dependencies. search Search PyPI for packages. wheel Build wheels from your requirements. hash Compute hashes of package archives. completion A helper command used for command completion. help Show help for commands. 3. Windows下python非官方第三方包地址Windows下python非官方第三方包地址 4. python中的对象引用python中set,list,tuple,dict都是表示对象,这些对象在给新对象赋值的时候是传递引用,并不是传值. 5. 返回值问题有时在一个循环里计算,然后将计算的结果一起返回,注意return语句的位置,不能放在循环里.尤其注意在循环语句比较多的情况下. 6. Python 按给定的长度分割字符串123456import reaa = 'asdf21232465'b=re.findall(r'.&#123;2&#125;',aa)print b# orprint [aa[i:i+2] for i in range(0, len(aa), 2)]","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://arvin-he.github.io/tags/Python/"}]},{"title":"Git命令使用","slug":"gitcmd-2017-03-31","date":"2017-03-31T01:47:37.000Z","updated":"2017-09-08T03:51:39.492Z","comments":true,"path":"2017/03/31/gitcmd-2017-03-31/","link":"","permalink":"http://arvin-he.github.io/2017/03/31/gitcmd-2017-03-31/","excerpt":"","text":"简介版本管理基本上是多人协作开发中必不可少的工具，常用的版本管理工具有：svn和git。虽然都有可视化的工具帮助我们使用这些工具，然而当你用上命令行之后，我想你会选择抛弃这些可视化工具。下面是我整理的一些常用的Git命令。 一个比较全面很好的Git书: Git Pro 第二版 一些概念: 工作区与暂存区Git和其他版本控制系统如SVN的一个不同之处就是有暂存区的概念。工作区就是你在电脑里能看到的目录，比如我的testgit文件夹就是一个工作区,但不包括.git这个隐藏目录.工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。Git的版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的暂存区，还有Git为我们自动创建的第一个分支master，以及指向master的一个指针叫HEAD。 我们把文件往 Git 版本库里添加的时候，是分两步执行的：第一步是用git add把文件添加进去，实际上就是把文件修改添加到暂存区；第二步是用git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支。因为我们创建Git版本库时，Git自动为我们创建了唯一一个master分支，所以现在git commit就是往master分支上提交更改。可以简单理解为，git add命令实际上就是把要提交的所有修改放到暂存区（Stage），然后执行git commit就可以一次性把暂存区的所有修改提交到分支。一旦提交后，如果你又没有对工作区做任何修改，那么工作区就是“干净”的。 global选项配置Git的时候，加上–global是针对当前用户起作用的，如果不加，那只针对当前的仓库起作用 1. 配置Git邮箱和用户名, 因为每一次提交都需要这些信息12$ git config --global user.name &quot;John Doe&quot;$ git config --global user.email johndoe@example.com 注意:如果用了 –global 选项，那么更改的配置文件就是位于你用户主目录下的那个，以后你所有的项目都会默认使用这里配置的用户信息。如果要在某个特定的项目中使用其他名字或者电邮，只要去掉 –global 选项重新配置即可，新的设定保存在当前项目的 .git/config 文件里。 2. 查看git配置信息123git config --list #检查已有的配置信息git config user.name #查看git用户名git config user.email #查看git邮箱 3. 在本地保存github帐号的用户名和密码,不用每次输入用户名和密码使用https协议时,在向远程仓库push提交内容时,总是每次要求输入你的github用户名和密码解决办法: 设置记住密码（默认15分钟） 1git config --global credential.helper cache 自己设置记住密码时间,比如一小时 1git config credential.helper ‘cache --timeout=3600’ 长期存储密码 1git config --global credential.helper store 配置好后在 .gitconfig 文件中可以看到. 4. 配置github上ssh密匙,不用每次输入用户名和密码使用ssh协议时,也要输入用户名和密码,要想不用每次输入用户名和密码,则在你的本地机器生成ssh的私匙和公匙,私匙保存在本地机器,公匙保存在你的github网站上的帐号设置上. 创建SSH Key在用户主目录下，看看有没有.ssh目录，如果有，再看看这个目录下有没有id_rsa和id_rsa.pub这两个文件，如果已经有了，可直接跳到下一步。如果没有，打开Shell（Windows下打开Git Bash），创建SSH Key： 1$ ssh-keygen -t rsa -C &quot;youremail@example.com&quot; 登陆GitHub，打开“Settings”，“SSH and GPG Keys”页面 点击“New SSH Key”，填上任意Title，在Key文本框里粘贴id_rsa.pub文件的内容 5. 移除跟踪但不删除文件，以便稍后在 .gitignore 文件中补上，用 –cached 选项即可1git rm --cached readme.txt 6. 修改.gitignore并更新本地和远程仓库 在.gitignore修改过滤规则,并保存. 更新本地和远程仓库1234# 注意有个点“.”git rm -r --cached .git add -Agit commit -m &quot;update .gitignore&quot; 配置.gitignore所有配置文件可以直接在线浏览：https://github.com/github/gitignore当然也可以配置全局忽略的文件，这样就不用每个项目都加gitignore了：git config --global core.excludesfile &#39;~/.gitignore&#39; 7. 丢弃本地修改,使用远程仓库的内容1234git fetch --allgit reset --hard origin/mastergit fetch 只是下载远程的库的内容，不做任何的合并,git reset 把HEAD指向刚刚下载的最新的版本 8. 本地仓库首次推送到github远程仓库 在github上建立一个和本地同名的仓库名称 在本地命令行输入:git remote add origin 远程仓库地址 将本地仓库同步到github远程仓库:git push -u origin master 9. 恢复本地删除的文件恢复已commit的文件:Git checkout commit_id -- file_name恢复未commit的文件:git checkout -- file_name 10. 打标签123456789101112131415git tag #显示已有标签git tag -l &apos;v1.4.2.*&apos; #用特定的搜索模式列出符合条件的标签#创建一个含附注类型的标签,-a （译注：取 annotated 的首字母）指定标签名字,-m 选项则指定了对应的标签说明git tag -a v1.4 -m &apos;my version 1.4&apos; git show v1.4 #查看相应标签的版本信息，并连同显示打标签时的提交对象git tag v1.4 #创建轻量级标签,一个 -a，-s 或 -m 选项都不用，直接给出标签名字即可git push origin v1.5 #默认情况下，git push 并不会把标签传送到远端服务器上，只有通过显式命令才能分享标签到远端仓库git push origin --tags # 一次推送所有本地新增的标签，可以使用 --tags 选项# 删除标签git tag -d v0.1 # 删除远程仓库标签,先从本地删除,再从远程删除git tag -d v0.9git push origin :refs/tags/v0.9 11. git将本地仓库上传到远程仓库本地新建了一个文件夹,并执行了git init,初始化为一个git仓库了, 然后add,再commit后,想要把本地仓库内容上传到github上去,但此时github上没有这个仓库.因此先到github上创建与你本地仓库同名的仓库,此时还是一个空仓库,需要把本地的内容上传到github上123git remote add origin https://github.com/yourname/yourrepo.gitgit push -u origin master # 第一次推送master分支时，加上了-u参数git push origin master 12. 版本回退在 Git中，用HEAD表示当前版本，也就是最新的提交commit id，上一个版本就是HEAD^，上上一个版本就是HEAD^^，往上100个版本写100个^比较容易数不过来，所以写成HEAD~100。12345678910# 查看日志git log# 简化日志信息git log --pretty=oneline# 当前版本回退到上一个版本，就可以使用git reset命令:git reset --hard HEAD^# 当前版本是过去的某个版本,想回到当前版本的之后的版本git reset --hard 2e70fdf(commit id) 撤销修改12# 把readme.md文件在工作区的修改全部撤销，即让这个文件回到最近一次git commit或git add时的状态,也可使用resetgit checkout -- readme.md Git显示颜色，会让命令输出看起来更醒目1git config --global color.ui true fatal: remote origin already exists 如果输入$ Git remote add origin git@github.com:djqiang（github帐号名）/gitdemo（项目名）.git提示出错信息：fatal: remote origin already exists. 解决办法如下：1.先输入$ git remote rm origin 2.再输入$ git remote add origin git@github.com:djqiang/gitdemo.git 就不会报错了！ 3.如果输入$ git remote rm origin 还是报错的话，error: Could not remove config section ‘remote.origin’. 我们需要修改gitconfig文件的内容 4.找到你的github的安装路径，我的是C:\\Users\\ASUS\\AppData\\Local\\GitHub\\PortableGit_ca477551eeb4aea0e4ae9fcd3358bd96720bb5c8\\etc 5.找到一个名为gitconfig的文件，打开它把里面的[remote “origin”]那一行删掉就好了！ 使用git在本地创建一个项目的过程123456789101112131415# 创建一个项目hello-world$ makdir ~/hello-world # 打开这个项目$ cd ~/hello-world # 初始化 $ git init $ touch README# 更新README文件$ git add README # 提交更新，并注释信息“first commit” $ git commit -m &apos;first commit&apos;# 连接远程github项目 $ git remote add origin git@github.com:defnngj/hello-world.git # 将本地项目更新到github项目上去$ git push -u origin master 如果输入$ git push origin master提示出错信息：error:failed to push som refs to …解决办法如下： 先输入$ git pull origin master //先把远程服务器github上面的文件拉下来 再输入$ git push origin master 如果出现报错 fatal: Couldn’t find remote ref master或者fatal: ‘origin’ does not appear to be a git repository以及fatal: Could not read from remote repository. 则需要重新输入$ git remote add origin git@github.com:djqiang/gitdemo.git","categories":[{"name":"工具","slug":"工具","permalink":"http://arvin-he.github.io/categories/工具/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://arvin-he.github.io/tags/Git/"}]},{"title":"正则表达式使用","slug":"reg-tutorial-2017-03-30","date":"2017-03-30T05:58:36.000Z","updated":"2017-09-08T03:51:40.176Z","comments":true,"path":"2017/03/30/reg-tutorial-2017-03-30/","link":"","permalink":"http://arvin-he.github.io/2017/03/30/reg-tutorial-2017-03-30/","excerpt":"1. 常用元字符 元字符 说明 . 匹配除换行符以外的任意字符 \\w 匹配字母或数字或下划线或汉字 \\s 匹配任意的空白符 \\d 匹配数字 \\b 匹配单词的开始或结束 ^ 匹配字符串的开始 $ 匹配字符串的结束","text":"1. 常用元字符 元字符 说明 . 匹配除换行符以外的任意字符 \\w 匹配字母或数字或下划线或汉字 \\s 匹配任意的空白符 \\d 匹配数字 \\b 匹配单词的开始或结束 ^ 匹配字符串的开始 $ 匹配字符串的结束 \\b 代表着单词的开头或结尾,即单词的分界处.通常英文的单词是由空格,标点符号或者换行来分隔的,但是\\b并不匹配这些单词分隔字符中的任何一个,它只匹配一个位置. . 点号也是一个元字符,匹配除换行符意外的任意任意字符. * 星号元字符,代表的不是字符,也不是位置,而是数量.它指定*前面的内容可以连续重复使用任意次数来使整个表达式得到匹配. .* 则表示匹配任意数量的不包含换行的字符 \\d 元字符,匹配一位数字 \\s 匹配任意的空白符,包括空格,制表符(Tab),换行符,中文全角空格等. \\w 匹配字母,数字,下划线或汉字等. \\d+ 匹配1个或者更多连续的数字 + 与 * 的区别: * 匹配重复任意次,也可能是0次 + 匹配重复1次或更多次 2. 字符转义查找匹配.或或\\等字符就得使用\\来取消这些字符的特殊意义,因为它们会被解释成别的意思。因此，应该使用.和\\和\\. 例如：C:\\Windows匹配C:\\Windows。 3. 重复匹配次数的限定符 代码/语法 说明 * 重复零次或更多次 + 重复一次或更多次 ? 重复零次或一次 {n} 重复n次 {n,} 重复n次或更多次 {n,m} 重复n到m次 4. 指定匹配范围匹配在指定字符范围或集合中的一个字符,用[指定你的字符范围或集合]如[aeiou] 匹配任何一个英文元音字母[.?!] 匹配标点符号(.或?或!)[0-9]代表的含意与\\d就是完全一致的：匹配一位数字 5. 多条件匹配多条件匹配,如果满足其中任意一个匹配条件则匹配,多个匹配条件使用|将多个匹配条件隔开.注意: 使用多条件匹配要注意各个条件的顺序,多条件匹配是从左到右地测试每个条件，如果满足了某个条件，就不会去再管其它的条件了。例如:\\d{5}-\\d{4}|\\d{5}这个表达式用于匹配美国的邮政编码。美国邮编的规则是5位数字，或者用连字号间隔的9位数字。如果你把它改成\\d{5}|\\d{5}-\\d{4}的话，那么就只会匹配5位的邮编(以及9位邮编的前5位)。 6. 分组重复单个字符: 直接在字符后面加上限定符重复多个字符: 使用括号指定子表达式,再对这个子表达式加次数限定符组号分配原则：分组0对应整个正则表达式实际上组号分配过程是要从左向右扫描两遍的：第一遍只给未命名组分配，第二遍只给命名组分配－－因此所有命名组的组号都大于未命名的组号你可以使用(?:exp)这样的语法来剥夺一个分组对组号分配的参与权例如:匹配IP((2[0-4]\\d|25[0-5]|[01]?\\d\\d?).){3}(2[0-4]\\d|25[0-5]|[01]?\\d\\d?)常用分组语法: 分类 语法 说明 捕获 (exp) 匹配exp,并捕获文本到自动命名的组里 捕获 (?exp) 匹配exp,并捕获文本到名称为name的组里，也可以写成(?’name’exp) 捕获 (?:exp) 匹配exp,不捕获匹配的文本，也不给此分组分配组号 零宽断言 (?=exp) 匹配exp前面的位置 零宽断言 (?&lt;=exp) 匹配 exp后面的位置 零宽断言 (?!exp) 匹配后面跟的不是exp的位置 零宽断言 (?&lt;!exp) 匹配前面不是exp的位置 注释 (?#comment) 这种类型的分组不对正则表达式的处理产生任何影响，用于提供注释让人阅读 第三个(?:exp)不会改变正则表达式的处理方式，只是这样的组匹配的内容不会像前两种那样被捕获到某个组里面，也不会拥有组号。 7. 反义有时需要查找不属于某个能简单定义的字符类的字符。比如想查找除了数字以外，其它任意字符都行的情况.常用到的反义： 语法 说明 \\W 匹配任意不是字母，数字，下划线，汉字的字符 \\S 匹配任意不是空白符的字符 \\D 匹配任意非数字的字符 \\B 匹配不是单词开头或结束的位置 例如:[^x] 匹配除了x以外的任意字符[^aeiou] 匹配除了aeiou这几个字母以外的任意字符 8. 后向引用使用小括号指定一个子表达式后，匹配这个子表达式的文本(也就是此分组捕获的内容)可以在表达式或其它程序中作进一步的处理。默认情况下，每个分组会自动拥有一个组号，规则是：从左向右，以分组的左括号为标志，第一个出现的分组的组号为1，第二个为2，以此类推。后向引用用于重复搜索前面某个分组匹配的文本。 你也可以自己指定子表达式的组名。指定一个子表达式的组名语法：(?\\w+)(或者把尖括号换成’也行：(?’Word’\\w+)),这样就把\\w+的组名指定为Word了。要反向引用这个分组捕获的内容，你可以使用\\k,所以上一个例子也可以写成这样：\\b(?\\w+)\\b\\s+\\k\\b。 9. 注释小括号的另一种用途是通过语法(?#comment)来包含注释 要包含注释的话，最好是启用“忽略模式里的空白符”选项，这样在编写表达式时能任意的添加空格，Tab，换行，而实际使用时这些都将被忽略。启用这个选项后，在#后面到这一行结束的所有文本都将被当成注释忽略掉。例如，我们可以前面的一个表达式写成这样：(?&lt;= # 断言要匹配的文本的前缀&lt;(\\w+)&gt; # 查找尖括号括起来的字母或数字(即HTML/XML标签)) # 前缀结束.* # 匹配任意文本(?= # 断言要匹配的文本的后缀&lt;\\/\\1&gt; # 查找尖括号括起来的内容：前面是一个”/“，后面是先前捕获的标签) # 后缀结束 10. 贪婪与懒惰正则表达式通常的行为是贪婪匹配贪婪匹配:一次匹配尽可能多的字符懒惰匹配:一次匹配尽可能少的字符贪婪匹配转懒惰匹配:只要在后面加上?懒惰限定符: 语法 说明 *? 重复任意次，但尽可能少重复 +? 重复1次或更多次，但尽可能少重复 ?? 重复0次或1次，但尽可能少重复 {n,m}? 重复n到m次，但尽可能少重复 {n,}? 重复n次以上，但尽可能少重复 11. 处理选项 名称 说明 IgnoreCase(忽略大小写) 匹配时不区分大小写。 Multiline(多行模式) 更改^和$的含义,使它们分别在任意一行的行首和行尾匹配,而不仅仅在整个字符串的开头和结尾匹配。(在此模式下,$的精确含意是:匹配\\n之前的位置以及字符串结束前的位置.) Singleline(单行模式) 更改.的含义，使它与每一个字符匹配（包括换行符\\n）。 IgnorePatternWhitespace(忽略空白) 忽略表达式中的非转义空白并启用由#标记的注释。 ExplicitCapture(显式捕获) 仅捕获已被显式命名的组。 12. 递归匹配/平衡组 语法 说明 (?’group’) 把捕获的内容命名为group,并压入堆栈(Stack) (?’-group’) 从堆栈上弹出最后压入堆栈的名为group的捕获内容，如果堆栈本来为空，则本分组的匹配失败 (?(group)yes&#124;no) 如果堆栈上存在以名为group的捕获内容的话，继续匹配yes部分的表达式，否则继续匹配no部分 (?!) 零宽负向先行断言，由于没有后缀表达式，试图匹配总是失败 我们需要做的是每碰到了左括号，就在压入一个”Open”,每碰到一个右括号，就弹出一个，到了最后就看看堆栈是否为空－－如果不为空那就证明左括号比右括号多，那匹配就应该失败。正则表达式引擎会进行回溯(放弃最前面或最后面的一些字符)，尽量使整个表达式得到匹配。123456789101112131415&lt; #最外层的左括号 [^&lt;&gt;]* #最外层的左括号后面的不是括号的内容 ( ( (?&apos;Open&apos;&lt;) #碰到了左括号，在黑板上写一个&quot;Open&quot; [^&lt;&gt;]* #匹配左括号后面的不是括号的内容 )+ ( (?&apos;-Open&apos;&gt;) #碰到了右括号，擦掉一个&quot;Open&quot; [^&lt;&gt;]* #匹配右括号后面不是括号的内容 )+ )* (?(Open)(?!)) #在遇到最外层的右括号前面，判断黑板上还有没有没擦掉的&quot;Open&quot;；如果还有，则匹配失败&gt; #最外层的右括号 平衡组的一个最常见的应用就是匹配HTML,下面这个例子可以匹配嵌套的标签： ]&gt;[^&lt;&gt;](((?’Open’]&gt;)[^&lt;&gt;])+((?’-Open’)[^&lt;&gt;])+)(?(Open)(?!)). 13. 未详细讨论的语法 代码/语法 说明 \\a 报警字符(打印它的效果是电脑嘀一声) \\b 通常是单词分界位置，但如果在字符类里使用代表退格 \\t 制表符，Tab \\r 回车 \\v 竖向制表符 \\f 换页符 \\n 换行符 \\e Escape \\0nn ASCII代码中八进制代码为nn的字符 \\xnn ASCII代码中十六进制代码为nn的字符 \\unnnn Unicode代码中十六进制代码为nnnn的字符 \\cN ASCII控制字符。比如\\cC代表Ctrl+C \\A 字符串开头(类似^，但不受处理多行选项的影响) \\Z 字符串结尾或行尾(不受处理多行选项的影响) \\z 字符串结尾(类似$，但不受处理多行选项的影响) \\G 当前搜索的开头 \\p{name} Unicode中命名为name的字符类，例如\\p{IsGreek} (?&gt;exp) 贪婪子表达式 (?\\-exp) 平衡组 (?im-nsx:exp) 在子表达式exp中改变处理选项 (?im-nsx) 为表达式后面的部分改变处理选项 (?(exp)yes\\ no) 把exp当作零宽正向先行断言，如果在这个位置能匹配，使用yes作为此组的表达式；否则使用no (?(exp)yes) 同上，只是使用空表达式作为no (?(name)yes\\ no) 如果命名为name的组捕获到了内容，使用yes作为表达式；否则使用no (?(name)yes) 同上，只是使用空表达式作为no 14. 常用正则表达式说明：正则表达式通常用于两种任务：1.验证，2.搜索/替换。用于验证时，通常需要在前后分别加上^和$，以匹配整个待验证字符串；搜索/替换时是否加上此限定则根据搜索的要求而定，此外，也有可能要在前后加上\\b而不是^和$。此表所列的常用正则表达式，除个别外均未在前后加上任何限定，请根据需要，自行处理。 说明 正则表达式 网址（URL） [a-zA-z]+://[^\\s]* IP地址(IP Address) ((2[0-4]\\d 25[0-5] [01]?\\d\\d?).){3}(2[0-4]\\d 25[0-5] [01]?\\d\\d?) 电子邮件(Email) \\w+([-+.]\\w+)@\\w+([-.]\\w+).\\w+([-.]\\w+)* QQ号码 [1-9]\\d{4,} HTML标记(包含内容或自闭合) &lt;(.)(.)&gt;.*&lt;\\/\\1&gt; &lt;(.*) \\/&gt; 密码(由数字/大写字母/小写字母/标点符号组成，四种都必有，8位以上) (?=^.{8,}$)(?=.\\d)(?=.\\W+)(?=.[A-Z])(?=.[a-z])(?!.\\n).$ 日期(年-月-日) (\\d{4} \\d{2})-((1[0-2]) (0?[1-9]))-(([12][0-9]) (3[01]) (0?[1-9])) 日期(月/日/年) ((1[0-2]) (0?[1-9]))/(([12][0-9]) (3[01]) (0?[1-9]))/(\\d{4} \\d{2}) 时间(小时:分钟, 24小时制) ((1 0?)[0-9] 2[0-3]):([0-5][0-9]) 汉字(字符) [\\u4e00-\\u9fa5] 中文及全角标点符号(字符) [\\u3000-\\u301e\\ufe10-\\ufe19\\ufe30-\\ufe44\\ufe50-\\ufe6b\\uff01-\\uffee] 中国大陆固定电话号码 (\\d{4}- \\d{3}-)?(\\d{8} \\d{7}) 中国大陆手机号码 1\\d{10} 中国大陆邮政编码 [1-9]\\d{5} 中国大陆身份证号(15位或18位) \\d{15}(\\d\\d[0-9xX])? 非负整数(正整数或零) \\d+ 正整数 [0-9][1-9][0-9] 负整数 -[0-9][1-9][0-9] 整数 -?\\d+ 小数 (-?\\d+)(.\\d+)? 不包含abc的单词 \\b((?!abc)\\w)+\\b 说明:该文章参考正则表达式教程","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"RegExp","slug":"RegExp","permalink":"http://arvin-he.github.io/tags/RegExp/"}]},{"title":"C/C++之const关键字","slug":"cpp-const-keyword-2017-03-29","date":"2017-03-29T06:34:05.000Z","updated":"2017-09-08T03:51:39.296Z","comments":true,"path":"2017/03/29/cpp-const-keyword-2017-03-29/","link":"","permalink":"http://arvin-he.github.io/2017/03/29/cpp-const-keyword-2017-03-29/","excerpt":"","text":"1. C中的const关键字const是C语言中保留的一个关键字，它用来限定一个变量是只读的.注意:在C语言中，用const修饰的变量必须在声明时进行初始化(用来修饰函数的形参除外).123456const int n; //这种声明方式是错误的const int n=5; //正确void fun(const int n); //正确const char a; //错误char * const p; //错误const char *p; //正确(注意这种为什么是正确的),因为这里const是修饰p指向的变量,而不是指针变量p本身 注意: 一旦一个变量被const修饰后，在程序中除初始化外对这个变量进行的赋值都是错误的。总结: 在C语言中用const去修饰一个变量，表示这个变量是只读的，不可通过显式的调用a去修改a的值，并且此时a仍然是一个变 量，不能等同于常量; 要注意const在声明变量时所处的位置，位置不同，在意义上可能会有很大的不同。如果const在’‘左边，则表示指针指向的变量的值不可变;如果const在’‘右边，则表示指针的值是不可变的; 2. C++中的关键字const修饰符把对象转变成常数对象，即用const进行修饰的变量的值在程序的任意位置将不能再被修改，就如同常数一样使用！任何修改该变量的尝试都会导致编译错误.注意：常量在定以后就不能被修改，所以定义时必须初始化.对于类中的const成员变量则必须通过初始化列表进行初始化1234567891011121314class A&#123;public: A(int i); const int &amp;r;private: const int a; static const int b;&#125;;const int A::b=10;A::A(int i):a(i), r(a)&#123;&#125; const对象作用域在全局作用域里定义非const变量时，它在整个程序中都可以访问，我们可以把一个非const变量定义在一个文件中，假设已经做了合适的声明，就可以在另外的文件中使用这个变量：123456// file1.cppint count;// file2.cppextern int count;++count; 在全局作用域声明的const变量是定义该const变量的文件的局部变量。此const变量只存在于那个文件中，不能被其他文件访问。通过指定const变量为extern，就可以在整个程序中访问const对象。1234567//file1.cppextern const int count = 10; //定义的时候就要指定extern,假如在整个程序中访问的话//file2.cppextern const int count;for (int index=0; index!=count; ++index)&#123;...&#125; 注意:非const变量默认为extern。要使const变量能够在其他文件中访问，必须在文件中显式指定它为extern。 const引用const引用是指向const对象的引用123const int count = 1024;const int &amp;refCount = count; //两者均为const对象int &amp;ref2 = count; //错误!不能用非const引用指向const对象 const 引用可以初始化为不同类型的对象或者初始化为右值。如字面值常量：1234int i = 10;//仅对const引用合法const int &amp;j = 10;const int &amp;k = j + i; 同样的初始化对于非const引用却是不合法的，而且会导致编译时错误。其原因非常微妙，值得解释一下。观察将引用绑定到不同的类型时所发生的事情，最容易理解上述行为12345int a = 5;const int &amp;b = a; //不合法编译器会做如下转换:int temp = a;const int &amp;b = temp; 注意：引用在内部存放的是一个对象的地址，它是该对象的别名。对于不可寻址的值，如文字常量，以及不同类型的对象，编译器为了实现引用，必须生成一个临时对象，引用实际上指向该对象，但用户不能访问它.如果b不是const,修改b的同时也修改了temp,但不是a,而期望修改b的同时修改了a的程序员会发现a没有被修改,这会造成bug.所以仅允许const引用绑定到需要临时使用的值完全避免了这个问题，直接告诉程序员不能修改，因为const引用是只读的.(其实就是避免程序员心理预期产生反差)注意：非const引用只能绑定到与该引用相同类型的对象。 const引用则可以绑定到不同但相关的类型的对象或绑定到右值。 const对象的动态数组如果在自由存储区中创建的数组存储了内置类型的const对象，则必须为这个数组提供初始化： 因为数组元素都是const对象，无法赋值。实现这个要求的唯一方法是对数组做值初始化.12const int *pci = new const int[100]; // errorconst int *pci_ok = new const int[100](); //OK C++允许定义类类型的const数组，但该类类型必须提供默认构造函数：12// 这里便会调用string类的默认构造函数初始化数组元素const string *pcs = new string[100] 指针和const限定符的关系指针常量:即指针本身的值是不可改变的，而指针指向的变量的值是可以改变的; 常量指针:即指针指向的变量的值是不可改变的，而指针本身的值是可以改变的; 可以这样理解:因为指针本身也是一个变量，只不过指针存放的是地址而已，而一旦指针变成了常量，即指针本身的值是不可变的，此时指针只能指向固定的存储单元;指针一般会指向一个变量，如果该变量成为一个常量，那么该变量的值就不能被修改，即常量指针，指针指向的是一个不可变的变量。 函数和const限定符的关系 类中的const成员函数（常量成员函数）在一个类中，任何不会修改数据成员的函数都应该声明为const类型。如果在编写const成员函数时，不慎修改了数据成员，或者调用了其它非const成员函数，编译器将指出错误，这无疑会提高程序的健壮性。使用const关键字进行说明的成员函数，称为常成员函数。只有常成员函数才有资格操作常量或常对象，没有使用const关键字说明的成员函数不能用来操作常对象。常成员函数说明格式如下： &lt;类型说明符&gt; &lt;函数名&gt; (&lt;参数表&gt;) const;其中，const是加在函数生明后面的类型修饰符，它是函数类型的一个组成部分，因此，在函数实现部分也要带const关键字。下面举一例子说明常成员函数的特征。1234567891011121314151617class Stack&#123;private: int m_num; int m_date[100];public: void Push(int elem); int Pop(void); int GetCount() const; //定义为const函数&#125;;int Stack::GetCount() const&#123; ++m_num; // error 编译错误,企图修改数据成员m_num Pop(); // error 编译错误,企图调用非const函数 return m_num;&#125; 既然const是定义为const函数的组成部分，那么就可以通过添加const实现函数重载.1234567891011121314151617181920212223242526272829303132333435class R&#123;public: R(int r1, int r2) &#123; R1 = r1; R2 = r2; &#125; void print(); void print() const;private: int R1, R2;&#125;;void R::print()&#123; cout&lt;&lt;R1;&#125;void R::print() const&#123; cout&lt;&lt;R2;&#125;void main()&#123; R a(5, 4); a.print(); const R b(20, 52); b.print(); //const对象默认调用const成员函数&#125;552 const 修饰函数返回值const修饰函数返回值其实用的并不是很多，它的含义和const修饰普通变量以及指针的含义基本相同.1234567const int func1(); //这个其实无意义,函数返回本身就是作为右值赋值.// 调用时 const int *pValue = func2();//func2可以看作一个变量,即指针内容不可变const int *func2(); // 调用时 const int *pValue = func3();//func3可以看作一个变量,即指针本身不可变int* const func3(); 一般情况下，函数的返回值为某个对象时，如果将其声明为const时，多用于操作符的重载。通常不建议用const修饰函数的返回值类型为某个对象或对某个对象引用的情况。原因如下：如果返回值为某个对象为const（const A test = A 实例）或某个对象的引用为const（const A&amp; test = A实例） ，则返回值具有const属性，则返回实例只能访问类A中的公有（保护）数据成员和const成员函数，并且不允许对其进行赋值操作，这在一般情况下很少用到。 const修饰函数参数 123456789101112//传递过来的参数在函数内不可以改变(无意义，因为Var本身就是形参)void func(const int var);//参数指针所指内容为常量不可变void func2(const char* var);// 参数指针本身为常量不可变(也无意义，因为char* Var也是形参)void func3(char* const var);//参数为引用，为了增加效率同时防止修改。修饰引用参数时：void func4(const Class&amp; var); //引用参数在函数内不可以改变void func5(const TYPE&amp; Var); //引用参数在函数内为常量不可变 这样的一个const引用传递和最普通的函数按值传递的效果是一模一样的,他禁止对引用的对象的一切修改,唯一不同的是按值传递会先建立一个类对象的副本, 然后传递过去,而它直接传递地址,所以这种传递比按值传递更有效.另外只有引用的const传递可以传递一个临时对象,因为临时对象都是const属性, 且是不可见的,他短时间存在一个局部域中,所以不能使用指针,只有引用的const传递能够捕捉到这个家伙. const限定符和static的区别 const定义的常量在超出其作用域之后其空间会被释放，而static定义的静态常量在函数执行后不会释放其存储空间。 static表示的是静态的。类的静态成员函数、静态成员变量是和类相关的，而不是和类的具体对象相关的。即使没有具体对象，也能调用类的静态成员函数和成员变量。一般类的静态函数几乎就是一个全局函数，只不过它的作用域限于包含它的文件中。 在C++中，static静态成员变量不能在类的内部初始化。在类的内部只是声明，定义必须在类定义体的外部，通常在类的实现文件中初始化，如：double Account::Rate=2.25; static关键字只能用于类定义体内部的声明中，定义时不能标示为static 在C++中，const成员变量也不能在类定义处初始化，只能通过构造函数初始化列表进行，并且必须有构造函数。 const数据成员,只在某个对象生存期内是常量，而对于整个类而言却是可变的。因为类可以创建多个对象，不同的对象其const数据成员的值可以不同。所以不能在类的声明中初始化const数据成员，因为类的对象没被创建时，编译器不知道const数据成员的值是什么。 const数据成员的初始化只能在类的构造函数的初始化列表中进行。要想建立在整个类中都恒定的常量，应该用类中的枚举常量来实现，或者static const。 const成员函数主要目的是防止成员函数修改对象的内容。即const成员函数不能修改成员变量的值，但可以访问成员变量。当方法成员函数时，该函数只能是const成员函数。 static成员函数主要目的是作为类作用域的全局函数。不能访问类的非静态数据成员。类的静态成员函数没有this指针，这导致：1、不能直接存取类的非静态成员变量，调用非静态成员函数2、不能被声明为virtual 关于static、const、static cosnt、const static成员的初始化问题 类里的const成员初始化在一个类里建立一个const时，不能给他初值 123456789101112class foo&#123;public: foo():i(100)&#123;&#125;private: const int i=100; //error!!! 不能在类中初始化&#125;;//或者通过这样的方式初始化foo::foo():i(100)&#123;&#125; 类里的static成员初始化：类中的static变量是属于类的，不属于某个对象，它在整个程序的运行过程中只有一个副本，因此不能在定义对象时 对变量进行初始化，就是不能用构造函数进行初始化，其正确的初始化方法是：数据类型 类名::静态数据成员名=值 123456789class foo&#123;public: foo():i(100)&#123;&#125;private: static int i;&#125;;int foo::i=20; 初始化在类体外进行,且前面不佳static,以免与一般静态变量或对象混淆 初始化时不加该成员的访问权限控制符 初始化时使用作用域操作符表明所属的类 类里的static cosnt 和 const static成员初始化（这两种写法是一致的！！） 123456789class Test&#123;public: static const int mask1; const static int mask2;&#125;;const Test::mask1 = 0xffff;const Test::mask2 = 0xffff; 它们初始化没有区别,虽然一个是静态常量一个是常量静态 静态都将存储在全局变量区域,其实最后结果都一样 可能不同编译器处理不同,但最后结果都一样 例子:1234567891011121314151617181920212223242526272829303132#include &lt;iostream&gt;using namespace std;class A&#123;public: A(int a); static void print(); //静态成员函数private: static int aa; //静态数据成员的声明 static const int count; //常量静态数据成员(可以在构造函数中初始化) const int bb; //常量数据成员&#125;;int A::aa=0; //静态成员定义+初始化const int A::count=25; //静态常量成员定义+初始化A::A(int a):bb(a) //常量成员的初始化&#123; aa+=1;&#125;void A::print()&#123; cout&lt;&lt;\"count=\"&lt;&lt;count&lt;&lt;endl; cout&lt;&lt;\"aa=\"&lt;&lt;aa&lt;&lt;endl;&#125;void main()&#123; A a(10); A::print(); //通过类访问静态成员函数 a.print(); //通过对象访问静态成员函数&#125; const的难点如果函数需要传入一个指针，面试官可能会问是否需要为该指针加上const，把const加在指针不同的位置有什么区别；如果写的函数需要传入的参数是一个复杂类型的实例，面试官可能会问传入值参数或者引用参数有什么区别，什么时候需要为传入的引用参数加上const。 const是用来声明一个常量的，当你不想让一个值被改变时就用const，const int max和int const max 是没有区别的，都可以。不涉及到指针const很好理解。一旦涉及到指针，则比较容易出问题。12345int b = 100;const int *a = &amp;b; //[1]int const *a = &amp;b; //[2]int* const a = &amp;b; //[3]const int* const a = &amp;b; //[4] 如果const位于星号的左侧，则const就是用来修饰指针所指向的变量，即指针指向的对象为常量；如果const位于星号的右侧，const就是修饰指针本身，即指针本身是常量。 因此，[1]和[2]的情况相同，都是指针所指向的内容为常量（const放在变量声明符的位置无关），这种情况下不允许对内容进行更改操作，如不能*a = 3 ；[3]为指针本身是常量，而指针所指向的内容不是常量，这种情况下不能对指针本身进行更改操作，如a++是错误的；[4]为指针本身和指向的内容均为常量。 参考: C++中的const关键字 浅谈C和C++中的const关键字","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"C/C++","slug":"C-C","permalink":"http://arvin-he.github.io/tags/C-C/"}]},{"title":"C++知识积累","slug":"cpp-keywords-2017-03-28","date":"2017-03-28T08:17:26.000Z","updated":"2017-09-08T03:51:39.311Z","comments":true,"path":"2017/03/28/cpp-keywords-2017-03-28/","link":"","permalink":"http://arvin-he.github.io/2017/03/28/cpp-keywords-2017-03-28/","excerpt":"","text":"1. 宏函数在Ｃ/C++语言中允许用一个标识符来表示一个字符串，称为宏，该字符串可以是常数、表达式、格式串等。在编译预处理时，对程序中所有出现的“宏名”，都用宏定义中的字符串去替换，这称为“宏替换”或“宏展开”。宏定义是由源程序中的宏定义命令完成的。宏替换是由预处理程序自动完成的。若字符串是表达式，则称之为函数式宏定义.普通函数式宏定义：MAX(a,b) { return a&gt;b?a:b;} 几个比较经典的宏函数1.12345678#define TO_PROG_LEN(mm) ((mm) / (settings.prog_length_units == CANON_UNITS_INCHES ? 25.4 : 1.0)) #define TO_PROG_ANG(deg) (Rad2Deg(deg)) #define CHK(bad, error_code) \\do&#123; \\ if (bad) &#123; return error_code; &#125; \\&#125; while(0) 2. C++禁止对象拷贝复制为什么有的时候需要禁止对象的拷贝复制?在类的设计里，不去实现拷贝构造和赋值操作不就完了吗？其实不行！C++会在背后偷偷的帮你现实一个默认的拷贝构造的版本，必须注意这个后门。 如何禁止对象的拷贝复制123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051class CPeople &#123; // ... private: // 将复制相关的操作定义为私有 CPeople()&#123;...&#125;; const CPeople&amp; operator=(const CPeople&amp; rhis)&#123;...&#125; &#125;; ``` 这样的设计，可以部分的禁止的类的复制，但是对于友元函数和类成员函数来说，还是可以调用其相关的复制操作的。```cppclass CPeople &#123; // ... private: // 将复制相关的操作定义为私有 CPeople(); // 只声明不实现 const CPeople&amp; operator=(const CPeople&amp; rhis); // 只声明不实现 &#125;; ``` 将拷贝构造函数与赋值函数，声明为private，并且不给出实现。这样就实现了类复制的完全禁止用户代码中的复制尝试将在编译时标记为错误，而成员函数与友元函数中的复制尝试将在链接时出现错误。上面介绍的这种技术在你熟悉的std::iostream类中已经得到了很好的应用，诸如ios_base、basic_ios和sentry，都采用这样的方式不允许复制操作。Boost为我们提供了另一种解决方式，这种方式更加完美，因为它可以将链接错误提前到编译时，毕竟早一点发现错误比晚发现要好。特意声明一个不可复制的类```cppboost::noncopyable#ifndef BOOST_NONCOPYABLE_HPP_INCLUDED #define BOOST_NONCOPYABLE_HPP_INCLUDED namespace boost &#123; // Private copy constructor and copy assignment ensure classes derived from // class noncopyable cannot be copied. // Contributed by Dave Abrahams namespace noncopyable_ // protection from unintended ADL &#123; class noncopyable &#123; protected: noncopyable() &#123;&#125; ~noncopyable() &#123;&#125; private: // emphasize the following members are private noncopyable( const noncopyable&amp; ); const noncopyable&amp; operator=( const noncopyable&amp; ); &#125;; &#125; typedef noncopyable_::noncopyable noncopyable; &#125; // namespace boost #endif // BOOST_NONCOPYABLE_HPP_INCLUDED 为了禁止拷贝对象，我们只需要让其私有继承自boost::noncopyable 1234class student:private boost::noncopyable&#123;......&#125; 当调用到派生类的拷贝构造函数或赋值函数进行复制时，不可避免的要调用基类对应的函数，因为这些操作是private，这样的操作会被编译器拒绝。需要注意，多重继承有时会使空基类noncopyable优化失效，所以这不适合用于多重继承的情形。 另外，如果只是不想要使用默认的拷贝构造函数或赋值函数，可以使用C++11提供的delete，C++11则使用delete关键字显式指示编译器不生成函数的默认版本。比如： 12345678class MyClass&#123;public:MyClass()=default;MyClass(const MyClass&amp; )=delete;......&#125; 当然，一旦函数被delete过了，那么重载该函数也是非法的，该函数我们习惯上称为删除函数。 3. C++虚析构函数什么情况下声明为虚析构函数并不是要把所有类的析构函数都写成虚函数。因为当类里面有虚函数的时候，编译器会给类添加一个虚函数表，里面来存放虚函数指针，这样就会增加类的存储空间。所以，只有当一个类被用来作为基类的时候，才把析构函数写成虚函数。 为什么基类的析构函数要声明成虚析构函数在实现多态时，当用基类操作派生类，在析构时防止只析构基类而不析构派生类的状况发生。直接的讲，C++中基类采用virtual虚析构函数是为了防止内存泄漏。具体地说，如果派生类中申请了内存空间，并在其析构函数中对这些内存空间进行释放。假设基类中采用的是非虚析构函数，当删除基类指针指向的派生类对象时就不会触发动态绑定，因而只会调用基类的析构函数，而不会调用派生类的析构函数。那么在这种情况下，派生类中申请的空间就得不到释放从而产生内存泄漏。所以，为了防止这种情况的发生，C++中基类的析构函数应采用virtual虚析构函数。 为什么派生类中定义了析构函数来释放其申请的资源，但是并没有得到调用。原因是基类指针指向了派生类对象，而基类中的析构函数却是非virtual的，而虚函数是动态绑定的基础。现在析构函数不是virtual的，因此不会发生动态绑定，而是静态绑定，指针的静态类型为基类指针，因此在delete时候只会调用基类的析构函数，而不会调用派生类的析构函数。这样，在派生类中申请的资源就不会得到释放，就会造成内存泄漏，这是相当危险的：如果系统中有大量的派生类对象被这样创建和销毁，就会有内存不断的泄漏，久而久之，系统就会因为缺少内存而崩溃。也就是说，在基类的析构函数为非虚析构函数的时候，并不一定会造成内存泄漏；当派生类对象的析构函数中有内存需要收回，并且在编程过程中采用了基类指针指向派生类对象，如为了实现多态，并且通过基类指针将该对象销毁，这时，就会因为基类的析构函数为非虚析构函数而不触发动态绑定，从而没有调用派生类的析构函数而导致内存泄漏。因此，为了防止这种情况下内存泄漏的发生，最好将基类的析构函数写成virtual虚析构函数。 4. C/C++中的#if defined() 和 #ifdef的区别 使用#ifdef如果使用#ifdef,则后面的内容不能加括号.If you use #ifdef syntax, remove the brackets. #if defined() 和 #ifdef的区别 #ifdef只能使用单个条件, #if defined(NAME)则可以组合多个条件The difference between the two is that #ifdef can only use a single condition,while #if defined(NAME) can do compound conditionals. 123456789#ifndef __EXPORT_H__#define __EXPORT_H__#if (defined WIN32 || defined _WIN32 || defined WINCE) &amp;&amp; defined INTERPRETER_LIBRARY# define INTERP_API __declspec(dllexport)#else# define INTERP_API#endif#endif // __EXPORT_H__ 5. C++之throwvoid myfunc(void)throw();这样的函数声明只是告诉此函数的使用者说，我不会抛出异常，方便调用者捕捉异常。而至于实现不实现异常捕获是你自己的事。函数是给别人用的，不是给自己用的。 6. 其他1239. 指针10. 函数指针11. 回调函数","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"C/C++","slug":"C-C","permalink":"http://arvin-he.github.io/tags/C-C/"}]},{"title":"C++之static关键字","slug":"cpp-keywords-2017-03-27","date":"2017-03-27T11:32:11.000Z","updated":"2017-09-08T03:51:39.308Z","comments":true,"path":"2017/03/27/cpp-keywords-2017-03-27/","link":"","permalink":"http://arvin-he.github.io/2017/03/27/cpp-keywords-2017-03-27/","excerpt":"","text":"1. static关键字C语言代码是以文件为单位来组织的，在一个源程序的所有源文件中，一个外部变量（注意不是局部变量）或者函数只能在一个源程序中定义一次，如果有重复定义的话编译器就会报错。伴随着不同源文件变量和函数之间的相互引用以及相互独立的关系，产生了extern和static关键字。 1.1 C中的static一个进程在内存中的布局如下表所示: |栈区 ||堆栈增长区||堆区 ||其他段 ||.bss段 ||.data段 ||.text段 | 其中.text段保存进程所执行的程序二进制文件，.data段保存进程所有的已初始化的全局变量，.bss段保存进程未初始化的全局变量。在进程的整个生命周期中，.data段和.bss段内的数据时跟整个进程同生共死的，也就是在进程结束之后这些数据内存才会被释放。 当一个进程的全局变量被声明为static之后，它的中文名叫静态全局变量。静态全局变量和其他的全局变量的存储地点并没有区别，都是在.data段（已初始化）或者.bss段（未初始化）内，但是它只在定义它的源文件内有效，其他源文件无法访问它。所以，普通全局变量加上static关键字修饰后,就只能被定义它的源文件中的变量或函数访问。 static局部变量 普通的局部变量在栈空间上分配，这个局部变量所在的函数被多次调用时，每次调用这个局部变量在栈上的位置都不一定相同。局部变量也可以在堆上动态分配，但是记得使用完这个堆空间后要释放之。 static局部变量中文名叫静态局部变量。它与普通的局部变量比起来有如下几个区别： 位置：静态局部变量被编译器放在全局存储区.data（注意：不在.bss段内，原因见3）），所以它虽然是局部的，但是在程序的整个生命周期中存在。 访问权限：静态局部变量只能被其作用域内的变量或函数访问。也就是说虽然它会在程序的整个生命周期中存在，由于它是static的，它不能被其他的函数和源文件访问。 值：静态局部变量如果没有被用户初始化，则会被编译器自动赋值为0，以后每次调用静态局部变量的时候都用上次调用后的值。这个比较好理解，每次函数调用静态局部变量的时候都修改它然后离开，下次读的时候从全局存储区读出的静态局部变量就是上次修改后的值。 static函数相信大家还记得C++面向对象编程中的private函数，私有函数只有该类的成员变量或成员函数可以访问。在C语言中，也有“private函数”，它就是接下来要说的static函数，完成面向对象编程中private函数的功能。 当你的程序中有很多个源文件的时候，你肯定会让某个源文件只提供一些外界需要的接口，其他的函数可能是为了实现这些接口而编写，这些其他的函数你可能并不希望被外界（非本源文件）所看到，这时候就可以用static修饰这些“其他的函数”.所以static函数的作用域是本源文件，把它想象为面向对象中的private函数就可以了。 1.2 类中的static关键字面向对象的static关键字 1.2.1 静态数据成员在类内数据成员的声明前加上关键字static，该数据成员就是类内的静态数据成员。先举一个静态数据成员的例子。 1234567891011121314151617181920212223242526272829303132333435//头文件#include &lt;iostream.h&gt;class Myclass&#123;public: Myclass(int a,int b,int c); void GetSum();private: int a,b,c; static int Sum;//声明静态数据成员&#125;;int Myclass::Sum=0;//定义并初始化静态数据成员//源文件Myclass::Myclass(int a,int b,int c)&#123; this-&gt;a=a; this-&gt;b=b; this-&gt;c=c; Sum+=a+b+c;&#125;void Myclass::GetSum()&#123; cout&lt;&lt;\"Sum=\"&lt;&lt;Sum&lt;&lt;endl;&#125;void main()&#123; Myclass M(1,2,3); M.GetSum(); Myclass N(4,5,6); N.GetSum(); M.GetSum();&#125; 可以看出，静态数据成员有以下特点： 对于非静态数据成员，每个类对象都有自己的拷贝。而静态数据成员被当作是类的成员,是类本身的一部分。无论这个类的对象被定义了多少个，静态数据成员在程序中也只有一份拷贝，被该类型的所有对象共享访问。也就是说，静态数据成员是该类的所有对象所共有的。对该类的多个对象来说，静态数据成员只分配一次内存，供所有对象共用。所以，静态数据成员的值对每个对象都是一样的，它的值可以更新. 静态数据成员存储在全局数据区。静态数据成员定义时要分配空间，所以不能在类的声明中定义。上例语句int Myclass::Sum=0;是定义静态数据成员,注意:这条语句是在整个类声明之外的,即static数据成员是类内声明，类外定义,static成员不通过类构造函数初始化，而是在定义时进行初始化.一个例外：初始化式为常量表达式，整型static const 数据成员（static const int） 可以在类的定义体内进行初始化. 静态数据成员和普通数据成员一样遵从public,protected,private访问规则. 因为静态数据成员在全局数据区分配内存，属于本类的所有对象共享，所以，它不属于特定的类对象，在没有产生类对象时其作用域就可见，即在没有产生类的实例时，我们就可以操作访问它. 静态数据成员初始化与一般数据成员初始化不同。静态数据成员初始化的格式为：＜数据类型＞＜类名＞::＜静态数据成员名＞=＜值＞ 类的静态数据成员有两种访问形式：＜类对象名＞.＜静态数据成员名＞ 或 ＜类类型名＞::＜静态数据成员名＞如果静态数据成员的访问权限允许的话（即public的成员），可在程序中，按上述格式来引用静态数据成员 ； 静态数据成员主要应用在各个对象都有相同的某项属性的时候.比如对于一个存款类，每个实例的利息都是相同的。所以，应该把利息设为存款类的静态数据成员。这有两个好处:第一，不管定义多少个存款类对象，利息数据成员都共享分配在全局数据区的内存，所以节省存储空间。第二，一旦利息需要改变时，只要改变一次，则所有存款类对象的利息全改变过来了； 同全局变量相比，使用静态数据成员有两个优势： 静态数据成员没有进入程序的全局名字空间，因此不存在与程序中其它全局名字冲突的可能性 可以实现信息隐藏。静态数据成员可以是private成员，而全局变量不能,不破坏类的封装 1.2.2 静态成员函数与静态数据成员一样，我们也可以创建一个静态成员函数，它为类的全部服务而不是为某一个类的具体对象服务。静态成员函数与静态数据成员一样，都是类的内部实现，属于类定义的一部分。普通的成员函数一般都隐含了一个this指针，this指针指向类的对象本身，因为普通成员函数总是具体的属于某个类的具体对象的。通常情况下，this是缺省的。如函数fn()实际上是this-&gt;fn()。但是与普通函数相比，静态成员函数由于不是与任何的对象相联系，因此它不具有this指针。从这个意义上讲，它无法访问属于类对象的非静态数据成员，也无法访问非静态成员函数，它只能调用其余的静态成员函数。下面举个静态成员函数的例子。 123456789101112131415161718192021222324252627282930313233343536//头文件#include &lt;iostream.h&gt;class Myclass&#123;public: Myclass(int a,int b,int c); static void GetSum(); //声明静态成员函数private: int a,b,c; static int Sum; //声明静态数据成员&#125;;int Myclass::Sum=0; //定义并初始化静态数据成员//源文件Myclass::Myclass(int a,int b,int c)&#123; this-&gt;a=a; this-&gt;b=b; this-&gt;c=c; Sum+=a+b+c; //非静态成员函数可以访问静态数据成员&#125;void Myclass::GetSum() //静态成员函数的实现&#123; // cout&lt;&lt;a&lt;&lt;endl; //错误代码，a是非静态数据成员 cout&lt;&lt;\"Sum=\"&lt;&lt;Sum&lt;&lt;endl;&#125;void main()&#123; Myclass M(1,2,3); M.GetSum(); Myclass N(4,5,6); N.GetSum(); Myclass::GetSum();&#125; 关于类的静态成员函数，可以总结为以下几点： 出现在类体外的函数定义不能指定关键字static； 静态成员之间可以相互访问，包括静态成员函数访问静态数据成员和访问静态成员函数； 非静态成员函数可以任意地访问静态成员函数和静态数据成员； 静态成员函数不能访问非静态成员函数和非静态数据成员； 由于没有this指针的额外开销，因此静态成员函数与类的全局函数相比速度上会有少许的增长； 调用静态成员函数，可以用成员访问操作符(.)和(-&gt;)为一个类的对象或指向类对象的指针调用静态成员函数，也可以直接使用如下格式：＜类名＞::＜静态成员函数名＞（＜参数表＞）调用类的静态成员函数。 成员函数声明为const说明该成员函数不会修改该成员函数所属的对象，所以static成员函数不能声明为const。static成员通过作用域操作符（直接调用）、对象、引用、指向该类类型对象的指针（间接调用） 12345678910111213class Person&#123; static double getHeight(); static const age = 30; string school;&#125;;Person xiaoming;Person *someone = &amp;xiaoming;double height;height = Person::getHeight(); //static成员通过作用域操作符（直接调用）height = xiaoming.getHeight(); //static成员通过对象（间接调用）height = someone-&gt;getHeight(); //static成员通过指向该类类型对象的指针（间接调用） static数据成员定义： 一般情况下，static数据成员是类内声明，类外定义; static成员不通过类构造函数初始化，而是在定义时进行初始化； 一个例外：初始化式为常量表达式，整型static const 数据成员（static const int） 可以在类的定义体内进行初始化：值得注意的是：const static数据成员在类的定义体中出始化时，该数据成员仍必须在类的定义体外定义，只是不再指定初始值：const int Person::age;常实型 static const数据成员不可在类内初始化。一个好的解决方法是使用宏定义： #define age 30常整型静态数据成员可以在类中直接初始化，而常实型静态数据成员不可以 123456789class circle&#123;int a; // 普通变量，不能在类中初始化static int b; // 静态变量，不能在类中初始化static const int c=2; // 静态常整型变量，可以在类中初始化static const double PI=3.1416;//error C2864: //只有静态常量整型数据成员才可以在类中初始化&#125; ;const int cicle::c ; //const static数据成员在类的定义体中出始化时，该数据成员仍必须在类的定义体外定义，只是不再指定初始值 b可以在类外进行初始化，且所有对象共享一个b的值：int circle::b = 2;double circle::PI = 3.1416; 知乎问答:static函数在头文件中定义有什么好处么？ 没有好处，不要这么做。除非该头文件只会被一个翻译单元（translation unit）所使用，那么static是可用作表示内部链接（internal linkage）。不过这种头文件和一般所指的头文件不同，通常会使用.inc文件后缀. 为了内联. 一般定义成static inline.隐患: 头文件中的 static 函数会在每个文件中生成一份代码，这造成代码冗余倒不是最大的问题，最大的问题是可能带来库文件与工程文件同一函数的代码的不一致性，这有风险。 参考文章 参考文章","categories":[{"name":"编程","slug":"编程","permalink":"http://arvin-he.github.io/categories/编程/"}],"tags":[{"name":"C/C++","slug":"C-C","permalink":"http://arvin-he.github.io/tags/C-C/"}]},{"title":"Windows下工具使用和技巧","slug":"tool-skill-2017-03-25","date":"2017-03-25T00:52:12.000Z","updated":"2017-09-11T00:42:30.071Z","comments":true,"path":"2017/03/25/tool-skill-2017-03-25/","link":"","permalink":"http://arvin-he.github.io/2017/03/25/tool-skill-2017-03-25/","excerpt":"","text":"1. cmder简介cmder是windows下一款很好用的命令行工具,支持绝大部分linux命令,自带git和vim. 1.1 解决cmder中文乱码问题win+alt+p打开设置面板，找到Startup-Envrioment选项在下面的文本框里添加一行 set LANG=zh_CN.UTF-8然后重启cmder 1.2 解决文字重叠问题Win + Alt + P 打开设置界面在mian &gt; font &gt; monospce 的勾去掉. 1.3 设置cmder分屏显示设置快捷键打开设置面板选择keys &amp; Macro,或者右击标题栏,在help中的Hotkeys中做如下设置找到Split: spliter Duplicate active “shell” to right:split,并选中在下面设置快捷键,如ctrl+Alt+1保存设置,然后重启. 1.4 cmder目录cmder不要放在c:/program files目录下,因为当你修改cmder设置,然后要保存设置时无法保存,因为往c:/program files写设置信息需要管理员权限,所以cmder还是放在C盘根目录下,或者其他盘的目录下. 2. 通过命令行追加环境变量例如添加C:\\phantomjs1SETX PATH &quot;%PATH%;C:\\\\phantomjs&quot; /M 如果写成下面的形式,则通过窗口查看机器的环境变量时会发现已经用C:\\phantomjs覆盖以前所有的环境变量,之前的环境变量全部没了.1SETX PATH C:\\\\phantomjs /M 注意:重启才能生效,只要当前还没有关机或者重启机器,则之前的环境变量还是能够在命令行中显示,覆盖的环境变量还没有生效,我们将之前的环境变量导入到文件中再拷贝回去就好了,然后重启机器生效. 3. windows下临时导入环境变量在windwos下添加环境变量后,不会立刻生效,必须要重启电脑后才能生效.有的时候不想重启电脑或者不能重启电脑该如何做呢?例如:在windows下安装了MingW编译器,想要使用gcc方法1: 切换到gcc.exe所在的目录下,直接调用gcc方法2: 临时导入环境变量: set PATH=C:\\MinGW\\bin;%PATH% 4. 关于每个文件夹下都有一个文件夹的快捷方式的问题这是Skypee快捷方式病毒(AutoIt3木马).杀毒软件和安全卫士都弄不干净的. 显示隐藏文件，找到病毒进入“文件夹选项”界面。点击“查看”，把“隐藏受保护的操作系统文件（推荐）”前面的勾去掉。选择 “显示隐藏的文件、文件夹和驱动器”。在everything中输入”AutoIt3.exe”,搜索出所有的AutoIt3.exe并删除 删除开机启动项打开“任务管理器”，点击“启动”，禁用AutoIt3.exe之类的，病毒还可能伪装成GoogleUpda、WindowsUpdate神马的，右键“属性”可以看到启动项实际位置，把C:\\Google下的都删了。 清理注册表Win+R，再输入regedit，打开注册表编辑器。搜索“C:\\Google”，把相关结果删除即可。注意：在注册器编辑表中，【数据】的选项框如果存在AutoIt之类的字样也一定要将词条注册表数据删除 删除病毒及其创建的快捷方式我们这里用批处理的方式快速删除。将以下内容保存为Skypee（AutoIt3木马）专杀工具.bat，复制到各个盘中，双击运行即可。先打开 记事本,复制以下的内容到记事本中。123456789101112131415@echo offtitle 快捷方式病毒专杀echo ------ 查找中 ...attrib -a -s -h -r skypeedel /f /s /q skypeeecho -----Skypee 已删除本盘的毒源------echo.ping -t -n 1 127.0.0.1&gt;nulecho -----清除此盘一级目录下的病毒快捷方式------for /f &quot;tokens=*&quot; %%i in (&apos;dir /ad /b *&apos;) do (del /f /s /q &quot;%%i\\%%i.lnk&quot;)echo -----清除结束 ^-^------ping -t -n 3 127.0.0.1&gt;nulexit 另存为到 你所中招的盘中，文件名就写上：Skypee（AutoIt3木马）专杀工具.bat，文件类型选择：所有保存文件后，复制到所需盘双击运行Skypee（AutoIt3木马）专杀工具.bat即可删除该盘中的Skypee（AutoIt3木马）的源头和它所生成的快捷方式的了。 你哪个分区有，就把这个 Skypee（AutoIt3木马）专杀工具.bat 复制到那个盘中运行就可以了。","categories":[{"name":"工具","slug":"工具","permalink":"http://arvin-he.github.io/categories/工具/"}],"tags":[{"name":"Tools","slug":"Tools","permalink":"http://arvin-he.github.io/tags/Tools/"}]},{"title":"Markdown使用","slug":"markdown-tutorial-2017-03-24","date":"2017-03-24T14:14:53.000Z","updated":"2017-09-08T03:51:39.788Z","comments":true,"path":"2017/03/24/markdown-tutorial-2017-03-24/","link":"","permalink":"http://arvin-he.github.io/2017/03/24/markdown-tutorial-2017-03-24/","excerpt":"","text":"1. 标题 使用 # 表示标题，一级标题使用一个 # ，二级标题使用两个 ## ，以此类推，共有六级标题。 使用 ===== 表示高阶标题，使用 ——- 表示次阶标题。1234# 这是一级标题========## 这是二级标题-------------- 注意: ==== 和 —- 表示标题时，大于等于2个都可以表示。 ===和—数目任意,但是至少要大于等于3个 不同的markdown编辑器对===和—支持不同,有的支持有的不支持,根据具体的编辑器而定. 2. 目录使用 [TOC] 生成目录。如一开始的目录所示。1[TOC] 注意: 如果你的标题都是按照Markdown语法书写的话，可以自动生成层级目录。 [TOC] 标记可能只能放在一级标题的前面，视不同的编译器而定。 3. 引用使用 &gt; 表示引用， &gt;&gt; 表示引用里面再套一层引用，依次类推。示例:例1：123&gt; 这是一级引用&gt;&gt; 这是二级引用&gt;&gt;&gt; 这是三级引用 这是一级引用 这是二级引用 这是三级引用 注意: 如果 &gt; 和 &gt;&gt; 嵌套使用的话，从 &gt;&gt; 退到 &gt; 时，必须之间要加一个空格或者 &gt; 作为过渡，否则默认为下一行和上一行是同一级别的引用。最好都加空格. 引用标记里可以使用其他标记，如：有序列表或无序列表标记，代码标记等。 4.代码引用 引用的代码语句只有一段,不分行,可以用 ` 将语句包起来. 引用的代码语句为多行,可以将```置于这段代码的首行和末行. 行内代码用``表示,即在文字行中插入代码. 例如:这是python code代码 5. 列表使用 1. 2. 3. 表示有序列表，使用 * 或 - 或 + 表示无序列表. 无序列表或有序列表标记和后面的文字之间要有一个空格隔开. 有序列表标记不是按照你写的数字进行显示的，而是根据当前有序列表标记所在位置显示的. 无序列表的项目符号是按照实心圆、空心圆、实心方格的层级关系递进的,通常情况下，同一层级使用同一种标记.便于自己查看和管理. 层级缩进,下一层级要比上一层级缩进4空格，否则仍然表示同一层级. hello hello hello 6. 粗体和斜体使用 * 或者 __ 表示粗体.使用 或者 表示斜体.注意:前后的 * 或 与要 加粗或倾斜的字体之间不能有空格. 7. 表格语法格式:123|head1|head2|head3||:----|:----:|-----:||content1|content2|content3| 其中: ——: 为右对齐:—— 为左对齐:——: 为居中对齐——- 为使用默认居中对齐 head可有可无 表格中含所有|字符,使用转义字符没有效果,使用ASCII字符集| 的ASCII 字符集为:124,在markdown下的格式”&#124;”,引号内的内容 每个Markdown解析器都不一样，可能左右居中对齐方式的表示方式不一样 8. 首行缩进 不断行的空白格&nbsp;或&#160;(半个英文空格) 半方大的空白&ensp;或&#8194;(一个英文空格) 全方大的空白&emsp;或&#8195;(两个英文空格)hello&nbsp;hello&ensp;hello&emsp;hello注意:Markdown语法会忽略首行开头的空格，如果要体现出首行开头空两个的效果，可以使用全角符号下的空格 ，windows下使用 shift+空格 切换。 9. 分割线使用 — 或者 ** 或者 表示水平分割线注意: 只要 * 或者 - 大于等于三个就可组成一条平行线。 使用 — 作为水平分割线时，要在它的前后都空一行，防止 — 被当成标题标记的表示方式。 10. 插入图片 使用! [Alt text] (/path/to/img.jpg “Optional title”) 导入图片.其中： Alt text 为如果图片无法显示时显示的文字； /path/to/img.jpg 为图片所在路径； Optional title 为显示标题.显示效果为在你将鼠标放到图片上后,会显示一个小框提示，提示的内容就是 Optional title 里的内容。注意:!和[]以及()之间的连接处不能有空格 参考式图片1234![][1][1]: http://upload-images.jianshu.io/upload_images/259-0ad0d0bfc1c608b6.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240注意: ![][1]之间不能有空格,引用的链接不能和![][1]相连接,要隔行. 11. 插入链接使用 [] (link “Optional title”) 表示行内链接.注意: []和()之间不能有空格 [] 内的内容为要添加链接的文字。 link 为链接地址。 Optional title 为显示标题。显示效果为在你将鼠标放到链接上后，会显示一个小框提示，提示的内容就是 Optional title 里的内容 行内链接这就是我们常用的地址：Baidu 1[Baidu](www.baidu.com &quot;百度一下，你就知道&quot; ) 参考式链接这就是我们常用的地址：Baidu 123[Baidu][1][1]:www.baidu.com &quot;百度一下，你就知道&quot; 注意: 参考式链接和行内链接的效果是一样的，各有利弊。 行内连接清晰易懂，可以清楚的知道链接的地址，但是不便于多次利用。 参考式链接可以重复使用，但不能即刻知道链接的地址。 12.下划线和删除线 使用 ~~ 表示删除线。示例:1~~这是一条删除线~~ 这是一条删除线注意: ~~ 和 要添加删除线的文字之间不能有空格。 下划线 &lt;u&gt;Underlined Text&lt;/u&gt; Underlined Text &lt;span style=&quot;border-bottom:2px dashed yellow;&quot;&gt;所添加下划线的行内文字&lt;/span&gt; 所添加下划线的行内文字 13. 反斜杠使用 \\ 表示反斜杠,这是一个转义字符,在你不想显示Markdown标记时可以使用反斜杠. 14. 标签和分类使用 标签: 或者 Tags: 表示标签标记.12标签: 数学 英语Tags: 数学 英语 标签: 数学 英语Tags: 数学 英语注意:标签: 或者 Tags: 的冒号要使用半角冒号,即英文冒号。 15. 注脚使用 [^footer] 表示注脚.123这是一个注脚测试[^footer1][^footer1]: 这是一个测试，用来阐释注脚。 这是一个注脚测试^footer1 注意:在需要解释一个名词，或者一本书，或者一个人时使用脚注标记。 16. 页内跳转使用html代码实现页内跳转。在要跳转到的位置定义个锚 hehe ，然后使用 你好将 你好 设置为一单击即跳转到 hehe 所在位置的效果。12[你好](#jump)&lt;span id = &quot;jump&quot;&gt;hehe&lt;/span&gt; 你好hehe","categories":[{"name":"工具","slug":"工具","permalink":"http://arvin-he.github.io/categories/工具/"}],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"http://arvin-he.github.io/tags/Markdown/"}]},{"title":"GitBook使用","slug":"gitbook-tutorial-2017-03-22","date":"2017-03-22T06:48:37.000Z","updated":"2017-09-08T03:51:39.488Z","comments":true,"path":"2017/03/22/gitbook-tutorial-2017-03-22/","link":"","permalink":"http://arvin-he.github.io/2017/03/22/gitbook-tutorial-2017-03-22/","excerpt":"","text":"1. 安装gitbook 安装nodejs和npm 安装gitbook命令行, npm install -g gitbook-cli 查看gitbook是否安装, gitbook -V, 没有安装的话就会自动安装gitbook 安装phantomjs-1.9.7方法:windows下:网上下载phantomjs-1.9.7-windows版本,解压缩,并设置环境变量.Linux下:1.从github上clone一份代码,phantomjs的github网址,2.进入这个clone下的仓库,查看发布的版本信息,git tag3.检出phantom1.9.7版本,git checkout 1.9.74.将这个目录放到C盘根目录下,并设置环境变量12345$ cd phantomjs$ git checkout 1.9.7 #注意：这里的1.9.7是phantom的版本号，可以由错误报告的第一行找出 $ ./build.sh --jobs 4$ sudo cp bin/phantomjs /bin/$ sudo npm install gitbook-pdf -g #重新进行安装 注意:因为gitbook-pdf依赖这个,直接安装gitbook-pdf会报下面的错.123456789101112131415161718192021Error: connect ETIMEDOUT at exports._errnoException (util.js:746:11) at TCPConnectWrap.afterConnect [as oncomplete] (net.js:1010:19)npm ERR! Linux 3.2.0-4-686-paenpm ERR! argv &quot;/usr/local/bin/node&quot; &quot;/usr/local/bin/npm&quot; &quot;install&quot; &quot;gitbook-pdf&quot; &quot;-g&quot;npm ERR! node v0.12.7npm ERR! npm v2.11.3npm ERR! code ELIFECYCLEnpm ERR! phantomjs@1.9.7-5 install: `node install.js`npm ERR! Exit status 1npm ERR! npm ERR! Failed at the phantomjs@1.9.7-5 install script &apos;node install.js&apos;.npm ERR! This is most likely a problem with the phantomjs package,npm ERR! not with npm itself.npm ERR! Tell the author that this fails on your system:npm ERR! node install.jsnpm ERR! You can get their info via:npm ERR! npm owner ls phantomjsnpm ERR! There is likely additional logging output above.npm ERR! Please include the following file with any support request:npm ERR! /home/wangxq/repository/phantomjs/npm-debug.log 安装gitbook生成PDF模块, npm install gitbook-pdf -g 如果开始安装gitbook-pdf失败后,在安装了phantomjs之后需要重新安装npm install gitbook-pdf -g 2. 使用gitbook2.1 README.md 与 SUMMARY.md创建和编写README.md 这个文件相当于一本Gitbook的简介。SUMMARY.md 这个文件是一本书的目录结构，使用Markdown语法12$ mkdir mybook$ vim SUMMARY.md 输入 简介 第一章 第一节 第二节 第二章 第一节 第二节 结束 2.2 生成图书目录结构 1gitbook init 2.3 本地图书预览1gitbook serve . 然后浏览器中输入 http://localhost:4000 就可以预览生成的以网页形式组织的书籍。在你的图书项目的目录中多了一个名为_book的文件目录，而这个目录中的文件，即是生成的静态网站内容。 2.4 指定图书生成目录使用build参数生成到指定目录,与直接预览生成的静态网站文件不一样的是，使用这个命令，你可以将内容输入到你所想要的目录中去：12$ mkdir /tmp/gitbook$ gitbook build --output=/tmp/gitbook 3. 生成PDF注意:转pdf时需要calibre的ebook-convert组件支持,不然会保存,转换失败.解决办法:下载calibre,有windows和linux版的,安装好后,添加环境变量,再重执行gitbook pdf .,新生成pdf在你的图书的目录中执行下面命令生成PDF.1gitbook pdf . 补充：生成的pdf可以用calibre转成你想要的设备尺寸. 4. 生成epub和mobi与电子书12gitbook epub .gitbook mobi .","categories":[{"name":"工具","slug":"工具","permalink":"http://arvin-he.github.io/categories/工具/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://arvin-he.github.io/tags/Git/"}]},{"title":"Maupassant-hexo主题使用","slug":"hexo-maupassant-2017-03-21","date":"2017-03-21T13:36:58.000Z","updated":"2017-09-08T03:51:39.495Z","comments":true,"path":"2017/03/21/hexo-maupassant-2017-03-21/","link":"","permalink":"http://arvin-he.github.io/2017/03/21/hexo-maupassant-2017-03-21/","excerpt":"","text":"1. maupassant主题简介Maupassant最初是由Cho为Typecho平台设计开发的一套响应式模板，体积只有20KB，在各种尺寸的设备上表现出色。主题地址 2. maupassant主题安装12345cd &apos;hexo博客目录&apos;git clone https://github.com/tufu9441/maupassant-hexo.git themes/maupassantnpm install hexo-renderer-jade --save // 渲染器npm install hexo-renderer-sass --savenpm install hexo-generator-feed --save // rss支持 3. 修改配置文件 Hexo中_config.yml配置文件修改有两处 language: zh-CN theme: maupassantmaupassant已经支持简体中文,以前用next主题时,language: zh-Hans maupassant主题下的_config.yml配置文件修改12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970fancybox: true ## 是否启用Fancybox图片灯箱效果duoshuo: ## 多说评论disqus: ## Disqus评论uyan: ## 友言评论gentie: ## 网易云跟帖google_search: false ## google搜索baidu_search: ## 百度搜索swiftype: ## swifttypekey站内搜索tinysou: ## 微搜索self_search: true ## 使用本地搜索google_analytics: ## Google Analytics 跟踪ID baidu_analytics: ## 百度统计 跟踪ID show_category_count: true ## 是否显示侧边栏分类数目shareto: true ## 是否使用分享按钮busuanzi: true ## 是否使用卜算子页面访问计数widgets_on_small_screens: false ## 是否在移动设备屏幕底部显示侧边栏menu: - page: home directory: . icon: fa-home - page: archive directory: archives/ icon: fa-archive - page: about directory: about/ icon: fa-user - page: commonweal directory: 404.html icon: fa-heartbeat # - page: rss # directory: atom.xml # icon: fa-rss# 选择和排列希望使用的侧边栏小工具widgets: ## Six widgets in sidebar provided: search, category, tag, recent_posts, rencent_comments and links. - search - category - tag - recent_posts - recent_comments - links# 友情链接，请依照格式填写。links: # - title: site-name1 # url: http://www.example1.com/ # - title: site-name2 # url: http://www.example2.com/ # - title: site-name3 # url: http://www.example3.com/timeline: - num: 1 word: 2014/06/12-Start - num: 2 word: 2014/11/29-XXX - num: 3 word: 2015/02/18-DDD - num: 4 word: More# Static files# 静态文件存储路径，方便设置CDN缓存js: jscss: css# Theme version# 主题版本，便于静态文件更新后刷新CDN缓存version: 0.0.0 4. 生成部署1234hexo cleanhexo ghexo shexo d 5. 更换Maupassant遇到的问题5.1 安装好并设置好相应配置文件后,执行hexo clean出现错误ERROR Plugin load failed: hexo-renderer-sassError: %1 is not a valid Win32 application.原因: hexo-renderer-sass没有安装好解决办法: 将node_modules文件夹删除,重新安装hexo和Maupassant的依赖,执行npm install注意:执行npm install之前请检查下package.json下的依赖模块是否遗漏,下面是我的package.json.12345678910111213141516171819202122232425&#123; &quot;name&quot;: &quot;hexo-site&quot;, &quot;version&quot;: &quot;0.0.0&quot;, &quot;private&quot;: true, &quot;hexo&quot;: &#123; &quot;version&quot;: &quot;3.2.2&quot; &#125;, &quot;dependencies&quot;: &#123; &quot;hexo&quot;: &quot;^3.2.2&quot;, &quot;hexo-deployer-git&quot;: &quot;^0.2.0&quot;, &quot;hexo-generator-archive&quot;: &quot;^0.1.4&quot;, &quot;hexo-generator-category&quot;: &quot;^0.1.3&quot;, &quot;hexo-generator-feed&quot;: &quot;^1.2.0&quot;, &quot;hexo-generator-index&quot;: &quot;^0.2.0&quot;, &quot;hexo-generator-json-content&quot;: &quot;^3.0.1&quot;, &quot;hexo-generator-search&quot;: &quot;^1.0.4&quot;, &quot;hexo-generator-tag&quot;: &quot;^0.2.0&quot;, &quot;hexo-renderer-ejs&quot;: &quot;^0.2.0&quot;, &quot;hexo-renderer-jade&quot;: &quot;^0.3.0&quot;, &quot;hexo-renderer-marked&quot;: &quot;^0.2.10&quot;, &quot;hexo-renderer-sass&quot;: &quot;^0.3.1&quot;, &quot;hexo-renderer-stylus&quot;: &quot;^0.3.1&quot;, &quot;hexo-server&quot;: &quot;^0.2.0&quot; &#125;&#125; 5.2 本地运行hexo s出现页面布局错乱原因:hexo-renderer-sass没有安装好,虽然页面能显示,但是总是错乱.出现这种情况是因为之前使用的主题是next主题,虽然配置文件都修改好,在安装hexo-renderer-sass依赖时出了点问题,在hexo-renderer-sass需要python2.7,而我安装的是python3,安装python2.7,并重新安装hexo-renderer-sass.如果还有问题就删除node_modules文件夹,重新安装吧.解决办法: 重新安装hexo-renderer-sass 5.3 设置本地搜索Maupassant默认使用google搜索,如果要使用本地搜索需要做两件事: 安装依赖模块:hexo-generator-search 12cd &apos;hexo博客目录&apos;npm install -g hexo-generator-search --save 修改Maupassant主题的配置文件将默认的google搜索设置为false,将本地搜索设置true 12345google_search: false ## google搜索baidu_search: ## 百度搜索swiftype: ## swifttypekey站内搜索tinysou: ## 微搜索self_search: true ## 使用本地搜索","categories":[{"name":"工具","slug":"工具","permalink":"http://arvin-he.github.io/categories/工具/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://arvin-he.github.io/tags/Hexo/"}]},{"title":"Next-hexo主题使用","slug":"hexo-next-2017-03-20","date":"2017-03-19T23:56:44.000Z","updated":"2017-09-08T03:51:39.497Z","comments":true,"path":"2017/03/20/hexo-next-2017-03-20/","link":"","permalink":"http://arvin-he.github.io/2017/03/20/hexo-next-2017-03-20/","excerpt":"","text":"1. next主题简介Next主题是我比较喜欢的主题之一,也是一开始使用的主题,风格简约. 2. 下载next主题12$ cd &apos;hexo目录&apos;$ git clone https://github.com/iissnan/hexo-theme-next themes/next 3. next主题配置注意: 在Hexo中的根目录下有一个_config.yml配置文件,而next主题中source目录下也有一个_config.yml配置文件.Hexo根目录的配置文件是配置hexo本身的配置,next主题下的配置则由主题作者提供，主要用于配置主题相关的选项.hexo-next官方配置教程","categories":[{"name":"工具","slug":"工具","permalink":"http://arvin-he.github.io/categories/工具/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://arvin-he.github.io/tags/Hexo/"}]},{"title":"Hexo搭建github博客","slug":"hexo-tutorial-2017-03-12","date":"2017-03-12T07:26:36.000Z","updated":"2017-09-08T03:51:39.501Z","comments":true,"path":"2017/03/12/hexo-tutorial-2017-03-12/","link":"","permalink":"http://arvin-he.github.io/2017/03/12/hexo-tutorial-2017-03-12/","excerpt":"","text":"1. 安装Hexo及依赖1.1 准备条件 安装git 有github帐号,并有仓库username.github.io 本地机器保存github的帐号和密码 1.2 安装hexo 安装nodejs 安装hexo, npm install -g hexo, 或者 npm install hexo-cli -g这里hexo需要全局安装,因为在终端要用到hexo命令,至于hexo的依赖就不需要全局安装了,在所在的项目目录下安装即可. 1.3 安装hexo依赖在hexo的根目录下有一个package.json文件,里面是hexo需要的依赖.依赖需要一个一个安装好.如果要添加其他模块的依赖,比如增加本地搜索功能时,需要安装hexo-generator-search模块,则使用命令:1npm install hexo-generator-search --save 在hexo根目录下node_modules文件夹下就会安装hexo-generator-search模块,并在package.json中写入对应的hexo-generator-search依赖条目.下面是我的package.json文件所用到的hexo依赖.1234567891011121314151617181920212223242526&#123; &quot;name&quot;: &quot;hexo-site&quot;, &quot;version&quot;: &quot;0.0.0&quot;, &quot;private&quot;: true, &quot;hexo&quot;: &#123; &quot;version&quot;: &quot;3.2.2&quot; &#125;, &quot;dependencies&quot;: &#123; &quot;hexo&quot;: &quot;^3.3.7&quot;, &quot;hexo-asset-image&quot;: &quot;git+https://github.com/CodeFalling/hexo-asset-image.git&quot;, &quot;hexo-deployer-git&quot;: &quot;^0.2.0&quot;, &quot;hexo-generator-archive&quot;: &quot;^0.1.4&quot;, &quot;hexo-generator-category&quot;: &quot;^0.1.3&quot;, &quot;hexo-generator-feed&quot;: &quot;^1.2.0&quot;, &quot;hexo-generator-index&quot;: &quot;^0.2.1&quot;, &quot;hexo-generator-json-content&quot;: &quot;^3.0.1&quot;, &quot;hexo-generator-search&quot;: &quot;^1.0.4&quot;, &quot;hexo-generator-tag&quot;: &quot;^0.2.0&quot;, &quot;hexo-renderer-ejs&quot;: &quot;^0.2.0&quot;, &quot;hexo-renderer-jade&quot;: &quot;^0.3.0&quot;, &quot;hexo-renderer-marked&quot;: &quot;^0.2.11&quot;, &quot;hexo-renderer-sass&quot;: &quot;^0.3.2&quot;, &quot;hexo-renderer-stylus&quot;: &quot;^0.3.3&quot;, &quot;hexo-server&quot;: &quot;^0.2.1&quot; &#125;&#125; 注意: 这些依赖不是全部必须的,根据你个人喜好和所需的功能以及不同主题的不同依赖所决定的,一开始hexo只安装基本的依赖.例如你安装了hexo-next主题,可查看hexo-next官方配置教程. 2. 配置Hexo在Hexo中的根目录下有一个_config.yml配置文件,根据你需要的功能进行配置.下面我指列出了常见的配置,没有列出的都是默认配置.1234567891011121314151617181920title: &quot;你的站点名&quot; #站点名，站点左上角subtitle: &quot;你站点的副标题&quot;description: &quot;你站点的描述&quot; #给搜索引擎看的，对站点的描述，可以自定义author: &quot;站点作者&quot;language: &quot;语言&quot; # 注意:不同的主题支持的语言配置会不一样,请注意你所选主题支持的语言.如next支持中文语言的配置是zh-Hans,不是zh-CN,当然后期也可能支持.url: http://username.github.io # 如果你用到站内搜索,需要配置一下你的url, 否则搜索正常但页面跳转不出来.tag_dir: tags # 你的标签目录,不打开则点击标签时没反应archive_dir: archives # 你的归档目录category_dir: categories # 你的分类目录per_page: 10 # 配置你一页显示文章数目,默认是10篇# 设置站内检索功能search: path: search.xml field: alltheme: next # 主题设置,根据你所选主题,在这里设置你的主题,没配置的话,就是空白也# 部署deploy: type: git repository: https://github.com/username/username.github.io.git # 根据你的github帐号的usename来替换 branch: master 3. 常用的功能配置3.1 设置Tags(标签)页面注意: Tags目录不会自动生成,需要你先配置再手动生成.12345$ cd &quot;hexo目录&quot;$ hexo new page tags # 会在source/tags/目录下生成index.md$ vim source/tags/index.md 在你的文章的开头即front-matter中添加一项:type: &quot;tags&quot; 也就是首先要确认站点配置文件里有tag_dir: tags这个配置选项打开,然后确认你所选主题配置文件里有tags: /tags这个配置选项打开(假如你选择next主题的话) 使用hexo new命令新建文章则会自动生成标签目录 在你的文章的开头即front-matter中添加一项type: “tags”,添加如下:12345---title: 你的题目tags: 你的标签category: 你的分类--- 多个标签的设置方式一：仿照Hexo配置文件中的写法tags: Hexo HTML JavaScript 方式二：伪JavaScript数组写法tags: [Hexo,HTML,JavaScript] 3.2 设置categories(分类)页面12345$ cd &quot;hexo目录&quot;$ hexo new page categories # 会在source/categories/目录下生成index.md$ vim source/categories/index.md在你的文章的开头即front-matter中添加一项:type: &quot;categories&quot; 也就是首先要确认站点配置文件里有category_dir: categories这个配置选项打开,然后确认你所选主题配置文件里有category_dir: /category_dir这个配置选项打开(假如你选择next主题的话) 使用hexo new命令新建文章则会自动生成分类目录 在你的文章的开头即front-matter中添加一项type: “categories”,添加如下:12345---title: 你的题目tags: 你的标签category: 你的分类--- 多个分类设置方式一：仿照Hexo配置文件中的写法categories: Hexo HTML JavaScript 方式二：伪JavaScript数组写法categories: [Hexo,HTML,JavaScript] 3.3 设置about页面12$ cd path/to/hexo$ hexo new page &quot;about&quot; # 会在source/about/目录下生成index.md 然后在souce/about/index.md中写入你想表达的内容. 3.4 设置索引目录里的图片因为索引设置为提取文档前150个字符，所以想在索引目录中插入图片，就在文章开头插入图片即可。 3.5 文章摘要首页默认显示文章摘要而非全文，可以在文章的front-matter中填写一项description:来设置你想显示的摘要，或者直接在文章内容中插入&lt;!–more–&gt;以隐藏后面的内容。1&lt;!--More--&gt; 若两者都未设置，则自动截取文章第一段作为摘要。然后重新生成部署,就会看到折叠效果了. 3.6 使用hexo站内搜索 安装 hexo-generator-search，在站点的根目录下执行以下命令： 1$ npm install hexo-generator-search --save 站点配置文件_config.yml配置注意:在站点下的_config.yml配置,不是主题里的_config.yml. 123search: path: search.xml field: all 主题_config.yml配置本地搜索设置为true,否则界面上不会显示搜索按钮 123# Local searchlocal_search: enable: true 3.7 在文章中插入本地图片 配置hexo下的_config.yml中post_asset_folder: true 安装CodeFalling/hexo-asset-image的插件来加载本地图片,插件地址 1npm install https://github.com/CodeFalling/hexo-asset-image --save 插入图片注意:当设置post_asset_folder为true参数后，在Hexo new newfile时会自动建立一个与文章同名的文件夹，可以把与该文章相关的所有资源都放到那个文件夹，如此一来，便可以方便的管理使用资源。 4. 使用hexo新建一个目录如:’hexo目录’cd ‘hexo目录’hexo init //文件夹自动生成建网站所需的文件npm install //在文件夹下安装node_modules,即安装依赖hexo g //生成静态文件hexo s //本地运行hexo d //部署到github上去 5. hexo使用5.1 hexo命令详解hexo inithexo new “postName” #新建文章hexo new draft “postName” #新建草稿文章hexo new page “pageName” #新建页面hexo clean #清除生成的静态文件hexo generate #生成静态页面至public目录hexo server #开启预览访问端口(默认端口4000，’ctrl + c’关闭server)hexo deploy #将.deploy目录部署到GitHubhexo help # 查看帮助hexo version #查看Hexo的版本hexo deploy -g #生成加部署hexo server -g #生成加预览hexo server –draft #本地预览包括草稿文件常用命令的简写hexo n == hexo newhexo g == hexo generatehexo s == hexo serverhexo d == hexo deploy常用组合hexo d -g #生成部署hexo s -g #生成预览 5.2 hexo使用流程一般用hexo new &lt;article&gt;来新建一篇文章, 这样新建的一篇文章是放在source/_post目录下的, 然后使用hexo g指令编译markldown文件, 将编译的HTML结果放在public目下, 之后hexo d,命令将public目录下的所有文档部署到github上去.但有时写了多篇文章,但是只有一篇文章需要发布,其他文章没有完成. 我们并不希望未完成的文章也发布出去, 这时就需要hexo的draft机制. 5.2.1 新建草稿使用hexo new draft &lt;article&gt; 命令新建一个草稿, 新建的文章放在source/_drafts目录下, hexo g 和 hexo d命令不会编译部署source/_drafts目录下的文章. 5.2.2 本机预览草稿使用hexo server --draft命令, 其中Hexo的Hexo server另外提供--draft参数，同时搭配hexo-browsersync plugins，就可以实现一边使用文本编辑器编辑markdown文章，一边使用浏览器预览文章。 5.2.3 将草稿发布为正式文章使用hexo publish &lt;filename&gt;命令, 该命令只是将文章从source/_drafts目录移到source/_posts目录下而已。之后的hexo generate与hexo deploy的用法还是完全一样的。注意:若日后想將正式文章反悔成为草稿，只需手动將文章从source/_posts目录移动到source/_drafts目录即可。 6. 搭建hexo过程中遇到的问题6.1 hexo无法上传到github, 但在本地localhost:4000是可以打开的On branch masternothing to commit, working directory cleanbash: /dev/tty: No such device or addresserror: failed to execute prompt script (exit code 1)fatal: could not read Username for ‘https://github.com‘: No errorFATAL Something’s wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.htmlError: bash: /dev/tty: No such device or addresserror: failed to execute prompt script (exit code 1)fatal: could not read Username for ‘https://github.com‘: No error原因:本地没有保存github用户名和密码,因为hexo d,是直接将生成的静态文件部署到github上去,一步到位的,意思就是部署的时候就要能拿到github的用户名和密码,如果拿不到就报错,部署不上去.注意: 使用的是https协议,因为当没有在本地保存你的github帐号的用户名和密码时,使用https协议push内容到github上去时就要每次手动输入github帐号上用户名和密码.而hexo d部署是一步到位的,中间没有机会让你输入你的github账户用户名和密码.解决办法: 使用https协议时,本地保存你的github账户的用户名和密码deploy:type: gitrepository: https://github.com/yourusername/yourusername.github.io.gitbranch: master 使用ssh协议,本地生成ssh key,并将公匙放到你的github上deploy:type: gitrepository: ssh://git@github.com/yourusername/yourusername.github.io.gitbranch: master 6.2 hexo部署失败 ERROR Deployer not found: git原因: 缺少nodejs的依赖解决办法: 在’hexo目录’的目录下执行 npm install hexo-deployer-git –save 6.3 Error: fatal: Not a git repository (or any of the parent directories): .gitFATAL Something’s wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.htmlError: fatal: Not a git repository (or any of the parent directories): .git at ChildProcess. (F:\\blogs\\node_modules\\hexo-util\\lib\\spawn.js:37:17) at emitTwo (events.js:106:13) at ChildProcess.emit (events.js:194:7) at ChildProcess.cp.emit (F:\\blogs\\node_modules\\cross-spawn\\lib\\enoent.js:40:29) at maybeClose (internal/child_process.js:899:16) at Socket. (internal/child_process.js:342:11) at emitOne (events.js:96:13) at Socket.emit (events.js:191:7) at Pipe._handle.close [as _onclose] (net.js:513:12)FATAL fatal: Not a git repository (or any of the parent directories): .gitError: fatal: Not a git repository (or any of the parent directories): .git at ChildProcess. (F:\\blogs\\node_modules\\hexo-util\\lib\\spawn.js:37:17) at emitTwo (events.js:106:13) at ChildProcess.emit (events.js:194:7) at ChildProcess.cp.emit (F:\\blogs\\node_modules\\cross-spawn\\lib\\enoent.js:40:29) at maybeClose (internal/child_process.js:899:16) at Socket. (internal/child_process.js:342:11) at emitOne (events.js:96:13) at Socket.emit (events.js:191:7) at Pipe._handle.close [as _onclose] (net.js:513:12)解决办法: 删除.deploy_git/ 文件夹,然后再次,hexo deploy, 就好了. 6.4 ERROR Local hexo not found in F:\\username.github.ioHexo搭建博客之后用Git已经将所有的source都同步到了git上，在另一台电脑上将源代码clone下来之后，直接执行hexo g,出现错误.$ hexo g&lt;ERROR Local hexo not foundERROR Try running: ‘npm install hexo –save’原因: 在另外一台机器上clone下来的内容,缺少hexo的依赖,因为在.gitignore里忽略将node_nodules文件夹push到github上去.就是hexo所依赖的nodejs的模块,所以用npm重新安装即可.解决办法:cd ‘hexo目录’npm installhexo g 6.5 执行hexo g或hexo本地测试运行重启后页面空白,提示 : WARN No layout: index.html此时页面都是白的，使用hexo clean 然后从新Generated再次运行还是空白原因: 在themes/文件夹的next主题是空的,因为在我的github上的next主题是作为submodule,是引用别人的仓库,在clone到一台新的机器上时并没有clone到本地来,如果你没有通过submodule引用别人的仓库,就不会出现这个问题.解决办法:cd ‘hexo目录’git submodule initgit submodule update注意: 克隆含有子模块的项目:克隆一个含有子模块的项目。 当你在克隆这样的项目时，默认会包含该子模块目录，但其中还没有任何文件.你必须运行两个命令：git submodule init 用来初始化本地配置文件，而 git submodule update 则从该项目中抓取所有数据并检出父项目中列出的合适的提交。 6.6 部署到github上去后发现没有更新,还是上次的页面解决办法: 删除.deploy_git/文件夹 hexo clean //清除上次生成的静态文件 hexo g //重新生成静态文件 hexo d //部署到github上去 6.7 点击”标签”和”分类”没有跳出标签和分类原因:Tags和Category需要手动生成,即需要输入命令生成.方法:生成Tags和categories123456789$ cd path/to/hexo$ hexo new page tags # 会在source/tags/目录下生成index.md$ hexo new page categories # 会在source/categories/目录下生成index.md$ vim source/tags/index.md 在date下面一行输入: type: &quot;tags&quot;$ vim source/categories/index.md在date下面一行输入: type: &quot;categories&quot; 6.8 关于404页面在本地正常显示,在Github上不显示问题原因:Github Pages强制要求https，所以文档内对js和css的请求都需要经过https传输的才行，而腾讯的404公益页面使用的默认为http.其中search_children.js主要提取了data.js及page.js两个文件，前者是寻找儿童的数据，在Github中没问题,后者中默认都是用http加载的js和css，所以不能直接用，故修改为https方式获取js与css，直接将page.js内容加入404.html页面，具体内容详见我的Github上的404页面.知乎上解决办法链接 6.9 hexo使用hexo-generator-search站内搜索问题: 可以搜索。但是搜索的页面跳转不对.原因: 站点下的_config.yml配置文件的url没有配置.解决: 将url设置你github.io的站点的url.123456# URL## If your site is put in a subdirectory, set url as &apos;http://yoursite.com/child&apos; and root as &apos;/child/&apos;url: http://username.github.ioroot: /permalink: :year/:month/:day/:title/permalink_defaults: 7. nodejs版本问题nodejs版本不要太高,最好不用最新版本,最新版本会废弃一些API, 如果hexo或者hexo插件里用到了那些废弃的api,这会让你的应用跑不起来.","categories":[{"name":"工具","slug":"工具","permalink":"http://arvin-he.github.io/categories/工具/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://arvin-he.github.io/tags/Hexo/"}]}]}